#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ€ç»ˆä¿®å¤ç›®å½•æ ¼å¼
ç¡®ä¿æ ¼å¼ç»Ÿä¸€ï¼š
- ä¸€çº§å­ä¸»é¢˜ï¼šä¸å¸¦ç‚¹å·ï¼ˆå¦‚ 1 å¼•è¨€ï¼‰
- äºŒçº§å­ä¸»é¢˜ï¼šå¸¦ç‚¹å·ï¼ˆå¦‚ 1.1 æ ¸å¿ƒæ€æƒ³ï¼‰
- ç§»é™¤emojiå’Œå¤šä½™ç©ºæ ¼
"""

import os
import re
from pathlib import Path

def clean_title(title):
    """æ¸…ç†æ ‡é¢˜ï¼Œç§»é™¤emojiå’Œå¤šä½™ç©ºæ ¼"""
    # ç§»é™¤emojiï¼ˆä¿ç•™ä¸­æ–‡å­—ç¬¦ã€æ•°å­—ã€å­—æ¯ã€æ ‡ç‚¹ï¼‰
    title = re.sub(r'[^\w\s\u4e00-\u9fff\-\(\)\[\]ï¼šï¼Œã€‚ã€]', '', title)
    # ç§»é™¤å¤šä½™ç©ºæ ¼
    title = re.sub(r'\s+', ' ', title)
    return title.strip()

def generate_anchor(text):
    """ç”Ÿæˆé”šç‚¹é“¾æ¥"""
    anchor = text.lower()
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™ä¸­æ–‡å­—ç¬¦
    anchor = re.sub(r'[^\w\s\u4e00-\u9fff-]', '', anchor)
    anchor = re.sub(r'\s+', '-', anchor)
    anchor = anchor.strip('-')
    return anchor

def extract_content_headers(content):
    """æå–å†…å®¹ä¸­çš„æ ‡é¢˜"""
    headers = []
    lines = content.split('\n')
    in_toc = False
    skip_patterns = ['ğŸ“‹ ç›®å½•', 'ç›®å½•', 'ç›®å½• | Table of Contents', 'å¯¼èˆª | Navigation', 
                    'ç›¸å…³ä¸»é¢˜ | Related Topics', 'å‚è€ƒæ–‡çŒ®', 'References', 'FAQ', 
                    'Glossary', 'Quick Reference', 'Learning Paths', 'Master Index']
    
    for line in lines:
        # æ£€æµ‹ç›®å½•åŒºåŸŸ
        if '## ğŸ“‹ ç›®å½•' in line or '## ç›®å½•' in line or '## ç›®å½• | Table of Contents' in line:
            in_toc = True
        elif in_toc and line.strip() == '---':
            in_toc = False
            continue
        
        if in_toc:
            continue
        
        # åŒ¹é…æ ‡é¢˜ï¼Œå¦‚ ## 1 å¼•è¨€ æˆ– ### 1.1 æ ¸å¿ƒæ€æƒ³
        # ä¹ŸåŒ¹é…å¸¦emojiçš„æ ‡é¢˜ï¼Œå¦‚ ## 1 ï¸âƒ£ RNN vs Transformer
        match = re.match(r'(#{2,})\s+(\d+(?:\.\d+)*)?\s*([^\d\s].*?)$', line)
        if match:
            level = len(match.group(1))
            number = match.group(2) if match.group(2) else None
            title = match.group(3).strip()
            
            # è·³è¿‡ç‰¹æ®Šæ ‡é¢˜å’Œä¸»æ ‡é¢˜
            if any(pattern in title for pattern in skip_patterns) or level == 1:
                continue
            
            # æ¸…ç†æ ‡é¢˜
            clean_title_text = clean_title(title)
            if clean_title_text:
                headers.append((level, number, clean_title_text, title))
    
    return headers

def normalize_number(number, level, parent_number=None):
    """è§„èŒƒåŒ–ç¼–å·"""
    if not number:
        return None
    
    # ç§»é™¤æ–‡ä»¶å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
    if '.' in number:
        parts = number.split('.')
        # å¦‚æœç¬¬ä¸€éƒ¨åˆ†æ˜¯æ–‡ä»¶ç¼–å·ï¼Œç§»é™¤å®ƒ
        if len(parts) > 1:
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡ä»¶ç¼–å·æ ¼å¼ï¼ˆå¦‚ 2.2.1ï¼‰
            if len(parts) >= 3:
                # å¯èƒ½æ˜¯æ–‡ä»¶ç¼–å·ï¼Œå°è¯•ç§»é™¤
                number = '.'.join(parts[1:])
    
    if level == 2:
        # ä¸€çº§å­ä¸»é¢˜ï¼šä¸å¸¦ç‚¹å·
        if '.' in number:
            return number.split('.')[0]
        return number
    elif level == 3:
        # äºŒçº§å­ä¸»é¢˜ï¼šå¸¦ç‚¹å·
        if parent_number:
            if '.' in number:
                return number
            else:
                return f"{parent_number}.{number}"
        else:
            if '.' in number:
                return number
            else:
                return f"1.{number}"
    return number

def assign_numbers_to_headers(headers):
    """ä¸ºæ ‡é¢˜åˆ†é…æ­£ç¡®çš„ç¼–å·"""
    numbered_headers = []
    current_numbers = {}
    
    for level, number, clean_title, original_title in headers:
        if level == 2:
            # ä¸€çº§å­ä¸»é¢˜
            if level not in current_numbers:
                current_numbers[level] = 1
            else:
                current_numbers[level] += 1
            
            # é‡ç½®æ‰€æœ‰å­çº§ç¼–å·
            for l in range(level + 1, 10):
                if l in current_numbers:
                    del current_numbers[l]
            
            final_number = str(current_numbers[level])
            numbered_headers.append((level, final_number, clean_title, original_title))
            
        elif level == 3:
            # äºŒçº§å­ä¸»é¢˜
            parent_level = level - 1
            if parent_level in current_numbers:
                parent_num = str(current_numbers[parent_level])
            else:
                parent_num = "1"
            
            if level not in current_numbers:
                current_numbers[level] = 1
            else:
                current_numbers[level] += 1
            
            # é‡ç½®æ›´æ·±å±‚çº§
            for l in range(level + 1, 10):
                if l in current_numbers:
                    del current_numbers[l]
            
            final_number = f"{parent_num}.{current_numbers[level]}"
            numbered_headers.append((level, final_number, clean_title, original_title))
        else:
            # æ›´æ·±å±‚çº§ï¼ˆä¸‰çº§åŠä»¥ä¸Šï¼‰
            parent_level = level - 1
            if parent_level in current_numbers:
                parent_num = str(current_numbers[parent_level])
            else:
                parent_num = "1"
            
            if level not in current_numbers:
                current_numbers[level] = 1
            else:
                current_numbers[level] += 1
            
            # é‡ç½®æ›´æ·±å±‚çº§
            for l in range(level + 1, 10):
                if l in current_numbers:
                    del current_numbers[l]
            
            # æ„å»ºå±‚çº§ç¼–å·
            parts = [parent_num]
            for l in range(3, level + 1):
                if l in current_numbers:
                    parts.append(str(current_numbers[l]))
                else:
                    parts.append("1")
            
            final_number = '.'.join(parts)
            numbered_headers.append((level, final_number, clean_title, original_title))
    
    return numbered_headers

def generate_toc(headers):
    """ç”Ÿæˆç›®å½•"""
    numbered_headers = assign_numbers_to_headers(headers)
    
    if not numbered_headers:
        return None
    
    toc_lines = ["## ğŸ“‹ ç›®å½•", ""]
    
    for level, number, clean_title, original_title in numbered_headers:
        indent = "  " * (level - 2)  # level 2 ä¸ç¼©è¿›ï¼Œlevel 3 ç¼©è¿›2ä¸ªç©ºæ ¼
        
        if level == 2:
            # ä¸€çº§å­ä¸»é¢˜ï¼šä¸å¸¦ç‚¹å·
            toc_title = f"{number} {clean_title}"
        else:
            # äºŒçº§åŠä»¥ä¸Šå­ä¸»é¢˜ï¼šå¸¦ç‚¹å·
            toc_title = f"{number} {clean_title}"
        
        anchor = generate_anchor(toc_title)
        toc_lines.append(f"{indent}- [{toc_title}](#{anchor})")
    
    toc_lines.append("")
    toc_lines.append("---")
    toc_lines.append("")
    
    return '\n'.join(toc_lines)

def fix_content_headers(content, headers):
    """ä¿®å¤å†…å®¹ä¸­çš„æ ‡é¢˜ç¼–å·"""
    numbered_headers = assign_numbers_to_headers(headers)
    
    lines = content.split('\n')
    fixed_lines = []
    in_toc = False
    header_index = 0
    
    for line in lines:
        # è·³è¿‡ç›®å½•éƒ¨åˆ†
        if '## ğŸ“‹ ç›®å½•' in line or '## ç›®å½•' in line or '## ç›®å½• | Table of Contents' in line:
            in_toc = True
        elif in_toc and line.strip() == '---':
            in_toc = False
            continue
        
        if in_toc:
            fixed_lines.append(line)
            continue
        
        # åŒ¹é…æ ‡é¢˜ï¼ˆåŒ…æ‹¬å¸¦emojiçš„ï¼‰
        match = re.match(r'(#{2,})\s+(\d+(?:\.\d+)*)?\s*([^\d\s].*?)$', line)
        if match:
            level = len(match.group(1))
            old_number = match.group(2) if match.group(2) else None
            title = match.group(3).strip()
            
            # è·³è¿‡ç‰¹æ®Šæ ‡é¢˜å’Œä¸»æ ‡é¢˜
            skip_patterns = ['ğŸ“‹ ç›®å½•', 'ç›®å½•', 'ç›®å½• | Table of Contents', 'å¯¼èˆª | Navigation', 
                            'ç›¸å…³ä¸»é¢˜ | Related Topics', 'å‚è€ƒæ–‡çŒ®', 'References']
            if any(pattern in title for pattern in skip_patterns) or level == 1:
                fixed_lines.append(line)
                continue
            
            # æ‰¾åˆ°å¯¹åº”çš„ç¼–å·æ ‡é¢˜
            if header_index < len(numbered_headers):
                h_level, h_number, h_clean_title, h_original_title = numbered_headers[header_index]
                # æ¸…ç†æ ‡é¢˜ç”¨äºåŒ¹é…
                clean_title_text = clean_title(title)
                
                if h_level == level and h_clean_title == clean_title_text:
                    # ä½¿ç”¨æ¸…ç†åçš„æ ‡é¢˜
                    new_line = f"{'#' * level} {h_number} {h_clean_title}"
                    fixed_lines.append(new_line)
                    header_index += 1
                else:
                    fixed_lines.append(line)
            else:
                fixed_lines.append(line)
        else:
            fixed_lines.append(line)
    
    return '\n'.join(fixed_lines)

def process_file(filepath):
    """å¤„ç†å•ä¸ªæ–‡ä»¶"""
    print(f"å¤„ç†æ–‡ä»¶: {filepath}")
    
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"  é”™è¯¯ï¼šæ— æ³•è¯»å–æ–‡ä»¶ - {e}")
        return False
    
    # æå–æ ‡é¢˜
    headers = extract_content_headers(content)
    
    if not headers:
        print(f"  è·³è¿‡ï¼šæœªæ‰¾åˆ°æ ‡é¢˜")
        return False
    
    # ä¿®å¤å†…å®¹ä¸­çš„æ ‡é¢˜ç¼–å·
    content = fix_content_headers(content, headers)
    
    # é‡æ–°æå–æ ‡é¢˜ï¼ˆå› ä¸ºå†…å®¹å·²æ›´æ–°ï¼‰
    headers = extract_content_headers(content)
    
    # ç”Ÿæˆæˆ–æ›´æ–°ç›®å½•
    toc = generate_toc(headers)
    
    if not toc:
        print(f"  è·³è¿‡ï¼šæ— æ³•ç”Ÿæˆç›®å½•")
        return False
    
    # æ’å…¥æˆ–æ›¿æ¢ç›®å½•
    lines = content.split('\n')
    
    # æ‰¾åˆ°ç°æœ‰ç›®å½•ä½ç½®å¹¶æ›¿æ¢
    toc_start = -1
    toc_end = -1
    
    for i, line in enumerate(lines):
        if '## ğŸ“‹ ç›®å½•' in line or '## ç›®å½•' in line or '## ç›®å½• | Table of Contents' in line:
            toc_start = i
        elif toc_start >= 0 and line.strip() == '---' and i > toc_start + 2:
            toc_end = i
            break
    
    if toc_start >= 0 and toc_end > toc_start:
        new_lines = lines[:toc_start] + toc.split('\n') + lines[toc_end + 1:]
        content = '\n'.join(new_lines)
    else:
        # å¦‚æœæ‰¾ä¸åˆ°ç›®å½•ï¼Œåœ¨ç¬¬ä¸€ä¸ªæ ‡é¢˜å‰æ’å…¥
        first_header = -1
        for i, line in enumerate(lines):
            if re.match(r'^##\s+\d', line) or (re.match(r'^##\s+[^#]', line) and 'ç›®å½•' not in line):
                first_header = i
                break
        if first_header >= 0:
            new_lines = lines[:first_header] + toc.split('\n') + lines[first_header:]
            content = '\n'.join(new_lines)
        else:
            print(f"  è­¦å‘Šï¼šæ— æ³•æ‰¾åˆ°æ’å…¥ä½ç½®")
            return False
    
    # å†™å›æ–‡ä»¶
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"  å®Œæˆï¼šå·²æ›´æ–°ç›®å½•")
        return True
    except Exception as e:
        print(f"  é”™è¯¯ï¼šæ— æ³•å†™å…¥æ–‡ä»¶ - {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    base_dir = Path(__file__).parent
    
    # æŒ‡å®šè¦å¤„ç†çš„æ–‡ä»¶
    target_files = [
        'Concept/AI_model_Perspective/02_Neural_Network_Theory/02.2_RNN_Transformer_Architecture.md',
        'Concept/AI_model_Perspective/02_Neural_Network_Theory/02.4_Transformer_Architecture.md',
        'Concept/AI_model_Perspective/02_Neural_Network_Theory/02.5_Universal_Approximation_Theorem.md',
        'Concept/AI_model_Perspective/03_Language_Models/03.4_Token_Generation_Mechanisms.md',
        'Concept/AI_model_Perspective/03_Language_Models/03.5_Embedding_Vector_Spaces.md',
        'Concept/AI_model_Perspective/03_Language_Models/03.6_Context_Window_Memory.md',
        'Concept/AI_model_Perspective/04_Semantic_Models/04.2_Continuous_Representation_Theory.md',
        'Concept/AI_model_Perspective/04_Semantic_Models/04.3_Distributional_Semantics.md',
        'Concept/AI_model_Perspective/04_Semantic_Models/04.4_Semantic_Similarity_Metrics.md',
        'Concept/AI_model_Perspective/04_Semantic_Models/04.5_Multimodal_Semantic_Integration.md',
        'Concept/AI_model_Perspective/04_Semantic_Models/04.6_Huang_Semantic_Model_Analysis.md',
        'Concept/AI_model_Perspective/05_Learning_Theory/05.2_Gold_Learnability_Theory.md',
    ]
    
    print(f"æ‰¾åˆ° {len(target_files)} ä¸ªæ–‡ä»¶éœ€è¦å¤„ç†")
    print("")
    
    processed = 0
    skipped = 0
    errors = 0
    
    for file_path in target_files:
        filepath = base_dir / file_path
        if not filepath.exists():
            print(f"  è·³è¿‡ï¼šæ–‡ä»¶ä¸å­˜åœ¨ - {filepath}")
            skipped += 1
            continue
        
        try:
            if process_file(filepath):
                processed += 1
            else:
                skipped += 1
        except Exception as e:
            print(f"  é”™è¯¯ï¼šå¤„ç†æ–‡ä»¶æ—¶å‡ºé”™ - {e}")
            errors += 1
    
    print(f"\n{'='*60}")
    print(f"å¤„ç†å®Œæˆï¼š")
    print(f"  - æˆåŠŸå¤„ç†ï¼š{processed} ä¸ªæ–‡ä»¶")
    print(f"  - è·³è¿‡ï¼š{skipped} ä¸ªæ–‡ä»¶")
    print(f"  - é”™è¯¯ï¼š{errors} ä¸ªæ–‡ä»¶")
    print(f"{'='*60}")

if __name__ == '__main__':
    main()
