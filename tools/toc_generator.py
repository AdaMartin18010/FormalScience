#!/usr/bin/env python3
"""
Formal Science TOC Generator
è‡ªåŠ¨ä¸ºmarkdownæ–‡æ¡£ç”Ÿæˆç›®å½•

Usage:
    python tools/toc_generator.py <file1.md> [file2.md ...]
    python tools/toc_generator.py Concept/*.md --max-level 3
    python tools/toc_generator.py --batch --dir Concept/
"""

import re
from pathlib import Path
from typing import List, Tuple
from dataclasses import dataclass
import argparse
import sys

try:
    from rich.console import Console
    from rich.progress import track
    HAS_RICH = True
except ImportError:
    HAS_RICH = False


@dataclass
class Header:
    """æ ‡é¢˜æ•°æ®ç±»"""
    level: int
    title: str
    anchor: str
    line_num: int


class TOCGenerator:
    """ç›®å½•ç”Ÿæˆå™¨"""
    
    def __init__(self, console=None):
        self.console = console if console else self._create_console()
        
        # TOCæ ‡è®°
        self.toc_start_marker = "<!-- TOC -->"
        self.toc_end_marker = "<!-- /TOC -->"
        
        # æ ‡é¢˜æ¨¡å¼
        self.header_pattern = re.compile(r'^(#{1,6})\s+(.+)$')
        
        # ç»Ÿè®¡
        self.processed_files = 0
        self.skipped_files = 0
        self.total_tocs = 0
    
    def _create_console(self):
        """åˆ›å»ºæ§åˆ¶å°å¯¹è±¡"""
        if HAS_RICH:
            return Console()
        else:
            class SimpleConsole:
                def print(self, *args, **kwargs):
                    print(*args)
            return SimpleConsole()
    
    def extract_headers(self, file: Path) -> List[Header]:
        """æå–æ‰€æœ‰æ ‡é¢˜"""
        headers = []
        
        try:
            with open(file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    match = self.header_pattern.match(line)
                    if match:
                        level = len(match.group(1))
                        title = match.group(2).strip()
                        
                        # ç§»é™¤æ ‡é¢˜ä¸­çš„é“¾æ¥
                        title = self._clean_title(title)
                        
                        anchor = self.title_to_anchor(title)
                        headers.append(Header(level, title, anchor, line_num))
        except Exception as e:
            self.console.print(f"[red]é”™è¯¯: æ— æ³•è¯»å–æ–‡ä»¶ {file}: {e}[/red]")
        
        return headers
    
    @staticmethod
    def _clean_title(title: str) -> str:
        """æ¸…ç†æ ‡é¢˜æ–‡æœ¬"""
        # ç§»é™¤markdowné“¾æ¥ [text](url)
        title = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', title)
        
        # ç§»é™¤è¡Œå†…ä»£ç æ ‡è®°
        title = re.sub(r'`([^`]+)`', r'\1', title)
        
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        title = re.sub(r'\s+', ' ', title).strip()
        
        return title
    
    @staticmethod
    def title_to_anchor(title: str) -> str:
        """
        æ ‡é¢˜è½¬é”šç‚¹ï¼ˆä¸GitHubå…¼å®¹ï¼‰
        ç¤ºä¾‹:
            "Hello World" -> "hello-world"
            "ç¬¬ä¸€ç«  å¼•è¨€" -> "ç¬¬ä¸€ç« -å¼•è¨€"
            "1. Introduction" -> "1-introduction"
        """
        # ç§»é™¤emojiå’Œç‰¹æ®Šç¬¦å·ï¼ˆä¿ç•™ä¸­è‹±æ–‡ã€æ•°å­—ã€ç©ºæ ¼ã€è¿å­—ç¬¦ï¼‰
        cleaned = re.sub(r'[^\w\s\u4e00-\u9fff-]', '', title)
        
        # è½¬å°å†™
        anchor = cleaned.strip().lower()
        
        # ç©ºæ ¼å’Œå¤šä¸ªè¿å­—ç¬¦æ›¿æ¢ä¸ºå•ä¸ªè¿å­—ç¬¦
        anchor = re.sub(r'[\s_]+', '-', anchor)
        anchor = re.sub(r'-+', '-', anchor)
        
        return anchor.strip('-')
    
    def generate_toc(self, headers: List[Header], max_level: int = 4, 
                    start_level: int = 1) -> str:
        """
        ç”Ÿæˆç›®å½•å­—ç¬¦ä¸²
        
        Args:
            headers: æ ‡é¢˜åˆ—è¡¨
            max_level: æœ€å¤§å±‚çº§
            start_level: èµ·å§‹å±‚çº§ï¼ˆç”¨äºè°ƒæ•´ç¼©è¿›ï¼‰
        
        Returns:
            ç›®å½•markdownæ–‡æœ¬
        """
        if not headers:
            return ""
        
        toc_lines = [self.toc_start_marker, ""]
        
        # æ‰¾åˆ°æœ€å°å±‚çº§ä½œä¸ºåŸºå‡†
        min_level = min(h.level for h in headers if h.level >= start_level)
        
        for header in headers:
            # è·³è¿‡æ ‡é¢˜çº§åˆ«è¿‡å¤§çš„
            if header.level > max_level:
                continue
            
            # è·³è¿‡èµ·å§‹çº§åˆ«ä¹‹å‰çš„
            if header.level < start_level:
                continue
            
            # è®¡ç®—ç¼©è¿›
            indent_level = header.level - min_level
            indent = "  " * indent_level
            
            # ç”Ÿæˆé“¾æ¥
            link = f"[{header.title}](#{header.anchor})"
            toc_lines.append(f"{indent}- {link}")
        
        toc_lines.extend(["", self.toc_end_marker, ""])
        
        return "\n".join(toc_lines)
    
    def has_existing_toc(self, content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›®å½•"""
        return self.toc_start_marker in content
    
    def remove_existing_toc(self, content: str) -> str:
        """ç§»é™¤ç°æœ‰ç›®å½•"""
        pattern = f"{re.escape(self.toc_start_marker)}.*?{re.escape(self.toc_end_marker)}"
        return re.sub(pattern, "", content, flags=re.DOTALL)
    
    def insert_toc(self, file: Path, toc: str, position: str = "after_title"):
        """
        æ’å…¥ç›®å½•åˆ°æ–‡ä»¶
        
        Args:
            file: æ–‡ä»¶è·¯å¾„
            toc: ç›®å½•å†…å®¹
            position: æ’å…¥ä½ç½® ('after_title' æˆ– 'top')
        """
        try:
            with open(file, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            self.console.print(f"[red]é”™è¯¯: æ— æ³•è¯»å– {file}: {e}[/red]")
            return False
        
        # ç§»é™¤æ—§ç›®å½•
        content = self.remove_existing_toc(content)
        
        # ç¡®å®šæ’å…¥ä½ç½®
        if position == "after_title":
            # åœ¨ç¬¬ä¸€ä¸ªä¸€çº§æ ‡é¢˜åæ’å…¥
            match = re.search(r'^#\s+.+$', content, re.MULTILINE)
            if match:
                insert_pos = match.end()
                # è·³è¿‡æ ‡é¢˜åçš„ç©ºè¡Œ
                next_content = content[insert_pos:]
                empty_lines = re.match(r'\n*', next_content)
                if empty_lines:
                    insert_pos += len(empty_lines.group(0))
                
                content = content[:insert_pos] + "\n\n" + toc + "\n" + content[insert_pos:]
            else:
                # æ²¡æœ‰ä¸€çº§æ ‡é¢˜ï¼Œæ’å…¥å¼€å¤´
                content = toc + "\n\n" + content
        else:
            # æ’å…¥å¼€å¤´
            content = toc + "\n\n" + content
        
        # å†™å›æ–‡ä»¶
        try:
            with open(file, 'w', encoding='utf-8') as f:
                f.write(content)
            return True
        except Exception as e:
            self.console.print(f"[red]é”™è¯¯: æ— æ³•å†™å…¥ {file}: {e}[/red]")
            return False
    
    def process_file(self, file: Path, max_level: int = 4, 
                    min_headers: int = 3, force: bool = False,
                    dry_run: bool = False) -> bool:
        """
        å¤„ç†å•ä¸ªæ–‡ä»¶
        
        Args:
            file: æ–‡ä»¶è·¯å¾„
            max_level: æœ€å¤§æ ‡é¢˜å±‚çº§
            min_headers: æœ€å°æ ‡é¢˜æ•°é‡ï¼ˆå°‘äºæ­¤æ•°é‡åˆ™è·³è¿‡ï¼‰
            force: å¼ºåˆ¶æ›´æ–°ï¼ˆå³ä½¿å·²æœ‰TOCï¼‰
            dry_run: é¢„è§ˆæ¨¡å¼ï¼ˆä¸å®é™…ä¿®æ”¹æ–‡ä»¶ï¼‰
        
        Returns:
            æ˜¯å¦æˆåŠŸå¤„ç†
        """
        if not file.exists():
            self.console.print(f"[yellow]è·³è¿‡: æ–‡ä»¶ä¸å­˜åœ¨ - {file}[/yellow]")
            self.skipped_files += 1
            return False
        
        # æå–æ ‡é¢˜
        headers = self.extract_headers(file)
        
        # æ£€æŸ¥æ ‡é¢˜æ•°é‡
        if len(headers) < min_headers:
            if HAS_RICH:
                self.console.print(f"[dim]è·³è¿‡: {file.name} (æ ‡é¢˜æ•° {len(headers)} < {min_headers})[/dim]")
            else:
                print(f"è·³è¿‡: {file.name} (æ ‡é¢˜æ•°ä¸è¶³)")
            self.skipped_files += 1
            return False
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰TOC
        try:
            with open(file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if self.has_existing_toc(content) and not force:
                if HAS_RICH:
                    self.console.print(f"[dim]è·³è¿‡: {file.name} (å·²æœ‰TOCï¼Œä½¿ç”¨--forceå¼ºåˆ¶æ›´æ–°)[/dim]")
                else:
                    print(f"è·³è¿‡: {file.name} (å·²æœ‰TOC)")
                self.skipped_files += 1
                return False
        except Exception as e:
            self.console.print(f"[red]é”™è¯¯: {file.name} - {e}[/red]")
            self.skipped_files += 1
            return False
        
        # ç”ŸæˆTOC
        toc = self.generate_toc(headers, max_level)
        
        # é¢„è§ˆæ¨¡å¼
        if dry_run:
            if HAS_RICH:
                self.console.print(f"[cyan]é¢„è§ˆ: {file.name}[/cyan]")
                self.console.print(f"[dim]{toc}[/dim]")
            else:
                print(f"\né¢„è§ˆ: {file.name}")
                print(toc)
            return True
        
        # æ’å…¥TOC
        if self.insert_toc(file, toc):
            if HAS_RICH:
                self.console.print(f"[green]âœ“[/green] {file.name} (ç”Ÿæˆ {len(headers)} é¡¹)")
            else:
                print(f"âœ“ {file.name} (ç”Ÿæˆ {len(headers)} é¡¹)")
            self.processed_files += 1
            self.total_tocs += 1
            return True
        else:
            self.skipped_files += 1
            return False
    
    def process_batch(self, files: List[Path], **kwargs):
        """æ‰¹é‡å¤„ç†æ–‡ä»¶"""
        if HAS_RICH:
            file_iter = track(files, description="å¤„ç†æ–‡ä»¶ä¸­...")
        else:
            file_iter = files
            print(f"å¤„ç† {len(files)} ä¸ªæ–‡ä»¶...")
        
        for file in file_iter:
            self.process_file(file, **kwargs)
    
    def print_summary(self):
        """æ‰“å°å¤„ç†æ‘˜è¦"""
        if HAS_RICH:
            self.console.print("\n[bold cyan]å¤„ç†æ‘˜è¦[/bold cyan]")
            self.console.print(f"âœ“ å¤„ç†æˆåŠŸ: [green]{self.processed_files}[/green]")
            self.console.print(f"âŠ— è·³è¿‡æ–‡ä»¶: [yellow]{self.skipped_files}[/yellow]")
            self.console.print(f"ğŸ“‘ ç”Ÿæˆç›®å½•: [cyan]{self.total_tocs}[/cyan]")
        else:
            print("\nå¤„ç†æ‘˜è¦:")
            print(f"âœ“ å¤„ç†æˆåŠŸ: {self.processed_files}")
            print(f"âŠ— è·³è¿‡æ–‡ä»¶: {self.skipped_files}")
            print(f"ğŸ“‘ ç”Ÿæˆç›®å½•: {self.total_tocs}")


def main():
    parser = argparse.ArgumentParser(
        description="ä¸ºmarkdownæ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆç›®å½•",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python tools/toc_generator.py Concept/README.md           # å•ä¸ªæ–‡ä»¶
  python tools/toc_generator.py Concept/*.md                # æ‰¹é‡å¤„ç†
  python tools/toc_generator.py --batch --dir Concept/      # æ‰«æç›®å½•
  python tools/toc_generator.py file.md --max-level 3       # é™åˆ¶å±‚çº§
  python tools/toc_generator.py file.md --force             # å¼ºåˆ¶æ›´æ–°
  python tools/toc_generator.py file.md --dry-run           # é¢„è§ˆæ¨¡å¼
        """
    )
    
    parser.add_argument(
        'files',
        nargs='*',
        type=Path,
        help='è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨'
    )
    
    parser.add_argument(
        '--batch',
        action='store_true',
        help='æ‰¹é‡æ¨¡å¼ï¼šæ‰«æç›®å½•ä¸‹æ‰€æœ‰markdownæ–‡ä»¶'
    )
    
    parser.add_argument(
        '--dir',
        type=Path,
        default=Path('.'),
        help='æ‰¹é‡æ¨¡å¼ä¸‹çš„æ‰«æç›®å½• (é»˜è®¤: å½“å‰ç›®å½•)'
    )
    
    parser.add_argument(
        '--max-level',
        type=int,
        default=4,
        help='æœ€å¤§æ ‡é¢˜å±‚çº§ (é»˜è®¤: 4)'
    )
    
    parser.add_argument(
        '--min-headers',
        type=int,
        default=3,
        help='æœ€å°æ ‡é¢˜æ•°é‡ï¼Œå°‘äºæ­¤æ•°é‡åˆ™è·³è¿‡ (é»˜è®¤: 3)'
    )
    
    parser.add_argument(
        '--force',
        action='store_true',
        help='å¼ºåˆ¶æ›´æ–°å·²æœ‰TOC'
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='é¢„è§ˆæ¨¡å¼ï¼šåªæ˜¾ç¤ºå°†ç”Ÿæˆçš„TOCï¼Œä¸ä¿®æ”¹æ–‡ä»¶'
    )
    
    args = parser.parse_args()
    
    # æ”¶é›†æ–‡ä»¶åˆ—è¡¨
    files = []
    
    if args.batch:
        # æ‰¹é‡æ¨¡å¼ï¼šæ‰«æç›®å½•
        if not args.dir.exists():
            print(f"é”™è¯¯: ç›®å½•ä¸å­˜åœ¨: {args.dir}")
            sys.exit(1)
        
        files = list(args.dir.rglob("*.md"))
        
        # æ’é™¤ä¸€äº›ç‰¹æ®Šæ–‡ä»¶
        exclude_patterns = ['node_modules', '.git', '__pycache__', 'LINK_', 'PROGRESS_', 'REPORT_']
        files = [f for f in files if not any(p in str(f) for p in exclude_patterns)]
    
    elif args.files:
        # æŒ‡å®šæ–‡ä»¶
        files = args.files
    else:
        parser.print_help()
        sys.exit(0)
    
    if not files:
        print("æœªæ‰¾åˆ°è¦å¤„ç†çš„æ–‡ä»¶")
        sys.exit(0)
    
    # åˆ›å»ºç”Ÿæˆå™¨
    console = Console() if HAS_RICH else None
    generator = TOCGenerator(console)
    
    # å¤„ç†æ–‡ä»¶
    if len(files) == 1:
        # å•æ–‡ä»¶æ¨¡å¼
        generator.process_file(
            files[0],
            max_level=args.max_level,
            min_headers=args.min_headers,
            force=args.force,
            dry_run=args.dry_run
        )
    else:
        # æ‰¹é‡æ¨¡å¼
        generator.process_batch(
            files,
            max_level=args.max_level,
            min_headers=args.min_headers,
            force=args.force,
            dry_run=args.dry_run
        )
    
    # æ‰“å°æ‘˜è¦
    generator.print_summary()


if __name__ == "__main__":
    main()

