# 26.3 èµ„æºå¼¹æ€§è°ƒåº¦

> **å­ä¸»é¢˜ç¼–å·**: 26.3
> **ä¸»é¢˜**: Serverlessè°ƒåº¦
> **æœ€åæ›´æ–°**: 2025-12-02
> **æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæˆ

---

## ğŸ“‹ ç›®å½•

- [1 æ¦‚è¿°](#1-æ¦‚è¿°)
- [2 æ€ç»´å¯¼å›¾](#2-æ€ç»´å¯¼å›¾)
- [3 è‡ªåŠ¨ä¼¸ç¼©ç­–ç•¥](#3-è‡ªåŠ¨ä¼¸ç¼©ç­–ç•¥)
- [4 Bin-Packingä¼˜åŒ–](#4-bin-packingä¼˜åŒ–)
- [5 çŸ¥è¯†çŸ©é˜µ](#5-çŸ¥è¯†çŸ©é˜µ)
- [6 å½¢å¼åŒ–æ¨¡å‹](#6-å½¢å¼åŒ–æ¨¡å‹)
- [7 è·¨è§†è§’é“¾æ¥](#7-è·¨è§†è§’é“¾æ¥)

---

## 1 æ¦‚è¿°

### 1.1 æ ¸å¿ƒæ´å¯Ÿ

Serverlessèµ„æºå¼¹æ€§è°ƒåº¦éœ€è¦åœ¨**å“åº”é€Ÿåº¦**ã€**èµ„æºæ•ˆç‡**å’Œ**æˆæœ¬**ä¹‹é—´å–å¾—å¹³è¡¡ã€‚ä¸ä¼ ç»Ÿauto-scalingä¸åŒï¼ŒServerlesséœ€è¦æ›´ç»†ç²’åº¦ã€æ›´å¿«é€Ÿçš„ä¼¸ç¼©èƒ½åŠ›ã€‚

### 1.2 å¼¹æ€§è°ƒåº¦ç‰¹ç‚¹

| ç‰¹ç‚¹ | ä¼ ç»ŸAuto-Scaling | Serverlesså¼¹æ€§ |
|------|-----------------|---------------|
| **ä¼¸ç¼©ç²’åº¦** | å®ä¾‹çº§ | å‡½æ•°çº§ |
| **å“åº”æ—¶é—´** | åˆ†é’Ÿçº§ | ç§’/æ¯«ç§’çº§ |
| **ç¼©å®¹åˆ°é›¶** | ä¸æ”¯æŒ | åŸç”Ÿæ”¯æŒ |
| **è®¡è´¹æ¨¡å¼** | æŒ‰å®ä¾‹ | æŒ‰è°ƒç”¨ |

---

## 2 æ€ç»´å¯¼å›¾

```mermaid
mindmap
  root((èµ„æºå¼¹æ€§è°ƒåº¦))
    æ‰©å®¹ç­–ç•¥
      é˜ˆå€¼è§¦å‘
        CPU/å†…å­˜
        å¹¶å‘æ•°
        é˜Ÿåˆ—æ·±åº¦
      é¢„æµ‹è§¦å‘
        è´Ÿè½½é¢„æµ‹
        è¶‹åŠ¿åˆ†æ
      æ··åˆè§¦å‘
        è§„åˆ™+é¢„æµ‹
    ç¼©å®¹ç­–ç•¥
      å†·å´æœŸ
        é¿å…éœ‡è¡
        ç¨³å®šçª—å£
      æ¸è¿›ç¼©å®¹
        é˜¶æ¢¯å¼
        å¹³æ»‘æ›²çº¿
      ç¼©å®¹åˆ°é›¶
        å®Œå…¨é‡Šæ”¾
        æˆæœ¬æœ€ä¼˜
    èµ„æºä¼˜åŒ–
      Bin-Packing
        é¦–æ¬¡é€‚åº”
        æœ€ä½³é€‚åº”
        ç¢ç‰‡æ•´ç†
      å¯†åº¦ä¼˜åŒ–
        è¶…é¢è®¢é˜…
        èµ„æºå…±äº«
    çº¦æŸå¤„ç†
      SLAä¿è¯
        å»¶è¿Ÿçº¦æŸ
        å¯ç”¨æ€§çº¦æŸ
      æˆæœ¬çº¦æŸ
        é¢„ç®—é™åˆ¶
        ROIä¼˜åŒ–
```

---

## 3 è‡ªåŠ¨ä¼¸ç¼©ç­–ç•¥

### 3.1 æ‰©å®¹ç­–ç•¥

```mermaid
graph TD
    M[ç›‘æ§æŒ‡æ ‡] --> A{è§¦å‘æ¡ä»¶?}

    A -->|å¹¶å‘>é˜ˆå€¼| B[å¹¶å‘è§¦å‘æ‰©å®¹]
    A -->|é˜Ÿåˆ—>é˜ˆå€¼| C[é˜Ÿåˆ—è§¦å‘æ‰©å®¹]
    A -->|é¢„æµ‹è´Ÿè½½ä¸Šå‡| D[é¢„æµ‹è§¦å‘æ‰©å®¹]

    B --> E{èµ„æºå……è¶³?}
    C --> E
    D --> E

    E -->|æ˜¯| F[ç«‹å³æ‰©å®¹]
    E -->|å¦| G[æ’é˜Ÿç­‰å¾…]

    F --> H[æ›´æ–°è·¯ç”±]
    G --> I[èµ„æºç”³è¯·]
    I --> F
```

### 3.2 æ‰©å®¹ç®—æ³•

```python
class ElasticScaler:
    """å¼¹æ€§ä¼¸ç¼©è°ƒåº¦å™¨"""

    def __init__(self, config: ScalingConfig):
        self.config = config
        self.metrics_collector = MetricsCollector()
        self.predictor = LoadPredictor()

    def evaluate_scaling(self, function_id: str) -> ScalingDecision:
        """è¯„ä¼°ä¼¸ç¼©å†³ç­–"""
        metrics = self.metrics_collector.get_metrics(function_id)
        current_instances = self.get_instance_count(function_id)

        # 1. åŸºäºå½“å‰è´Ÿè½½
        load_based = self._load_based_decision(metrics, current_instances)

        # 2. åŸºäºé¢„æµ‹
        prediction_based = self._prediction_based_decision(function_id)

        # 3. ç»¼åˆå†³ç­–
        return self._combine_decisions(load_based, prediction_based)

    def _load_based_decision(self, metrics: Metrics, current: int) -> int:
        """åŸºäºè´Ÿè½½çš„å†³ç­–"""
        # å¹¶å‘ç‡
        concurrency_ratio = metrics.active_requests / (current * self.config.target_concurrency)

        if concurrency_ratio > self.config.scale_up_threshold:
            # æ‰©å®¹
            target = int(current * concurrency_ratio / self.config.target_utilization)
            return min(target, self.config.max_instances)
        elif concurrency_ratio < self.config.scale_down_threshold:
            # ç¼©å®¹
            target = max(int(current * concurrency_ratio), self.config.min_instances)
            return target
        else:
            return current

    def _prediction_based_decision(self, function_id: str) -> int:
        """åŸºäºé¢„æµ‹çš„å†³ç­–"""
        predicted_load = self.predictor.predict(function_id, lookahead=timedelta(minutes=5))
        return int(np.ceil(predicted_load / self.config.target_concurrency))

    def _combine_decisions(self, load_based: int, prediction_based: int) -> ScalingDecision:
        """ç»¼åˆå†³ç­–"""
        # å–ä¸¤è€…ä¸­æ›´ä¿å®ˆçš„å€¼
        target = max(load_based, prediction_based)

        return ScalingDecision(
            target_instances=target,
            confidence=0.8,
            reason=f"load={load_based}, predicted={prediction_based}",
        )
```

### 3.3 ç¼©å®¹ç­–ç•¥

```python
class ScaleDownPolicy:
    """ç¼©å®¹ç­–ç•¥"""

    def __init__(self, config: ScaleDownConfig):
        self.config = config
        self.cooldown_tracker = CooldownTracker()

    def can_scale_down(self, function_id: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥ç¼©å®¹"""
        # æ£€æŸ¥å†·å´æœŸ
        if self.cooldown_tracker.in_cooldown(function_id):
            return False

        # æ£€æŸ¥ç¨³å®šçª—å£
        metrics_history = self.get_metrics_window(function_id, self.config.stability_window)
        if not self._is_stable(metrics_history):
            return False

        return True

    def calculate_scale_down(self, function_id: str, current: int) -> int:
        """è®¡ç®—ç¼©å®¹ç›®æ ‡"""
        metrics = self.get_current_metrics(function_id)

        # æ¸è¿›ç¼©å®¹ï¼ˆé¿å…éœ‡è¡ï¼‰
        target = max(
            self.config.min_instances,
            int(current * (1 - self.config.scale_down_rate)),
            int(metrics.active_requests / self.config.target_concurrency),
        )

        return target

    def _is_stable(self, metrics_history: List[Metrics]) -> bool:
        """æ£€æŸ¥è´Ÿè½½æ˜¯å¦ç¨³å®š"""
        if len(metrics_history) < 3:
            return False

        values = [m.active_requests for m in metrics_history]
        variance = np.var(values)
        mean = np.mean(values)

        # å˜å¼‚ç³»æ•°å°äºé˜ˆå€¼
        cv = np.sqrt(variance) / mean if mean > 0 else 0
        return cv < self.config.stability_threshold
```

### 3.4 ç¼©å®¹åˆ°é›¶

```mermaid
sequenceDiagram
    participant S as è°ƒåº¦å™¨
    participant I as å®ä¾‹
    participant M as ç›‘æ§

    Note over S,M: æ­£å¸¸è¿è¡Œ

    M->>S: æœ€åè¯·æ±‚å®Œæˆ
    S->>S: å¯åŠ¨ç©ºé—²è®¡æ—¶å™¨

    loop ç©ºé—²æ£€æŸ¥
        M->>S: æ— æ–°è¯·æ±‚
        S->>S: è®¡æ—¶å™¨é€’å¢
    end

    Note over S: è¾¾åˆ°ç©ºé—²é˜ˆå€¼

    S->>I: ä¼˜é›…å…³é—­ä¿¡å·
    I->>I: å®Œæˆè¿›è¡Œä¸­ä»»åŠ¡
    I->>S: å…³é—­ç¡®è®¤
    S->>I: ç»ˆæ­¢å®ä¾‹

    Note over S: å®ä¾‹æ•° = 0
    Note over S: ä¿ç•™è·¯ç”±é…ç½®
```

---

## 4 Bin-Packingä¼˜åŒ–

### 4.1 é—®é¢˜å®šä¹‰

```text
Serverless Bin-Packingé—®é¢˜:

ç»™å®š:
  - Nä¸ªå‡½æ•°å®ä¾‹ï¼Œæ¯ä¸ªéœ€è¦èµ„æº (cpu_i, mem_i)
  - Mä¸ªèŠ‚ç‚¹ï¼Œæ¯ä¸ªå®¹é‡ (CPU_j, MEM_j)

ç›®æ ‡:
  minimize ä½¿ç”¨çš„èŠ‚ç‚¹æ•°

çº¦æŸ:
  Î£ cpu_i â‰¤ CPU_j  (æ¯ä¸ªèŠ‚ç‚¹)
  Î£ mem_i â‰¤ MEM_j  (æ¯ä¸ªèŠ‚ç‚¹)
  æ¯ä¸ªå®ä¾‹åˆ†é…åˆ°æ°å¥½ä¸€ä¸ªèŠ‚ç‚¹
```

### 4.2 Bin-Packingç®—æ³•

```python
class BinPackingScheduler:
    """Bin-Packingè°ƒåº¦å™¨"""

    def __init__(self, nodes: List[Node]):
        self.nodes = nodes

    def schedule(self, instances: List[FunctionInstance]) -> Dict[str, str]:
        """è°ƒåº¦å®ä¾‹åˆ°èŠ‚ç‚¹"""
        # æŒ‰èµ„æºéœ€æ±‚é™åºæ’åºï¼ˆFirst Fit Decreasingï¼‰
        sorted_instances = sorted(
            instances,
            key=lambda i: (i.cpu_request + i.memory_request),
            reverse=True,
        )

        assignments = {}

        for instance in sorted_instances:
            node = self._find_best_fit(instance)
            if node:
                node.allocate(instance)
                assignments[instance.id] = node.id
            else:
                # æ— æ³•è°ƒåº¦ï¼Œéœ€è¦æ–°èŠ‚ç‚¹
                new_node = self._request_new_node()
                new_node.allocate(instance)
                assignments[instance.id] = new_node.id

        return assignments

    def _find_best_fit(self, instance: FunctionInstance) -> Optional[Node]:
        """Best Fitç®—æ³•"""
        best_node = None
        best_remaining = float('inf')

        for node in self.nodes:
            if node.can_fit(instance):
                remaining = node.remaining_capacity()
                if remaining < best_remaining:
                    best_remaining = remaining
                    best_node = node

        return best_node

    def defragment(self):
        """ç¢ç‰‡æ•´ç†"""
        # æ”¶é›†æ‰€æœ‰å®ä¾‹
        all_instances = []
        for node in self.nodes:
            all_instances.extend(node.instances)
            node.clear()

        # é‡æ–°è°ƒåº¦
        self.schedule(all_instances)

        # é‡Šæ”¾ç©ºèŠ‚ç‚¹
        empty_nodes = [n for n in self.nodes if n.is_empty()]
        for node in empty_nodes:
            node.release()
```

### 4.3 å¤šç»´èµ„æºæ‰“åŒ…

```mermaid
graph TB
    subgraph "èŠ‚ç‚¹èµ„æº"
        N1["èŠ‚ç‚¹1<br/>CPU: 80%<br/>MEM: 60%"]
        N2["èŠ‚ç‚¹2<br/>CPU: 40%<br/>MEM: 90%"]
        N3["èŠ‚ç‚¹3<br/>CPU: 70%<br/>MEM: 30%"]
    end

    subgraph "å¾…è°ƒåº¦å‡½æ•°"
        F1["F1: CPUé«˜, MEMä½"]
        F2["F2: CPUä½, MEMé«˜"]
    end

    F1 -->|æœ€ä½³| N3
    F2 -->|æœ€ä½³| N1

    style N1 fill:#ffffcc
    style N2 fill:#ffcccc
    style N3 fill:#ccffcc
```

---

## 5 çŸ¥è¯†çŸ©é˜µ

### 5.1 ä¼¸ç¼©ç­–ç•¥å¯¹æ¯”

| ç­–ç•¥ | å“åº”é€Ÿåº¦ | å‡†ç¡®æ€§ | æˆæœ¬ | å¤æ‚åº¦ |
|------|---------|-------|------|-------|
| **é˜ˆå€¼è§¦å‘** | å¿« | ä¸­ | ä¸­ | ä½ |
| **é¢„æµ‹è§¦å‘** | ä¸­ | é«˜ | ä½ | é«˜ |
| **æ··åˆè§¦å‘** | å¿« | é«˜ | ä¸­ | é«˜ |
| **äº‹ä»¶è§¦å‘** | æå¿« | - | ä½ | ä¸­ |

### 5.2 Bin-Packingç®—æ³•å¯¹æ¯”

| ç®—æ³• | è£…ç®±æ•ˆç‡ | æ—¶é—´å¤æ‚åº¦ | é€‚ç”¨åœºæ™¯ |
|------|---------|-----------|---------|
| **First Fit** | ä¸­ | O(n) | åœ¨çº¿è°ƒåº¦ |
| **Best Fit** | é«˜ | O(n log n) | æ‰¹é‡è°ƒåº¦ |
| **First Fit Decreasing** | é«˜ | O(n log n) | ç¦»çº¿ä¼˜åŒ– |

---

## 6 å½¢å¼åŒ–æ¨¡å‹

### 6.1 ä¼¸ç¼©å†³ç­–æ¨¡å‹

```text
ä¼¸ç¼©å†³ç­–ä¼˜åŒ–:

çŠ¶æ€: S = (N, Î», Q)
  N: å½“å‰å®ä¾‹æ•°
  Î»: å½“å‰è¯·æ±‚ç‡
  Q: é˜Ÿåˆ—æ·±åº¦

åŠ¨ä½œ: A = {æ‰©å®¹k, ç¼©å®¹k, ä¿æŒ}

å¥–åŠ±å‡½æ•°:
  R(s, a) = -C_instance Ã— N - C_cold Ã— P_cold(N, Î») - C_queue Ã— Q

è½¬ç§»: P(s'|s, a)
  å–å†³äºè´Ÿè½½å˜åŒ–æ¨¡å‹

æœ€ä¼˜ç­–ç•¥:
  Ï€* = argmax_Ï€ E[Î£ Î³^t R(s_t, a_t)]
```

### 6.2 èµ„æºåˆ©ç”¨ç‡è¯æ˜

```text
å®šç†: Best Fit Decreasingè¾¾åˆ°æœ€ä¼˜åˆ©ç”¨ç‡çš„11/9è¿‘ä¼¼

å¯¹äºBin-Packingé—®é¢˜:
  OPT â‰¤ BFD â‰¤ (11/9)OPT + 6/9

è¯æ˜æ€è·¯:
1. ç‰©å“æŒ‰å¤§å°é™åºæ’åˆ—
2. å¤§ç‰©å“ä¼˜å…ˆå¡«å……
3. å°ç‰©å“å¡«è¡¥ç©ºéš™
4. æµªè´¹ç©ºé—´æœ‰ç•Œ
```

---

## 7 è·¨è§†è§’é“¾æ¥

### 7.1 è°ƒåº¦è§†è§’å…³è”

- [åˆ†å¸ƒå¼è°ƒåº¦](../06_è°ƒåº¦æ¨¡å‹/06.4_åˆ†å¸ƒå¼ç³»ç»Ÿè°ƒåº¦.md) - é›†ç¾¤è°ƒåº¦
- [K8sè°ƒåº¦](../05_è™šæ‹ŸåŒ–å®¹å™¨åŒ–æ²™ç›’åŒ–/05.2_å®¹å™¨åŒ–æŠ€æœ¯.md) - å®¹å™¨è°ƒåº¦

### 7.2 å½¢å¼è¯­è¨€è§†è§’å…³è”

| å½¢å¼è¯­è¨€æ¦‚å¿µ | å¼¹æ€§è°ƒåº¦å¯¹åº” | æ˜ å°„è¯´æ˜ |
|------------|------------|---------|
| **ç±»å‹æ¨æ–­** | èµ„æºä¼°ç®— | è‡ªåŠ¨æ¨æ–­éœ€æ±‚ |
| **åƒåœ¾å›æ”¶** | å®ä¾‹å›æ”¶ | è‡ªåŠ¨é‡Šæ”¾èµ„æº |

---

**è¿”å›**: [Serverlessè°ƒåº¦ä¸»ç´¢å¼•](./README.md) | [è°ƒåº¦è§†è§’ä¸»ç´¢å¼•](../README.md)
