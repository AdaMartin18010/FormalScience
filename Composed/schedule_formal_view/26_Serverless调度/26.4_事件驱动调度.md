# 26.4 äº‹ä»¶é©±åŠ¨è°ƒåº¦

> **å­ä¸»é¢˜ç¼–å·**: 26.4
> **ä¸»é¢˜**: Serverlessè°ƒåº¦
> **æœ€åæ›´æ–°**: 2025-12-02
> **æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæˆ

---

## ğŸ“‹ ç›®å½•

- [1 æ¦‚è¿°](#1-æ¦‚è¿°)
- [2 æ€ç»´å¯¼å›¾](#2-æ€ç»´å¯¼å›¾)
- [3 äº‹ä»¶æºç±»å‹](#3-äº‹ä»¶æºç±»å‹)
- [4 äº‹ä»¶è·¯ç”±è°ƒåº¦](#4-äº‹ä»¶è·¯ç”±è°ƒåº¦)
- [5 æµå¤„ç†è°ƒåº¦](#5-æµå¤„ç†è°ƒåº¦)
- [6 çŸ¥è¯†çŸ©é˜µ](#6-çŸ¥è¯†çŸ©é˜µ)
- [7 å½¢å¼åŒ–æ¨¡å‹](#7-å½¢å¼åŒ–æ¨¡å‹)
- [8 è·¨è§†è§’é“¾æ¥](#8-è·¨è§†è§’é“¾æ¥)

---

## 1 æ¦‚è¿°

### 1.1 æ ¸å¿ƒæ´å¯Ÿ

äº‹ä»¶é©±åŠ¨æ˜¯Serverlessçš„æ ¸å¿ƒæ‰§è¡Œæ¨¡å‹ã€‚å‡½æ•°ä¸ä¸»åŠ¨è¿è¡Œï¼Œè€Œæ˜¯å“åº”äº‹ä»¶è§¦å‘ã€‚äº‹ä»¶é©±åŠ¨è°ƒåº¦éœ€è¦å¤„ç†**äº‹ä»¶è·¯ç”±**ã€**è´Ÿè½½å‡è¡¡**å’Œ**æµé‡æ§åˆ¶**ç­‰æŒ‘æˆ˜ã€‚

### 1.2 äº‹ä»¶é©±åŠ¨ç‰¹ç‚¹

| ç‰¹ç‚¹ | æè¿° | è°ƒåº¦æŒ‘æˆ˜ |
|------|------|---------|
| **å¼‚æ­¥è§¦å‘** | äº‹ä»¶åˆ°è¾¾å³è§¦å‘ | çªå‘æµé‡å¤„ç† |
| **æ¾è€¦åˆ** | ç”Ÿäº§è€…æ¶ˆè´¹è€…åˆ†ç¦» | æ¶ˆæ¯å¯é ä¼ é€’ |
| **å¯ä¼¸ç¼©** | æŒ‰äº‹ä»¶é‡ä¼¸ç¼© | ç²¾ç¡®ä¼¸ç¼© |
| **å¹‚ç­‰æ€§** | å¯èƒ½é‡å¤è§¦å‘ | å»é‡å¤„ç† |

---

## 2 æ€ç»´å¯¼å›¾

```mermaid
mindmap
  root((äº‹ä»¶é©±åŠ¨è°ƒåº¦))
    äº‹ä»¶æº
      åŒæ­¥äº‹ä»¶
        HTTPè¯·æ±‚
        APIç½‘å…³
        gRPC
      å¼‚æ­¥äº‹ä»¶
        æ¶ˆæ¯é˜Ÿåˆ—
        äº‹ä»¶æ€»çº¿
        Webhook
      å®šæ—¶äº‹ä»¶
        Cron
        Rate
        å®šæ—¶å™¨
      å­˜å‚¨äº‹ä»¶
        å¯¹è±¡å­˜å‚¨
        æ•°æ®åº“
        æ–‡ä»¶ç³»ç»Ÿ
    äº‹ä»¶è·¯ç”±
      è·¯ç”±ç­–ç•¥
        è½®è¯¢
        åŠ æƒ
        ä¸€è‡´æ€§å“ˆå¸Œ
      è¿‡æ»¤è§„åˆ™
        å†…å®¹è¿‡æ»¤
        æ¨¡å¼åŒ¹é…
        æ¡ä»¶è·¯ç”±
    è´Ÿè½½å‡è¡¡
      è¯·æ±‚çº§
        éšæœº
        æœ€å°‘è¿æ¥
      å‡½æ•°çº§
        å®ä¾‹äº²å’Œ
        åœ°ç†æ„ŸçŸ¥
    æµé‡æ§åˆ¶
      é™æµ
        ä»¤ç‰Œæ¡¶
        æ¼æ¡¶
      èƒŒå‹
        é˜Ÿåˆ—ç¼“å†²
        æ‹’ç»ç­–ç•¥
```

---

## 3 äº‹ä»¶æºç±»å‹

### 3.1 äº‹ä»¶æºåˆ†ç±»

```mermaid
graph TB
    subgraph "åŒæ­¥äº‹ä»¶æº"
        S1[HTTP/HTTPS]
        S2[API Gateway]
        S3[gRPC]
        S4[GraphQL]
    end

    subgraph "å¼‚æ­¥äº‹ä»¶æº"
        A1[SQS/Kafka]
        A2[SNS/Pub/Sub]
        A3[EventBridge]
        A4[Webhook]
    end

    subgraph "è§¦å‘å™¨äº‹ä»¶æº"
        T1[S3/GCS/Blob]
        T2[DynamoDB/Firestore]
        T3[CloudWatch]
        T4[Cronå®šæ—¶å™¨]
    end

    subgraph "å‡½æ•°"
        F[Lambda/Function]
    end

    S1 --> F
    S2 --> F
    A1 --> F
    A2 --> F
    T1 --> F
    T4 --> F
```

### 3.2 äº‹ä»¶æºé…ç½®ç¤ºä¾‹

```yaml
# AWS SAM å¤šäº‹ä»¶æºé…ç½®
Resources:
  MyFunction:
    Type: AWS::Serverless::Function
    Properties:
      Handler: index.handler
      Runtime: nodejs18.x
      Events:
        # HTTP APIäº‹ä»¶
        HttpApi:
          Type: HttpApi
          Properties:
            Path: /items
            Method: GET

        # SQSé˜Ÿåˆ—äº‹ä»¶
        SQSEvent:
          Type: SQS
          Properties:
            Queue: !GetAtt MyQueue.Arn
            BatchSize: 10

        # S3å­˜å‚¨äº‹ä»¶
        S3Event:
          Type: S3
          Properties:
            Bucket: !Ref MyBucket
            Events: s3:ObjectCreated:*

        # å®šæ—¶äº‹ä»¶
        ScheduleEvent:
          Type: Schedule
          Properties:
            Schedule: rate(5 minutes)

        # EventBridgeè§„åˆ™
        EventBridgeRule:
          Type: EventBridgeRule
          Properties:
            Pattern:
              source:
                - "my.application"
              detail-type:
                - "order.created"
```

### 3.3 äº‹ä»¶æ ¼å¼æ ‡å‡†

```json
// CloudEventsæ ¼å¼ (CNCFæ ‡å‡†)
{
  "specversion": "1.0",
  "type": "com.example.order.created",
  "source": "/orders/service",
  "id": "A234-1234-1234",
  "time": "2025-12-02T10:00:00Z",
  "datacontenttype": "application/json",
  "data": {
    "orderId": "12345",
    "customerId": "67890",
    "amount": 99.99
  }
}
```

---

## 4 äº‹ä»¶è·¯ç”±è°ƒåº¦

### 4.1 è·¯ç”±ç­–ç•¥

```mermaid
graph LR
    subgraph "è·¯ç”±ç­–ç•¥"
        R1[è½®è¯¢ Round Robin]
        R2[åŠ æƒè½®è¯¢]
        R3[æœ€å°‘è¿æ¥]
        R4[ä¸€è‡´æ€§å“ˆå¸Œ]
        R5[åœ°ç†è·¯ç”±]
    end

    E[äº‹ä»¶] --> R1
    E --> R2
    E --> R3
    E --> R4
    E --> R5

    R1 --> I1[å®ä¾‹1]
    R1 --> I2[å®ä¾‹2]
    R4 --> I3[å®ä¾‹3 ç²˜æ€§]
```

### 4.2 äº‹ä»¶è·¯ç”±å™¨å®ç°

```python
class EventRouter:
    """äº‹ä»¶è·¯ç”±å™¨"""

    def __init__(self, strategy: RoutingStrategy):
        self.strategy = strategy
        self.function_registry: Dict[str, List[FunctionInstance]] = {}
        self.rules: List[RoutingRule] = []

    def route(self, event: CloudEvent) -> Optional[FunctionInstance]:
        """è·¯ç”±äº‹ä»¶åˆ°å‡½æ•°å®ä¾‹"""
        # 1. åŒ¹é…è·¯ç”±è§„åˆ™
        target_function = self._match_rules(event)
        if not target_function:
            return None

        # 2. è·å–å¯ç”¨å®ä¾‹
        instances = self.function_registry.get(target_function, [])
        available = [i for i in instances if i.is_healthy()]

        if not available:
            # è§¦å‘æ‰©å®¹
            return self._scale_and_route(target_function, event)

        # 3. é€‰æ‹©å®ä¾‹
        return self.strategy.select(available, event)

    def _match_rules(self, event: CloudEvent) -> Optional[str]:
        """åŒ¹é…è·¯ç”±è§„åˆ™"""
        for rule in self.rules:
            if rule.matches(event):
                return rule.target_function
        return None

    def add_rule(self, rule: RoutingRule):
        """æ·»åŠ è·¯ç”±è§„åˆ™"""
        self.rules.append(rule)
        self.rules.sort(key=lambda r: r.priority, reverse=True)


class ConsistentHashStrategy(RoutingStrategy):
    """ä¸€è‡´æ€§å“ˆå¸Œè·¯ç”±"""

    def __init__(self, replicas: int = 100):
        self.replicas = replicas
        self.ring: SortedDict = SortedDict()

    def select(self, instances: List[FunctionInstance], event: CloudEvent) -> FunctionInstance:
        """é€‰æ‹©å®ä¾‹"""
        # åŸºäºäº‹ä»¶å±æ€§è®¡ç®—å“ˆå¸Œ
        key = self._get_partition_key(event)
        hash_value = self._hash(key)

        # åœ¨å“ˆå¸Œç¯ä¸ŠæŸ¥æ‰¾
        idx = self.ring.bisect_left(hash_value)
        if idx >= len(self.ring):
            idx = 0

        return self.ring.peekitem(idx)[1]

    def _get_partition_key(self, event: CloudEvent) -> str:
        """è·å–åˆ†åŒºé”®"""
        # å¯ä»¥æ˜¯ç”¨æˆ·IDã€è®¢å•IDç­‰
        return event.data.get('partitionKey', event.id)
```

### 4.3 äº‹ä»¶è¿‡æ»¤

```python
class EventFilter:
    """äº‹ä»¶è¿‡æ»¤å™¨"""

    def __init__(self, pattern: Dict):
        self.pattern = pattern

    def matches(self, event: CloudEvent) -> bool:
        """æ£€æŸ¥äº‹ä»¶æ˜¯å¦åŒ¹é…è¿‡æ»¤å™¨"""
        return self._match_recursive(self.pattern, event.to_dict())

    def _match_recursive(self, pattern: Any, value: Any) -> bool:
        """é€’å½’åŒ¹é…"""
        if isinstance(pattern, dict):
            if not isinstance(value, dict):
                return False
            for key, sub_pattern in pattern.items():
                if key not in value:
                    return False
                if not self._match_recursive(sub_pattern, value[key]):
                    return False
            return True
        elif isinstance(pattern, list):
            # åˆ—è¡¨è¡¨ç¤ºORæ¡ä»¶
            return any(self._match_recursive(p, value) for p in pattern)
        else:
            # ç²¾ç¡®åŒ¹é…æˆ–é€šé…ç¬¦
            if pattern == "*":
                return True
            return pattern == value


# ä½¿ç”¨ç¤ºä¾‹
filter_pattern = {
    "source": ["order-service", "payment-service"],
    "detail-type": ["order.created"],
    "detail": {
        "status": ["pending", "confirmed"],
    }
}

filter = EventFilter(filter_pattern)
```

---

## 5 æµå¤„ç†è°ƒåº¦

### 5.1 æµå¤„ç†æ¨¡å‹

```mermaid
graph LR
    subgraph "äº‹ä»¶æµ"
        E1[äº‹ä»¶1]
        E2[äº‹ä»¶2]
        E3[äº‹ä»¶3]
        E4[äº‹ä»¶n]
    end

    subgraph "æ‰¹å¤„ç†"
        B1[æ‰¹æ¬¡1]
        B2[æ‰¹æ¬¡2]
    end

    subgraph "å‡½æ•°å¤„ç†"
        F1[å‡½æ•°å®ä¾‹1]
        F2[å‡½æ•°å®ä¾‹2]
    end

    E1 --> B1
    E2 --> B1
    E3 --> B2
    E4 --> B2

    B1 --> F1
    B2 --> F2
```

### 5.2 æµè°ƒåº¦å™¨

```python
class StreamScheduler:
    """æµäº‹ä»¶è°ƒåº¦å™¨"""

    def __init__(self, config: StreamConfig):
        self.config = config
        self.batches: Dict[str, EventBatch] = {}
        self.timers: Dict[str, Timer] = {}

    def process_event(self, event: CloudEvent, stream_id: str):
        """å¤„ç†æµäº‹ä»¶"""
        batch = self._get_or_create_batch(stream_id)
        batch.add(event)

        # æ£€æŸ¥æ‰¹æ¬¡æ˜¯å¦æ»¡è¶³è§¦å‘æ¡ä»¶
        if self._should_flush(batch):
            self._flush_batch(stream_id)

    def _should_flush(self, batch: EventBatch) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆ·æ–°æ‰¹æ¬¡"""
        return (
            batch.size >= self.config.batch_size or
            batch.bytes >= self.config.max_batch_bytes or
            batch.age >= self.config.max_batch_age
        )

    def _flush_batch(self, stream_id: str):
        """åˆ·æ–°æ‰¹æ¬¡"""
        batch = self.batches.pop(stream_id, None)
        if batch and batch.events:
            # è°ƒåº¦æ‰¹æ¬¡å¤„ç†
            self._dispatch_batch(batch)

    def _dispatch_batch(self, batch: EventBatch):
        """åˆ†å‘æ‰¹æ¬¡åˆ°å‡½æ•°"""
        # é€‰æ‹©ç›®æ ‡å‡½æ•°
        function = self.router.route_batch(batch)

        # æ„å»ºæ‰¹å¤„ç†è¯·æ±‚
        request = BatchRequest(
            events=batch.events,
            metadata={
                'batch_id': batch.id,
                'batch_size': batch.size,
                'source_stream': batch.stream_id,
            }
        )

        # å¼‚æ­¥è°ƒç”¨å‡½æ•°
        self.invoker.invoke_async(function, request)


class EventBatch:
    """äº‹ä»¶æ‰¹æ¬¡"""

    def __init__(self, stream_id: str):
        self.id = str(uuid.uuid4())
        self.stream_id = stream_id
        self.events: List[CloudEvent] = []
        self.created_at = datetime.now()

    @property
    def size(self) -> int:
        return len(self.events)

    @property
    def bytes(self) -> int:
        return sum(len(json.dumps(e.to_dict())) for e in self.events)

    @property
    def age(self) -> timedelta:
        return datetime.now() - self.created_at

    def add(self, event: CloudEvent):
        self.events.append(event)
```

### 5.3 èƒŒå‹å¤„ç†

```python
class BackpressureController:
    """èƒŒå‹æ§åˆ¶å™¨"""

    def __init__(self, config: BackpressureConfig):
        self.config = config
        self.queue_depth: Dict[str, int] = defaultdict(int)
        self.processing_rate: Dict[str, float] = defaultdict(float)

    def should_accept(self, function_id: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ¥å—æ–°äº‹ä»¶"""
        depth = self.queue_depth[function_id]

        if depth >= self.config.max_queue_depth:
            return False

        if depth >= self.config.warning_threshold:
            # æ¦‚ç‡æ€§æ‹’ç»
            accept_prob = 1 - (depth - self.config.warning_threshold) / \
                         (self.config.max_queue_depth - self.config.warning_threshold)
            return random.random() < accept_prob

        return True

    def get_throttle_delay(self, function_id: str) -> float:
        """è·å–é™æµå»¶è¿Ÿ"""
        depth = self.queue_depth[function_id]
        rate = self.processing_rate[function_id]

        if rate <= 0:
            return 0

        # åŸºäºLittle's Lawä¼°ç®—ç­‰å¾…æ—¶é—´
        estimated_wait = depth / rate

        # å¦‚æœç­‰å¾…æ—¶é—´è¿‡é•¿ï¼Œå¢åŠ å»¶è¿Ÿ
        if estimated_wait > self.config.target_latency:
            return estimated_wait - self.config.target_latency

        return 0

    def on_event_received(self, function_id: str):
        """äº‹ä»¶æ¥æ”¶å›è°ƒ"""
        self.queue_depth[function_id] += 1

    def on_event_processed(self, function_id: str, duration: float):
        """äº‹ä»¶å¤„ç†å®Œæˆå›è°ƒ"""
        self.queue_depth[function_id] -= 1

        # æ›´æ–°å¤„ç†é€Ÿç‡ï¼ˆæŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰
        alpha = 0.1
        instant_rate = 1 / duration if duration > 0 else float('inf')
        self.processing_rate[function_id] = (
            alpha * instant_rate +
            (1 - alpha) * self.processing_rate[function_id]
        )
```

---

## 6 çŸ¥è¯†çŸ©é˜µ

### 6.1 äº‹ä»¶æºå¯¹æ¯”

| äº‹ä»¶æº | å»¶è¿Ÿ | ååé‡ | å¯é æ€§ | é€‚ç”¨åœºæ™¯ |
|-------|------|-------|-------|---------|
| **HTTP/API** | æä½ | é«˜ | ä½ | åŒæ­¥è°ƒç”¨ |
| **æ¶ˆæ¯é˜Ÿåˆ—** | ä½ | æé«˜ | é«˜ | å¼‚æ­¥å¤„ç† |
| **äº‹ä»¶æ€»çº¿** | ä¸­ | é«˜ | é«˜ | äº‹ä»¶é©±åŠ¨ |
| **å­˜å‚¨è§¦å‘** | ä¸­ | ä¸­ | é«˜ | æ•°æ®å¤„ç† |
| **å®šæ—¶å™¨** | - | ä½ | é«˜ | å®šæ—¶ä»»åŠ¡ |

### 6.2 è·¯ç”±ç­–ç•¥å¯¹æ¯”

| ç­–ç•¥ | è´Ÿè½½å‡è¡¡ | äº²å’Œæ€§ | å¤æ‚åº¦ | é€‚ç”¨åœºæ™¯ |
|------|---------|-------|-------|---------|
| **è½®è¯¢** | å‡åŒ€ | æ—  | ä½ | æ— çŠ¶æ€ |
| **åŠ æƒ** | å¯æ§ | æ—  | ä½ | å¼‚æ„å®ä¾‹ |
| **ä¸€è‡´æ€§å“ˆå¸Œ** | è¾ƒå‡ | é«˜ | ä¸­ | æœ‰çŠ¶æ€ |
| **æœ€å°‘è¿æ¥** | å‡åŒ€ | æ—  | ä¸­ | é•¿è¿æ¥ |

---

## 7 å½¢å¼åŒ–æ¨¡å‹

### 7.1 äº‹ä»¶è·¯ç”±å½¢å¼åŒ–

```text
äº‹ä»¶è·¯ç”±ç³»ç»Ÿ:

å®šä¹‰:
  E: äº‹ä»¶ç©ºé—´
  F: å‡½æ•°ç©ºé—´
  I: å®ä¾‹ç©ºé—´
  R: E â†’ F â†’ I (è·¯ç”±å‡½æ•°)

è·¯ç”±è§„åˆ™:
  r = (pattern, target, priority)
  R(e) = argmax_{r âˆˆ Rules} { r.target | r.pattern.matches(e) }

è´Ÿè½½å‡è¡¡:
  LB: F Ã— List<I> â†’ I
  ç­–ç•¥: è½®è¯¢ã€ä¸€è‡´æ€§å“ˆå¸Œç­‰
```

### 7.2 æµå¤„ç†å»¶è¿Ÿæ¨¡å‹

```text
æµå¤„ç†å»¶è¿Ÿ:

T_total = T_batch + T_queue + T_process

å…¶ä¸­:
  T_batch = min(batch_size/event_rate, max_batch_age)
  T_queue = queue_depth / processing_rate
  T_process = function_execution_time

ä¼˜åŒ–ç›®æ ‡:
  minimize E[T_total]
  subject to: T_total â‰¤ SLA
```

---

## 8 è·¨è§†è§’é“¾æ¥

### 8.1 è°ƒåº¦è§†è§’å…³è”

- [æ¶ˆæ¯é˜Ÿåˆ—è°ƒåº¦](../04_åŒæ­¥é€šä¿¡æœºåˆ¶/) - æ¶ˆæ¯è°ƒåº¦
- [åˆ†å¸ƒå¼è°ƒåº¦](../06_è°ƒåº¦æ¨¡å‹/06.4_åˆ†å¸ƒå¼ç³»ç»Ÿè°ƒåº¦.md) - äº‹ä»¶åˆ†å‘
- [ç½‘ç»œè°ƒåº¦](../15_ç½‘ç»œè°ƒåº¦ç³»ç»Ÿ/) - æµé‡æ§åˆ¶

### 8.2 å½¢å¼è¯­è¨€è§†è§’å…³è”

| å½¢å¼è¯­è¨€æ¦‚å¿µ | äº‹ä»¶é©±åŠ¨å¯¹åº” | æ˜ å°„è¯´æ˜ |
|------------|------------|---------|
| **ååº”å¼ç¼–ç¨‹** | äº‹ä»¶æµå¤„ç† | å“åº”å¼æ¨¡å‹ |
| **Actoræ¨¡å‹** | å‡½æ•°å®ä¾‹ | æ¶ˆæ¯ä¼ é€’ |
| **CPS** | å¼‚æ­¥å›è°ƒ | å»¶ç»­ä¼ é€’ |

---

**è¿”å›**: [Serverlessè°ƒåº¦ä¸»ç´¢å¼•](./README.md) | [è°ƒåº¦è§†è§’ä¸»ç´¢å¼•](../README.md)
