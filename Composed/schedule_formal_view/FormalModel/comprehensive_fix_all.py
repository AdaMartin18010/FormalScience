#!/usr/bin/env python3
"""
å…¨é¢ä¿®å¤æ‰€æœ‰Markdownæ–‡ä»¶çš„ç›®å½•ç»“æ„å’Œç« èŠ‚ç¼–å·
"""
import os
import re
from pathlib import Path
from typing import List, Tuple, Dict

def extract_all_headings(content: str) -> List[Tuple[int, str, str]]:
    """æå–æ‰€æœ‰æ ‡é¢˜"""
    headings = []
    lines = content.split('\n')
    
    for line in lines:
        match = re.match(r'^(#{1,6})\s+(.+)$', line)
        if match:
            level = len(match.group(1))
            text = match.group(2).strip()
            # ç§»é™¤ç¼–å·ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            text_clean = re.sub(r'^\d+\.?\d*\.?\d*\.?\d*\.?\s*', '', text)
            # ç”Ÿæˆé”šç‚¹ID
            anchor = re.sub(r'[^\w\s-]', '', text_clean.lower())
            anchor = re.sub(r'[-\s]+', '-', anchor)
            anchor = anchor.strip('-')
            headings.append((level, text, anchor))
    
    return headings

def generate_clean_toc(headings: List[Tuple[int, str, str]], start_level: int = 2) -> str:
    """ç”Ÿæˆå¹²å‡€çš„ç›®å½•ç»“æ„"""
    toc_lines = []
    
    for level, text, anchor in headings:
        if level < start_level:
            continue
        
        indent = (level - start_level) * 2
        toc_line = ' ' * indent + f'- [{text}](#{anchor})'
        toc_lines.append(toc_line)
    
    return '\n'.join(toc_lines)

def fix_file_comprehensive(file_path: str) -> bool:
    """å…¨é¢ä¿®å¤å•ä¸ªæ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"é”™è¯¯: æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
        return False
    
    # æŸ¥æ‰¾ç›®å½•éƒ¨åˆ†
    toc_pattern = r'(## ğŸ“‹ ç›®å½•\s*\n\n)(.*?)(\n\n---)'
    match = re.search(toc_pattern, content, re.DOTALL)
    
    if not match:
        return True  # æ²¡æœ‰ç›®å½•ï¼Œè·³è¿‡
    
    # æå–æ‰€æœ‰æ ‡é¢˜
    headings = extract_all_headings(content)
    
    if len(headings) < 2:
        return True  # æ ‡é¢˜å¤ªå°‘ï¼Œè·³è¿‡
    
    # ç”Ÿæˆæ–°ç›®å½•
    new_toc = generate_clean_toc(headings, start_level=2)
    
    # æ›¿æ¢ç›®å½•éƒ¨åˆ†
    new_content = content[:match.start(1)] + match.group(1) + new_toc + match.group(3) + content[match.end(3):]
    
    # å†™å›æ–‡ä»¶
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
        return True
    except Exception as e:
        print(f"é”™è¯¯: æ— æ³•å†™å…¥æ–‡ä»¶ {file_path}: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    base_dir = Path(__file__).parent
    md_files = []
    
    exclude_files = ['schedule_model.md', 'README.md', 'fix_toc_structure.py', 
                     'fix_section_numbering.py', 'remove_duplicate_sections.py',
                     'comprehensive_fix_all.py', 'å†…å®¹å¯¹æ¯”æ£€æŸ¥æŠ¥å‘Š.md',
                     'æ–‡ä»¶æ‹†åˆ†å®Œæˆæ€»ç»“.md', 'æ–‡ä»¶æ‹†åˆ†è¿›åº¦æŠ¥å‘Š.md']
    
    for root, dirs, files in os.walk(base_dir):
        for file in files:
            if file.endswith('.md') and file not in exclude_files:
                file_path = os.path.join(root, file)
                md_files.append(file_path)
    
    print(f"æ‰¾åˆ° {len(md_files)} ä¸ªMarkdownæ–‡ä»¶")
    print("å¼€å§‹å…¨é¢ä¿®å¤ç›®å½•ç»“æ„...\n")
    
    fixed_count = 0
    
    for file_path in sorted(md_files):
        rel_path = os.path.relpath(file_path, base_dir)
        if fix_file_comprehensive(file_path):
            print(f"âœ… å·²ä¿®å¤: {rel_path}")
            fixed_count += 1
    
    print(f"\nå®Œæˆï¼æˆåŠŸä¿®å¤: {fixed_count} ä¸ªæ–‡ä»¶")

if __name__ == '__main__':
    main()
