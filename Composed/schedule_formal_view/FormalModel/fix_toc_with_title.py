#!/usr/bin/env python3
"""
ç»Ÿä¸€æ‰€æœ‰æ–‡ä»¶çš„ç›®å½•æ ¼å¼ï¼Œç¡®ä¿åŒ…å«æ–‡ä»¶æ ‡é¢˜
"""
import os
import re
from pathlib import Path
from typing import List, Tuple, Dict

def generate_anchor(text: str) -> str:
    """ç”ŸæˆMarkdownæ ‡å‡†é”šç‚¹ID"""
    # ç§»é™¤ç¼–å·ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    text_clean = re.sub(r'^\d+\.?\d*\.?\d*\.?\d*\.?\s*', '', text)
    # è½¬æ¢ä¸ºå°å†™
    text_clean = text_clean.lower()
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™å­—æ¯ã€æ•°å­—ã€ç©ºæ ¼å’Œè¿å­—ç¬¦
    text_clean = re.sub(r'[^\w\s-]', '', text_clean)
    # å°†ç©ºæ ¼å’Œå¤šä¸ªè¿å­—ç¬¦æ›¿æ¢ä¸ºå•ä¸ªè¿å­—ç¬¦
    text_clean = re.sub(r'[-\s]+', '-', text_clean)
    # ç§»é™¤é¦–å°¾çš„è¿å­—ç¬¦
    text_clean = text_clean.strip('-')
    return text_clean

def extract_file_title(content: str) -> Tuple[str, str]:
    """æå–æ–‡ä»¶æ ‡é¢˜"""
    # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªä¸€çº§æ ‡é¢˜
    match = re.match(r'^#\s+(.+)$', content, re.MULTILINE)
    if match:
        title = match.group(1).strip()
        anchor = generate_anchor(title)
        return title, anchor
    return None, None

def extract_all_headings(content: str) -> List[Tuple[int, str, str]]:
    """æå–æ‰€æœ‰æ ‡é¢˜åŠå…¶é”šç‚¹ID"""
    headings = []
    lines = content.split('\n')
    
    for line in lines:
        match = re.match(r'^(#{1,6})\s+(.+)$', line)
        if match:
            level = len(match.group(1))
            text = match.group(2).strip()
            anchor = generate_anchor(text)
            headings.append((level, text, anchor))
    
    return headings

def fix_toc_with_title(file_path: str) -> bool:
    """ä¿®å¤ç›®å½•ï¼Œç¡®ä¿åŒ…å«æ–‡ä»¶æ ‡é¢˜"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"é”™è¯¯: æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
        return False
    
    # æŸ¥æ‰¾ç›®å½•éƒ¨åˆ†
    toc_pattern = r'(## ğŸ“‹ ç›®å½•\s*\n\n)(.*?)(\n\n---)'
    match = re.search(toc_pattern, content, re.DOTALL)
    
    if not match:
        return True  # æ²¡æœ‰ç›®å½•ï¼Œè·³è¿‡
    
    # æå–æ–‡ä»¶æ ‡é¢˜
    file_title, file_anchor = extract_file_title(content)
    if not file_title:
        return True  # æ²¡æœ‰æ–‡ä»¶æ ‡é¢˜ï¼Œè·³è¿‡
    
    # æå–æ‰€æœ‰æ ‡é¢˜
    headings = extract_all_headings(content)
    
    if len(headings) < 2:
        return True  # æ ‡é¢˜å¤ªå°‘ï¼Œè·³è¿‡
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å·²åŒ…å«æ–‡ä»¶æ ‡é¢˜
    toc_content = match.group(2)
    if file_title in toc_content or file_anchor in toc_content:
        # å·²åŒ…å«ï¼Œæ£€æŸ¥æ ¼å¼æ˜¯å¦æ­£ç¡®
        first_line = toc_content.split('\n')[0].strip()
        if first_line.startswith(f'- [{file_title}]'):
            return True  # æ ¼å¼æ­£ç¡®ï¼Œæ— éœ€ä¿®æ”¹
    
    # ç”Ÿæˆæ–°ç›®å½•
    toc_lines = []
    
    # ç¬¬ä¸€è¡Œï¼šæ–‡ä»¶æ ‡é¢˜
    toc_lines.append(f'- [{file_title}](#{file_anchor})')
    
    # ç¬¬äºŒè¡Œï¼šç›®å½•æ ‡é¢˜
    toc_lines.append(f'  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)')
    
    # å…¶ä»–æ ‡é¢˜ï¼ˆè·³è¿‡æ–‡ä»¶æ ‡é¢˜å’Œç›®å½•æ ‡é¢˜ï¼‰
    for level, text, anchor in headings:
        if level == 1:  # è·³è¿‡æ–‡ä»¶æ ‡é¢˜
            continue
        if level == 2 and text == 'ğŸ“‹ ç›®å½•':  # è·³è¿‡ç›®å½•æ ‡é¢˜
            continue
        
        indent = (level - 2) * 2
        if level == 2:
            indent = 2  # äºŒçº§æ ‡é¢˜éœ€è¦ç¼©è¿›
        toc_line = ' ' * indent + f'- [{text}](#{anchor})'
        toc_lines.append(toc_line)
    
    new_toc = '\n'.join(toc_lines)
    
    # æ›¿æ¢ç›®å½•éƒ¨åˆ†
    new_content = content[:match.start(1)] + match.group(1) + new_toc + match.group(3) + content[match.end(3):]
    
    # å†™å›æ–‡ä»¶
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
        return True
    except Exception as e:
        print(f"é”™è¯¯: æ— æ³•å†™å…¥æ–‡ä»¶ {file_path}: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    base_dir = Path(__file__).parent
    md_files = []
    
    exclude_files = ['schedule_model.md', 'README.md', 'fix_toc_structure.py', 
                     'fix_section_numbering.py', 'remove_duplicate_sections.py',
                     'comprehensive_fix_all.py', 'fix_toc_anchors.py',
                     'fix_toc_with_title.py', 'å†…å®¹å¯¹æ¯”æ£€æŸ¥æŠ¥å‘Š.md',
                     'æ–‡ä»¶æ‹†åˆ†å®Œæˆæ€»ç»“.md', 'æ–‡ä»¶æ‹†åˆ†è¿›åº¦æŠ¥å‘Š.md',
                     'ç›®å½•ç»“æ„ä¿®å¤å®ŒæˆæŠ¥å‘Š.md']
    
    for root, dirs, files in os.walk(base_dir):
        for file in files:
            if file.endswith('.md') and file not in exclude_files:
                file_path = os.path.join(root, file)
                md_files.append(file_path)
    
    print(f"æ‰¾åˆ° {len(md_files)} ä¸ªMarkdownæ–‡ä»¶")
    print("å¼€å§‹ç»Ÿä¸€ç›®å½•æ ¼å¼ï¼ˆåŒ…å«æ–‡ä»¶æ ‡é¢˜ï¼‰...\n")
    
    fixed_count = 0
    skipped_count = 0
    
    for file_path in sorted(md_files):
        rel_path = os.path.relpath(file_path, base_dir)
        if fix_toc_with_title(file_path):
            # æ£€æŸ¥æ˜¯å¦çœŸçš„ä¿®æ”¹äº†
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            toc_match = re.search(r'## ğŸ“‹ ç›®å½•\s*\n\n(.*?)\n\n---', content, re.DOTALL)
            if toc_match:
                first_line = toc_match.group(1).split('\n')[0].strip()
                if first_line.startswith('- ['):
                    print(f"âœ… å·²ä¿®å¤: {rel_path}")
                    fixed_count += 1
                else:
                    skipped_count += 1
        else:
            skipped_count += 1
    
    print(f"\nå®Œæˆï¼ä¿®å¤: {fixed_count}, è·³è¿‡: {skipped_count}")

if __name__ == '__main__':
    main()
