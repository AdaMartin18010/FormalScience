#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤é”šç‚¹é“¾æ¥ï¼Œç¡®ä¿ä¸ç®€åŒ–åçš„æ ‡é¢˜åŒ¹é…
"""

import os
import re
from pathlib import Path

def generate_anchor(text):
    """ç”Ÿæˆé”šç‚¹é“¾æ¥ï¼ˆåŸºäºæ–‡æœ¬ï¼‰"""
    # è½¬æ¢ä¸ºå°å†™ï¼Œæ›¿æ¢ç©ºæ ¼ä¸ºè¿å­—ç¬¦ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦
    anchor = text.lower()
    anchor = re.sub(r'[^\w\s-]', '', anchor)
    anchor = re.sub(r'\s+', '-', anchor)
    return anchor

def extract_file_number(filename):
    """ä»æ–‡ä»¶åæå–ç¼–å·ï¼Œå¦‚ 01.1_CPUå¾®æ¶æ„.md -> (1, 1)"""
    match = re.match(r'(\d+)\.(\d+)_', filename)
    if match:
        return (int(match.group(1)), int(match.group(2)))
    return None

def parse_toc(content):
    """è§£æç›®å½•å†…å®¹ï¼Œè¿”å›ç›®å½•è¡Œåˆ—è¡¨"""
    lines = content.split('\n')
    toc_start = -1
    toc_end = -1
    
    for i, line in enumerate(lines):
        if line.strip() == '## ğŸ“‹ ç›®å½•':
            toc_start = i
        elif toc_start >= 0 and line.strip() == '---' and i > toc_start + 2:
            toc_end = i
            break
    
    if toc_start >= 0 and toc_end > toc_start:
        return lines[toc_start:toc_end], toc_start, toc_end
    return None, -1, -1

def fix_toc_anchors(toc_lines):
    """ä¿®å¤ç›®å½•ä¸­çš„é”šç‚¹é“¾æ¥"""
    fixed_lines = []
    
    for line in toc_lines:
        # è·³è¿‡ç©ºè¡Œå’Œç›®å½•æ ‡é¢˜
        if not line.strip() or line.strip() == '## ğŸ“‹ ç›®å½•' or line.strip().startswith('- [ğŸ“‹ ç›®å½•]'):
            fixed_lines.append(line)
            continue
        
        # åŒ¹é…ç›®å½•é¡¹ï¼Œå¦‚ - [1 æ‰§è¡Œå¼•æ“](#1-æ‰§è¡Œå¼•æ“) æˆ– - [æ‰§è¡Œå¼•æ“](#æ‰§è¡Œå¼•æ“)
        match = re.match(r'(\s*)- \[(.+?)\]\(#(.+?)\)', line)
        if match:
            indent = match.group(1)
            title = match.group(2)
            old_anchor = match.group(3)
            
            # ç”Ÿæˆæ–°çš„é”šç‚¹ï¼ˆåŸºäºæ ‡é¢˜ï¼‰
            new_anchor = generate_anchor(title)
            
            # å¦‚æœé”šç‚¹ä¸åŒï¼Œæ›´æ–°å®ƒ
            if new_anchor != old_anchor:
                new_line = f"{indent}- [{title}](#{new_anchor})"
                fixed_lines.append(new_line)
            else:
                fixed_lines.append(line)
        else:
            fixed_lines.append(line)
    
    return fixed_lines

def process_file(filepath):
    """å¤„ç†å•ä¸ªæ–‡ä»¶"""
    print(f"å¤„ç†æ–‡ä»¶: {filepath}")
    
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # è§£æå¹¶ä¿®å¤ç›®å½•
    toc_lines, toc_start, toc_end = parse_toc(content)
    if toc_lines:
        fixed_toc = fix_toc_anchors(toc_lines)
        
        # æ›¿æ¢ç›®å½•
        lines = content.split('\n')
        new_lines = lines[:toc_start] + fixed_toc + lines[toc_end:]
        content = '\n'.join(new_lines)
        
        # å†™å›æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"  å®Œæˆï¼šå·²ä¿®å¤é”šç‚¹é“¾æ¥")
        return True
    else:
        print(f"  è·³è¿‡ï¼šæœªæ‰¾åˆ°ç›®å½•")
        return False

def main():
    """ä¸»å‡½æ•°"""
    base_dir = Path(__file__).parent
    
    # æŸ¥æ‰¾æ‰€æœ‰markdownæ–‡ä»¶
    md_files = list(base_dir.rglob('*.md'))
    
    # æ’é™¤READMEå’Œæ€»è§ˆæ–‡ä»¶
    exclude_patterns = ['README.md', 'æ€»è§ˆ.md', 'æ€»ç»“.md', 'è¯´æ˜.md', 'æŒ‡å—.md', 'æŠ¥å‘Š.md', 'å¤‡ä»½.md', 'fix_toc', 'simplify_toc', 'simplify_subsection', 'fix_anchors']
    md_files = [f for f in md_files if not any(p in f.name for p in exclude_patterns)]
    
    print(f"æ‰¾åˆ° {len(md_files)} ä¸ªmarkdownæ–‡ä»¶")
    
    processed = 0
    for md_file in sorted(md_files):
        if process_file(md_file):
            processed += 1
    
    print(f"\nå¤„ç†å®Œæˆï¼šå…±å¤„ç† {processed} ä¸ªæ–‡ä»¶")

if __name__ == '__main__':
    main()
