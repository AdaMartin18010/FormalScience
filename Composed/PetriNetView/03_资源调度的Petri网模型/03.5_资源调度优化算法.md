# 03.5 èµ„æºè°ƒåº¦ä¼˜åŒ–ç®—æ³•

> **å­ä¸»é¢˜**: 03.5
> **æ‰€å±ä¸»é¢˜**: 03 èµ„æºè°ƒåº¦çš„Petriç½‘æ¨¡å‹
> **æœ€åæ›´æ–°**: 2025-12-02

---

## ğŸ“‹ ç›®å½•

- [03.5 èµ„æºè°ƒåº¦ä¼˜åŒ–ç®—æ³•](#035-èµ„æºè°ƒåº¦ä¼˜åŒ–ç®—æ³•)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1 åŸºäºPetriç½‘çš„èµ„æºä¼˜åŒ–æ¨¡å‹](#1-åŸºäºpetriç½‘çš„èµ„æºä¼˜åŒ–æ¨¡å‹)
  - [2 PetriRLæ¡†æ¶ï¼ˆPetriç½‘+å¼ºåŒ–å­¦ä¹ ï¼‰](#2-petrirlæ¡†æ¶petriç½‘å¼ºåŒ–å­¦ä¹ )
  - [3 é—ä¼ ç®—æ³•ä¼˜åŒ–](#3-é—ä¼ ç®—æ³•ä¼˜åŒ–)
  - [4 å®é™…æ¡ˆä¾‹ï¼šåŠå¯¼ä½“åˆ¶é€ èµ„æºè°ƒåº¦](#4-å®é™…æ¡ˆä¾‹åŠå¯¼ä½“åˆ¶é€ èµ„æºè°ƒåº¦)

---

## 1 åŸºäºPetriç½‘çš„èµ„æºä¼˜åŒ–æ¨¡å‹

**ä¼˜åŒ–ç›®æ ‡**ï¼š

$$
\min \text{Cost}(M, \sigma) = \sum_{t \in \sigma} c_t
$$

çº¦æŸæ¡ä»¶ï¼š

- èµ„æºæœ‰ç•Œæ€§
- æ­»é”è‡ªç”±
- å…¬å¹³æ€§

---

## 2 PetriRLæ¡†æ¶ï¼ˆPetriç½‘+å¼ºåŒ–å­¦ä¹ ï¼‰

**PetriRL** (2024 arXiv)ï¼šç»“åˆPetriç½‘å»ºæ¨¡å’Œæ·±åº¦å¼ºåŒ–å­¦ä¹ è¿›è¡Œè°ƒåº¦ä¼˜åŒ–ã€‚

**æ ¸å¿ƒæ€æƒ³**ï¼š

- **çŠ¶æ€**ï¼šPetriç½‘æ ‡è®° $M$
- **åŠ¨ä½œ**ï¼šé€‰æ‹©ç‚¹ç«å“ªä¸ªä½¿èƒ½å˜è¿ $t$
- **å¥–åŠ±**ï¼šå®Œæˆä»»åŠ¡æ•°ã€èµ„æºåˆ©ç”¨ç‡ç­‰

```python
import torch
import torch.nn as nn

class PetriRLAgent:
    """PetriRLæ™ºèƒ½è°ƒåº¦ä»£ç†"""

    def __init__(self, state_dim, action_dim):
        self.state_dim = state_dim
        self.action_dim = action_dim

        # DQNç½‘ç»œ
        self.q_network = nn.Sequential(
            nn.Linear(state_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, action_dim)
        )

        self.optimizer = torch.optim.Adam(self.q_network.parameters(), lr=0.001)

    def encode_marking(self, pn, M):
        """å°†Petriç½‘æ ‡è®°ç¼–ç ä¸ºçŠ¶æ€å‘é‡"""
        state = []
        for p in sorted(pn.places):
            state.append(M.get(p, 0))
        return torch.tensor(state, dtype=torch.float32)

    def select_action(self, pn, M, epsilon=0.1):
        """Îµ-greedyç­–ç•¥é€‰æ‹©åŠ¨ä½œ"""
        import random

        enabled = [t for t in pn.transitions if is_enabled(pn, M, t)]

        if not enabled:
            return None

        if random.random() < epsilon:
            # æ¢ç´¢ï¼šéšæœºé€‰æ‹©
            return random.choice(enabled)
        else:
            # åˆ©ç”¨ï¼šé€‰æ‹©Qå€¼æœ€é«˜çš„
            state = self.encode_marking(pn, M)
            q_values = self.q_network(state)

            # åªè€ƒè™‘ä½¿èƒ½çš„å˜è¿
            trans_to_idx = {t: i for i, t in enumerate(sorted(pn.transitions))}
            enabled_q = [(t, q_values[trans_to_idx[t]].item()) for t in enabled]

            return max(enabled_q, key=lambda x: x[1])[0]

    def train(self, experience_buffer):
        """è®­ç»ƒQç½‘ç»œ"""
        # DQNè®­ç»ƒé€»è¾‘
        pass

# ä½¿ç”¨PetriRL
agent = PetriRLAgent(state_dim=10, action_dim=20)
selected_transition = agent.select_action(pn, current_marking)
print(f"PetriRLé€‰æ‹©: {selected_transition}")
```

---

## 3 é—ä¼ ç®—æ³•ä¼˜åŒ–

```python
class GeneticSchedulingOptimizer:
    """é—ä¼ ç®—æ³•ä¼˜åŒ–Petriç½‘è°ƒåº¦"""

    def __init__(self, pn, M0, population_size=100):
        self.pn = pn
        self.M0 = M0
        self.population_size = population_size

    def encode_firing_sequence(self, sigma):
        """ç¼–ç ç‚¹ç«åºåˆ—ä¸ºæŸ“è‰²ä½“"""
        trans_to_idx = {t: i for i, t in enumerate(sorted(self.pn.transitions))}
        return [trans_to_idx[t] for t in sigma]

    def fitness(self, sigma):
        """è®¡ç®—é€‚åº”åº¦ï¼ˆæœ€å°åŒ–makespanï¼‰"""
        M = self.M0.copy()
        time = 0

        for t in sigma:
            if is_enabled(self.pn, M, t):
                M = fire_transition(self.pn, M, t)
                time += 1  # ç®€åŒ–ï¼šæ¯ä¸ªå˜è¿è€—æ—¶1
            else:
                return float('inf')  # éæ³•åºåˆ—

        return time

    def evolve(self, generations=1000):
        """é—ä¼ ç®—æ³•è¿›åŒ–"""
        # åˆå§‹åŒ–ç§ç¾¤
        population = self._initialize_population()

        for gen in range(generations):
            # è¯„ä¼°é€‚åº”åº¦
            fitness_scores = [(chromo, self.fitness(chromo)) for chromo in population]
            fitness_scores.sort(key=lambda x: x[1])

            # é€‰æ‹©ã€äº¤å‰ã€å˜å¼‚
            # ï¼ˆå®ç°ç•¥ï¼‰

        return fitness_scores[0][0]  # è¿”å›æœ€ä¼˜è§£
```

---

## 4 å®é™…æ¡ˆä¾‹ï¼šåŠå¯¼ä½“åˆ¶é€ èµ„æºè°ƒåº¦

**åŸºäº2024å¹´ç ”ç©¶ï¼šç»„åˆè®¾å¤‡çš„Petriç½‘å»ºæ¨¡ä¸è°ƒåº¦**

```python
def create_semiconductor_manufacturing():
    """
    åŠå¯¼ä½“æ™¶åœ†åˆ¶é€ Petriç½‘æ¨¡å‹

    è®¾å¤‡ï¼š
    - 3å°å…‰åˆ»æœº
    - 2å°èš€åˆ»æœº
    - 4å°æ¸…æ´—æœº

    å·¥ä»¶ï¼š
    - 10ç‰‡æ™¶åœ†
    - æ¯ç‰‡éœ€ç»è¿‡ï¼šå…‰åˆ» -> èš€åˆ» -> æ¸…æ´—
    """
    pn = PetriNet()

    # è®¾å¤‡èµ„æº
    pn.add_place('p_litho', tokens=3)   # å…‰åˆ»æœº
    pn.add_place('p_etch', tokens=2)    # èš€åˆ»æœº
    pn.add_place('p_clean', tokens=4)   # æ¸…æ´—æœº

    # æ™¶åœ†
    for i in range(10):
        wafer = f'W{i+1}'

        # é˜¶æ®µ1ï¼šå…‰åˆ»
        pn.add_place(f'p_{wafer}_ready', tokens=1)
        pn.add_transition(f't_{wafer}_litho')
        pn.add_arc(f'p_{wafer}_ready', f't_{wafer}_litho')
        pn.add_arc('p_litho', f't_{wafer}_litho')
        pn.add_place(f'p_{wafer}_after_litho', tokens=0)
        pn.add_arc(f't_{wafer}_litho', f'p_{wafer}_after_litho')
        pn.add_arc(f't_{wafer}_litho', 'p_litho')  # é‡Šæ”¾å…‰åˆ»æœº

        # é˜¶æ®µ2ï¼šèš€åˆ»
        pn.add_transition(f't_{wafer}_etch')
        pn.add_arc(f'p_{wafer}_after_litho', f't_{wafer}_etch')
        pn.add_arc('p_etch', f't_{wafer}_etch')
        pn.add_place(f'p_{wafer}_after_etch', tokens=0)
        pn.add_arc(f't_{wafer}_etch', f'p_{wafer}_after_etch')
        pn.add_arc(f't_{wafer}_etch', 'p_etch')

        # é˜¶æ®µ3ï¼šæ¸…æ´—
        pn.add_transition(f't_{wafer}_clean')
        pn.add_arc(f'p_{wafer}_after_etch', f't_{wafer}_clean')
        pn.add_arc('p_clean', f't_{wafer}_clean')
        pn.add_place(f'p_{wafer}_done', tokens=0)
        pn.add_arc(f't_{wafer}_clean', f'p_{wafer}_done')
        pn.add_arc(f't_{wafer}_clean', 'p_clean')

    return pn

# ä¼˜åŒ–
semi_pn = create_semiconductor_manufacturing()

# ä½¿ç”¨PetriRLä¼˜åŒ–è°ƒåº¦ç­–ç•¥
agent = PetriRLAgent(state_dim=30, action_dim=30)
# è®­ç»ƒ...

print("åŠå¯¼ä½“åˆ¶é€ è°ƒåº¦ä¼˜åŒ–ï¼š")
print("  ç“¶é¢ˆï¼šèš€åˆ»æœºï¼ˆ2å°ï¼Œæœ€å°‘ï¼‰")
print("  å»ºè®®ï¼šå¢åŠ èš€åˆ»æœºæˆ–ä¼˜åŒ–è°ƒåº¦é¡ºåº")
```

---

**è¿”å›**: [03 èµ„æºè°ƒåº¦çš„Petriç½‘æ¨¡å‹](README.md)

**å‚è€ƒæ–‡çŒ®**ï¼š

1. arXiv:2402.00046 (2024). "PetriRL: Deep Reinforcement Learning for Job Shop Scheduling using Petri Nets"
2. ç»„åˆè®¾å¤‡çš„Petriç½‘å»ºæ¨¡ä¸è°ƒåº¦ç»¼è¿° (2024)
