#!/usr/bin/env python3
"""
æ‰¹é‡TOCç”Ÿæˆå·¥å…·
è‡ªåŠ¨ä¸ºMarkdownæ–‡æ¡£ç”Ÿæˆå¹¶æ’å…¥ç›®å½•ï¼ˆTable of Contentsï¼‰
æ”¯æŒåŒè¯­æ ¼å¼å’Œå¤šçº§æ ‡é¢˜
"""

import os
import re
from pathlib import Path
from typing import List, Dict, Tuple
import json

class TOCGenerator:
    def __init__(self):
        self.toc_pattern = re.compile(r'##\s*ç›®å½•\s*\|\s*Table of Contents', re.IGNORECASE)
        self.heading_pattern = re.compile(r'^(#{1,6})\s+(.+)$')
        
    def has_toc(self, content: str) -> bool:
        """æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²æœ‰TOC"""
        return bool(self.toc_pattern.search(content))
    
    def extract_headings(self, content: str) -> List[Dict]:
        """æå–æ‰€æœ‰æ ‡é¢˜"""
        lines = content.split('\n')
        headings = []
        
        for i, line in enumerate(lines, 1):
            match = self.heading_pattern.match(line)
            if match:
                level = len(match.group(1))
                title = match.group(2).strip()
                
                # è·³è¿‡TOCæ ‡é¢˜æœ¬èº«
                if level == 2 and self.toc_pattern.search(line):
                    continue
                
                # è·³è¿‡å…ƒæ•°æ®è¡Œï¼ˆå¦‚æœåœ¨æ–‡æ¡£å¼€å¤´çš„å‰10è¡Œï¼‰
                if i <= 10 and ('ç‰ˆæœ¬' in title or 'çŠ¶æ€' in title or 'æ—¶é—´' in title):
                    continue
                
                headings.append({
                    'line': i,
                    'level': level,
                    'title': title,
                    'raw': line
                })
        
        return headings
    
    def generate_anchor(self, title: str) -> str:
        """ç”ŸæˆGitHubé£æ ¼çš„é”šç‚¹"""
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™ä¸­è‹±æ–‡ã€æ•°å­—ã€ç©ºæ ¼ã€ä¸‹åˆ’çº¿
        anchor = re.sub(r'[^\w\s\u4e00-\u9fff-]', '', title)
        # è½¬å°å†™
        anchor = anchor.lower()
        # ç©ºæ ¼è½¬è¿å­—ç¬¦
        anchor = anchor.replace(' ', '-')
        # ç§»é™¤å¤šä½™çš„è¿å­—ç¬¦
        anchor = re.sub(r'-+', '-', anchor)
        anchor = anchor.strip('-')
        return anchor
    
    def generate_toc_item(self, heading: Dict) -> str:
        """ç”Ÿæˆå•ä¸ªTOCæ¡ç›®"""
        level = heading['level']
        title = heading['title']
        anchor = self.generate_anchor(title)
        
        # ç¼©è¿›ï¼ˆlevel 1 ä¸æ˜¾ç¤ºï¼Œä»level 2å¼€å§‹ï¼‰
        indent = '  ' * (level - 2) if level >= 2 else ''
        
        # ç”Ÿæˆé“¾æ¥
        toc_line = f"{indent}- [{title}](#{anchor})"
        
        return toc_line
    
    def generate_toc(self, headings: List[Dict]) -> str:
        """ç”Ÿæˆå®Œæ•´çš„TOC"""
        toc_lines = []
        toc_lines.append("## ç›®å½• | Table of Contents")
        toc_lines.append("")
        
        for heading in headings:
            # åªåŒ…å«level 1-4çš„æ ‡é¢˜
            if heading['level'] <= 4:
                toc_lines.append(self.generate_toc_item(heading))
        
        toc_lines.append("")
        toc_lines.append("---")
        toc_lines.append("")
        
        return '\n'.join(toc_lines)
    
    def insert_toc(self, content: str, toc: str) -> str:
        """åœ¨æ–‡æ¡£ä¸­æ’å…¥TOC"""
        lines = content.split('\n')
        
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªH2æ ‡é¢˜çš„ä½ç½®ï¼ˆä¸»æ ‡é¢˜H1ä¹‹åï¼‰
        insert_pos = 0
        found_h1 = False
        
        for i, line in enumerate(lines):
            if line.startswith('# ') and not found_h1:
                found_h1 = True
                insert_pos = i + 1
                continue
            
            # å¦‚æœå·²ç»æ‰¾åˆ°H1ï¼Œä¸”å½“å‰æ˜¯ç¬¬ä¸€ä¸ªå†…å®¹è¡Œ
            if found_h1 and line.strip() and not line.startswith('---'):
                insert_pos = i
                break
        
        # å¦‚æœæ‰¾ä¸åˆ°åˆé€‚çš„ä½ç½®ï¼Œæ’å…¥åœ¨å¼€å¤´
        if insert_pos == 0:
            insert_pos = 3  # ç•™å‡ºæ ‡é¢˜å’Œç©ºè¡Œ
        
        # æ’å…¥TOC
        new_lines = lines[:insert_pos] + toc.split('\n') + lines[insert_pos:]
        
        return '\n'.join(new_lines)
    
    def process_file(self, file_path: Path, dry_run: bool = False) -> Dict:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        result = {
            'path': str(file_path),
            'status': 'unchanged',
            'message': ''
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰TOC
            if self.has_toc(content):
                result['status'] = 'skipped'
                result['message'] = 'å·²æœ‰TOC'
                return result
            
            # æå–æ ‡é¢˜
            headings = self.extract_headings(content)
            
            if not headings:
                result['status'] = 'skipped'
                result['message'] = 'æ— æ ‡é¢˜'
                return result
            
            if len(headings) < 2:
                result['status'] = 'skipped'
                result['message'] = 'æ ‡é¢˜å¤ªå°‘'
                return result
            
            # ç”ŸæˆTOC
            toc = self.generate_toc(headings)
            
            # æ’å…¥TOC
            new_content = self.insert_toc(content, toc)
            
            # å†™å…¥æ–‡ä»¶ï¼ˆé™¤éæ˜¯dry runï¼‰
            if not dry_run:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                result['status'] = 'added'
                result['message'] = f'æ·»åŠ TOCï¼ŒåŒ…å«{len(headings)}ä¸ªæ ‡é¢˜'
            else:
                result['status'] = 'would_add'
                result['message'] = f'å°†æ·»åŠ TOCï¼ŒåŒ…å«{len(headings)}ä¸ªæ ‡é¢˜'
            
            result['heading_count'] = len(headings)
            
        except Exception as e:
            result['status'] = 'error'
            result['message'] = str(e)
        
        return result
    
    def process_directory(self, dir_path: Path, pattern: str = '*.md', 
                          exclude_patterns: List[str] = None, 
                          dry_run: bool = False) -> List[Dict]:
        """æ‰¹é‡å¤„ç†ç›®å½•"""
        if exclude_patterns is None:
            exclude_patterns = ['README.md', 'GLOSSARY.md', 'FAQ.md', 
                              'LEARNING_PATHS.md', '*REPORT*.md', 
                              '*SUMMARY*.md', '*COMPLETION*.md']
        
        results = []
        
        for md_file in sorted(dir_path.rglob(pattern)):
            # æ£€æŸ¥æ’é™¤è§„åˆ™
            should_exclude = False
            for exclude_pattern in exclude_patterns:
                if '*' in exclude_pattern:
                    # ç®€å•çš„é€šé…ç¬¦åŒ¹é…
                    regex = exclude_pattern.replace('*', '.*')
                    if re.search(regex, md_file.name, re.IGNORECASE):
                        should_exclude = True
                        break
                elif md_file.name == exclude_pattern:
                    should_exclude = True
                    break
            
            if should_exclude:
                continue
            
            result = self.process_file(md_file, dry_run=dry_run)
            results.append(result)
            
            # æ‰“å°è¿›åº¦
            status_icon = {
                'added': 'âœ…',
                'would_add': 'ğŸ”„',
                'skipped': 'â­ï¸',
                'unchanged': '-',
                'error': 'âŒ'
            }.get(result['status'], '?')
            
            print(f"{status_icon} {result['status']:12} {md_file.name:60} {result['message']}")
        
        return results
    
    def generate_report(self, results: List[Dict], output_file: str):
        """ç”Ÿæˆå¤„ç†æŠ¥å‘Š"""
        report = []
        report.append("# æ‰¹é‡TOCç”ŸæˆæŠ¥å‘Š\n")
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        report.append(f"**å¤„ç†æ–‡ä»¶æ•°**: {len(results)}\n\n")
        report.append("---\n\n")
        
        # ç»Ÿè®¡
        status_counts = {}
        for r in results:
            status = r['status']
            status_counts[status] = status_counts.get(status, 0) + 1
        
        report.append("## ğŸ“Š å¤„ç†ç»Ÿè®¡\n\n")
        for status, count in sorted(status_counts.items()):
            icon = {
                'added': 'âœ… å·²æ·»åŠ ',
                'would_add': 'ğŸ”„ å°†æ·»åŠ ',
                'skipped': 'â­ï¸ å·²è·³è¿‡',
                'unchanged': '- æœªå˜åŒ–',
                'error': 'âŒ é”™è¯¯'
            }.get(status, status)
            report.append(f"- **{icon}**: {count} ä¸ª\n")
        report.append("\n")
        
        # æˆåŠŸæ·»åŠ çš„æ–‡ä»¶
        added = [r for r in results if r['status'] in ['added', 'would_add']]
        if added:
            report.append(f"## âœ… æˆåŠŸå¤„ç†çš„æ–‡æ¡£ ({len(added)}ä¸ª)\n\n")
            for r in added:
                msg = r.get('message', '')
                report.append(f"- `{r['path']}` - {msg}\n")
            report.append("\n")
        
        # è·³è¿‡çš„æ–‡ä»¶
        skipped = [r for r in results if r['status'] == 'skipped']
        if skipped:
            report.append(f"## â­ï¸ è·³è¿‡çš„æ–‡æ¡£ ({len(skipped)}ä¸ª)\n\n")
            for r in skipped:
                msg = r.get('message', '')
                report.append(f"- `{r['path']}` - {msg}\n")
            report.append("\n")
        
        # é”™è¯¯çš„æ–‡ä»¶
        errors = [r for r in results if r['status'] == 'error']
        if errors:
            report.append(f"## âŒ å¤„ç†é”™è¯¯ ({len(errors)}ä¸ª)\n\n")
            for r in errors:
                report.append(f"- `{r['path']}`\n")
                report.append(f"  - é”™è¯¯: {r['message']}\n")
            report.append("\n")
        
        # å†™å…¥æ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(report)
        
        print(f"\næŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='æ‰¹é‡ä¸ºMarkdownæ–‡æ¡£ç”ŸæˆTOC')
    parser.add_argument('directory', help='è¦å¤„ç†çš„ç›®å½•')
    parser.add_argument('--dry-run', action='store_true', help='é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶')
    parser.add_argument('--exclude', nargs='+', help='è¦æ’é™¤çš„æ–‡ä»¶æ¨¡å¼', default=[])
    parser.add_argument('--output', default='TOC_GENERATION_REPORT.md', help='æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶')
    
    args = parser.parse_args()
    
    generator = TOCGenerator()
    
    dir_path = Path(args.directory)
    if not dir_path.exists():
        print(f"é”™è¯¯ï¼šç›®å½• {dir_path} ä¸å­˜åœ¨")
        return
    
    print(f"{'=' * 80}")
    print(f"æ‰¹é‡TOCç”Ÿæˆå·¥å…·")
    print(f"{'=' * 80}")
    print(f"ç›®æ ‡ç›®å½•: {dir_path}")
    print(f"æ¨¡å¼: {'é¢„è§ˆæ¨¡å¼' if args.dry_run else 'æ‰§è¡Œæ¨¡å¼'}")
    print(f"{'=' * 80}\n")
    
    # å¤„ç†æ–‡ä»¶
    results = generator.process_directory(dir_path, exclude_patterns=args.exclude, dry_run=args.dry_run)
    
    # ç”ŸæˆæŠ¥å‘Š
    generator.generate_report(results, args.output)
    
    # æ€»ç»“
    print(f"\n{'=' * 80}")
    print(f"å¤„ç†å®Œæˆï¼")
    print(f"{'=' * 80}")
    added_count = len([r for r in results if r['status'] in ['added', 'would_add']])
    print(f"{'é¢„è®¡' if args.dry_run else 'å·²'}æ·»åŠ TOC: {added_count} ä¸ªæ–‡æ¡£")
    print(f"è¯¦ç»†æŠ¥å‘Š: {args.output}")

if __name__ == '__main__':
    main()

