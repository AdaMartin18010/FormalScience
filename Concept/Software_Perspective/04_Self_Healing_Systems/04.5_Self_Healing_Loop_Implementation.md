# 4.5 自愈闭环实现

## 概述

本文档提供**OTLP + OPA + GitOps**三位一体自愈系统的**完整实施指南**，从零到生产级部署。

## 系统架构

### 完整拓扑

```
┌────────────────────────────────────────────────────────┐
│  应用层 (Application Layer)                            │
│  - 集成 OTEL SDK                                       │
│  - 发送 Metrics/Traces/Logs                            │
└────────────────┬───────────────────────────────────────┘
                 │ OTLP (gRPC :4317 / HTTP :4318)
                 ↓
┌────────────────────────────────────────────────────────┐
│  感知层 (Observability Layer)                          │
│  ┌──────────────────┐    ┌──────────────────┐        │
│  │ OTEL Collector   │    │  Prometheus      │        │
│  │ - 接收 OTLP      │───>│  - 存储指标      │        │
│  │ - 转换格式       │    │  - 计算告警      │        │
│  └──────────────────┘    └─────────┬────────┘        │
└──────────────────────────────────────┼─────────────────┘
                                       │ AlertManager Webhook
                                       ↓
┌────────────────────────────────────────────────────────┐
│  决策层 (Policy Layer)                                 │
│  ┌──────────────────────────────────────────────┐     │
│  │  OPA Gateway                                 │     │
│  │  - 接收告警 JSON                             │     │
│  │  - 执行 Rego 策略                            │     │
│  │  - 返回决策 {allow: true, action: "rollback"}│     │
│  └──────────────────┬───────────────────────────┘     │
└─────────────────────┼──────────────────────────────────┘
                      │ HTTP POST
                      ↓
┌────────────────────────────────────────────────────────┐
│  执行层 (Execution Layer)                              │
│  ┌──────────────────────────────────────────────┐     │
│  │  PR Controller (轻量 Go 服务)               │     │
│  │  - 接收 OPA 决策                             │     │
│  │  - Clone Git repo                            │     │
│  │  - 修改配置 (image tag / replicas)           │     │
│  │  - 创建 PR                                   │     │
│  └──────────────────┬───────────────────────────┘     │
└─────────────────────┼──────────────────────────────────┘
                      │ Git Push
                      ↓
┌────────────────────────────────────────────────────────┐
│  同步层 (GitOps Layer)                                 │
│  ┌────────────┐                ┌──────────────────┐   │
│  │ Git Repo   │                │  ArgoCD          │   │
│  │ - configs/ │<───pull────────│  - 检测变化      │   │
│  │ - overlays/│                │  - 自动同步      │   │
│  └────────────┘                └────────┬─────────┘   │
└──────────────────────────────────────────┼──────────────┘
                                           │ kubectl apply
                                           ↓
┌────────────────────────────────────────────────────────┐
│  Kubernetes Cluster                                    │
│  - Deployment updated                                  │
│  - Pods rolled back                                    │
└────────────────┬───────────────────────────────────────┘
                 │ 状态反馈
                 └──> (回到感知层，验证修复效果)
```

---

## 实施步骤（2 周计划）

### Week 1: 基础设施搭建

#### Day 1-2: 部署 OpenTelemetry Collector

**安装**：
```bash
# 使用 Helm 安装
helm repo add open-telemetry https://open-telemetry.github.io/opentelemetry-helm-charts
helm install otel-collector open-telemetry/opentelemetry-collector \
  --namespace observability --create-namespace \
  --values otel-collector-values.yaml
```

**配置** (`otel-collector-values.yaml`):
```yaml
mode: deployment

config:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318
  
  processors:
    batch:
      timeout: 10s
      send_batch_size: 1024
    
    memory_limiter:
      limit_mib: 512
      spike_limit_mib: 128
  
  exporters:
    prometheus:
      endpoint: "0.0.0.0:8889"
      namespace: app
    
    logging:
      loglevel: info
  
  service:
    pipelines:
      metrics:
        receivers: [otlp]
        processors: [memory_limiter, batch]
        exporters: [prometheus, logging]
      
      traces:
        receivers: [otlp]
        processors: [memory_limiter, batch]
        exporters: [logging]

ports:
  otlp-grpc:
    enabled: true
    containerPort: 4317
    servicePort: 4317
    protocol: TCP
  
  otlp-http:
    enabled: true
    containerPort: 4318
    servicePort: 4318
    protocol: TCP
  
  prometheus:
    enabled: true
    containerPort: 8889
    servicePort: 8889
    protocol: TCP
```

**验证**：
```bash
# 检查 Pod 状态
kubectl get pods -n observability

# 测试 OTLP 端点
curl http://otel-collector:8889/metrics
```

#### Day 3-4: 部署 Prometheus + Alertmanager

**安装**：
```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace observability \
  --values prometheus-values.yaml
```

**配置** (`prometheus-values.yaml`):
```yaml
prometheus:
  prometheusSpec:
    additionalScrapeConfigs:
    - job_name: 'otel-collector'
      static_configs:
      - targets: ['otel-collector:8889']
    
    # 告警规则
    additionalPrometheusRulesMap:
      self-heal-rules:
        groups:
        - name: self_healing
          interval: 30s
          rules:
          - alert: HighErrorRate
            expr: |
              rate(http_requests_total{status=~"5.."}[5m]) /
              rate(http_requests_total[5m]) > 0.05
            for: 5m
            labels:
              severity: critical
              auto_heal: "true"
            annotations:
              summary: "Error rate > 5% for 5 minutes"
              service: "{{ $labels.service }}"
          
          - alert: HighRestartCount
            expr: |
              increase(kube_pod_container_status_restarts_total[10m]) > 3
            labels:
              severity: warning
              auto_heal: "true"
            annotations:
              summary: "Pod restarted > 3 times in 10 minutes"

alertmanager:
  config:
    route:
      group_by: ['alertname', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'opa-gateway'
      routes:
      - matchers:
        - auto_heal = "true"
        receiver: 'opa-gateway'
    
    receivers:
    - name: 'opa-gateway'
      webhook_configs:
      - url: 'http://opa-gateway.default.svc:8080/v1/data/selfheal/handle_alert'
        send_resolved: false
        http_config:
          follow_redirects: true
```

#### Day 5-6: 部署 OPA + Gatekeeper

**安装 OPA Gateway**：
```bash
kubectl create namespace policy-system

# 部署 OPA
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opa-gateway
  namespace: policy-system
spec:
  replicas: 2
  selector:
    matchLabels:
      app: opa-gateway
  template:
    metadata:
      labels:
        app: opa-gateway
    spec:
      containers:
      - name: opa
        image: openpolicyagent/opa:latest
        args:
        - "run"
        - "--server"
        - "--addr=0.0.0.0:8181"
        - "--set=decision_logs.console=true"
        - "/policies"
        ports:
        - containerPort: 8181
        volumeMounts:
        - name: policies
          mountPath: /policies
      volumes:
      - name: policies
        configMap:
          name: opa-policies
---
apiVersion: v1
kind: Service
metadata:
  name: opa-gateway
  namespace: policy-system
spec:
  selector:
    app: opa-gateway
  ports:
  - port: 8080
    targetPort: 8181
EOF
```

**OPA 策略** (`opa-policies.rego`):
```rego
package selfheal

import future.keywords.if
import future.keywords.in

# 默认不允许自愈
default allow_rollback = false
default allow_scale = false

# 允许回滚的条件
allow_rollback if {
    input.alert.labels.alertname == "HighErrorRate"
    input.alert.labels.severity == "critical"
    input.metrics.error_rate > 0.05
    input.metrics.restart_count > 3
    
    # 时间窗口限制：最多 2 次/30 分钟
    count(recent_rollbacks) < 2
}

# 允许扩容的条件
allow_scale if {
    input.alert.labels.alertname == "HighCPU"
    input.metrics.cpu_usage > 0.8
    input.current_replicas < input.max_replicas
}

# 决策输出
decision = {
    "allow_rollback": allow_rollback,
    "allow_scale": allow_scale,
    "action": action,
    "reason": reason
}

action = "rollback" if allow_rollback
action = "scale_up" if {
    not allow_rollback
    allow_scale
}
action = "none" if {
    not allow_rollback
    not allow_scale
}

reason = sprintf("Error rate %.2f%% > threshold 5%%", [input.metrics.error_rate * 100]) if allow_rollback
reason = sprintf("CPU usage %.0f%% > threshold 80%%", [input.metrics.cpu_usage * 100]) if allow_scale
reason = "No action needed" if action == "none"

# 历史回滚记录（模拟，实际应从数据库读取）
recent_rollbacks = []
```

**部署策略**：
```bash
kubectl create configmap opa-policies \
  --from-file=selfheal.rego=opa-policies.rego \
  -n policy-system
```

#### Day 7: 部署 ArgoCD

```bash
kubectl create namespace argocd
kubectl apply -n argocd -f \
  https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# 启用 selfHeal
kubectl patch application myapp -n argocd --type merge -p '
spec:
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
'
```

---

### Week 2: 自愈控制器开发

#### PR Controller 实现（Go）

**main.go**:
```go
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "net/http"
    "os"
    "os/exec"
    
    "github.com/google/go-github/v50/github"
    "golang.org/x/oauth2"
)

type OPADecision struct {
    AllowRollback bool   `json:"allow_rollback"`
    AllowScale    bool   `json:"allow_scale"`
    Action        string `json:"action"`
    Reason        string `json:"reason"`
}

type AlertPayload struct {
    Alert struct {
        Labels      map[string]string `json:"labels"`
        Annotations map[string]string `json:"annotations"`
    } `json:"alert"`
}

func main() {
    http.HandleFunc("/webhook", handleWebhook)
    log.Println("PR Controller listening on :9090")
    log.Fatal(http.ListenAndServe(":9090", nil))
}

func handleWebhook(w http.ResponseWriter, r *http.Request) {
    var payload AlertPayload
    if err := json.NewDecoder(r.Body).Decode(&payload); err != nil {
        http.Error(w, err.Error(), http.StatusBadRequest)
        return
    }
    
    // 查询 OPA 决策
    decision, err := queryOPA(payload)
    if err != nil {
        http.Error(w, err.Error(), http.StatusInternalServerError)
        return
    }
    
    // 执行动作
    if decision.AllowRollback {
        if err := performRollback(payload); err != nil {
            log.Printf("Rollback failed: %v", err)
            http.Error(w, err.Error(), http.StatusInternalServerError)
            return
        }
    }
    
    w.WriteHeader(http.StatusOK)
    fmt.Fprintf(w, "Action: %s, Reason: %s", decision.Action, decision.Reason)
}

func queryOPA(payload AlertPayload) (*OPADecision, error) {
    // 构造 OPA 输入
    input := map[string]interface{}{
        "alert": payload.Alert,
        "metrics": map[string]interface{}{
            "error_rate":     0.08,  // 实际应从 Prometheus 查询
            "restart_count":  5,
            "cpu_usage":      0.85,
        },
        "current_replicas": 3,
        "max_replicas":     10,
    }
    
    // 调用 OPA API
    resp, err := http.Post(
        "http://opa-gateway.policy-system.svc:8080/v1/data/selfheal/decision",
        "application/json",
        toJSON(input),
    )
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()
    
    var result struct {
        Result OPADecision `json:"result"`
    }
    if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
        return nil, err
    }
    
    return &result.Result, nil
}

func performRollback(payload AlertPayload) error {
    service := payload.Alert.Labels["service"]
    
    // Clone Git 仓库
    repoPath := "/tmp/configs"
    if err := gitClone("https://github.com/myorg/configs.git", repoPath); err != nil {
        return err
    }
    
    // 修改配置（回滚到上一版本）
    manifestPath := fmt.Sprintf("%s/overlays/prod/%s-deployment.yaml", repoPath, service)
    if err := rollbackImageTag(manifestPath); err != nil {
        return err
    }
    
    // 提交并创建 PR
    commitMsg := fmt.Sprintf("Auto rollback %s: error rate exceeded threshold", service)
    if err := gitCommitAndPush(repoPath, commitMsg); err != nil {
        return err
    }
    
    if err := createGitHubPR(service, commitMsg); err != nil {
        return err
    }
    
    log.Printf("Rollback PR created for %s", service)
    return nil
}

func gitClone(repo, path string) error {
    cmd := exec.Command("git", "clone", repo, path)
    return cmd.Run()
}

func rollbackImageTag(manifestPath string) error {
    // 简化实现：将 image tag 从 v1.2.0 改为 v1.1.0
    // 实际应解析 YAML 并获取上一版本
    cmd := exec.Command("sed", "-i", "s/image: myapp:v1.2.0/image: myapp:v1.1.0/", manifestPath)
    return cmd.Run()
}

func gitCommitAndPush(repoPath, message string) error {
    commands := [][]string{
        {"git", "-C", repoPath, "add", "."},
        {"git", "-C", repoPath, "commit", "-m", message},
        {"git", "-C", repoPath, "push", "origin", "main"},
    }
    
    for _, cmd := range commands {
        if err := exec.Command(cmd[0], cmd[1:]...).Run(); err != nil {
            return err
        }
    }
    return nil
}

func createGitHubPR(service, message string) error {
    ctx := context.Background()
    ts := oauth2.StaticTokenSource(
        &oauth2.Token{AccessToken: os.Getenv("GITHUB_TOKEN")},
    )
    tc := oauth2.NewClient(ctx, ts)
    client := github.NewClient(tc)
    
    newPR := &github.NewPullRequest{
        Title: github.String(message),
        Head:  github.String("main"),
        Base:  github.String("main"),
        Body:  github.String("Automated rollback by self-healing system"),
    }
    
    _, _, err := client.PullRequests.Create(ctx, "myorg", "configs", newPR)
    return err
}

func toJSON(v interface{}) *bytes.Reader {
    b, _ := json.Marshal(v)
    return bytes.NewReader(b)
}
```

**部署**：
```bash
# 构建镜像
docker build -t myorg/pr-controller:v1.0 .

# 部署到 K8s
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pr-controller
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pr-controller
  template:
    metadata:
      labels:
        app: pr-controller
    spec:
      containers:
      - name: controller
        image: myorg/pr-controller:v1.0
        env:
        - name: GITHUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: github-token
              key: token
        ports:
        - containerPort: 9090
---
apiVersion: v1
kind: Service
metadata:
  name: pr-controller
  namespace: default
spec:
  selector:
    app: pr-controller
  ports:
  - port: 8080
    targetPort: 9090
EOF
```

---

## 端到端测试

### 混沌实验

**场景 1：模拟高错误率**

```bash
# 使用 Chaos Mesh 注入错误
kubectl apply -f - <<EOF
apiVersion: chaos-mesh.org/v1alpha1
kind: HTTPChaos
metadata:
  name: inject-errors
  namespace: default
spec:
  mode: all
  selector:
    namespaces:
    - default
    labelSelectors:
      app: myapp
  target: Response
  abort: true
  duration: 10m
  scheduler:
    cron: "@every 1m"
EOF
```

**预期结果**：
```
1. Prometheus 检测到错误率 > 5%
2. Alertmanager 发送 Webhook 到 OPA
3. OPA 策略判断：allow_rollback = true
4. PR Controller 创建回滚 PR
5. ArgoCD 同步回滚
6. 错误率恢复正常
总耗时：< 2 分钟
```

**验证**：
```bash
# 查看告警
kubectl port-forward -n observability svc/prometheus-alertmanager 9093:9093
# 访问 http://localhost:9093

# 查看 OPA 决策日志
kubectl logs -n policy-system deployment/opa-gateway

# 查看 Git PR
gh pr list --repo myorg/configs
```

---

## 生产优化

### 1. 限流防抖

**问题**：避免频繁回滚

**解决**：
```rego
package selfheal

# 限流：最多 2 次/30 分钟
allow_rollback if {
    # ... 其他条件 ...
    
    # 查询最近 30 分钟的回滚记录
    recent_rollbacks := http.send({
        "method": "GET",
        "url": "http://metrics-api/recent_rollbacks?service=myapp&window=30m"
    }).body
    
    count(recent_rollbacks) < 2
}
```

### 2. 金丝雀验证

**问题**：回滚后仍可能有问题

**解决**：
```yaml
# ArgoCD 配置
apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: myapp
spec:
  strategy:
    canary:
      steps:
      - setWeight: 10
      - pause: {duration: 5m}  # 观察 5 分钟
      - setWeight: 50
      - pause: {duration: 10m}
      analysis:
        templates:
        - templateName: error-rate-check
        args:
        - name: threshold
          value: "0.05"
```

### 3. 通知与审计

**Slack 通知**：
```go
func notifySlack(action, service, reason string) {
    payload := map[string]interface{}{
        "text": fmt.Sprintf(":warning: Auto-healing action taken\nService: %s\nAction: %s\nReason: %s", 
            service, action, reason),
    }
    http.Post(os.Getenv("SLACK_WEBHOOK"), "application/json", toJSON(payload))
}
```

**审计日志**：
```sql
-- 记录所有自愈动作
CREATE TABLE self_heal_actions (
    id SERIAL PRIMARY KEY,
    timestamp TIMESTAMP DEFAULT NOW(),
    service VARCHAR(255),
    action VARCHAR(50),
    reason TEXT,
    decision JSON,
    pr_url VARCHAR(512),
    success BOOLEAN
);
```

---

## 监控面板

### Grafana Dashboard JSON

```json
{
  "dashboard": {
    "title": "Self-Healing System",
    "panels": [
      {
        "title": "Auto-Healing Actions (24h)",
        "targets": [{
          "expr": "sum(self_heal_actions_total) by (action)"
        }],
        "type": "timeseries"
      },
      {
        "title": "MTTR",
        "targets": [{
          "expr": "avg(self_heal_mttr_seconds)"
        }],
        "type": "stat"
      },
      {
        "title": "Success Rate",
        "targets": [{
          "expr": "sum(self_heal_success_total) / sum(self_heal_actions_total)"
        }],
        "type": "gauge"
      }
    ]
  }
}
```

---

## 成本分析

### 资源需求

| 组件 | CPU | 内存 | 存储 | 副本 | 成本/月 |
|-----|-----|------|------|------|---------|
| OTEL Collector | 0.5 核 | 512 MB | - | 2 | $20 |
| Prometheus | 2 核 | 4 GB | 100 GB | 2 | $150 |
| OPA | 0.5 核 | 256 MB | - | 2 | $15 |
| PR Controller | 0.2 核 | 128 MB | - | 1 | $5 |
| ArgoCD | 1 核 | 1 GB | 10 GB | 2 | $60 |
| **总计** | **4.7 核** | **6 GB** | **110 GB** | - | **$250** |

### ROI 计算

**传统运维成本**：
```
值班工程师：2 人 × $8K/月 = $16K/月
平均故障：10 次/月 × 30 min × $200/小时 = $1K/月
总计：$17K/月
```

**自愈系统**：
```
基础设施：$250/月
人工介入：1 次/月 × 30 min × $200/小时 = $100/月
总计：$350/月

节省：$17K - $350 = $16.65K/月 (98%)
ROI：16650 / 250 = 66 倍
```

---

## 关键洞察

### 洞察 1：60 秒黄金窗口

**MTTR 分解**：
```
0-10s:   OTLP 采集指标
10-30s:  Prometheus 触发告警
30-40s:  OPA 策略判断
40-50s:  创建 Git PR
50-60s:  ArgoCD 同步回滚
60s+:    验证恢复

关键：每个环节都要优化
```

### 洞察 2：策略是核心

**系统质量 = 策略质量**

- 好的策略：精准触发，误报率 < 1%
- 差的策略：频繁误触发，反而增加故障

### 洞察 3：渐进式推广

**不要一步到位**：
```
阶段 1（1 周）：非生产环境验证
阶段 2（2 周）：生产环境单个服务
阶段 3（1 月）：扩展到 10 个服务
阶段 4（3 月）：全量服务
```

---

## 相关主题

- [4.1 自愈架构原理](./04.1_Self_Healing_Architecture.md)
- [4.2 OTLP 可观测性](./04.2_OTLP_Observability.md)
- [4.3 OPA 策略引擎](./04.3_OPA_Policy_Engine.md)
- [4.4 GitOps 声明式修复](./04.4_GitOps_Declarative_Remediation.md)

---

**导航**：[返回自愈系统](./README.md) | [← 上一节：GitOps 修复](./04.4_GitOps_Declarative_Remediation.md) | [下一章：配置管理 →](../05_Configuration_Scaling/README.md)

