# 4.2 OTLP 统一可观测性

## 核心定义

**OTLP**（OpenTelemetry Protocol）：统一的可观测性数据采集、传输、处理协议，整合了 Metrics、Logs、Traces 三大支柱。

## 为什么需要 OTLP？

### 传统可观测性的碎片化

```
问题 1：供应商锁定
- Prometheus → Prometheus 格式
- Datadog → Datadog Agent
- New Relic → New Relic SDK

切换供应商 = 重写所有埋点代码

问题 2：数据孤岛
- Metrics: Prometheus
- Logs: Elasticsearch
- Traces: Jaeger
三者无法关联，排查问题困难

问题 3：高维护成本
- 每个服务需要集成 3+ 工具
- 不同语言不同 SDK
- 配置复杂，学习成本高
```

### OTLP 解决方案

```
统一标准：
- 一套 SDK
- 一个 Protocol
- 一个 Collector

结果：
✅ 埋点一次，导出多种后端
✅ Metrics/Logs/Traces 自动关联
✅ 切换供应商只需改配置
```

---

## OTLP 架构

### 完整数据流

```
┌──────────────────────────────────────────────────────┐
│  Application (Instrumented)                          │
│  ┌────────────────────────────────────────────────┐ │
│  │  OpenTelemetry SDK                             │ │
│  │  - Auto-instrumentation (HTTP, DB, etc.)       │ │
│  │  - Manual spans (business logic)               │ │
│  │  - Context propagation (W3C TraceContext)      │ │
│  └────────────────┬───────────────────────────────┘ │
└───────────────────┼──────────────────────────────────┘
                    │ OTLP (gRPC/HTTP)
                    ↓
┌──────────────────────────────────────────────────────┐
│  OTEL Collector (Agent Mode)                         │
│  ┌────────────────────────────────────────────────┐ │
│  │  Receivers: OTLP, Prometheus, Jaeger           │ │
│  │  Processors: Batch, Filter, Transform          │ │
│  │  Exporters: Prometheus, Jaeger, Loki, ...      │ │
│  └────────────────┬───────────────────────────────┘ │
└───────────────────┼──────────────────────────────────┘
                    │
        ┌───────────┼───────────┐
        │           │           │
        ↓           ↓           ↓
  ┌─────────┐ ┌─────────┐ ┌─────────┐
  │Prometheus│Jaeger    │Loki     │
  └─────────┘ └─────────┘ └─────────┘
```

### 三大信号类型

#### 1. Metrics（指标）

**定义**：聚合的数值型时间序列数据

**类型**：
```
Counter（计数器）：
- 只增不减
- 例：http_requests_total

Gauge（仪表）：
- 可增可减
- 例：cpu_usage_percent

Histogram（直方图）：
- 分布统计
- 例：http_request_duration_seconds

Summary（摘要）：
- 分位数统计
- 例：http_request_duration_quantile
```

**示例**：
```go
// Go SDK
import "go.opentelemetry.io/otel/metric"

meter := otel.Meter("myservice")

// Counter
requestCounter, _ := meter.Int64Counter(
    "http.server.requests",
    metric.WithDescription("HTTP request count"),
    metric.WithUnit("{request}"),
)

// Gauge
cpuGauge, _ := meter.Float64ObservableGauge(
    "system.cpu.usage",
    metric.WithDescription("CPU usage percentage"),
    metric.WithUnit("{percent}"),
    metric.WithFloat64Callback(func(ctx context.Context, o metric.Float64Observer) error {
        o.Observe(getCPUUsage())
        return nil
    }),
)

// Histogram
requestDuration, _ := meter.Float64Histogram(
    "http.server.duration",
    metric.WithDescription("HTTP request duration"),
    metric.WithUnit("ms"),
)

// 使用
requestCounter.Add(ctx, 1, metric.WithAttributes(
    attribute.String("http.method", "GET"),
    attribute.String("http.route", "/api/users"),
))

start := time.Now()
// ... handle request ...
requestDuration.Record(ctx, time.Since(start).Milliseconds())
```

#### 2. Traces（追踪）

**定义**：请求在分布式系统中的完整路径

**概念**：
```
Trace（追踪）：一次完整的请求
├── Span 1: API Gateway (100ms)
│   ├── Span 2: Auth Service (20ms)
│   └── Span 3: User Service (60ms)
│       ├── Span 4: Database Query (40ms)
│       └── Span 5: Cache Get (5ms)
└── Span 6: Response (10ms)
```

**示例**：
```python
# Python SDK
from opentelemetry import trace
from opentelemetry.trace import Status, StatusCode

tracer = trace.get_tracer(__name__)

@app.route('/api/users/<user_id>')
def get_user(user_id):
    # 自动创建 Span
    with tracer.start_as_current_span("get_user") as span:
        span.set_attribute("user.id", user_id)
        
        # 嵌套 Span
        with tracer.start_as_current_span("fetch_from_cache") as cache_span:
            user = cache.get(f"user:{user_id}")
            if user:
                cache_span.set_attribute("cache.hit", True)
                return user
            cache_span.set_attribute("cache.hit", False)
        
        # 数据库查询
        with tracer.start_as_current_span("fetch_from_db") as db_span:
            try:
                user = db.query(f"SELECT * FROM users WHERE id={user_id}")
                db_span.set_status(Status(StatusCode.OK))
                return user
            except Exception as e:
                db_span.set_status(Status(StatusCode.ERROR, str(e)))
                db_span.record_exception(e)
                raise
```

**Context Propagation（上下文传播）**：
```
Service A → Service B → Service C

HTTP Headers:
traceparent: 00-4bf92f3577b34da6a3ce929d0e0e4736-00f067aa0ba902b7-01
            ││ └─ Trace ID                    └─ Span ID       └─ Flags
            │└─ Version
            └─ Format

Service A:
  Span ID: 00f067aa0ba902b7
  
Service B (接收到 traceparent):
  Parent Span ID: 00f067aa0ba902b7
  Span ID: 0af7651916cd43dd  # 新生成
  
Service C (接收到 Service B 的 traceparent):
  Parent Span ID: 0af7651916cd43dd
  Span ID: 00f067aa0ba902b8
```

#### 3. Logs（日志）

**定义**：结构化的事件记录

**传统 vs OTLP 日志**：

```
传统日志（纯文本）:
2025-10-27 10:23:45 ERROR Failed to connect to database

OTLP 日志（结构化 + 关联）:
{
  "timestamp": "2025-10-27T10:23:45.123Z",
  "severity": "ERROR",
  "body": "Failed to connect to database",
  "attributes": {
    "service.name": "user-api",
    "db.system": "postgresql",
    "db.connection_string": "postgres://localhost:5432"
  },
  "trace_id": "4bf92f3577b34da6a3ce929d0e0e4736",
  "span_id": "00f067aa0ba902b7",
  "resource": {
    "service.name": "user-api",
    "service.version": "1.2.0",
    "host.name": "pod-12345"
  }
}
```

**自动关联**：
```python
import logging
from opentelemetry.instrumentation.logging import LoggingInstrumentor

# 初始化
LoggingInstrumentor().instrument()

logger = logging.getLogger(__name__)

# 日志自动包含 trace_id 和 span_id
with tracer.start_as_current_span("process_order"):
    logger.info("Processing order", extra={"order_id": 12345})
    # 输出自动包含当前 span 的 trace_id
```

---

## OTLP Collector 深度解析

### 三大组件

#### 1. Receivers（接收器）

**作用**：接收不同格式的数据

```yaml
receivers:
  # OTLP 原生
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318
  
  # Prometheus Pull
  prometheus:
    config:
      scrape_configs:
      - job_name: 'myapp'
        static_configs:
        - targets: ['localhost:8080']
  
  # Jaeger 兼容
  jaeger:
    protocols:
      grpc:
        endpoint: 0.0.0.0:14250
      thrift_http:
        endpoint: 0.0.0.0:14268
  
  # Zipkin 兼容
  zipkin:
    endpoint: 0.0.0.0:9411
```

#### 2. Processors（处理器）

**作用**：转换、过滤、聚合数据

**常用处理器**：

```yaml
processors:
  # 批处理（性能优化）
  batch:
    timeout: 10s
    send_batch_size: 1024
    send_batch_max_size: 2048
  
  # 内存限制
  memory_limiter:
    limit_mib: 512
    spike_limit_mib: 128
    check_interval: 1s
  
  # 属性操作
  attributes:
    actions:
    - key: environment
      value: production
      action: insert
    - key: sensitive_data
      action: delete
  
  # 过滤（丢弃不需要的数据）
  filter:
    metrics:
      exclude:
        match_type: regexp
        metric_names:
        - ".*debug.*"
  
  # 资源检测
  resourcedetection:
    detectors: [env, system, docker, kubernetes]
    timeout: 5s
  
  # Span 处理
  span:
    name:
      from_attributes: ["http.method", "http.route"]
      separator: " "
```

**自定义处理器示例**（降采样）：

```yaml
processors:
  # 降采样：只保留 10% 的 trace
  probabilistic_sampler:
    sampling_percentage: 10
  
  # 尾部采样：只保留慢请求和错误请求
  tail_sampling:
    policies:
    - name: errors
      type: status_code
      status_code: {status_codes: [ERROR]}
    - name: slow
      type: latency
      latency: {threshold_ms: 1000}
    - name: sample_normal
      type: probabilistic
      probabilistic: {sampling_percentage: 1}
```

#### 3. Exporters（导出器）

**作用**：发送数据到后端

```yaml
exporters:
  # Prometheus（Metrics）
  prometheus:
    endpoint: "0.0.0.0:8889"
    namespace: "myapp"
  
  # Prometheus Remote Write
  prometheusremotewrite:
    endpoint: "http://prometheus:9090/api/v1/write"
  
  # Jaeger（Traces）
  jaeger:
    endpoint: jaeger:14250
    tls:
      insecure: true
  
  # OTLP（转发到另一个 Collector）
  otlp:
    endpoint: otel-collector-gateway:4317
    tls:
      insecure: true
  
  # Loki（Logs）
  loki:
    endpoint: http://loki:3100/loki/api/v1/push
  
  # Elasticsearch（Logs）
  elasticsearch:
    endpoints: [http://elasticsearch:9200]
    index: 'logs-myapp'
  
  # 云厂商
  awsxray:
    region: us-west-2
  
  googlecloud:
    project: my-project
  
  azuremonitor:
    instrumentation_key: "abc123"
```

### Pipeline 配置

```yaml
service:
  pipelines:
    # Metrics 管道
    metrics:
      receivers: [otlp, prometheus]
      processors: [memory_limiter, batch, resourcedetection]
      exporters: [prometheus, prometheusremotewrite]
    
    # Traces 管道
    traces:
      receivers: [otlp, jaeger, zipkin]
      processors: [memory_limiter, batch, tail_sampling, span]
      exporters: [jaeger, otlp]
    
    # Logs 管道
    logs:
      receivers: [otlp]
      processors: [memory_limiter, batch, attributes]
      exporters: [loki, elasticsearch]
```

---

## 自动埋点 vs 手动埋点

### 自动埋点（Auto-Instrumentation）

**支持的库/框架**：

| 语言 | 自动支持 |
|-----|---------|
| **Java** | JDBC, Spring, Kafka, gRPC, HTTP clients |
| **Python** | Flask, Django, Requests, PostgreSQL, Redis |
| **Go** | net/http, gRPC, database/sql |
| **Node.js** | Express, HTTP, MongoDB, MySQL |

**Java 示例**：
```bash
# 下载 Agent
curl -L -O https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/latest/download/opentelemetry-javaagent.jar

# 启动应用（零代码修改）
java -javaagent:opentelemetry-javaagent.jar \
     -Dotel.service.name=my-app \
     -Dotel.traces.exporter=otlp \
     -Dotel.metrics.exporter=otlp \
     -Dotel.exporter.otlp.endpoint=http://localhost:4317 \
     -jar myapp.jar
```

**Python 示例**：
```bash
# 安装
pip install opentelemetry-distro opentelemetry-exporter-otlp
opentelemetry-bootstrap -a install

# 运行（零代码修改）
opentelemetry-instrument \
    --traces_exporter otlp \
    --metrics_exporter otlp \
    --service_name my-app \
    --exporter_otlp_endpoint http://localhost:4317 \
    python app.py
```

**自动捕获的信息**：
```
HTTP 请求：
- Method, URL, Status Code
- Request/Response headers (可配置)
- Duration

数据库查询：
- SQL 语句（可脱敏）
- 执行时间
- 连接信息

gRPC 调用：
- Method, Status
- Request/Response metadata
```

### 手动埋点（Manual Instrumentation）

**业务逻辑埋点**：

```python
from opentelemetry import trace

tracer = trace.get_tracer(__name__)

@app.route('/api/orders', methods=['POST'])
def create_order():
    with tracer.start_as_current_span("create_order") as span:
        # 业务参数
        order_data = request.json
        span.set_attribute("order.amount", order_data['amount'])
        span.set_attribute("order.items_count", len(order_data['items']))
        
        # 业务逻辑 1：验证库存
        with tracer.start_as_current_span("validate_inventory") as inv_span:
            inventory_ok = check_inventory(order_data['items'])
            inv_span.set_attribute("inventory.ok", inventory_ok)
            if not inventory_ok:
                inv_span.add_event("Inventory insufficient")
                return {"error": "Out of stock"}, 400
        
        # 业务逻辑 2：计算价格
        with tracer.start_as_current_span("calculate_price") as price_span:
            total_price = calculate_total(order_data['items'])
            price_span.set_attribute("order.total_price", total_price)
            span.set_attribute("order.total_price", total_price)  # 也记录到父 span
        
        # 业务逻辑 3：扣款
        with tracer.start_as_current_span("charge_payment") as pay_span:
            try:
                payment_result = charge(user_id, total_price)
                pay_span.set_attribute("payment.status", "success")
                pay_span.set_attribute("payment.transaction_id", payment_result['tx_id'])
            except PaymentError as e:
                pay_span.set_status(Status(StatusCode.ERROR))
                pay_span.record_exception(e)
                return {"error": "Payment failed"}, 500
        
        # 创建订单
        order = save_order(order_data, payment_result)
        span.set_attribute("order.id", order.id)
        
        return {"order_id": order.id}, 201
```

---

## 关联查询：从 Metrics 到 Traces 到 Logs

### 典型场景

**问题**：P95 延迟飙升到 5 秒

**步骤 1：Metrics 定位时间和服务**

```promql
# Grafana 查询
histogram_quantile(0.95,
  rate(http_request_duration_seconds_bucket[5m])
)

# 发现：user-api 在 10:23-10:28 延迟飙升
```

**步骤 2：Traces 定位慢请求**

```
在 Jaeger UI:
1. 输入时间范围：10:23-10:28
2. 输入服务：user-api
3. 过滤：duration > 5s

找到 Trace ID: 4bf92f3577b34da6a3ce929d0e0e4736

查看 Trace:
├── user-api: GET /api/users/123 (5200ms)
    ├── auth-service: validate_token (50ms) ✅
    └── database: SELECT * FROM users (5100ms) ❌ 慢！
```

**步骤 3：Logs 定位根因**

```
在 Loki/Grafana:
查询：{service="user-api", trace_id="4bf92f3577b34da6a3ce929d0e0e4736"}

日志：
10:25:34 ERROR [trace_id=4bf92...] Database connection pool exhausted
10:25:34 WARN  [trace_id=4bf92...] Waiting for available connection (5000ms)
10:25:39 INFO  [trace_id=4bf92...] Query completed

根因：连接池耗尽，等待连接 5 秒
```

### 自动关联配置

**Grafana Exemplars**（Prometheus + Jaeger 关联）：

```yaml
# Prometheus 配置
scrape_configs:
- job_name: 'myapp'
  scrape_interval: 15s
  static_configs:
  - targets: ['localhost:8080']
  # 启用 exemplar
  metric_relabel_configs:
  - source_labels: [__name__]
    regex: 'http_request_duration_seconds.*'
    action: keep
  
# Grafana 配置
datasources:
- name: Prometheus
  type: prometheus
  url: http://prometheus:9090
  jsonData:
    exemplarTraceIdDestinations:
    - name: trace_id
      datasourceUid: jaeger-uid
```

**效果**：
- 在 Grafana Metrics 图表中
- 点击任意数据点
- 自动跳转到对应的 Trace

---

## 性能优化

### 1. 采样策略

**Head Sampling（头部采样）**：
```yaml
# Collector 配置
processors:
  probabilistic_sampler:
    sampling_percentage: 10  # 只保留 10%
```

**Tail Sampling（尾部采样）**：
```yaml
processors:
  tail_sampling:
    decision_wait: 10s  # 等待 span 完整后再决定
    policies:
    - name: always_sample_errors
      type: status_code
      status_code: {status_codes: [ERROR]}
    - name: sample_slow_requests
      type: latency
      latency: {threshold_ms: 1000}
    - name: sample_1_percent_normal
      type: probabilistic
      probabilistic: {sampling_percentage: 1}
```

**对比**：

| 采样方式 | 优点 | 缺点 | 适用场景 |
|---------|------|------|---------|
| **Head** | 简单、低延迟 | 可能丢失重要trace | 高流量系统 |
| **Tail** | 智能保留重要trace | 需要缓存、有延迟 | 低流量、调试 |

### 2. 批处理

```yaml
processors:
  batch:
    timeout: 10s           # 最长等待时间
    send_batch_size: 1024  # 达到 1024 条立即发送
    send_batch_max_size: 2048  # 最大批次大小
```

**性能提升**：
- 单条发送：1000 QPS → 网络开销 1000 次/秒
- 批量发送：1000 QPS → 网络开销 10 次/秒（100 倍优化）

### 3. 属性限制

```yaml
processors:
  attributes:
    actions:
    # 限制字符串长度
    - key: http.url
      action: truncate
      limit: 128
    
    # 删除敏感数据
    - key: password
      action: delete
    - key: credit_card
      action: delete
```

---

## 成本分析

### 数据量估算

**假设**：1000 QPS 的微服务

```
Traces:
- 每请求 1 个 trace，平均 5 个 span
- 每 span 约 1 KB
- 1000 QPS × 5 span × 1 KB = 5 MB/s = 13 TB/月

Metrics:
- 100 个指标，15s 采集间隔
- 每指标 ~100 bytes
- 100 × 100 bytes × 4 (每分钟) × 60 × 24 × 30 = 17 GB/月

Logs:
- 每请求 10 条日志
- 每条 500 bytes
- 1000 QPS × 10 × 500 bytes = 5 MB/s = 13 TB/月

总计：26 TB/月（未压缩）
```

### 成本优化

| 策略 | 效果 | 实施难度 |
|-----|------|---------|
| **采样** | -90% traces | 简单 |
| **压缩** | -70% 存储 | 简单（自动）|
| **保留时间** | 只保留 7 天 | 简单 |
| **降精度** | Metrics 60s → 300s | 中等 |
| **过滤** | 去除调试日志 | 简单 |

**优化后**：
```
Traces: 13 TB × 10% (采样) × 30% (压缩) = 0.4 TB/月
Metrics: 17 GB × 30% (压缩) = 5 GB/月
Logs: 13 TB × 50% (过滤) × 30% (压缩) = 2 TB/月

总计：2.4 TB/月

存储成本（S3）：2.4 TB × $0.023/GB = $56/月
```

---

## 关键洞察

### 洞察 1：统一 > 完美

```
不要追求"最好的" Metrics/Traces/Logs 工具
而是追求"统一的"标准

好处：
- 切换成本低
- 多云/混合云友好
- 团队学习成本低
```

### 洞察 2：自动埋点覆盖 80%

```
80% 的可观测性需求：
- HTTP 请求
- 数据库查询
- 缓存访问
- 消息队列

这些都可以自动埋点，无需手写代码
```

### 洞察 3：关联是核心价值

```
单独的 Metrics/Traces/Logs 价值有限

真正价值：
Metrics（发现问题）
  ↓ trace_id
Traces（定位瓶颈）
  ↓ span_id
Logs（根因分析）
```

---

## 相关主题

- [4.1 自愈系统架构](./04.1_Self_Healing_Architecture.md)
- [4.3 OPA 策略引擎](./04.3_OPA_Policy_Engine.md)
- [4.4 GitOps 声明式修复](./04.4_GitOps_Declarative_Remediation.md)
- [6.1 可观测性三大支柱](../06_Observability_Governance/06.1_Three_Pillars_Observability.md)

---

**导航**：[返回自愈系统](./README.md) | [← 上一节：自愈架构](./04.1_Self_Healing_Architecture.md) | [下一节：OPA 策略引擎 →](./04.3_OPA_Policy_Engine.md)

