# PACå­¦ä¹ æ¡†æ¶ï¼ˆProbably Approximately Correct Learning Framework)

## ç›®å½• | Table of Contents

- [PACå­¦ä¹ æ¡†æ¶ï¼ˆProbably Approximately Correct Learning Framework)](#pacå­¦ä¹ æ¡†æ¶probably-approximately-correct-learning-framework)
- [ç›®å½•](#ç›®å½•)
- [å¼•è¨€](#å¼•è¨€)
  - [æ ¸å¿ƒæ€æƒ³](#æ ¸å¿ƒæ€æƒ³)
  - [ä¸Goldå­¦ä¹ çš„å¯¹æ¯”](#ä¸goldå­¦ä¹ çš„å¯¹æ¯”)
- [PACå­¦ä¹ çš„å½¢å¼åŒ–å®šä¹‰](#pacå­¦ä¹ çš„å½¢å¼åŒ–å®šä¹‰)
  - [1. åŸºæœ¬è®¾å®š](#1-åŸºæœ¬è®¾å®š)
    - [å®ä¾‹ç©ºé—´ï¼ˆInstance Spaceï¼‰](#å®ä¾‹ç©ºé—´instance-space)
    - [æ¦‚å¿µç±»ï¼ˆConcept Classï¼‰](#æ¦‚å¿µç±»concept-class)
    - [æ•°æ®åˆ†å¸ƒï¼ˆData Distributionï¼‰](#æ•°æ®åˆ†å¸ƒdata-distribution)
    - [è®­ç»ƒæ ·æœ¬](#è®­ç»ƒæ ·æœ¬)
  - [2. æ³›åŒ–è¯¯å·®ï¼ˆGeneralization Errorï¼‰](#2-æ³›åŒ–è¯¯å·®generalization-error)
  - [3. PACå¯å­¦ä¹ æ€§å®šä¹‰](#3-pacå¯å­¦ä¹ æ€§å®šä¹‰)
- [PACå¯å­¦ä¹ æ€§](#pacå¯å­¦ä¹ æ€§)
  - [1. å¯å®ç°æƒ…å†µï¼ˆRealizable Caseï¼‰](#1-å¯å®ç°æƒ…å†µrealizable-case)
  - [2. ä¸å¯çŸ¥æƒ…å†µï¼ˆAgnostic Caseï¼‰](#2-ä¸å¯çŸ¥æƒ…å†µagnostic-case)
- [æ ·æœ¬å¤æ‚åº¦](#æ ·æœ¬å¤æ‚åº¦)
  - [1. å®šä¹‰](#1-å®šä¹‰)
  - [2. æœ‰é™å‡è®¾ç©ºé—´](#2-æœ‰é™å‡è®¾ç©ºé—´)
  - [3. æ— é™å‡è®¾ç©ºé—´](#3-æ— é™å‡è®¾ç©ºé—´)
- [æœ‰é™å‡è®¾ç©ºé—´çš„PACå­¦ä¹ ](#æœ‰é™å‡è®¾ç©ºé—´çš„pacå­¦ä¹ )
  - [1. ä¸€è‡´æ€§ç®—æ³•ï¼ˆConsistency Algorithmï¼‰](#1-ä¸€è‡´æ€§ç®—æ³•consistency-algorithm)
  - [2. ä¾‹å­ï¼šçŸ©å½¢å­¦ä¹ ](#2-ä¾‹å­çŸ©å½¢å­¦ä¹ )
- [VCç»´ç†è®º](#vcç»´ç†è®º)
  - [1. VCç»´å®šä¹‰](#1-vcç»´å®šä¹‰)
  - [2. åŸºæœ¬PACå®šç†](#2-åŸºæœ¬pacå®šç†)
  - [3. VCç»´çš„è®¡ç®—](#3-vcç»´çš„è®¡ç®—)
    - [ä¾‹å­1ï¼šçº¿æ€§åˆ†ç±»å™¨åœ¨ â„Â²](#ä¾‹å­1çº¿æ€§åˆ†ç±»å™¨åœ¨-â„Â²)
    - [ä¾‹å­2ï¼šç¥ç»ç½‘ç»œ](#ä¾‹å­2ç¥ç»ç½‘ç»œ)
- [ä¸å¯çŸ¥PACå­¦ä¹ ](#ä¸å¯çŸ¥pacå­¦ä¹ )
  - [1. é—®é¢˜è®¾å®š](#1-é—®é¢˜è®¾å®š)
  - [2. ä¸å¯çŸ¥å­¦ä¹ ç›®æ ‡](#2-ä¸å¯çŸ¥å­¦ä¹ ç›®æ ‡)
  - [3. ç»éªŒé£é™©æœ€å°åŒ–ï¼ˆEmpirical Risk Minimization, ERMï¼‰](#3-ç»éªŒé£é™©æœ€å°åŒ–empirical-risk-minimization-erm)
- [PACå­¦ä¹ ä¸ç¥ç»ç½‘ç»œ](#pacå­¦ä¹ ä¸ç¥ç»ç½‘ç»œ)
  - [1. ç¥ç»ç½‘ç»œçš„VCç»´](#1-ç¥ç»ç½‘ç»œçš„vcç»´)
  - [2. è¿‡å‚æ•°åŒ–çš„æ‚–è®º](#2-è¿‡å‚æ•°åŒ–çš„æ‚–è®º)
  - [3. PAC-Bayesç†è®º](#3-pac-bayesç†è®º)
- [å±€é™æ€§ä¸æ‰©å±•](#å±€é™æ€§ä¸æ‰©å±•)
  - [1. PACæ¡†æ¶çš„å±€é™æ€§](#1-pacæ¡†æ¶çš„å±€é™æ€§)
    - [1.1 i.i.d.å‡è®¾](#11-iidå‡è®¾)
    - [1.2 æœ€åæƒ…å†µåˆ†æ](#12-æœ€åæƒ…å†µåˆ†æ)
    - [1.3 è®¡ç®—å¤æ‚æ€§](#13-è®¡ç®—å¤æ‚æ€§)
  - [2. æ‰©å±•æ–¹å‘](#2-æ‰©å±•æ–¹å‘)
    - [2.1 åœ¨çº¿å­¦ä¹ ï¼ˆOnline Learningï¼‰](#21-åœ¨çº¿å­¦ä¹ online-learning)
    - [2.2 ä¸»åŠ¨å­¦ä¹ ï¼ˆActive Learningï¼‰](#22-ä¸»åŠ¨å­¦ä¹ active-learning)
    - [2.3 è¿ç§»å­¦ä¹ ï¼ˆTransfer Learningï¼‰](#23-è¿ç§»å­¦ä¹ transfer-learning)
- [æ€»ç»“](#æ€»ç»“)
  - [æ ¸å¿ƒè¦ç‚¹](#æ ¸å¿ƒè¦ç‚¹)
  - [ä¸å…¶ä»–å­¦ä¹ ç†è®ºçš„å…³ç³»](#ä¸å…¶ä»–å­¦ä¹ ç†è®ºçš„å…³ç³»)
  - [å¯¹AIçš„å¯ç¤º](#å¯¹aiçš„å¯ç¤º)
  - [å“²å­¦åæ€](#å“²å­¦åæ€)
- [å‚è€ƒæ–‡çŒ®](#å‚è€ƒæ–‡çŒ®)
  - [åŸºç¡€ç†è®º](#åŸºç¡€ç†è®º)
  - [VCç»´](#vcç»´)
  - [ç°ä»£æ•™æ](#ç°ä»£æ•™æ)
  - [ç¥ç»ç½‘ç»œ](#ç¥ç»ç½‘ç»œ)

---

## ç›®å½•

- [å¼•è¨€](#å¼•è¨€)
- [PACå­¦ä¹ çš„å½¢å¼åŒ–å®šä¹‰](#pacå­¦ä¹ çš„å½¢å¼åŒ–å®šä¹‰)
- [PACå¯å­¦ä¹ æ€§](#pacå¯å­¦ä¹ æ€§)
- [æ ·æœ¬å¤æ‚åº¦](#æ ·æœ¬å¤æ‚åº¦)
- [æœ‰é™å‡è®¾ç©ºé—´çš„PACå­¦ä¹ ](#æœ‰é™å‡è®¾ç©ºé—´çš„pacå­¦ä¹ )
- [VCç»´ç†è®º](#vcç»´ç†è®º)
- [ä¸å¯çŸ¥PACå­¦ä¹ ](#ä¸å¯çŸ¥pacå­¦ä¹ )
- [PACå­¦ä¹ ä¸ç¥ç»ç½‘ç»œ](#pacå­¦ä¹ ä¸ç¥ç»ç½‘ç»œ)
- [å±€é™æ€§ä¸æ‰©å±•](#å±€é™æ€§ä¸æ‰©å±•)
- [æ€»ç»“](#æ€»ç»“)
- [å‚è€ƒæ–‡çŒ®](#å‚è€ƒæ–‡çŒ®)

---

## å¼•è¨€

**PACå­¦ä¹ æ¡†æ¶**ï¼ˆProbably Approximately Correct Learning Frameworkï¼‰æ˜¯ç”±Leslie Valiantäº1984å¹´æå‡ºçš„è®¡ç®—å­¦ä¹ ç†è®ºçš„åŸºç¡€æ¡†æ¶ã€‚

### æ ¸å¿ƒæ€æƒ³

> **ä¸€ä¸ªæ¦‚å¿µæ˜¯å¯å­¦ä¹ çš„ï¼Œå¦‚æœå­˜åœ¨ä¸€ä¸ªç®—æ³•ï¼Œèƒ½å¤Ÿåœ¨å¤šé¡¹å¼æ—¶é—´å†…ï¼Œä»¥é«˜æ¦‚ç‡å­¦ä¹ åˆ°ä¸€ä¸ªè¿‘ä¼¼æ­£ç¡®çš„å‡è®¾ã€‚**

**å…³é”®è¯**ï¼š

- **Probably**ï¼ˆé«˜æ¦‚ç‡ï¼‰ï¼šå…è®¸å°æ¦‚ç‡å¤±è´¥
- **Approximately**ï¼ˆè¿‘ä¼¼ï¼‰ï¼šå…è®¸å°è¯¯å·®
- **Correct**ï¼ˆæ­£ç¡®ï¼‰ï¼šåœ¨æ•°æ®åˆ†å¸ƒä¸Šè¡¨ç°å¥½

### ä¸Goldå­¦ä¹ çš„å¯¹æ¯”

| ç»´åº¦ | Goldå­¦ä¹  | PACå­¦ä¹  | å‚è€ƒæ–‡çŒ® |
|------|---------|---------|----------|
| **ç›®æ ‡** | ç²¾ç¡®è¯†åˆ«è¯­è¨€ | è¿‘ä¼¼å­¦ä¹ æ¦‚å¿µ | [Valiant, 1984](https://dl.acm.org/doi/10.1145/1968.1972) |
| **è¯¯å·®** | ä¸å…è®¸ | å…è®¸å°è¯¯å·® Îµ | [Wikipedia: PAC Learning](https://en.wikipedia.org/wiki/Probably_approximately_correct_learning) |
| **æ¦‚ç‡** | å¿…é¡»æˆåŠŸ | é«˜æ¦‚ç‡æˆåŠŸ (1-Î´) | |
| **æ—¶é—´** | æ— é™åˆ¶ | å¤šé¡¹å¼æ—¶é—´ | |
| **å®ç”¨æ€§** | ç†è®ºæ¨¡å‹ | æ›´è´´è¿‘å®é™… | |

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: PAC Learning](https://en.wikipedia.org/wiki/Probably_approximately_correct_learning)
- [Valiant, 1984](https://dl.acm.org/doi/10.1145/1968.1972) - A Theory of the Learnable

---

## PACå­¦ä¹ çš„å½¢å¼åŒ–å®šä¹‰

### 1. åŸºæœ¬è®¾å®š

#### å®ä¾‹ç©ºé—´ï¼ˆInstance Spaceï¼‰

```text
ğ’³ï¼šå®ä¾‹çš„é›†åˆ
```

**ä¾‹å­**ï¼š

- å›¾åƒè¯†åˆ«ï¼šğ’³ = â„áµˆï¼ˆåƒç´ å‘é‡ï¼‰
- æ–‡æœ¬åˆ†ç±»ï¼šğ’³ = Î£*ï¼ˆå­—ç¬¦ä¸²ï¼‰
- é€»è¾‘æ¦‚å¿µï¼šğ’³ = {0,1}â¿ï¼ˆå¸ƒå°”å‘é‡ï¼‰

#### æ¦‚å¿µç±»ï¼ˆConcept Classï¼‰

```text
ğ’ âŠ† 2^ğ’³ï¼šæ¦‚å¿µçš„é›†åˆ
```

æ¯ä¸ªæ¦‚å¿µ c âˆˆ ğ’ æ˜¯ ğ’³ çš„ä¸€ä¸ªå­é›†ï¼š

```text
c : ğ’³ â†’ {0,1}
```

**ä¾‹å­**ï¼š

- **çŸ©å½¢æ¦‚å¿µ**ï¼šğ’ = {axis-aligned rectangles in â„Â²}
- **çº¿æ€§åˆ†ç±»å™¨**ï¼šğ’ = {åŠç©ºé—´}
- **å†³ç­–æ ‘**ï¼šğ’ = {æ·±åº¦â‰¤dçš„å†³ç­–æ ‘}

#### æ•°æ®åˆ†å¸ƒï¼ˆData Distributionï¼‰

```text
ğ’Ÿï¼šğ’³ ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒ
```

- **æœªçŸ¥**ï¼šå­¦ä¹ å™¨ä¸çŸ¥é“ ğ’Ÿ
- **å›ºå®š**ï¼šè®­ç»ƒå’Œæµ‹è¯•æ¥è‡ªåŒä¸€åˆ†å¸ƒ
- **ä»»æ„**ï¼šå¯ä»¥æ˜¯ä»»ä½•åˆ†å¸ƒ

#### è®­ç»ƒæ ·æœ¬

ä»åˆ†å¸ƒ ğ’Ÿ ä¸­i.i.d.é‡‡æ ·ï¼š

```text
S = {(xâ‚, c(xâ‚)), ..., (xâ‚˜, c(xâ‚˜))}
```

å…¶ä¸­ï¼š

- xáµ¢ ~ ğ’Ÿ
- c(xáµ¢) âˆˆ {0,1} æ˜¯çœŸå®æ ‡ç­¾

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Shalev-Shwartz & Ben-David, 2014](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/) - Understanding Machine Learning

### 2. æ³›åŒ–è¯¯å·®ï¼ˆGeneralization Errorï¼‰

**å®šä¹‰**ï¼š

å‡è®¾ h çš„**æ³›åŒ–è¯¯å·®**ï¼ˆæˆ–**çœŸå®è¯¯å·®**ï¼‰ä¸ºï¼š

```text
error_ğ’Ÿ(h) = Pr_{x~ğ’Ÿ}[h(x) â‰  c(x)]
```

å³ï¼šä»åˆ†å¸ƒ ğ’Ÿ ä¸­éšæœºé‡‡æ ·ä¸€ä¸ªå®ä¾‹ï¼Œh é¢„æµ‹é”™è¯¯çš„æ¦‚ç‡ã€‚

**ç»éªŒè¯¯å·®**ï¼ˆEmpirical Errorï¼‰ï¼š

åœ¨è®­ç»ƒé›† S ä¸Šçš„è¯¯å·®ï¼š

```text
error_S(h) = (1/m) âˆ‘áµ¢â‚Œâ‚áµ ğŸ™[h(xáµ¢) â‰  c(xáµ¢)]
```

**ç›®æ ‡**ï¼š

æ‰¾åˆ° h ä½¿å¾— error_ğ’Ÿ(h) å°ã€‚

### 3. PACå¯å­¦ä¹ æ€§å®šä¹‰

**å®šä¹‰ï¼ˆPACå¯å­¦ä¹ ï¼‰**ï¼š

æ¦‚å¿µç±» ğ’ æ˜¯**PACå¯å­¦ä¹ çš„**ï¼Œå¦‚æœå­˜åœ¨ç®—æ³• ğ’œ å’Œå¤šé¡¹å¼å‡½æ•° poly(Â·,Â·,Â·,Â·)ï¼Œä½¿å¾—ï¼š

å¯¹äº**ä»»æ„**ï¼š

- Îµ > 0ï¼ˆè¯¯å·®å‚æ•°ï¼‰
- Î´ > 0ï¼ˆå¤±è´¥æ¦‚ç‡å‚æ•°ï¼‰
- åˆ†å¸ƒ ğ’Ÿ
- ç›®æ ‡æ¦‚å¿µ c âˆˆ ğ’

ç®—æ³• ğ’œ åœ¨æ¥æ”¶åˆ° m â‰¥ poly(1/Îµ, 1/Î´, n, size(c)) ä¸ªè®­ç»ƒæ ·æœ¬åï¼Œä»¥æ¦‚ç‡è‡³å°‘ 1-Î´ è¾“å‡ºå‡è®¾ hï¼Œä½¿å¾—ï¼š

```text
error_ğ’Ÿ(h) â‰¤ Îµ
```

ä¸”è¿è¡Œæ—¶é—´ä¸º poly(1/Îµ, 1/Î´, n, size(c))ã€‚

**ç¬¦å·è¯´æ˜**ï¼š

- nï¼šå®ä¾‹çš„"å¤§å°"æˆ–ç»´åº¦
- size(c)ï¼šç›®æ ‡æ¦‚å¿µçš„è¡¨ç¤ºå¤§å°

**é€šä¿—ç†è§£**ï¼š

> **ç»™æˆ‘è¶³å¤Ÿå¤šçš„æ ·æœ¬ï¼ˆå¤šé¡¹å¼æ•°é‡ï¼‰ï¼Œæˆ‘å°±èƒ½ä»¥é«˜æ¦‚ç‡ï¼ˆ1-Î´ï¼‰å­¦åˆ°ä¸€ä¸ªè¿‘ä¼¼å¥½çš„å‡è®¾ï¼ˆè¯¯å·®â‰¤Îµï¼‰ï¼Œè€Œä¸”æ—¶é—´æ˜¯å¤šé¡¹å¼çš„ã€‚**

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Valiant, 1984](https://dl.acm.org/doi/10.1145/1968.1972) - åŸå§‹å®šä¹‰

---

## PACå¯å­¦ä¹ æ€§

### 1. å¯å®ç°æƒ…å†µï¼ˆRealizable Caseï¼‰

**å‡è®¾**ï¼š

å­˜åœ¨ h*âˆˆ ğ’ï¼Œä½¿å¾— error_ğ’Ÿ(h*) = 0ã€‚

å³ï¼šç›®æ ‡æ¦‚å¿µç¡®å®åœ¨å‡è®¾ç±»ä¸­ã€‚

**å­¦ä¹ ç›®æ ‡**ï¼š

æ‰¾åˆ° hï¼Œä½¿å¾— error_ğ’Ÿ(h) â‰¤ Îµã€‚

### 2. ä¸å¯çŸ¥æƒ…å†µï¼ˆAgnostic Caseï¼‰

**æ›´ä¸€èˆ¬æƒ…å†µ**ï¼š

ä¸å‡è®¾ç›®æ ‡æ¦‚å¿µåœ¨ ğ’ ä¸­ã€‚

**å­¦ä¹ ç›®æ ‡**ï¼š

æ‰¾åˆ° hï¼Œä½¿å¾—ï¼š

```text
error_ğ’Ÿ(h) â‰¤ min_{h'âˆˆ ğ’} error_ğ’Ÿ(h') + Îµ
```

å³ï¼šh çš„è¯¯å·®æ¥è¿‘ ğ’ ä¸­æœ€å¥½å‡è®¾çš„è¯¯å·®ã€‚

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Kearns & Vazirani, 1994](https://mitpress.mit.edu/9780262111935/an-introduction-to-computational-learning-theory/) - An Introduction to Computational Learning Theory

---

## æ ·æœ¬å¤æ‚åº¦

### 1. å®šä¹‰

**æ ·æœ¬å¤æ‚åº¦**ï¼ˆSample Complexityï¼‰ï¼š

ä¸ºäº†è¾¾åˆ° PACå­¦ä¹ çš„è¦æ±‚ï¼Œéœ€è¦çš„**æœ€å°‘æ ·æœ¬æ•°** mã€‚

å½¢å¼åŒ–ï¼š

```text
m_ğ’(Îµ, Î´) = ä½¿å¾— PACå­¦ä¹ æˆåŠŸæ‰€éœ€çš„æœ€å°æ ·æœ¬æ•°
```

### 2. æœ‰é™å‡è®¾ç©ºé—´

**å®šç†ï¼ˆæœ‰é™å‡è®¾ç©ºé—´çš„æ ·æœ¬å¤æ‚åº¦ï¼‰**ï¼š

è®¾ |ğ’| < âˆï¼ˆå‡è®¾ç±»æ˜¯æœ‰é™çš„ï¼‰ï¼Œåˆ™æ ·æœ¬å¤æ‚åº¦ä¸ºï¼š

```text
m â‰¥ (1/Îµ) (ln|ğ’| + ln(1/Î´))
```

**è¯æ˜æ€è·¯**ï¼š

1. **åå‡è®¾**ï¼šerror_ğ’Ÿ(h) > Îµ çš„å‡è®¾
2. **å•ä¸ªåå‡è®¾"å¹¸å­˜"**ï¼šåœ¨ m ä¸ªæ ·æœ¬ä¸Šéƒ½çŒœå¯¹çš„æ¦‚ç‡ â‰¤ (1-Îµ)áµ
3. **æ‰€æœ‰åå‡è®¾"å¹¸å­˜"**ï¼šæ¦‚ç‡ â‰¤ |ğ’| (1-Îµ)áµ
4. è¦æ±‚è¿™ä¸ªæ¦‚ç‡ â‰¤ Î´ï¼Œè§£å¾— mã€‚

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Shalev-Shwartz & Ben-David, 2014](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/) - å®šç†4.1

### 3. æ— é™å‡è®¾ç©ºé—´

å¯¹äºæ— é™å‡è®¾ç©ºé—´ï¼ˆå¦‚çº¿æ€§åˆ†ç±»å™¨ã€ç¥ç»ç½‘ç»œï¼‰ï¼Œéœ€è¦ç”¨**VCç»´**æ¥åˆ»ç”»ã€‚

---

## æœ‰é™å‡è®¾ç©ºé—´çš„PACå­¦ä¹ 

### 1. ä¸€è‡´æ€§ç®—æ³•ï¼ˆConsistency Algorithmï¼‰

**ç®—æ³•**ï¼š

```python
def ConsistencyLearner(S):
    """
    S: è®­ç»ƒæ ·æœ¬ {(xâ‚, yâ‚), ..., (xâ‚˜, yâ‚˜)}
    """
    for h in ğ’:
        if h ä¸ S ä¸€è‡´ï¼ˆå³ h(xáµ¢) = yáµ¢ å¯¹æ‰€æœ‰ iï¼‰:
            return h
    return None  # ä¸å¯å®ç°æƒ…å†µ
```

**å®šç†**ï¼š

å¦‚æœ ğ’ æ˜¯æœ‰é™çš„ï¼Œåˆ™ä¸€è‡´æ€§ç®—æ³•æ˜¯PACå­¦ä¹ å™¨ï¼ˆåœ¨å¯å®ç°æƒ…å†µä¸‹ï¼‰ã€‚

### 2. ä¾‹å­ï¼šçŸ©å½¢å­¦ä¹ 

**æ¦‚å¿µç±»**ï¼š

è½´å¯¹é½çŸ©å½¢ï¼š

```text
R = [aâ‚, bâ‚] Ã— [aâ‚‚, bâ‚‚] âŠ‚ â„Â²
```

**å‡è®¾ç©ºé—´å¤§å°**ï¼š

è™½ç„¶çŸ©å½¢æœ‰æ— ç©·å¤šä¸ªï¼Œä½†åªéœ€è€ƒè™‘**ç”±æ ·æœ¬ç‚¹å†³å®šçš„çŸ©å½¢**ã€‚

**PACå¯å­¦ä¹ æ€§**ï¼š

- âœ… çŸ©å½¢æ˜¯PACå¯å­¦ä¹ çš„
- æ ·æœ¬å¤æ‚åº¦ï¼šO((1/Îµ) log(1/Î´))

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Kearns & Vazirani, 1994](https://mitpress.mit.edu/9780262111935/an-introduction-to-computational-learning-theory/) - Example 1.1

---

## VCç»´ç†è®º

### 1. VCç»´å®šä¹‰

**æ‰“æ•£ï¼ˆShatteringï¼‰**ï¼š

å‡è®¾ç±» ğ’ **æ‰“æ•£**äº†ç‚¹é›† {xâ‚, ..., xâ‚˜}ï¼Œå¦‚æœï¼š

å¯¹äº {0,1}áµ çš„**æ¯ä¸€ç§**æ ‡è®°æ–¹å¼ï¼Œéƒ½å­˜åœ¨ h âˆˆ ğ’ å®ç°å®ƒã€‚

**VCç»´**ï¼ˆVapnik-Chervonenkis Dimensionï¼‰ï¼š

```text
VC-dim(ğ’) = ğ’ èƒ½æ‰“æ•£çš„æœ€å¤§ç‚¹é›†çš„å¤§å°
```

**ä¾‹å­**ï¼š

1. **çº¿æ€§åˆ†ç±»å™¨åœ¨ â„áµˆ**ï¼š

    ```text
    VC-dim = d + 1
    ```

2. **é—´éš”è‡³å°‘ä¸º Î³ çš„çº¿æ€§åˆ†ç±»å™¨**ï¼š

    ```text
    VC-dim = O((R/Î³)Â²)  ï¼ˆå…¶ä¸­ R æ˜¯æ•°æ®åŠå¾„ï¼‰
    ```

3. **æ·±åº¦ä¸º d çš„å†³ç­–æ ‘**ï¼š

    ```text
    VC-dim = Î˜(d log d)
    ```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: VC Dimension](https://en.wikipedia.org/wiki/VC_dimension)
- [Vapnik & Chervonenkis, 1971](https://en.wikipedia.org/wiki/VC_dimension) - On the Uniform Convergence of Relative Frequencies of Events

### 2. åŸºæœ¬PACå®šç†

**å®šç†ï¼ˆFundamental Theorem of PAC Learningï¼‰**ï¼š

è®¾ ğ’ æ˜¯å‡è®¾ç±»ï¼Œd = VC-dim(ğ’)ã€‚

**Part 1**ï¼ˆå……åˆ†æ€§ï¼‰ï¼š

å¦‚æœ d < âˆï¼Œåˆ™ ğ’ æ˜¯PACå¯å­¦ä¹ çš„ï¼Œä¸”æ ·æœ¬å¤æ‚åº¦ä¸ºï¼š

```text
m = O((d/Îµ) log(1/Îµ) + (1/Îµ) log(1/Î´))
```

**Part 2**ï¼ˆå¿…è¦æ€§ï¼‰ï¼š

å¦‚æœ ğ’ æ˜¯PACå¯å­¦ä¹ çš„ï¼Œåˆ™ d < âˆã€‚

**æ„ä¹‰**ï¼š

> **VCç»´å®Œå…¨åˆ»ç”»äº†PACå¯å­¦ä¹ æ€§ï¼šæœ‰é™VCç»´ âŸº PACå¯å­¦ä¹ **

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Vapnik, 1998](https://link.springer.com/book/10.1007/978-1-4757-3264-1) - Statistical Learning Theory
- [Shalev-Shwartz & Ben-David, 2014](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/) - Theorem 6.7

### 3. VCç»´çš„è®¡ç®—

#### ä¾‹å­1ï¼šçº¿æ€§åˆ†ç±»å™¨åœ¨ â„Â²

**VC-dim = 3**:

**è¯æ˜**ï¼š

1. **å¯ä»¥æ‰“æ•£3ä¸ªç‚¹**ï¼š

    ```text
    å–éå…±çº¿çš„3ä¸ªç‚¹ï¼Œå¯ä»¥ç”¨ç›´çº¿å®ç°æ‰€æœ‰8ç§æ ‡è®°
    ```

2. **ä¸èƒ½æ‰“æ•£4ä¸ªç‚¹**ï¼š

    ```text
    4ä¸ªç‚¹ä¸­è‡³å°‘æœ‰3ä¸ªæ„æˆä¸‰è§’å½¢ï¼Œç¬¬4ä¸ªç‚¹åœ¨å†…éƒ¨æˆ–å¤–éƒ¨
    å­˜åœ¨ä¸€ç§æ ‡è®°æ–¹å¼æ— æ³•ç”¨ç›´çº¿å®ç°ï¼ˆå¦‚XORï¼‰
    ```

#### ä¾‹å­2ï¼šç¥ç»ç½‘ç»œ

**å•å±‚æ„ŸçŸ¥æœº**ï¼ˆdä¸ªè¾“å…¥ï¼‰ï¼š

```text
VC-dim = d + 1
```

**å¤šå±‚ç¥ç»ç½‘ç»œ**ï¼ˆWä¸ªæƒé‡ï¼‰ï¼š

```text
VC-dim = O(W log W)
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Bartlett et al., 2019](https://arxiv.org/abs/1703.11008) - Nearly-Tight VC-Dimension and Pseudodimension Bounds for Piecewise Linear Neural Networks

---

## ä¸å¯çŸ¥PACå­¦ä¹ 

### 1. é—®é¢˜è®¾å®š

**æ”¾æ¾å‡è®¾**ï¼š

ä¸å†å‡è®¾ç›®æ ‡æ¦‚å¿µ c âˆˆ ğ’ï¼ˆå¯å®ç°æ€§ï¼‰ã€‚

**æ•°æ®ç”Ÿæˆ**ï¼š

```text
(x, y) ~ ğ’Ÿ
```

å…¶ä¸­ y å¯èƒ½ä¸æ˜¯ç”± c(x) å†³å®šçš„ï¼ˆå¯èƒ½æœ‰å™ªå£°ï¼‰ã€‚

### 2. ä¸å¯çŸ¥å­¦ä¹ ç›®æ ‡

**ç›®æ ‡**ï¼š

æ‰¾åˆ° h âˆˆ ğ’ï¼Œä½¿å¾—ï¼š

```text
error_ğ’Ÿ(h) â‰¤ min_{h'âˆˆğ’} error_ğ’Ÿ(h') + Îµ
```

å³ï¼šh çš„è¯¯å·®æ¥è¿‘ ğ’ ä¸­æœ€ä¼˜å‡è®¾ã€‚

### 3. ç»éªŒé£é™©æœ€å°åŒ–ï¼ˆEmpirical Risk Minimization, ERMï¼‰

**ç®—æ³•**ï¼š

```python
def ERM(S):
    """
    S: è®­ç»ƒæ ·æœ¬ {(xâ‚, yâ‚), ..., (xâ‚˜, yâ‚˜)}
    """
    return argmin_{h âˆˆ ğ’} error_S(h)
```

å³ï¼šè¿”å›åœ¨è®­ç»ƒé›†ä¸Šè¯¯å·®æœ€å°çš„å‡è®¾ã€‚

**å®šç†**ï¼š

å¦‚æœ VC-dim(ğ’) = d < âˆï¼Œåˆ™ERMæ˜¯ä¸å¯çŸ¥PACå­¦ä¹ å™¨ï¼Œæ ·æœ¬å¤æ‚åº¦ä¸ºï¼š

```text
m = O((d/ÎµÂ²) log(1/Îµ) + (1/ÎµÂ²) log(1/Î´))
```

**æ³¨æ„**ï¼šä¸å¯çŸ¥æƒ…å†µä¸‹ï¼Œæ ·æœ¬å¤æ‚åº¦æ˜¯ O(1/ÎµÂ²)ï¼Œæ¯”å¯å®ç°æƒ…å†µçš„ O(1/Îµ) æ›´é«˜ã€‚

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Vapnik, 1998](https://link.springer.com/book/10.1007/978-1-4757-3264-1) - Statistical Learning Theory

---

## PACå­¦ä¹ ä¸ç¥ç»ç½‘ç»œ

### 1. ç¥ç»ç½‘ç»œçš„VCç»´

**å®šç†ï¼ˆå•éšå±‚ç½‘ç»œï¼‰**ï¼š

è®¾ç¥ç»ç½‘ç»œæœ‰ W ä¸ªæƒé‡ï¼Œåˆ™ï¼š

```text
VC-dim = Î˜(WÂ²)  ï¼ˆReLUæ¿€æ´»ï¼‰
```

**å®šç†ï¼ˆæ·±åº¦ç½‘ç»œï¼‰**ï¼š

å¯¹äºæ·±åº¦ä¸º Lã€å®½åº¦ä¸º W çš„ç½‘ç»œï¼š

```text
VC-dim = Î©(LW log(LW))
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Bartlett et al., 2019](https://arxiv.org/abs/1703.11008) - Nearly-Tight VC-Dimension Bounds

### 2. è¿‡å‚æ•°åŒ–çš„æ‚–è®º

**è§‚å¯Ÿ**ï¼š

ç°ä»£æ·±åº¦ç½‘ç»œçš„å‚æ•°æ•°é‡è¿œè¶…è®­ç»ƒæ ·æœ¬æ•°ï¼š

```text
W â‰« m
```

**PACç†è®ºé¢„æµ‹**ï¼š

æ ¹æ®VCç»´ç†è®ºï¼Œæ ·æœ¬å¤æ‚åº¦åº”ä¸ºï¼š

```text
m = Î©(W)
```

æ‰€ä»¥åº”è¯¥**è¿‡æ‹Ÿåˆ**ã€‚

**å®é™…**ï¼š

å¤§ç½‘ç»œå¾€å¾€**æ³›åŒ–æ›´å¥½**ï¼

**è§£é‡Šå°è¯•**ï¼š

1. **éšå¼æ­£åˆ™åŒ–**ï¼šSGDå€¾å‘äºæ‰¾åˆ°"ç®€å•"çš„è§£
2. **æœ‰æ•ˆå®¹é‡**ï¼šç½‘ç»œå®é™…å­¦ä¹ çš„å‡½æ•°ç±»æ¯”å‚æ•°ç©ºé—´å°
3. **è¿‡å‚æ•°åŒ–çš„ä¼˜åŠ¿**ï¼šæ›´å®¹æ˜“ä¼˜åŒ–

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Zhang et al., 2017](https://arxiv.org/abs/1611.03530) - Understanding Deep Learning Requires Rethinking Generalization
- [Belkin et al., 2019](https://www.pnas.org/doi/10.1073/pnas.1903070116) - Reconciling Modern Machine Learning and the Bias-Variance Trade-off

### 3. PAC-Bayesç†è®º

**æ‰©å±•**ï¼š

è€ƒè™‘å‡è®¾çš„**å…ˆéªŒåˆ†å¸ƒ** P å’Œ**åéªŒåˆ†å¸ƒ** Qã€‚

**PAC-Bayesç•Œ**ï¼š

```text
Pr_{h~Q}[error_ğ’Ÿ(h)] â‰¤ Pr_{h~Q}[error_S(h)] + O(âˆš((KL(Q||P) + log(m/Î´)) / m))
```

å…¶ä¸­ KL(Q||P) æ˜¯åéªŒä¸å…ˆéªŒçš„KLæ•£åº¦ã€‚

**ç›´è§‰**ï¼š

å¦‚æœåéªŒæ¥è¿‘å…ˆéªŒï¼ˆKLå°ï¼‰ï¼Œåˆ™æ³›åŒ–å¥½ã€‚

**å‚è€ƒæ–‡çŒ®**ï¼š

- [McAllester, 1999](https://www.sciencedirect.com/science/article/pii/S0890540198926247) - PAC-Bayesian Model Averaging

---

## å±€é™æ€§ä¸æ‰©å±•

### 1. PACæ¡†æ¶çš„å±€é™æ€§

#### 1.1 i.i.d.å‡è®¾

**å‡è®¾**ï¼š

è®­ç»ƒå’Œæµ‹è¯•æ•°æ®ç‹¬ç«‹åŒåˆ†å¸ƒã€‚

**é—®é¢˜**ï¼š

- å®é™…æ•°æ®å¯èƒ½ç›¸å…³ï¼ˆæ—¶é—´åºåˆ—ï¼‰
- åˆ†å¸ƒå¯èƒ½æ¼‚ç§»ï¼ˆconcept driftï¼‰

**æ‰©å±•**ï¼š

- åœ¨çº¿å­¦ä¹ 
- ä¸»åŠ¨å­¦ä¹ 

#### 1.2 æœ€åæƒ…å†µåˆ†æ

**PACè¦æ±‚**ï¼š

å¯¹**ä»»æ„**åˆ†å¸ƒéƒ½æˆåŠŸã€‚

**é—®é¢˜**ï¼š

è¿‡äºä¿å®ˆï¼Œå®é™…åˆ†å¸ƒå¯èƒ½æœ‰ç»“æ„ã€‚

**æ‰©å±•**ï¼š

- åˆ†å¸ƒç›¸å…³çš„ç•Œ
- å¹³å‡æƒ…å†µåˆ†æ

#### 1.3 è®¡ç®—å¤æ‚æ€§

**PACå¯å­¦ä¹ æ€§**ï¼š

åªå…³å¿ƒæ ·æœ¬å¤æ‚åº¦ï¼Œä¸å…³å¿ƒè®¡ç®—å¤æ‚åº¦ã€‚

**é—®é¢˜**ï¼š

æœ‰äº›æ¦‚å¿µPACå¯å­¦ä¹ ï¼Œä½†è®¡ç®—å›°éš¾ï¼ˆNP-hardï¼‰ã€‚

**æ‰©å±•**ï¼š

- å¼ºPACå¯å­¦ä¹ æ€§ï¼ˆå¤šé¡¹å¼æ—¶é—´ï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Kearns & Vazirani, 1994](https://mitpress.mit.edu/9780262111935/an-introduction-to-computational-learning-theory/) - Chapter 3

### 2. æ‰©å±•æ–¹å‘

#### 2.1 åœ¨çº¿å­¦ä¹ ï¼ˆOnline Learningï¼‰

**è®¾å®š**ï¼š

- æ•°æ®ä¸€ä¸ªä¸€ä¸ªåˆ°è¾¾
- æ¯æ¬¡é¢„æµ‹åç«‹å³å¾—åˆ°åé¦ˆ
- ç›®æ ‡ï¼šæœ€å°åŒ–ç´¯ç§¯è¯¯å·®

**ä»£è¡¨ç®—æ³•**ï¼š

- æ„ŸçŸ¥æœº
- åŠ æƒå¤šæ•°ç®—æ³•
- Hedgeç®—æ³•

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Online Machine Learning](https://en.wikipedia.org/wiki/Online_machine_learning)

#### 2.2 ä¸»åŠ¨å­¦ä¹ ï¼ˆActive Learningï¼‰

**è®¾å®š**ï¼š

å­¦ä¹ å™¨å¯ä»¥**é€‰æ‹©**è¦æ ‡æ³¨çš„æ ·æœ¬ã€‚

**ä¼˜åŠ¿**ï¼š

å‡å°‘æ ‡æ³¨æˆæœ¬ã€‚

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Settles, 2009](https://minds.wisconsin.edu/handle/1793/60660) - Active Learning Literature Survey

#### 2.3 è¿ç§»å­¦ä¹ ï¼ˆTransfer Learningï¼‰

**è®¾å®š**ï¼š

åˆ©ç”¨æºä»»åŠ¡çš„çŸ¥è¯†å¸®åŠ©ç›®æ ‡ä»»åŠ¡å­¦ä¹ ã€‚

**ä¸PACçš„å…³ç³»**ï¼š

æ”¾æ¾i.i.d.å‡è®¾ï¼Œå…è®¸åˆ†å¸ƒä¸åŒã€‚

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Transfer Learning](https://en.wikipedia.org/wiki/Transfer_learning)

---

## æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **PACå­¦ä¹ å®šä¹‰**ï¼šé«˜æ¦‚ç‡ï¼ˆ1-Î´ï¼‰ã€è¿‘ä¼¼ï¼ˆè¯¯å·®â‰¤Îµï¼‰ã€å¤šé¡¹å¼æ—¶é—´
2. **æ ·æœ¬å¤æ‚åº¦**ï¼š
   - æœ‰é™å‡è®¾ï¼šO((1/Îµ) log|ğ’|)
   - VCç»´ï¼šO((d/Îµ) log(1/Îµ))ï¼Œd = VC-dim
3. **åŸºæœ¬PACå®šç†**ï¼šæœ‰é™VCç»´ âŸº PACå¯å­¦ä¹ 
4. **ä¸å¯çŸ¥å­¦ä¹ **ï¼šä¸å‡è®¾å¯å®ç°æ€§ï¼Œæ ·æœ¬å¤æ‚åº¦ O(1/ÎµÂ²)
5. **ç¥ç»ç½‘ç»œ**ï¼šVCç»´ = O(W log W)ï¼Œä½†æ³›åŒ–ç†è®ºä¸å®Œå–„
6. **å±€é™æ€§**ï¼ši.i.d.å‡è®¾ã€æœ€åæƒ…å†µã€è®¡ç®—å¤æ‚æ€§

### ä¸å…¶ä»–å­¦ä¹ ç†è®ºçš„å…³ç³»

| ç†è®º | å…³æ³¨ç‚¹ | è¯¯å·® | æ¦‚ç‡ | å‚è€ƒæ–‡çŒ® |
|------|--------|------|------|----------|
| **Goldå­¦ä¹ ** | ç²¾ç¡®è¯†åˆ«è¯­è¨€ | ä¸å…è®¸ | å¿…é¡»æˆåŠŸ | [Gold, 1967](https://www.sciencedirect.com/science/article/pii/S001999586790165X) |
| **PACå­¦ä¹ ** | è¿‘ä¼¼å­¦ä¹ æ¦‚å¿µ | å…è®¸ Îµ | é«˜æ¦‚ç‡ 1-Î´ | [Valiant, 1984](https://dl.acm.org/doi/10.1145/1968.1972) |
| **åœ¨çº¿å­¦ä¹ ** | ç´¯ç§¯è¯¯å·® | æ‚”ç•Œ | ä¸æ¶‰åŠ | [Cesa-Bianchi & Lugosi, 2006](https://www.cambridge.org/core/books/prediction-learning-and-games/0C9CA63B4BCA2DB6D2F8DE04B19DB158) |
| **ç»Ÿè®¡å­¦ä¹ ** | æœŸæœ›é£é™© | æ³›åŒ–ç•Œ | æ¶‰åŠ | [Vapnik, 1998](https://link.springer.com/book/10.1007/978-1-4757-3264-1) |

### å¯¹AIçš„å¯ç¤º

1. **æœ‰é™VCç»´æ˜¯å¯å­¦ä¹ æ€§çš„å…³é”®**
2. **æ ·æœ¬å¤æ‚åº¦éšç²¾åº¦è¦æ±‚æŒ‡æ•°å¢é•¿**ï¼ˆ1/Îµï¼‰
3. **ç¥ç»ç½‘ç»œçš„æ³›åŒ–ç†è®ºä»ä¸å®Œå–„**
4. **å®é™…å­¦ä¹ å¯èƒ½è¶…è¶ŠPACæ¡†æ¶çš„ä¿è¯**

### å“²å­¦åæ€

> **PACå­¦ä¹ æ­ç¤ºäº†ä¸€ä¸ªæ·±åˆ»çš„æ´å¯Ÿï¼šå®Œç¾å­¦ä¹ æ˜¯ä¸å¯èƒ½çš„ï¼ˆå…è®¸è¯¯å·®Îµï¼‰ï¼Œå®Œå…¨ç¡®å®šä¹Ÿæ˜¯ä¸å¿…è¦çš„ï¼ˆå…è®¸å¤±è´¥æ¦‚ç‡Î´ï¼‰ã€‚å­¦ä¹ çš„æœ¬è´¨æ˜¯åœ¨æœ‰é™èµ„æºä¸‹åšå‡ºåˆç†çš„è¿‘ä¼¼ã€‚**

---

## å‚è€ƒæ–‡çŒ®

### åŸºç¡€ç†è®º

1. [Wikipedia: PAC Learning](https://en.wikipedia.org/wiki/Probably_approximately_correct_learning)
2. [Valiant, 1984](https://dl.acm.org/doi/10.1145/1968.1972) - A Theory of the Learnable
3. [Kearns & Vazirani, 1994](https://mitpress.mit.edu/9780262111935/an-introduction-to-computational-learning-theory/) - An Introduction to Computational Learning Theory

### VCç»´

1. [Wikipedia: VC Dimension](https://en.wikipedia.org/wiki/VC_dimension)
2. [Vapnik & Chervonenkis, 1971](https://en.wikipedia.org/wiki/VC_dimension) - On the Uniform Convergence
3. [Vapnik, 1998](https://link.springer.com/book/10.1007/978-1-4757-3264-1) - Statistical Learning Theory

### ç°ä»£æ•™æ

1. [Shalev-Shwartz & Ben-David, 2014](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/) - Understanding Machine Learning: From Theory to Algorithms
2. [Mohri et al., 2018](https://cs.nyu.edu/~mohri/mlbook/) - Foundations of Machine Learning

### ç¥ç»ç½‘ç»œ

1. [Zhang et al., 2017](https://arxiv.org/abs/1611.03530) - Understanding Deep Learning Requires Rethinking Generalization
2. [Bartlett et al., 2019](https://arxiv.org/abs/1703.11008) - Nearly-Tight VC-Dimension Bounds
3. [Belkin et al., 2019](https://www.pnas.org/doi/10.1073/pnas.1903070116) - Reconciling Modern Machine Learning

---

*æœ¬æ–‡æ¡£ç³»ç»Ÿé˜è¿°äº†PACå­¦ä¹ æ¡†æ¶çš„ç†è®ºåŸºç¡€ã€æ ¸å¿ƒå®šç†å’Œå¯¹ç°ä»£æœºå™¨å­¦ä¹ çš„å¯ç¤ºï¼Œä¸ºç†è§£å­¦ä¹ ç†è®ºæä¾›äº†åšå®çš„åŸºç¡€ã€‚*
