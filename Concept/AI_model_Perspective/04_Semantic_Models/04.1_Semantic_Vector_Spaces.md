# è¯­ä¹‰å‘é‡ç©ºé—´ï¼ˆSemantic Vector Spacesï¼‰

## ç›®å½• | Table of Contents

- [è¯­ä¹‰å‘é‡ç©ºé—´ï¼ˆSemantic Vector Spacesï¼‰](#è¯­ä¹‰å‘é‡ç©ºé—´semantic-vector-spaces)
- [ç›®å½•](#ç›®å½•)
- [å¼•è¨€](#å¼•è¨€)
  - [æ ¸å¿ƒæ€æƒ³](#æ ¸å¿ƒæ€æƒ³)
  - [å…³é”®é—®é¢˜](#å…³é”®é—®é¢˜)
- [ä»ç¬¦å·åˆ°å‘é‡ï¼šè¡¨ç¤ºçš„èŒƒå¼è½¬æ¢](#ä»ç¬¦å·åˆ°å‘é‡è¡¨ç¤ºçš„èŒƒå¼è½¬æ¢)
  - [ä¼ ç»Ÿç¬¦å·è¡¨ç¤º](#ä¼ ç»Ÿç¬¦å·è¡¨ç¤º)
  - [One-Hotè¡¨ç¤º](#one-hotè¡¨ç¤º)
  - [åˆ†å¸ƒå¼è¡¨ç¤ºï¼ˆDistributed Representationï¼‰](#åˆ†å¸ƒå¼è¡¨ç¤ºdistributed-representation)
  - [èŒƒå¼è½¬æ¢çš„æœ¬è´¨](#èŒƒå¼è½¬æ¢çš„æœ¬è´¨)
- [å‘é‡ç©ºé—´æ¨¡å‹çš„æ•°å­¦åŸºç¡€](#å‘é‡ç©ºé—´æ¨¡å‹çš„æ•°å­¦åŸºç¡€)
  - [å‘é‡ç©ºé—´çš„å®šä¹‰](#å‘é‡ç©ºé—´çš„å®šä¹‰)
  - [å†…ç§¯ä¸èŒƒæ•°](#å†…ç§¯ä¸èŒƒæ•°)
  - [è·ç¦»ä¸ç›¸ä¼¼åº¦åº¦é‡](#è·ç¦»ä¸ç›¸ä¼¼åº¦åº¦é‡)
    - [1. æ¬§å‡ é‡Œå¾—è·ç¦»](#1-æ¬§å‡ é‡Œå¾—è·ç¦»)
    - [2. ä½™å¼¦ç›¸ä¼¼åº¦](#2-ä½™å¼¦ç›¸ä¼¼åº¦)
    - [3. ä½™å¼¦è·ç¦»](#3-ä½™å¼¦è·ç¦»)
- [è¯­ä¹‰å‘é‡ç©ºé—´çš„å‡ ä½•ç»“æ„](#è¯­ä¹‰å‘é‡ç©ºé—´çš„å‡ ä½•ç»“æ„)
  - [è¯­ä¹‰å‘é‡ç©ºé—´çš„å®šä¹‰](#è¯­ä¹‰å‘é‡ç©ºé—´çš„å®šä¹‰)
  - [å‡ ä½•æ€§è´¨](#å‡ ä½•æ€§è´¨)
    - [1. èšç±»æ€§ï¼ˆClusteringï¼‰](#1-èšç±»æ€§clustering)
    - [2. çº¿æ€§æ€§ï¼ˆLinearityï¼‰](#2-çº¿æ€§æ€§linearity)
    - [3. å¯åˆ†æ€§ï¼ˆSeparabilityï¼‰](#3-å¯åˆ†æ€§separability)
  - [æ‹“æ‰‘ç»“æ„](#æ‹“æ‰‘ç»“æ„)
    - [1. æµå½¢ç»“æ„ï¼ˆManifold Structureï¼‰](#1-æµå½¢ç»“æ„manifold-structure)
    - [2. æ›²ç‡ï¼ˆCurvatureï¼‰](#2-æ›²ç‡curvature)
- [è¯­ä¹‰å‘é‡ç©ºé—´çš„æ„å»ºæ–¹æ³•](#è¯­ä¹‰å‘é‡ç©ºé—´çš„æ„å»ºæ–¹æ³•)
  - [1. åŸºäºè®¡æ•°çš„æ–¹æ³•ï¼ˆCount-basedï¼‰](#1-åŸºäºè®¡æ•°çš„æ–¹æ³•count-based)
    - [æœ¯è¯­-æ–‡æ¡£çŸ©é˜µï¼ˆTerm-Document Matrixï¼‰](#æœ¯è¯­-æ–‡æ¡£çŸ©é˜µterm-document-matrix)
    - [è¯-ä¸Šä¸‹æ–‡çŸ©é˜µï¼ˆWord-Context Matrixï¼‰](#è¯-ä¸Šä¸‹æ–‡çŸ©é˜µword-context-matrix)
  - [2. åŸºäºé¢„æµ‹çš„æ–¹æ³•ï¼ˆPrediction-basedï¼‰](#2-åŸºäºé¢„æµ‹çš„æ–¹æ³•prediction-based)
    - [Word2Vec](#word2vec)
    - [GloVeï¼ˆGlobal Vectorsï¼‰](#gloveglobal-vectors)
  - [3. åŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•ï¼ˆNeural-basedï¼‰](#3-åŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•neural-based)
    - [ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤ºï¼ˆContextualized Representationsï¼‰](#ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤ºcontextualized-representations)
- [è¯­ä¹‰å‘é‡ç©ºé—´çš„æ€§è´¨](#è¯­ä¹‰å‘é‡ç©ºé—´çš„æ€§è´¨)
  - [1. åˆ†å¸ƒå‡è®¾ï¼ˆDistributional Hypothesisï¼‰](#1-åˆ†å¸ƒå‡è®¾distributional-hypothesis)
  - [2. ç»„åˆæ€§ï¼ˆCompositionalityï¼‰](#2-ç»„åˆæ€§compositionality)
  - [3. å¯å­¦ä¹ æ€§ï¼ˆLearnabilityï¼‰](#3-å¯å­¦ä¹ æ€§learnability)
- [è¯­ä¹‰å‘é‡ç©ºé—´çš„ç»´åº¦é—®é¢˜](#è¯­ä¹‰å‘é‡ç©ºé—´çš„ç»´åº¦é—®é¢˜)
  - [ç»´åº¦çš„é€‰æ‹©](#ç»´åº¦çš„é€‰æ‹©)
  - [ç»´åº¦çš„å½±å“](#ç»´åº¦çš„å½±å“)
  - [å†…åœ¨ç»´åº¦ï¼ˆIntrinsic Dimensionalityï¼‰](#å†…åœ¨ç»´åº¦intrinsic-dimensionality)
- [è¯­ä¹‰å‘é‡ç©ºé—´çš„å±€é™æ€§](#è¯­ä¹‰å‘é‡ç©ºé—´çš„å±€é™æ€§)
  - [1. é™æ€æ€§ï¼ˆStatic Embeddingsï¼‰](#1-é™æ€æ€§static-embeddings)
  - [2. åè§ä¸å…¬å¹³æ€§ï¼ˆBias and Fairnessï¼‰](#2-åè§ä¸å…¬å¹³æ€§bias-and-fairness)
  - [3. å¯è§£é‡Šæ€§ï¼ˆInterpretabilityï¼‰](#3-å¯è§£é‡Šæ€§interpretability)
  - [4. è®¡ç®—æˆæœ¬ï¼ˆComputational Costï¼‰](#4-è®¡ç®—æˆæœ¬computational-cost)
- [æ€»ç»“](#æ€»ç»“)
  - [æ ¸å¿ƒè¦ç‚¹](#æ ¸å¿ƒè¦ç‚¹)
  - [è¯­ä¹‰å‘é‡ç©ºé—´çš„æ„ä¹‰](#è¯­ä¹‰å‘é‡ç©ºé—´çš„æ„ä¹‰)
  - [æœªè§£é—®é¢˜](#æœªè§£é—®é¢˜)
- [å‚è€ƒæ–‡çŒ®](#å‚è€ƒæ–‡çŒ®)
  - [åŸºç¡€ç†è®º](#åŸºç¡€ç†è®º)
  - [è¯å‘é‡](#è¯å‘é‡)
  - [ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤º](#ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤º)
  - [å‡ ä½•ä¸æ‹“æ‰‘](#å‡ ä½•ä¸æ‹“æ‰‘)
  - [åè§ä¸å…¬å¹³æ€§](#åè§ä¸å…¬å¹³æ€§)
  - [æ•™æ](#æ•™æ)

---

## å¼•è¨€

**è¯­ä¹‰å‘é‡ç©ºé—´**ï¼ˆSemantic Vector Spaceï¼‰æ˜¯ç°ä»£AIï¼Œç‰¹åˆ«æ˜¯å¤§è¯­è¨€æ¨¡å‹çš„æ ¸å¿ƒè¡¨ç¤ºèŒƒå¼ã€‚å®ƒå°†ç¦»æ•£çš„ç¬¦å·ï¼ˆè¯ã€å¥å­ã€å›¾åƒç­‰ï¼‰æ˜ å°„åˆ°è¿ç»­çš„é«˜ç»´å‘é‡ç©ºé—´ä¸­ï¼Œä½¿å¾—**è¯­ä¹‰ä¸Šç›¸ä¼¼çš„å¯¹è±¡åœ¨å‡ ä½•ä¸Šç›¸è¿‘**ã€‚

### æ ¸å¿ƒæ€æƒ³

> **å°†"æ„ä¹‰"ï¼ˆMeaningï¼‰ç¼–ç ä¸º"ä½ç½®"ï¼ˆPositionï¼‰ï¼šè¯­ä¹‰ä¸å†æ˜¯ç¬¦å·çš„å±æ€§ï¼Œè€Œæ˜¯å‘é‡ç©ºé—´ä¸­çš„å‡ ä½•å…³ç³»ã€‚**

### å…³é”®é—®é¢˜

1. **è¡¨ç¤ºè®ºé—®é¢˜**ï¼šä»€ä¹ˆæ˜¯"æ„ä¹‰"ï¼Ÿå¦‚ä½•ç”¨å‘é‡è¡¨ç¤ºæ„ä¹‰ï¼Ÿ
2. **å‡ ä½•é—®é¢˜**ï¼šå‘é‡ç©ºé—´çš„å‡ ä½•ç»“æ„å¦‚ä½•åæ˜ è¯­ä¹‰ç»“æ„ï¼Ÿ
3. **å­¦ä¹ é—®é¢˜**ï¼šå¦‚ä½•ä»æ•°æ®ä¸­å­¦ä¹ åˆ°æœ‰æ„ä¹‰çš„å‘é‡è¡¨ç¤ºï¼Ÿ
4. **å“²å­¦é—®é¢˜**ï¼šå‘é‡è¡¨ç¤ºçœŸçš„"ç†è§£"äº†è¯­ä¹‰ï¼Œè¿˜æ˜¯åªæ˜¯ç»Ÿè®¡å…³è”ï¼Ÿ

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Vector Space Model](https://en.wikipedia.org/wiki/Vector_space_model)
- [Wikipedia: Distributional Semantics](https://en.wikipedia.org/wiki/Distributional_semantics)

---

## ä»ç¬¦å·åˆ°å‘é‡ï¼šè¡¨ç¤ºçš„èŒƒå¼è½¬æ¢

### ä¼ ç»Ÿç¬¦å·è¡¨ç¤º

**ç¬¦å·ä¸»ä¹‰AI**ï¼ˆSymbolic AIï¼‰å°†æ„ä¹‰è¡¨ç¤ºä¸º**ç¦»æ•£ç¬¦å·åŠå…¶å…³ç³»**ï¼š

```text
cat âŠ‘ animal  ï¼ˆçŒ«æ˜¯åŠ¨ç‰©çš„å­ç±»ï¼‰
âˆ€x (cat(x) â†’ animal(x))  ï¼ˆæ‰€æœ‰çŒ«éƒ½æ˜¯åŠ¨ç‰©ï¼‰
```

**ç‰¹ç‚¹**ï¼š

- âœ… **ç²¾ç¡®**ï¼šé€»è¾‘å…³ç³»æ˜ç¡®
- âœ… **å¯è§£é‡Š**ï¼šæ¨ç†è¿‡ç¨‹é€æ˜
- âŒ **è„†å¼±**ï¼šéš¾ä»¥å¤„ç†æ¨¡ç³Šæ€§å’Œå™ªå£°
- âŒ **çŸ¥è¯†è·å–ç“¶é¢ˆ**ï¼šéœ€è¦æ‰‹å·¥ç¼–å†™è§„åˆ™

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Symbolic AI](https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence)
- [Russell & Norvig, 2020](https://en.wikipedia.org/wiki/Artificial_Intelligence:_A_Modern_Approach) - Artificial Intelligence: A Modern Approach

### One-Hotè¡¨ç¤º

**æœ€ç®€å•çš„å‘é‡è¡¨ç¤º**ï¼šæ¯ä¸ªè¯å¯¹åº”ä¸€ä¸ªç»´åº¦ï¼Œè¯æ±‡è¡¨å¤§å°ä¸º |V|

```text
cat  = [1, 0, 0, 0, ..., 0]  âˆˆ â„|V|
dog  = [0, 1, 0, 0, ..., 0]  âˆˆ â„|V|
animal = [0, 0, 1, 0, ..., 0]  âˆˆ â„|V|
```

**é—®é¢˜**ï¼š

- âŒ **ç»´åº¦ç¾éš¾**ï¼š|V| é€šå¸¸æ˜¯ 10â´ ~ 10âµ
- âŒ **ç¨€ç–æ€§**ï¼šæ¯ä¸ªå‘é‡åªæœ‰ä¸€ä¸ªéé›¶å…ƒç´ 
- âŒ **æ— è¯­ä¹‰**ï¼šä»»æ„ä¸¤ä¸ªè¯çš„ä½™å¼¦ç›¸ä¼¼åº¦éƒ½æ˜¯ 0

```text
cos(cat, dog) = cos(cat, animal) = 0
```

å³ï¼šcatä¸dogçš„"è·ç¦»"ç­‰äºcatä¸animalçš„"è·ç¦»"ï¼Œè¿™æ˜¾ç„¶ä¸åˆç†ã€‚

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: One-Hot Encoding](https://en.wikipedia.org/wiki/One-hot)

### åˆ†å¸ƒå¼è¡¨ç¤ºï¼ˆDistributed Representationï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼šå°†æ¯ä¸ªè¯è¡¨ç¤ºä¸º**ä½ç»´ç¨ å¯†å‘é‡**ï¼ˆé€šå¸¸ d = 100 ~ 4096ï¼‰

```text
cat    = [0.2, -0.5, 0.8, ..., 0.3]  âˆˆ â„áµˆ
dog    = [0.3, -0.4, 0.7, ..., 0.2]  âˆˆ â„áµˆ
animal = [0.25, -0.45, 0.75, ..., 0.25]  âˆˆ â„áµˆ
```

**å…³é”®æ€§è´¨**ï¼š

```text
cos(cat, dog) â‰ˆ 0.85  ï¼ˆé«˜ï¼‰
cos(cat, animal) â‰ˆ 0.78  ï¼ˆä¸­ï¼‰
cos(cat, apple) â‰ˆ 0.12  ï¼ˆä½ï¼‰
```

**ä¼˜åŠ¿**ï¼š

- âœ… **ä½ç»´**ï¼šd â‰ª |V|
- âœ… **ç¨ å¯†**ï¼šæ‰€æœ‰ç»´åº¦éƒ½æœ‰æ„ä¹‰
- âœ… **è¯­ä¹‰**ï¼šç›¸ä¼¼è¯åœ¨å‘é‡ç©ºé—´ä¸­ç›¸è¿‘

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Hinton et al., 1986](https://en.wikipedia.org/wiki/Connectionism) - Learning Distributed Representations of Concepts
- [Wikipedia: Distributed Representation](https://en.wikipedia.org/wiki/Distributed_representation)

### èŒƒå¼è½¬æ¢çš„æœ¬è´¨

| ç»´åº¦ | ç¬¦å·è¡¨ç¤º | å‘é‡è¡¨ç¤º | å‚è€ƒæ–‡çŒ® |
|------|---------|----------|----------|
| **è¡¨ç¤ºæ–¹å¼** | ç¦»æ•£ç¬¦å· | è¿ç»­å‘é‡ | [Bengio et al., 2013](https://arxiv.org/abs/1206.5533) |
| **è¯­ä¹‰ç¼–ç ** | é€»è¾‘å…³ç³» | å‡ ä½•å…³ç³» | [Turney & Pantel, 2010](https://www.jair.org/index.php/jair/article/view/10640) |
| **ç›¸ä¼¼åº¦** | äººå·¥å®šä¹‰ | è‡ªåŠ¨å­¦ä¹  | [Mikolov et al., 2013](https://arxiv.org/abs/1301.3781) |
| **æ³›åŒ–èƒ½åŠ›** | å¼± | å¼º | [Goodfellow et al., 2016](https://www.deeplearningbook.org/) |
| **å¯è§£é‡Šæ€§** | å¼º | å¼± | [Lipton, 2018](https://arxiv.org/abs/1606.03490) |

---

## å‘é‡ç©ºé—´æ¨¡å‹çš„æ•°å­¦åŸºç¡€

### å‘é‡ç©ºé—´çš„å®šä¹‰

**å®šä¹‰ï¼ˆå‘é‡ç©ºé—´ï¼‰**ï¼š

ä¸€ä¸ª**å‘é‡ç©ºé—´** V æ˜¯ä¸€ä¸ªé›†åˆï¼Œé…æœ‰ä¸¤ä¸ªè¿ç®—ï¼š

1. **å‘é‡åŠ æ³•**ï¼šğ’– + ğ’— âˆˆ V
2. **æ ‡é‡ä¹˜æ³•**ï¼šÎ± ğ’– âˆˆ V ï¼ˆÎ± âˆˆ â„ï¼‰

æ»¡è¶³ä»¥ä¸‹**å…«æ¡å…¬ç†**ï¼š

1. åŠ æ³•äº¤æ¢å¾‹ï¼šğ’– + ğ’— = ğ’— + ğ’–
2. åŠ æ³•ç»“åˆå¾‹ï¼š(ğ’– + ğ’—) + ğ’˜ = ğ’– + (ğ’— + ğ’˜)
3. åŠ æ³•é›¶å…ƒï¼šâˆƒ ğŸ, ğ’– + ğŸ = ğ’–
4. åŠ æ³•é€†å…ƒï¼šâˆƒ -ğ’–, ğ’– + (-ğ’–) = ğŸ
5. ä¹˜æ³•å•ä½å…ƒï¼š1 Â· ğ’– = ğ’–
6. ä¹˜æ³•ç»“åˆå¾‹ï¼šÎ±(Î²ğ’–) = (Î±Î²)ğ’–
7. åˆ†é…å¾‹1ï¼šÎ±(ğ’– + ğ’—) = Î±ğ’– + Î±ğ’—
8. åˆ†é…å¾‹2ï¼š(Î± + Î²)ğ’– = Î±ğ’– + Î²ğ’–

**AIä¸­çš„å‘é‡ç©ºé—´**ï¼šé€šå¸¸æ˜¯ â„áµˆï¼ˆdç»´æ¬§å‡ é‡Œå¾—ç©ºé—´ï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Vector Space](https://en.wikipedia.org/wiki/Vector_space)
- [Strang, 2016](https://en.wikipedia.org/wiki/Introduction_to_Linear_Algebra) - Introduction to Linear Algebra

### å†…ç§¯ä¸èŒƒæ•°

**å®šä¹‰ï¼ˆå†…ç§¯ï¼‰**ï¼š

ä¸€ä¸ª**å†…ç§¯**æ˜¯å‡½æ•° âŸ¨Â·,Â·âŸ© : V Ã— V â†’ â„ï¼Œæ»¡è¶³ï¼š

1. **å¯¹ç§°æ€§**ï¼šâŸ¨ğ’–, ğ’—âŸ© = âŸ¨ğ’—, ğ’–âŸ©
2. **çº¿æ€§**ï¼šâŸ¨Î±ğ’– + Î²ğ’—, ğ’˜âŸ© = Î±âŸ¨ğ’–, ğ’˜âŸ© + Î²âŸ¨ğ’—, ğ’˜âŸ©
3. **æ­£å®šæ€§**ï¼šâŸ¨ğ’–, ğ’–âŸ© â‰¥ 0ï¼Œä¸” âŸ¨ğ’–, ğ’–âŸ© = 0 âŸº ğ’– = ğŸ

**æ¬§å‡ é‡Œå¾—å†…ç§¯**ï¼š

```text
âŸ¨ğ’–, ğ’—âŸ© = ğ’– Â· ğ’— = âˆ‘áµ¢ uáµ¢váµ¢
```

**å®šä¹‰ï¼ˆèŒƒæ•°ï¼‰**ï¼š

ç”±å†…ç§¯å¯¼å‡ºçš„**èŒƒæ•°**ï¼ˆé•¿åº¦ï¼‰ï¼š

```text
â€–ğ’–â€– = âˆšâŸ¨ğ’–, ğ’–âŸ©
```

å¯¹äºæ¬§å‡ é‡Œå¾—ç©ºé—´ï¼š

```text
â€–ğ’–â€–â‚‚ = âˆš(âˆ‘áµ¢ uáµ¢Â²)  ï¼ˆLâ‚‚èŒƒæ•°ï¼‰
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Inner Product Space](https://en.wikipedia.org/wiki/Inner_product_space)
- [Wikipedia: Norm (mathematics)](https://en.wikipedia.org/wiki/Norm_(mathematics))

### è·ç¦»ä¸ç›¸ä¼¼åº¦åº¦é‡

#### 1. æ¬§å‡ é‡Œå¾—è·ç¦»

```text
d(ğ’–, ğ’—) = â€–ğ’– - ğ’—â€–â‚‚ = âˆš(âˆ‘áµ¢ (uáµ¢ - váµ¢)Â²)
```

**ç‰¹ç‚¹**ï¼š

- âœ… ç›´è§‚çš„"å‡ ä½•è·ç¦»"
- âŒ å—å‘é‡é•¿åº¦å½±å“

#### 2. ä½™å¼¦ç›¸ä¼¼åº¦

```text
cos(ğ’–, ğ’—) = âŸ¨ğ’–, ğ’—âŸ© / (â€–ğ’–â€– â€–ğ’—â€–)
```

**å€¼åŸŸ**ï¼š[-1, 1]

- cos(ğ’–, ğ’—) = 1ï¼šå®Œå…¨ç›¸åŒæ–¹å‘
- cos(ğ’–, ğ’—) = 0ï¼šæ­£äº¤ï¼ˆæ— å…³ï¼‰
- cos(ğ’–, ğ’—) = -1ï¼šå®Œå…¨ç›¸åæ–¹å‘

**ç‰¹ç‚¹**ï¼š

- âœ… ä¸å—å‘é‡é•¿åº¦å½±å“ï¼ˆåªçœ‹æ–¹å‘ï¼‰
- âœ… ç¬¦åˆäººç±»å¯¹"ç›¸ä¼¼åº¦"çš„ç›´è§‰
- âœ… **AIä¸­æœ€å¸¸ç”¨çš„ç›¸ä¼¼åº¦åº¦é‡**

#### 3. ä½™å¼¦è·ç¦»

```text
d_cos(ğ’–, ğ’—) = 1 - cos(ğ’–, ğ’—)
```

**å€¼åŸŸ**ï¼š[0, 2]

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)
- [Wikipedia: Euclidean Distance](https://en.wikipedia.org/wiki/Euclidean_distance)

---

## è¯­ä¹‰å‘é‡ç©ºé—´çš„å‡ ä½•ç»“æ„

### è¯­ä¹‰å‘é‡ç©ºé—´çš„å®šä¹‰

**å®šä¹‰ï¼ˆè¯­ä¹‰å‘é‡ç©ºé—´ï¼‰**ï¼š

ä¸€ä¸ª**è¯­ä¹‰å‘é‡ç©ºé—´** ğ• æ˜¯ä¸€ä¸ªä¸‰å…ƒç»„ (â„áµˆ, Enc, Sem)ï¼Œå…¶ä¸­ï¼š

- **â„áµˆ**ï¼šdç»´æ¬§å‡ é‡Œå¾—ç©ºé—´ï¼ˆå‡ ä½•ç©ºé—´ï¼‰
- **Enc : Î£ â†’ â„áµˆ**ï¼šç¼–ç å™¨ï¼Œå°†ç¬¦å·æ˜ å°„åˆ°å‘é‡
- **Sem**ï¼šè¯­ä¹‰å…³ç³»é›†åˆï¼Œå®šä¹‰äº†ç¬¦å·é—´çš„è¯­ä¹‰å…³ç³»

**å…³é”®è¦æ±‚**ï¼š

> **å‡ ä½•å…³ç³» â‰ˆ è¯­ä¹‰å…³ç³»**

å½¢å¼åŒ–ï¼šå¯¹äºè¯­ä¹‰å…³ç³» R(a, b)ï¼Œåº”æœ‰ï¼š

```text
R(a, b) â‡’ d(Enc(a), Enc(b)) è¾ƒå°
Â¬R(a, b) â‡’ d(Enc(a), Enc(b)) è¾ƒå¤§
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Turney & Pantel, 2010](https://www.jair.org/index.php/jair/article/view/10640) - From Frequency to Meaning

### å‡ ä½•æ€§è´¨

#### 1. èšç±»æ€§ï¼ˆClusteringï¼‰

**è¯­ä¹‰ç›¸ä¼¼çš„è¯èšé›†åœ¨ä¸€èµ·**ï¼š

```text
{cat, dog, rabbit, ...} â† åŠ¨ç‰©èšç±»
{red, blue, green, ...} â† é¢œè‰²èšç±»
{run, walk, jump, ...}  â† åŠ¨ä½œèšç±»
```

**æ•°å­¦è¡¨è¿°**ï¼š

è®¾ C æ˜¯ä¸€ä¸ªè¯­ä¹‰ç±»åˆ«ï¼Œåˆ™ï¼š

```text
âˆ€a, b âˆˆ C : E[d(Enc(a), Enc(b))] < E[d(Enc(a), Enc(x))]
                                   x âˆ‰ C
```

#### 2. çº¿æ€§æ€§ï¼ˆLinearityï¼‰

**è¯­ä¹‰å…³ç³»å¯ä»¥ç”¨å‘é‡è¿ç®—è¡¨ç¤º**ï¼š

ç»å…¸ä¾‹å­ï¼ˆWord2Vecï¼‰ï¼š

```text
king - man + woman â‰ˆ queen
```

æ›´ä¸€èˆ¬åœ°ï¼š

```text
vec(Paris) - vec(France) â‰ˆ vec(Berlin) - vec(Germany)
```

**æ•°å­¦è¡¨è¿°**ï¼š

å¯¹äºå…³ç³» R : A â†’ Bï¼Œå­˜åœ¨å‘é‡ ğ’“ âˆˆ â„áµˆï¼Œä½¿å¾—ï¼š

```text
R(a, b) â‡’ Enc(b) â‰ˆ Enc(a) + ğ’“
```

#### 3. å¯åˆ†æ€§ï¼ˆSeparabilityï¼‰

**ä¸åŒè¯­ä¹‰ç±»åˆ«çº¿æ€§å¯åˆ†**ï¼š

å¯¹äºäºŒå…ƒåˆ†ç±»ä»»åŠ¡ï¼ˆå¦‚æƒ…æ„Ÿåˆ†æï¼šæ­£é¢/è´Ÿé¢ï¼‰ï¼Œå­˜åœ¨è¶…å¹³é¢ ğ’˜ âˆˆ â„áµˆï¼Œä½¿å¾—ï¼š

```text
âŸ¨ğ’˜, Enc(x)âŸ© > 0  â‡”  x âˆˆ Positive
âŸ¨ğ’˜, Enc(x)âŸ© < 0  â‡”  x âˆˆ Negative
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Mikolov et al., 2013](https://arxiv.org/abs/1301.3781) - Linguistic Regularities in Continuous Space
- [Wikipedia: Linear Separability](https://en.wikipedia.org/wiki/Linear_separability)

### æ‹“æ‰‘ç»“æ„

è¯­ä¹‰å‘é‡ç©ºé—´ä¸ä»…æ˜¯åº¦é‡ç©ºé—´ï¼Œè¿˜å…·æœ‰**æ‹“æ‰‘ç»“æ„**ï¼š

#### 1. æµå½¢ç»“æ„ï¼ˆManifold Structureï¼‰

**å‡è®¾**ï¼šé«˜ç»´è¯­ä¹‰å‘é‡ç©ºé—´å®é™…ä¸Šæ˜¯**ä½ç»´æµå½¢åµŒå…¥åˆ°é«˜ç»´ç©ºé—´**ã€‚

```text
çœŸå®è¯­ä¹‰ç©ºé—´ M âŠ‚ â„áµˆ  ï¼ˆM æ˜¯ä½ç»´æµå½¢ï¼‰
å†…åœ¨ç»´åº¦ â‰ª åµŒå…¥ç»´åº¦ d
```

**ç›´è§‰**ï¼šè™½ç„¶åµŒå…¥åœ¨ d=768 ç»´ç©ºé—´ï¼Œä½†å®é™…"è‡ªç”±åº¦"å¯èƒ½åªæœ‰ 10~100 ç»´ã€‚

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Manifold](https://en.wikipedia.org/wiki/Manifold)
- [Fefferman et al., 2016](https://www.pnas.org/doi/full/10.1073/pnas.1408993113) - Testing the Manifold Hypothesis

#### 2. æ›²ç‡ï¼ˆCurvatureï¼‰

æœ€è¿‘ç ”ç©¶è¡¨æ˜ï¼Œè¯­ä¹‰ç©ºé—´å¯èƒ½å…·æœ‰**è´Ÿæ›²ç‡**ï¼ˆåŒæ›²å‡ ä½•ï¼‰ï¼š

**åŒæ›²å‡ ä½•çš„ä¼˜åŠ¿**ï¼š

- âœ… æ›´é€‚åˆè¡¨ç¤º**å±‚æ¬¡ç»“æ„**ï¼ˆå¦‚ WordNetï¼‰
- âœ… åœ¨ç›¸åŒç»´åº¦ä¸‹æœ‰**æŒ‡æ•°çº§æ›´å¤§çš„å®¹é‡**

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Nickel & Kiela, 2017](https://arxiv.org/abs/1705.08039) - PoincarÃ© Embeddings for Learning Hierarchical Representations
- [Wikipedia: Hyperbolic Geometry](https://en.wikipedia.org/wiki/Hyperbolic_geometry)

---

## è¯­ä¹‰å‘é‡ç©ºé—´çš„æ„å»ºæ–¹æ³•

### 1. åŸºäºè®¡æ•°çš„æ–¹æ³•ï¼ˆCount-basedï¼‰

#### æœ¯è¯­-æ–‡æ¡£çŸ©é˜µï¼ˆTerm-Document Matrixï¼‰

**å®šä¹‰**ï¼š

```text
X âˆˆ â„|V|Ã—|D|
Xáµ¢â±¼ = è¯ wáµ¢ åœ¨æ–‡æ¡£ dâ±¼ ä¸­å‡ºç°çš„æ¬¡æ•°
```

**é™ç»´æ–¹æ³•**ï¼š

- **å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰**ï¼šX â‰ˆ U Î£ Váµ€
- **æ½œåœ¨è¯­ä¹‰åˆ†æï¼ˆLSAï¼‰**ï¼šå– U çš„å‰ k åˆ—ä½œä¸ºè¯å‘é‡

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Latent Semantic Analysis](https://en.wikipedia.org/wiki/Latent_semantic_analysis)
- [Deerwester et al., 1990](https://en.wikipedia.org/wiki/Latent_semantic_analysis) - Indexing by Latent Semantic Analysis

#### è¯-ä¸Šä¸‹æ–‡çŸ©é˜µï¼ˆWord-Context Matrixï¼‰

**å®šä¹‰**ï¼š

```text
X âˆˆ â„|V|Ã—|V|
Xáµ¢â±¼ = è¯ wáµ¢ ä¸è¯ wâ±¼ åœ¨çª—å£å†…å…±ç°çš„æ¬¡æ•°
```

**å˜ä½“**ï¼š

- **åŸå§‹è®¡æ•°**ï¼šXáµ¢â±¼ = count(wáµ¢, wâ±¼)
- **ç‚¹äº’ä¿¡æ¯ï¼ˆPMIï¼‰**ï¼š

```text
PMI(wáµ¢, wâ±¼) = log P(wáµ¢, wâ±¼) / (P(wáµ¢) P(wâ±¼))
```

- **æ­£ç‚¹äº’ä¿¡æ¯ï¼ˆPPMIï¼‰**ï¼š

```text
PPMI(wáµ¢, wâ±¼) = max(0, PMI(wáµ¢, wâ±¼))
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Pointwise Mutual Information](https://en.wikipedia.org/wiki/Pointwise_mutual_information)

### 2. åŸºäºé¢„æµ‹çš„æ–¹æ³•ï¼ˆPrediction-basedï¼‰

#### Word2Vec

**æ ¸å¿ƒæ€æƒ³**ï¼šé€šè¿‡**é¢„æµ‹ä¸Šä¸‹æ–‡**æˆ–**ä»ä¸Šä¸‹æ–‡é¢„æµ‹ç›®æ ‡è¯**æ¥å­¦ä¹ å‘é‡ã€‚

**ä¸¤ç§æ¶æ„**ï¼š

1. **CBOW**ï¼ˆContinuous Bag-of-Wordsï¼‰ï¼š

    ```text
    P(wâ‚œ | wâ‚œâ‚‹â‚™, ..., wâ‚œâ‚‹â‚, wâ‚œâ‚Šâ‚, ..., wâ‚œâ‚Šâ‚™)
    ```

    ä»ä¸Šä¸‹æ–‡é¢„æµ‹ä¸­å¿ƒè¯

2. **Skip-Gram**ï¼š

    ```text
    P(wâ‚œâ‚‹â‚™, ..., wâ‚œâ‚‹â‚, wâ‚œâ‚Šâ‚, ..., wâ‚œâ‚Šâ‚™ | wâ‚œ)
    ```

ä»ä¸­å¿ƒè¯é¢„æµ‹ä¸Šä¸‹æ–‡

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Mikolov et al., 2013](https://arxiv.org/abs/1301.3781) - Efficient Estimation of Word Representations in Vector Space
- [Wikipedia: Word2vec](https://en.wikipedia.org/wiki/Word2vec)

#### GloVeï¼ˆGlobal Vectorsï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼šç»“åˆå…¨å±€ç»Ÿè®¡ä¿¡æ¯ï¼ˆå…±ç°çŸ©é˜µï¼‰å’Œå±€éƒ¨é¢„æµ‹ï¼ˆWord2Vecï¼‰ã€‚

**ç›®æ ‡å‡½æ•°**ï¼š

```text
J = âˆ‘áµ¢â±¼ f(Xáµ¢â±¼) (ğ’–áµ¢áµ€ ğ’—â±¼ + báµ¢ + câ±¼ - log Xáµ¢â±¼)Â²
```

å…¶ä¸­ï¼š

- Xáµ¢â±¼ï¼šè¯ wáµ¢ å’Œ wâ±¼ çš„å…±ç°æ¬¡æ•°
- f(x)ï¼šæƒé‡å‡½æ•°ï¼Œå‰Šå¼±é«˜é¢‘è¯çš„å½±å“

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Pennington et al., 2014](https://nlp.stanford.edu/pubs/glove.pdf) - GloVe: Global Vectors for Word Representation
- [Wikipedia: GloVe](https://en.wikipedia.org/wiki/GloVe)

### 3. åŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•ï¼ˆNeural-basedï¼‰

#### ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤ºï¼ˆContextualized Representationsï¼‰

**ä¼ ç»Ÿæ–¹æ³•çš„å±€é™**ï¼šæ¯ä¸ªè¯åªæœ‰**ä¸€ä¸ªå›ºå®šå‘é‡**ï¼Œæ— æ³•å¤„ç†**ä¸€è¯å¤šä¹‰**ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š**ä¸Šä¸‹æ–‡ç›¸å…³çš„å‘é‡è¡¨ç¤º**

```text
vec("bank") åœ¨ "river bank" ä¸­ â‰  vec("bank") åœ¨ "bank account" ä¸­
```

**ä»£è¡¨æ¨¡å‹**ï¼š

1. **ELMo**ï¼ˆEmbeddings from Language Modelsï¼‰ï¼š

    ```text
    ğ’‰áµ¢ = BiLSTM(wâ‚, ..., wâ‚™)[i]
    ```

2. **BERT**ï¼ˆBidirectional Encoder Representations from Transformersï¼‰ï¼š

    ```text
    ğ’‰áµ¢ = Transformer(wâ‚, ..., wâ‚™)[i]
    ```

3. **GPT**ï¼ˆGenerative Pre-trained Transformerï¼‰ï¼š

    ```text
    ğ’‰áµ¢ = TransformerDecoder(wâ‚, ..., wáµ¢)[i]
    ```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Peters et al., 2018](https://arxiv.org/abs/1802.05365) - Deep Contextualized Word Representations
- [Devlin et al., 2019](https://arxiv.org/abs/1810.04805) - BERT
- [Radford et al., 2018](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf) - Improving Language Understanding

---

## è¯­ä¹‰å‘é‡ç©ºé—´çš„æ€§è´¨

### 1. åˆ†å¸ƒå‡è®¾ï¼ˆDistributional Hypothesisï¼‰

**æ ¸å¿ƒåŸç†**ï¼š

> **"A word is characterized by the company it keeps."**
>
> **"è¯çš„æ„ä¹‰ç”±å…¶ä¸Šä¸‹æ–‡å†³å®šã€‚"**
>
> â€” J. R. Firth (1957)

**å½¢å¼åŒ–**ï¼š

```text
Sem(wâ‚) â‰ˆ Sem(wâ‚‚)  âŸº  Context(wâ‚) â‰ˆ Context(wâ‚‚)
```

**ä¾‹å­**ï¼š

```text
"cat" å’Œ "dog" ç»å¸¸å‡ºç°åœ¨ç›¸ä¼¼ä¸Šä¸‹æ–‡ä¸­ï¼š
  - "I have a ___ as a pet."
  - "The ___ is sleeping."
  - "Feed the ___."

å› æ­¤ï¼Œvec(cat) â‰ˆ vec(dog)
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Firth, 1957](https://en.wikipedia.org/wiki/Distributional_semantics) - A Synopsis of Linguistic Theory
- [Harris, 1954](https://www.jstor.org/stable/411805) - Distributional Structure

### 2. ç»„åˆæ€§ï¼ˆCompositionalityï¼‰

**é—®é¢˜**ï¼šå¦‚ä½•ä»è¯å‘é‡å¾—åˆ°å¥å­å‘é‡ï¼Ÿ

**ç®€å•æ–¹æ³•**ï¼š

1. **å¹³å‡**ï¼š

    ```text
    vec(sentence) = (1/n) âˆ‘áµ¢ vec(wáµ¢)
    ```

2. **åŠ æƒå¹³å‡**ï¼ˆå¦‚ TF-IDF æƒé‡ï¼‰

**é«˜çº§æ–¹æ³•**ï¼š

1. **RNN/LSTM**ï¼š

    ```text
    ğ’‰â‚œ = LSTM(ğ’‰â‚œâ‚‹â‚, vec(wâ‚œ))
    vec(sentence) = ğ’‰â‚™
    ```

2. **Transformer**ï¼š

    ```text
    ğ’‰â‚, ..., ğ’‰â‚™ = Transformer(vec(wâ‚), ..., vec(wâ‚™))
    vec(sentence) = ğ’‰â‚  ï¼ˆæˆ–å¹³å‡ï¼‰
    ```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Principle of Compositionality](https://en.wikipedia.org/wiki/Principle_of_compositionality)

### 3. å¯å­¦ä¹ æ€§ï¼ˆLearnabilityï¼‰

**å…³é”®é—®é¢˜**ï¼šä»æœ‰é™æ•°æ®ä¸­å­¦ä¹ åˆ°çš„å‘é‡èƒ½å¦æ³›åŒ–ï¼Ÿ

**ç†è®ºä¿è¯**ï¼š

- **Johnson-Lindenstrausså¼•ç†**ï¼šé«˜ç»´å‘é‡å¯ä»¥è¿‘ä¼¼ä¿è·åœ°æŠ•å½±åˆ°ä½ç»´ç©ºé—´
- **éšæœºæŠ•å½±**ï¼šéšæœºåˆå§‹åŒ–çš„å‘é‡ç»è¿‡è®­ç»ƒå¯ä»¥å­¦ä¹ åˆ°æœ‰æ„ä¹‰çš„è¡¨ç¤º

**ç»éªŒå‘ç°**ï¼š

- âœ… å¤§è§„æ¨¡è¯­æ–™ï¼ˆå¦‚10äº¿è¯ï¼‰å¯ä»¥å­¦ä¹ åˆ°é«˜è´¨é‡çš„è¯å‘é‡
- âœ… é¢„è®­ç»ƒæ¨¡å‹å¯ä»¥è¿ç§»åˆ°ä¸‹æ¸¸ä»»åŠ¡

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Johnson-Lindenstrauss Lemma](https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma)

---

## è¯­ä¹‰å‘é‡ç©ºé—´çš„ç»´åº¦é—®é¢˜

### ç»´åº¦çš„é€‰æ‹©

**ç»éªŒæ³•åˆ™**ï¼š

| åº”ç”¨åœºæ™¯ | å…¸å‹ç»´åº¦ | å‚è€ƒæ¨¡å‹ |
|---------|---------|----------|
| è¯å‘é‡ï¼ˆWord2Vec, GloVeï¼‰ | 50 ~ 300 | [Mikolov et al., 2013](https://arxiv.org/abs/1301.3781) |
| å¥å­å‘é‡ï¼ˆSentence-BERTï¼‰ | 384 ~ 768 | [Reimers & Gurevych, 2019](https://arxiv.org/abs/1908.10084) |
| BERT-base | 768 | [Devlin et al., 2019](https://arxiv.org/abs/1810.04805) |
| BERT-large | 1024 | [Devlin et al., 2019](https://arxiv.org/abs/1810.04805) |
| GPT-3 | 12288 | [Brown et al., 2020](https://arxiv.org/abs/2005.14165) |

### ç»´åº¦çš„å½±å“

**ç»´åº¦å¤ªä½**ï¼š

- âŒ è¡¨è¾¾èƒ½åŠ›ä¸è¶³ï¼Œéš¾ä»¥åŒºåˆ†ç»†å¾®è¯­ä¹‰å·®å¼‚
- âŒ ç±»æ¯”å…³ç³»ï¼ˆå¦‚ king - man + woman â‰ˆ queenï¼‰ç²¾åº¦ä¸‹é™

**ç»´åº¦å¤ªé«˜**ï¼š

- âŒ è¿‡æ‹Ÿåˆé£é™©
- âŒ è®¡ç®—å’Œå­˜å‚¨æˆæœ¬å¢åŠ 
- âŒ **ç»´åº¦ç¾éš¾**ï¼ˆCurse of Dimensionalityï¼‰

### å†…åœ¨ç»´åº¦ï¼ˆIntrinsic Dimensionalityï¼‰

**è§‚å¯Ÿ**ï¼šè™½ç„¶åµŒå…¥ç»´åº¦ d å¾ˆé«˜ï¼ˆå¦‚768ï¼‰ï¼Œä½†**å®é™…æœ‰æ•ˆç»´åº¦å¯èƒ½è¿œå°äº d**ã€‚

**å†…åœ¨ç»´åº¦ä¼°è®¡æ–¹æ³•**ï¼š

1. **PCAåˆ†æ**ï¼šçœ‹å‰ k ä¸ªä¸»æˆåˆ†è§£é‡Šäº†å¤šå°‘æ–¹å·®
2. **å±€éƒ¨ç»´åº¦ä¼°è®¡**ï¼šä¼°è®¡æµå½¢çš„å±€éƒ¨ç»´åº¦

**ç»éªŒå‘ç°**ï¼š

- BERTçš„768ç»´å‘é‡çš„å†…åœ¨ç»´åº¦çº¦ä¸º 100~200
- è¯´æ˜å­˜åœ¨å¤§é‡å†—ä½™

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Intrinsic Dimension](https://en.wikipedia.org/wiki/Intrinsic_dimension)

---

## è¯­ä¹‰å‘é‡ç©ºé—´çš„å±€é™æ€§

### 1. é™æ€æ€§ï¼ˆStatic Embeddingsï¼‰

**é—®é¢˜**ï¼šä¼ ç»ŸWord2Vec/GloVeä¸ºæ¯ä¸ªè¯åˆ†é…**å›ºå®šå‘é‡**ï¼Œæ— æ³•å¤„ç†ï¼š

- **ä¸€è¯å¤šä¹‰**ï¼ˆPolysemyï¼‰ï¼š

```text
"bank" åœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸­æœ‰ä¸åŒå«ä¹‰
```

- **ä¸Šä¸‹æ–‡ä¾èµ–**ï¼š

```text
"good" åœ¨ "good food" å’Œ "good enough" ä¸­å«ä¹‰ä¸åŒ
```

**è§£å†³æ–¹æ¡ˆ**ï¼šä¸Šä¸‹æ–‡åŒ–è¡¨ç¤ºï¼ˆELMo, BERT, GPTï¼‰

### 2. åè§ä¸å…¬å¹³æ€§ï¼ˆBias and Fairnessï¼‰

**é—®é¢˜**ï¼šå‘é‡ç©ºé—´ä¼š**ç»§æ‰¿è®­ç»ƒæ•°æ®ä¸­çš„ç¤¾ä¼šåè§**ã€‚

**ä¾‹å­**ï¼š

```text
vec(programmer) - vec(man) + vec(woman) â‰ˆ vec(homemaker)
```

**åŸå› **ï¼šè®­ç»ƒè¯­æ–™ä¸­çš„æ€§åˆ«åˆ»æ¿å°è±¡è¢«ç¼–ç åˆ°å‘é‡ä¸­ã€‚

**ç¼“è§£æ–¹æ³•**ï¼š

1. **å»åç½®ç®—æ³•**ï¼šè°ƒæ•´å‘é‡ä½¿å…¶åœ¨æ€§åˆ«æ–¹å‘ä¸Šæ­£äº¤
2. **å¯¹æŠ—è®­ç»ƒ**ï¼šè®©æ¨¡å‹æ— æ³•ä»å‘é‡ä¸­é¢„æµ‹æ•æ„Ÿå±æ€§
3. **æ•°æ®å¹³è¡¡**ï¼šä½¿ç”¨æ›´å¹³è¡¡çš„è®­ç»ƒæ•°æ®

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Bolukbasi et al., 2016](https://arxiv.org/abs/1607.06520) - Man is to Computer Programmer as Woman is to Homemaker?
- [Wikipedia: Algorithmic Bias](https://en.wikipedia.org/wiki/Algorithmic_bias)

### 3. å¯è§£é‡Šæ€§ï¼ˆInterpretabilityï¼‰

**é—®é¢˜**ï¼šå‘é‡çš„**å„ä¸ªç»´åº¦æ²¡æœ‰æ˜ç¡®è¯­ä¹‰**ã€‚

**ä¾‹å­**ï¼š

```text
vec(cat)[42] = 0.73  â† è¿™ä¸ª0.73ä»£è¡¨ä»€ä¹ˆï¼Ÿ
```

**å°è¯•**ï¼š

- **å¯è§£é‡Šç»´åº¦**ï¼šæŸäº›ç»´åº¦ä¼¼ä¹å¯¹åº”ç‰¹å®šè¯­ä¹‰ï¼ˆå¦‚æ€§åˆ«ã€æ—¶æ€ï¼‰
- **æ¢æµ‹ä»»åŠ¡**ï¼ˆProbing Tasksï¼‰ï¼šè®­ç»ƒåˆ†ç±»å™¨çœ‹å‘é‡æ˜¯å¦ç¼–ç äº†ç‰¹å®šä¿¡æ¯

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Belinkov & Glass, 2019](https://arxiv.org/abs/1812.08951) - Analysis Methods in Neural Language Processing

### 4. è®¡ç®—æˆæœ¬ï¼ˆComputational Costï¼‰

**é—®é¢˜**ï¼šé«˜ç»´å‘é‡çš„è¿ç®—æˆæœ¬é«˜æ˜‚ã€‚

| æ“ä½œ | å¤æ‚åº¦ | åœºæ™¯ |
|------|--------|------|
| å‘é‡ç‚¹ç§¯ | O(d) | ç›¸ä¼¼åº¦è®¡ç®— |
| çŸ©é˜µä¹˜æ³• | O(ndÂ²) | Transformer |
| æœ€è¿‘é‚»æœç´¢ | O(Nd) | å‘é‡æ£€ç´¢ |

**è§£å†³æ–¹æ¡ˆ**ï¼š

1. **é‡åŒ–**ï¼ˆQuantizationï¼‰ï¼šå‡å°‘æµ®ç‚¹ç²¾åº¦ï¼ˆFP32 â†’ FP16 â†’ INT8ï¼‰
2. **ç¨€ç–åŒ–**ï¼ˆSparsificationï¼‰ï¼šå¤§éƒ¨åˆ†ç»´åº¦ç½®é›¶
3. **è¿‘ä¼¼æœ€è¿‘é‚»**ï¼ˆANNï¼‰ï¼šç”¨ç´¢å¼•ç»“æ„åŠ é€Ÿæ£€ç´¢ï¼ˆå¦‚ FAISSï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Nearest Neighbor Search](https://en.wikipedia.org/wiki/Nearest_neighbor_search)
- [Johnson et al., 2019](https://arxiv.org/abs/1702.08734) - Billion-Scale Similarity Search with GPUs

---

## æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **èŒƒå¼è½¬æ¢**ï¼šä»ç¬¦å·åˆ°å‘é‡ï¼Œä»ç¦»æ•£åˆ°è¿ç»­
2. **åˆ†å¸ƒå‡è®¾**ï¼šè¯çš„æ„ä¹‰ç”±å…¶ä¸Šä¸‹æ–‡å†³å®š
3. **å‡ ä½•ç»“æ„**ï¼šè¯­ä¹‰å…³ç³» â‡” å‡ ä½•å…³ç³»
4. **å­¦ä¹ æ–¹æ³•**ï¼šè®¡æ•°æ³•ã€é¢„æµ‹æ³•ã€ç¥ç»ç½‘ç»œæ³•
5. **ä¸Šä¸‹æ–‡åŒ–**ï¼šä»é™æ€å‘é‡åˆ°åŠ¨æ€å‘é‡
6. **å±€é™æ€§**ï¼šåè§ã€ä¸å¯è§£é‡Šã€è®¡ç®—æˆæœ¬

### è¯­ä¹‰å‘é‡ç©ºé—´çš„æ„ä¹‰

> **è¯­ä¹‰å‘é‡ç©ºé—´æ˜¯AIä»ç¬¦å·ä¸»ä¹‰åˆ°è¿æ¥ä¸»ä¹‰è½¬å˜çš„æ ¸å¿ƒè½½ä½“ã€‚å®ƒå°†"æ„ä¹‰"ä»ç¦»æ•£çš„é€»è¾‘å‘½é¢˜è½¬åŒ–ä¸ºè¿ç»­çš„å‡ ä½•å¯¹è±¡ï¼Œä½¿å¾—æœºå™¨å­¦ä¹ æ–¹æ³•èƒ½å¤Ÿç›´æ¥å¤„ç†è¯­ä¹‰ã€‚**

### æœªè§£é—®é¢˜

1. **ç†è®º**ï¼šä¸ºä»€ä¹ˆå‘é‡è¡¨ç¤ºèƒ½å¤Ÿæ•æ‰è¯­ä¹‰ï¼Ÿ
2. **å“²å­¦**ï¼šå‘é‡ç›¸ä¼¼åº¦çœŸçš„ä»£è¡¨"ç†è§£"å—ï¼Ÿ
3. **æŠ€æœ¯**ï¼šå¦‚ä½•æ„å»ºæ›´å¥½çš„è¯­ä¹‰ç©ºé—´ï¼ˆå¦‚åŒæ›²ç©ºé—´ã€é‡å­ç©ºé—´ï¼‰ï¼Ÿ
4. **ä¼¦ç†**ï¼šå¦‚ä½•æ¶ˆé™¤å‘é‡ä¸­çš„åè§ï¼Ÿ

---

## å‚è€ƒæ–‡çŒ®

### åŸºç¡€ç†è®º

1. [Wikipedia: Vector Space Model](https://en.wikipedia.org/wiki/Vector_space_model)
2. [Wikipedia: Distributional Semantics](https://en.wikipedia.org/wiki/Distributional_semantics)
3. [Wikipedia: Vector Space](https://en.wikipedia.org/wiki/Vector_space)
4. [Turney & Pantel, 2010](https://www.jair.org/index.php/jair/article/view/10640) - From Frequency to Meaning: Vector Space Models of Semantics

### è¯å‘é‡

1. [Mikolov et al., 2013](https://arxiv.org/abs/1301.3781) - Efficient Estimation of Word Representations in Vector Space
2. [Pennington et al., 2014](https://nlp.stanford.edu/pubs/glove.pdf) - GloVe: Global Vectors for Word Representation
3. [Wikipedia: Word2vec](https://en.wikipedia.org/wiki/Word2vec)
4. [Wikipedia: GloVe](https://en.wikipedia.org/wiki/GloVe)

### ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤º

1. [Peters et al., 2018](https://arxiv.org/abs/1802.05365) - Deep Contextualized Word Representations (ELMo)
2. [Devlin et al., 2019](https://arxiv.org/abs/1810.04805) - BERT: Pre-training of Deep Bidirectional Transformers
3. [Radford et al., 2018](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf) - Improving Language Understanding by Generative Pre-Training

### å‡ ä½•ä¸æ‹“æ‰‘

1. [Nickel & Kiela, 2017](https://arxiv.org/abs/1705.08039) - PoincarÃ© Embeddings for Learning Hierarchical Representations
2. [Wikipedia: Manifold](https://en.wikipedia.org/wiki/Manifold)
3. [Wikipedia: Hyperbolic Geometry](https://en.wikipedia.org/wiki/Hyperbolic_geometry)

### åè§ä¸å…¬å¹³æ€§

1. [Bolukbasi et al., 2016](https://arxiv.org/abs/1607.06520) - Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings
2. [Wikipedia: Algorithmic Bias](https://en.wikipedia.org/wiki/Algorithmic_bias)

### æ•™æ

1. [Goodfellow et al., 2016](https://www.deeplearningbook.org/) - Deep Learning
2. [Jurafsky & Martin, 2023](https://web.stanford.edu/~jurafsky/slp3/) - Speech and Language Processing (3rd ed.)

---

*æœ¬æ–‡æ¡£ç³»ç»Ÿé˜è¿°äº†è¯­ä¹‰å‘é‡ç©ºé—´çš„ç†è®ºåŸºç¡€ã€æ„å»ºæ–¹æ³•å’Œæ€§è´¨ï¼Œä¸ºç†è§£ç°ä»£AIçš„è¡¨ç¤ºå­¦ä¹ æä¾›äº†åšå®çš„æ•°å­¦å’Œæ¦‚å¿µåŸºç¡€ã€‚*
