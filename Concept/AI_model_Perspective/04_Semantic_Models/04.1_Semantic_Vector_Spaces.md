# è¯­ä¹‰å‘é‡ç©ºé—´ï¼ˆSemantic Vector Spacesï¼‰

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0
> **æœ€åæ›´æ–°**: 2025-10-27
> **æ–‡æ¡£è§„æ¨¡**: 838è¡Œ | è¯­ä¹‰å‘é‡ç©ºé—´çš„æ•°å­¦ç†è®ºåŸºç¡€
> **é˜…è¯»å»ºè®®**: æœ¬æ–‡è¯¦è§£è¯­ä¹‰å‘é‡ç©ºé—´çš„å‡ ä½•ç»“æ„ä¸æ•°å­¦æ€§è´¨ï¼Œå»ºè®®ç»“åˆçº¿æ€§ä»£æ•°å’Œæ‹“æ‰‘å­¦çŸ¥è¯†å­¦ä¹ 

---

## ğŸ“‹ ç›®å½•

- [è¯­ä¹‰å‘é‡ç©ºé—´ï¼ˆSemantic Vector Spacesï¼‰](#è¯­ä¹‰å‘é‡ç©ºé—´semantic-vector-spaces)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
    - [2 . è¡¨ç¤ºèŒƒå¼æ¼”è¿›å…¨æ™¯å›¾](#2--è¡¨ç¤ºèŒƒå¼æ¼”è¿›å…¨æ™¯å›¾)
    - [3 . è¯­ä¹‰å‘é‡æ„å»ºæ–¹æ³•å¯¹æ¯”çŸ©é˜µ](#3--è¯­ä¹‰å‘é‡æ„å»ºæ–¹æ³•å¯¹æ¯”çŸ©é˜µ)
    - [4 . è¯­ä¹‰ç›¸ä¼¼åº¦åº¦é‡æ–¹æ³•å¯¹æ¯”](#4--è¯­ä¹‰ç›¸ä¼¼åº¦åº¦é‡æ–¹æ³•å¯¹æ¯”)
    - [5 . è¯å‘é‡å­¦ä¹ æ–¹æ³•æ€ç»´å¯¼å›¾](#5--è¯å‘é‡å­¦ä¹ æ–¹æ³•æ€ç»´å¯¼å›¾)
    - [6 . è¯­ä¹‰å‘é‡ç©ºé—´å‡ ä½•æ€§è´¨åˆ†æ](#6--è¯­ä¹‰å‘é‡ç©ºé—´å‡ ä½•æ€§è´¨åˆ†æ)
    - [7 . Word2Vec/GloVe/BERTæ·±åº¦å¯¹æ¯”](#7--word2vecglovebertæ·±åº¦å¯¹æ¯”)
    - [8 . è¯­ä¹‰å‘é‡ç©ºé—´åº”ç”¨å…¨æ™¯](#8--è¯­ä¹‰å‘é‡ç©ºé—´åº”ç”¨å…¨æ™¯)
    - [9 . è¯­ä¹‰å‘é‡ç©ºé—´å±€é™æ€§ä¸æœªæ¥æ–¹å‘](#9--è¯­ä¹‰å‘é‡ç©ºé—´å±€é™æ€§ä¸æœªæ¥æ–¹å‘)
  - [1 å¼•è¨€](#1-å¼•è¨€)
    - [1 æ ¸å¿ƒæ€æƒ³](#1-æ ¸å¿ƒæ€æƒ³)
    - [2.2 å…³é”®é—®é¢˜](#22-å…³é”®é—®é¢˜)
  - [2 ä»ç¬¦å·åˆ°å‘é‡ï¼šè¡¨ç¤ºçš„èŒƒå¼è½¬æ¢](#2-ä»ç¬¦å·åˆ°å‘é‡è¡¨ç¤ºçš„èŒƒå¼è½¬æ¢)
    - [1 ä¼ ç»Ÿç¬¦å·è¡¨ç¤º](#1-ä¼ ç»Ÿç¬¦å·è¡¨ç¤º)
    - [3.2 One-Hotè¡¨ç¤º](#32-one-hotè¡¨ç¤º)
    - [3.3 åˆ†å¸ƒå¼è¡¨ç¤ºï¼ˆDistributed Representationï¼‰](#33-åˆ†å¸ƒå¼è¡¨ç¤ºdistributed-representation)
    - [3.4 èŒƒå¼è½¬æ¢çš„æœ¬è´¨](#34-èŒƒå¼è½¬æ¢çš„æœ¬è´¨)
  - [3 å‘é‡ç©ºé—´æ¨¡å‹çš„æ•°å­¦åŸºç¡€](#3-å‘é‡ç©ºé—´æ¨¡å‹çš„æ•°å­¦åŸºç¡€)
    - [1 å‘é‡ç©ºé—´çš„å®šä¹‰](#1-å‘é‡ç©ºé—´çš„å®šä¹‰)
    - [4.2 å†…ç§¯ä¸èŒƒæ•°](#42-å†…ç§¯ä¸èŒƒæ•°)
    - [4.3 è·ç¦»ä¸ç›¸ä¼¼åº¦åº¦é‡](#43-è·ç¦»ä¸ç›¸ä¼¼åº¦åº¦é‡)
      - [1 . æ¬§å‡ é‡Œå¾—è·ç¦»](#1--æ¬§å‡ é‡Œå¾—è·ç¦»)
      - [2 . ä½™å¼¦ç›¸ä¼¼åº¦](#2--ä½™å¼¦ç›¸ä¼¼åº¦)
      - [3 . ä½™å¼¦è·ç¦»](#3--ä½™å¼¦è·ç¦»)
  - [4 è¯­ä¹‰å‘é‡ç©ºé—´çš„å‡ ä½•ç»“æ„](#4-è¯­ä¹‰å‘é‡ç©ºé—´çš„å‡ ä½•ç»“æ„)
    - [1 è¯­ä¹‰å‘é‡ç©ºé—´çš„å®šä¹‰](#1-è¯­ä¹‰å‘é‡ç©ºé—´çš„å®šä¹‰)
    - [5.2 å‡ ä½•æ€§è´¨](#52-å‡ ä½•æ€§è´¨)
      - [1 . èšç±»æ€§ï¼ˆClusteringï¼‰](#1--èšç±»æ€§clustering)
      - [2 . çº¿æ€§æ€§ï¼ˆLinearityï¼‰](#2--çº¿æ€§æ€§linearity)
      - [3 . å¯åˆ†æ€§ï¼ˆSeparabilityï¼‰](#3--å¯åˆ†æ€§separability)
    - [5.3 æ‹“æ‰‘ç»“æ„](#53-æ‹“æ‰‘ç»“æ„)
      - [1 . æµå½¢ç»“æ„ï¼ˆManifold Structureï¼‰](#1--æµå½¢ç»“æ„manifold-structure)
      - [2 . æ›²ç‡ï¼ˆCurvatureï¼‰](#2--æ›²ç‡curvature)
  - [5 è¯­ä¹‰å‘é‡ç©ºé—´çš„æ„å»ºæ–¹æ³•](#5-è¯­ä¹‰å‘é‡ç©ºé—´çš„æ„å»ºæ–¹æ³•)
    - [1 . åŸºäºè®¡æ•°çš„æ–¹æ³•ï¼ˆCount-basedï¼‰](#1--åŸºäºè®¡æ•°çš„æ–¹æ³•count-based)
      - [1 æœ¯è¯­-æ–‡æ¡£çŸ©é˜µï¼ˆTerm-Document Matrixï¼‰](#1-æœ¯è¯­-æ–‡æ¡£çŸ©é˜µterm-document-matrix)
      - [2 è¯-ä¸Šä¸‹æ–‡çŸ©é˜µï¼ˆWord-Context Matrixï¼‰](#2-è¯-ä¸Šä¸‹æ–‡çŸ©é˜µword-context-matrix)
    - [2 . åŸºäºé¢„æµ‹çš„æ–¹æ³•ï¼ˆPrediction-basedï¼‰](#2--åŸºäºé¢„æµ‹çš„æ–¹æ³•prediction-based)
      - [1 Word2Vec](#1-word2vec)
      - [2 GloVeï¼ˆGlobal Vectorsï¼‰](#2-gloveglobal-vectors)
    - [3 . åŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•ï¼ˆNeural-basedï¼‰](#3--åŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•neural-based)
      - [1 ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤ºï¼ˆContextualized Representationsï¼‰](#1-ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤ºcontextualized-representations)
  - [6 è¯­ä¹‰å‘é‡ç©ºé—´çš„æ€§è´¨](#6-è¯­ä¹‰å‘é‡ç©ºé—´çš„æ€§è´¨)
    - [1 . åˆ†å¸ƒå‡è®¾ï¼ˆDistributional Hypothesisï¼‰](#1--åˆ†å¸ƒå‡è®¾distributional-hypothesis)
    - [2 . ç»„åˆæ€§ï¼ˆCompositionalityï¼‰](#2--ç»„åˆæ€§compositionality)
    - [3 . å¯å­¦ä¹ æ€§ï¼ˆLearnabilityï¼‰](#3--å¯å­¦ä¹ æ€§learnability)
  - [7 è¯­ä¹‰å‘é‡ç©ºé—´çš„ç»´åº¦é—®é¢˜](#7-è¯­ä¹‰å‘é‡ç©ºé—´çš„ç»´åº¦é—®é¢˜)
    - [1 ç»´åº¦çš„é€‰æ‹©](#1-ç»´åº¦çš„é€‰æ‹©)
    - [8.2 ç»´åº¦çš„å½±å“](#82-ç»´åº¦çš„å½±å“)
    - [8.3 å†…åœ¨ç»´åº¦ï¼ˆIntrinsic Dimensionalityï¼‰](#83-å†…åœ¨ç»´åº¦intrinsic-dimensionality)
  - [8 è¯­ä¹‰å‘é‡ç©ºé—´çš„å±€é™æ€§](#8-è¯­ä¹‰å‘é‡ç©ºé—´çš„å±€é™æ€§)
    - [1 . é™æ€æ€§ï¼ˆStatic Embeddingsï¼‰](#1--é™æ€æ€§static-embeddings)
    - [2 . åè§ä¸å…¬å¹³æ€§ï¼ˆBias and Fairnessï¼‰](#2--åè§ä¸å…¬å¹³æ€§bias-and-fairness)
    - [3 . å¯è§£é‡Šæ€§ï¼ˆInterpretabilityï¼‰](#3--å¯è§£é‡Šæ€§interpretability)
    - [4 . è®¡ç®—æˆæœ¬ï¼ˆComputational Costï¼‰](#4--è®¡ç®—æˆæœ¬computational-cost)
  - [9 æ€»ç»“](#9-æ€»ç»“)
    - [1 æ ¸å¿ƒè¦ç‚¹](#1-æ ¸å¿ƒè¦ç‚¹)
    - [10.2 è¯­ä¹‰å‘é‡ç©ºé—´çš„æ„ä¹‰](#102-è¯­ä¹‰å‘é‡ç©ºé—´çš„æ„ä¹‰)
    - [10.3 æœªè§£é—®é¢˜](#103-æœªè§£é—®é¢˜)
  - [å‚è€ƒæ–‡çŒ®](#å‚è€ƒæ–‡çŒ®)
    - [10.4 åŸºç¡€ç†è®º](#104-åŸºç¡€ç†è®º)
    - [10.5 è¯å‘é‡](#105-è¯å‘é‡)
    - [10.6 ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤º](#106-ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤º)
    - [10.7 å‡ ä½•ä¸æ‹“æ‰‘](#107-å‡ ä½•ä¸æ‹“æ‰‘)
    - [10.8 åè§ä¸å…¬å¹³æ€§](#108-åè§ä¸å…¬å¹³æ€§)
    - [10.9 æ•™æ](#109-æ•™æ)
  - [å¯¼èˆª | Navigation](#å¯¼èˆª--navigation)
  - [ç›¸å…³ä¸»é¢˜ | Related Topics](#ç›¸å…³ä¸»é¢˜--related-topics)
    - [10.10 æœ¬ç« èŠ‚](#1010-æœ¬ç« èŠ‚)
    - [10.11 ç›¸å…³ç« èŠ‚](#1011-ç›¸å…³ç« èŠ‚)
    - [10.12 è·¨è§†è§’é“¾æ¥](#1012-è·¨è§†è§’é“¾æ¥)

---


### 2 . è¡¨ç¤ºèŒƒå¼æ¼”è¿›å…¨æ™¯å›¾

```mermaid
graph TB
    subgraph ç¬¦å·ä¸»ä¹‰æ—¶ä»£ 1950s-1990s
        Symbolic[ç¬¦å·é€»è¾‘<br/>ä¸€é˜¶è°“è¯é€»è¾‘]
        KnowledgeBase[çŸ¥è¯†åº“<br/>Cyc, WordNet]
        Rules[è§„åˆ™ç³»ç»Ÿ<br/>ä¸“å®¶ç³»ç»Ÿ]

        Symbolic --> KnowledgeBase
        KnowledgeBase --> Rules
    end

    subgraph ç»Ÿè®¡æ—¶ä»£ 1990s-2010s
        OneHot[One-Hotç¼–ç <br/>é«˜ç»´ç¨€ç–]
        TF IDF[TF-IDF<br/>æœ¯è¯­-æ–‡æ¡£çŸ©é˜µ]
        LSA[LSA/LSI<br/>å¥‡å¼‚å€¼åˆ†è§£]

        OneHot --> TF_IDF
        TF_IDF --> LSA
    end

    subgraph åˆ†å¸ƒå¼è¡¨ç¤ºæ—¶ä»£ 2013-2018
        Word2Vec[Word2Vec<br/>CBOW/Skip-gram]
        GloVe[GloVe<br/>å…¨å±€å‘é‡]
        FastText[FastText<br/>å­è¯å‘é‡]

        LSA --> Word2Vec
        Word2Vec --> GloVe
        GloVe --> FastText
    end

    subgraph ä¸Šä¸‹æ–‡åŒ–æ—¶ä»£ 2018-ç°åœ¨
        ELMo[ELMo<br/>åŒå‘LSTM]
        BERT[BERT<br/>Transformerç¼–ç å™¨]
        GPT[GPTç³»åˆ—<br/>Transformerè§£ç å™¨]

        FastText --> ELMo
        ELMo --> BERT
        BERT --> GPT
    end

    subgraph æ ¸å¿ƒçªç ´
        Break1[çªç ´1: åˆ†å¸ƒå‡è®¾<br/>1950s Firth]
        Break2[çªç ´2: ç¥ç»è¯­è¨€æ¨¡å‹<br/>2003 Bengio]
        Break3[çªç ´3: Word2Vec<br/>2013 Mikolov]
        Break4[çªç ´4: Transformer<br/>2017 Vaswani]

        Break1 --> LSA
        Break2 --> Word2Vec
        Break3 --> Word2Vec
        Break4 --> BERT
    end

    subgraph å…³é”®æ¼”è¿›
        Static[é™æ€è¡¨ç¤º<br/>ä¸€è¯ä¸€å‘é‡]
        Dynamic[åŠ¨æ€è¡¨ç¤º<br/>ä¸Šä¸‹æ–‡ä¾èµ–]
        Multimodal[å¤šæ¨¡æ€è¡¨ç¤º<br/>è·¨æ¨¡æ€èåˆ]

        Word2Vec --> Static
        BERT --> Dynamic
        GPT --> Dynamic
        Dynamic -.æœªæ¥.-> Multimodal
    end

    style Symbolic fill:#ffcccc,stroke:#333,stroke-width:2px
    style Word2Vec fill:#ffff99,stroke:#333,stroke-width:3px
    style BERT fill:#99ff99,stroke:#333,stroke-width:3px
    style GPT fill:#99ccff,stroke:#333,stroke-width:3px
    style Break3 fill:#ff6b6b,stroke:#333,stroke-width:3px
```

---

### 3 . è¯­ä¹‰å‘é‡æ„å»ºæ–¹æ³•å¯¹æ¯”çŸ©é˜µ

| æ–¹æ³• | æå‡ºå¹´ä»½ | æ ¸å¿ƒæ€æƒ³ | ç»´åº¦ | è®­ç»ƒå¤æ‚åº¦ | ä¼˜åŠ¿ | åŠ£åŠ¿ | ä»£è¡¨æ¨¡å‹ |
|------|---------|---------|------|-----------|------|------|---------|
| **One-Hot** | 1960s | æ¯ä¸ªè¯ä¸€ä¸ªç‹¬çƒ­å‘é‡ | $|\mathcal{V}|$ | $O(1)$ | ç®€å• | æ— è¯­ä¹‰ã€ç»´åº¦çˆ†ç‚¸ | - |
| **TF-IDF** | 1970s | è¯é¢‘Ã—é€†æ–‡æ¡£é¢‘ç‡ | $|\mathcal{V}|$ | $O(n\|\mathcal{V}\|)$ | è€ƒè™‘é‡è¦æ€§ | ç¨€ç–ã€æ— è¯­ä¹‰ | Salton VSM |
| **LSA** | 1990 | SVDé™ç»´ | 100-300 | $O(n^2d)$ | é™ç»´ã€è¯­ä¹‰ | çº¿æ€§å‡è®¾ | Latent Semantic |
| **Word2Vec<br/>(CBOW)** | 2013 | ä¸Šä¸‹æ–‡é¢„æµ‹ä¸­å¿ƒè¯ | 300 | $O(T\|\mathcal{V}\|)$ | é«˜æ•ˆã€è¯­ä¹‰ä¸°å¯Œ | é™æ€ã€å¤šä¹‰è¯ | Mikolov |
| **Word2Vec<br/>(Skip-gram)** | 2013 | ä¸­å¿ƒè¯é¢„æµ‹ä¸Šä¸‹æ–‡ | 300 | $O(T\|\mathcal{V}\|)$ | æ€§èƒ½ä¼˜äºCBOW | é™æ€ã€å¤šä¹‰è¯ | Mikolov |
| **GloVe** | 2014 | å…¨å±€å…±ç°çŸ©é˜µåˆ†è§£ | 300 | $O(\|C\|)$ | ç»“åˆå…¨å±€+å±€éƒ¨ | é™æ€ | Pennington |
| **FastText** | 2016 | å­è¯å‘é‡ï¼ˆn-gramï¼‰ | 300 | $O(T\|\mathcal{V}\|)$ | å¤„ç†OOV | å†…å­˜å ç”¨å¤§ | Facebook |
| **ELMo** | 2018 | åŒå‘LSTM | 1024 | $O(TL^2)$ | ä¸Šä¸‹æ–‡åŒ– | è®¡ç®—æ…¢ | AllenNLP |
| **BERT** | 2018 | TransformeråŒå‘ç¼–ç  | 768/1024 | $O(TL^2)$ | å¼ºä¸Šä¸‹æ–‡ã€é¢„è®­ç»ƒ | è®¡ç®—å¯†é›† | Google |
| **GPT-3** | 2020 | Transformerè§£ç å™¨ | 12288 | $O(TL^2)$ | è¶…å¤§è§„æ¨¡ã€æ¶Œç° | èµ„æºå¯†é›† | OpenAI |

**å…³é”®æ¼”è¿›è¶‹åŠ¿**:

1. **ç»´åº¦**: ç¨€ç–é«˜ç»´ â†’ å¯†é›†ä¸­ç»´ â†’ è¶…å¤§ç»´
2. **è¯­ä¹‰**: æ— è¯­ä¹‰ â†’ é™æ€è¯­ä¹‰ â†’ ä¸Šä¸‹æ–‡åŒ–è¯­ä¹‰
3. **å¤æ‚åº¦**: ç®€å•å¿«é€Ÿ â†’ å¤æ‚å¼ºå¤§

---

### 4 . è¯­ä¹‰ç›¸ä¼¼åº¦åº¦é‡æ–¹æ³•å¯¹æ¯”

```mermaid
graph TD
    subgraph è·ç¦»åº¦é‡
        Euclidean[æ¬§å‡ é‡Œå¾—è·ç¦»<br/>$d = \|\mathbf{u}-\mathbf{v}\|_2$]
        Manhattan[æ›¼å“ˆé¡¿è·ç¦»<br/>$d = \|\mathbf{u}-\mathbf{v}\|_1$]
        Chebyshev[åˆ‡æ¯”é›ªå¤«è·ç¦»<br/>$d = \|\mathbf{u}-\mathbf{v}\|_{\infty}$]

        Euclidean -.é—®é¢˜.-> LengthSensitive[å¯¹å‘é‡é•¿åº¦æ•æ„Ÿ]
    end

    subgraph è§’åº¦åº¦é‡
        Cosine[ä½™å¼¦ç›¸ä¼¼åº¦<br/>$\cos\theta = \frac{\mathbf{u}\cdot\mathbf{v}}{\|\mathbf{u}\|\|\mathbf{v}\|}$]
        CosineDist[ä½™å¼¦è·ç¦»<br/>$d = 1 - \cos\theta$]

        Cosine -->|æœ€å¸¸ç”¨| NLP[NLPæ ‡å‡†åº¦é‡]
        Cosine -.ä¼˜åŠ¿.-> LengthInvariant[é•¿åº¦ä¸å˜æ€§]
    end

    subgraph ä¿¡æ¯è®ºåº¦é‡
        KL[KLæ•£åº¦<br/>$D_{KL}(P\|Q)$]
        JS[JSæ•£åº¦<br/>å¯¹ç§°KL]

        KL -.ç”¨äº.-> Probability[æ¦‚ç‡åˆ†å¸ƒå¯¹æ¯”]
    end

    subgraph å­¦ä¹ åº¦é‡
        Mahalanobis[é©¬æ°è·ç¦»<br/>è€ƒè™‘åæ–¹å·®]
        Learned[å­¦ä¹ åº¦é‡<br/>ç¥ç»ç½‘ç»œ]

        Learned --> Siamese[å­ªç”Ÿç½‘ç»œ]
        Learned --> Triplet[ä¸‰å…ƒç»„æŸå¤±]
    end

    subgraph å®è·µé€‰æ‹©
        Task1[è¯å‘é‡ç›¸ä¼¼åº¦] --> Cosine
        Task2[èšç±»åˆ†æ] --> Euclidean
        Task3[æ£€ç´¢æ’åº] --> CosineDist
        Task4[å¼‚å¸¸æ£€æµ‹] --> Mahalanobis
    end

    style Cosine fill:#4ecdc4,stroke:#333,stroke-width:3px
    style NLP fill:#ffd93d,stroke:#333,stroke-width:2px
```

**åº¦é‡æ€§è´¨å¯¹æ¯”**:

| åº¦é‡ | å€¼åŸŸ | å¯¹ç§°æ€§ | ä¸‰è§’ä¸ç­‰å¼ | é•¿åº¦ä¸å˜ | è®¡ç®—å¤æ‚åº¦ | é€‚ç”¨åœºæ™¯ |
|------|------|--------|-----------|---------|-----------|---------|
| **æ¬§æ°è·ç¦»** | $[0, \infty)$ | âœ… | âœ… | âŒ | $O(d)$ | èšç±»ã€KNN |
| **ä½™å¼¦ç›¸ä¼¼åº¦** | $[-1, 1]$ | âœ… | âŒ | âœ… | $O(d)$ | **è¯å‘é‡ï¼ˆé¦–é€‰ï¼‰** |
| **ä½™å¼¦è·ç¦»** | $[0, 2]$ | âœ… | âœ… | âœ… | $O(d)$ | æ£€ç´¢æ’åº |
| **KLæ•£åº¦** | $[0, \infty)$ | âŒ | âŒ | - | $O(d)$ | æ¦‚ç‡åˆ†å¸ƒ |
| **é©¬æ°è·ç¦»** | $[0, \infty)$ | âœ… | âœ… | âŒ | $O(d^2)$ | å¼‚å¸¸æ£€æµ‹ |

---

### 5 . è¯å‘é‡å­¦ä¹ æ–¹æ³•æ€ç»´å¯¼å›¾

```mermaid
mindmap
  root((è¯å‘é‡<br/>å­¦ä¹ ))
    åŸºäºè®¡æ•°Count-Based
      æœ¯è¯­-æ–‡æ¡£çŸ©é˜µ
        TF-IDF
        BM25
      è¯-ä¸Šä¸‹æ–‡çŸ©é˜µ
        PMI
        PPMI
      é™ç»´æŠ€æœ¯
        SVD/PCA
        LSA/LSI
      ä¼˜åŠ¿
        å…¨å±€ç»Ÿè®¡
        å¯è§£é‡Šæ€§
      åŠ£åŠ¿
        ç¨€ç–æ€§
        ç»´åº¦ç¾éš¾
    åŸºäºé¢„æµ‹Prediction-Based
      Word2Vec
        CBOW
          ä¸Šä¸‹æ–‡é¢„æµ‹ä¸­å¿ƒ
          å¿«é€Ÿ
        Skip-gram
          ä¸­å¿ƒé¢„æµ‹ä¸Šä¸‹æ–‡
          æ•ˆæœå¥½
        è´Ÿé‡‡æ ·
          åŠ é€Ÿè®­ç»ƒ
        å±‚æ¬¡Softmax
          æ ‘ç»“æ„
      GloVe
        å…¨å±€å…±ç°
        çŸ©é˜µåˆ†è§£
        ç»“åˆä¸¤è€…
      FastText
        å­è¯n-gram
        å¤„ç†OOV
        å½¢æ€ä¸°å¯Œè¯­è¨€
      ä¼˜åŠ¿
        å¯†é›†å‘é‡
        è¯­ä¹‰ä¸°å¯Œ
      åŠ£åŠ¿
        é™æ€è¡¨ç¤º
        å¤šä¹‰è¯é—®é¢˜
    åŸºäºç¥ç»ç½‘ç»œNeural-Based
      ELMo
        åŒå‘LSTM
        ä¸Šä¸‹æ–‡åŒ–
        ç‰¹å¾æå–å™¨
      BERT
        Transformer
        åŒå‘ç¼–ç 
        Masked LM
        é¢„è®­ç»ƒ-å¾®è°ƒ
      GPT
        Transformer
        å•å‘è§£ç 
        è‡ªå›å½’LM
      T5
        ç¼–ç å™¨-è§£ç å™¨
        Text-to-Text
      ä¼˜åŠ¿
        åŠ¨æ€è¡¨ç¤º
        å¤„ç†å¤šä¹‰è¯
        å¼ºå¤§æ³›åŒ–
      åŠ£åŠ¿
        è®¡ç®—å¯†é›†
        èµ„æºéœ€æ±‚å¤§
    æ ¸å¿ƒå‡è®¾
      åˆ†å¸ƒå‡è®¾
        Firth 1957
        ä¸Šä¸‹æ–‡å†³å®šè¯­ä¹‰
      ç»„åˆæ€§å‡è®¾
        å‘é‡å¯åŠ æ€§
        è¯­ä¹‰ç»„åˆ
```

---

### 6 . è¯­ä¹‰å‘é‡ç©ºé—´å‡ ä½•æ€§è´¨åˆ†æ

```mermaid
graph TD
    subgraph èšç±»æ€§Clustering
        Similar[è¯­ä¹‰ç›¸ä¼¼è¯èšé›†]
        Example1[king, queen, prince â†’ çš‡å®¤]
        Example2[run, walk, jog â†’ è¿åŠ¨]

        Similar --> Example1
        Similar --> Example2
    end

    subgraph çº¿æ€§æ€§Linearity
        Analogy[ç±»æ¯”å…³ç³»<br/>å‘é‡ç®—æœ¯]
        Example3[king - man + woman â‰ˆ queen]
        Example4[Paris - France + Italy â‰ˆ Rome]

        Analogy --> Example3
        Analogy --> Example4

        Formula[$\mathbf{v}_{queen} \approx \mathbf{v}_{king} - \mathbf{v}_{man} + \mathbf{v}_{woman}$]
    end

    subgraph å¯åˆ†æ€§Separability
        Hyperplane[è¶…å¹³é¢åˆ†ç¦»]
        Classification[æ”¯æŒåˆ†ç±»ä»»åŠ¡]

        Hyperplane --> SVM[SVMçº¿æ€§åˆ†ç±»]
        Hyperplane --> Logistic[é€»è¾‘å›å½’]
    end

    subgraph æµå½¢ç»“æ„Manifold
        LowDim[å†…åœ¨ä½ç»´]
        NonLinear[éçº¿æ€§ç»“æ„]

        LowDim --> Dimension[$d_{\text{intrinsic}} \ll d_{\text{ambient}}$]
        NonLinear --> Curvature[æ›²ç‡éé›¶]
    end

    subgraph æ‹“æ‰‘æ€§è´¨
        Connected[è¿é€šæ€§]
        Dense[ç¨ å¯†æ€§]

        Connected --> Path[ä»»æ„ä¸¤è¯æœ‰è·¯å¾„]
        Dense --> Neighbor[æ€»æœ‰è¿‘é‚»]
    end

    Example3 -.éªŒè¯.-> Word2Vec[Word2Vecå®éªŒ<br/>Mikolov 2013]
    Example4 -.éªŒè¯.-> GloVe[GloVeå®éªŒ<br/>Pennington 2014]

    Similar --> Clustering[K-meansèšç±»]
    Analogy --> Retrieval[ç±»æ¯”æ£€ç´¢]
    Hyperplane --> TaskPerformance[ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½]

    style Analogy fill:#ff6b6b,stroke:#333,stroke-width:3px
    style Example3 fill:#4ecdc4,stroke:#333,stroke-width:2px
    style Word2Vec fill:#ffd93d,stroke:#333,stroke-width:2px
```

**çº¿æ€§æ€§å®éªŒç»“æœ**ï¼ˆWord2Vecï¼‰:

| ç±»æ¯”ä»»åŠ¡ | å‡†ç¡®ç‡ |
|---------|--------|
| å›½å®¶-é¦–éƒ½ | 73% |
| æ€§åˆ«å…³ç³» | 88% |
| æ—¶æ€å˜åŒ– | 61% |
| å¤æ•°å½¢å¼ | 78% |

---

### 7 . Word2Vec/GloVe/BERTæ·±åº¦å¯¹æ¯”

| ç»´åº¦ | Word2Vec (2013) | GloVe (2014) | BERT (2018) |
|------|----------------|--------------|-------------|
| **æ ¸å¿ƒæ€æƒ³** | å±€éƒ¨ä¸Šä¸‹æ–‡é¢„æµ‹ | å…¨å±€å…±ç°çŸ©é˜µåˆ†è§£ | åŒå‘ä¸Šä¸‹æ–‡ç¼–ç  |
| **è®­ç»ƒç›®æ ‡** | $\max \log P(w_o\|w_i)$ | $\min \sum (w_i^T w_j - \log X_{ij})^2$ | Masked LM + NSP |
| **è¡¨ç¤ºç±»å‹** | é™æ€ï¼ˆä¸€è¯ä¸€å‘é‡ï¼‰ | é™æ€ï¼ˆä¸€è¯ä¸€å‘é‡ï¼‰ | åŠ¨æ€ï¼ˆä¸Šä¸‹æ–‡ä¾èµ–ï¼‰ |
| **å¤šä¹‰è¯** | âŒ æ— æ³•åŒºåˆ† | âŒ æ— æ³•åŒºåˆ† | âœ… æ ¹æ®ä¸Šä¸‹æ–‡åŒºåˆ† |
| **è®­ç»ƒæ•°æ®** | å±€éƒ¨çª—å£ | å…¨å±€å…±ç°ç»Ÿè®¡ | å¤§è§„æ¨¡è¯­æ–™ |
| **æ¨¡å‹ç»“æ„** | æµ…å±‚ç¥ç»ç½‘ç»œ | çŸ©é˜µåˆ†è§£ | æ·±å±‚Transformer |
| **ç»´åº¦** | 300 | 300 | 768/1024 |
| **è®­ç»ƒæ—¶é—´** | å°æ—¶çº§ | å°æ—¶çº§ | å¤©çº§ï¼ˆå•æœºï¼‰ |
| **å†…å­˜å ç”¨** | å°ï¼ˆGBï¼‰ | å°ï¼ˆGBï¼‰ | å¤§ï¼ˆTBï¼‰ |
| **æ¨ç†é€Ÿåº¦** | æå¿«ï¼ˆæŸ¥è¡¨ï¼‰ | æå¿«ï¼ˆæŸ¥è¡¨ï¼‰ | æ…¢ï¼ˆå‰å‘ä¼ æ’­ï¼‰ |
| **OOVå¤„ç†** | âŒ æ— æ³•å¤„ç† | âŒ æ— æ³•å¤„ç† | âœ… å­è¯Tokenization |
| **ä¸‹æ¸¸ä»»åŠ¡** | éœ€å¾®è°ƒ | éœ€å¾®è°ƒ | é¢„è®­ç»ƒ+å¾®è°ƒèŒƒå¼ |
| **è¯­ä¹‰æ•è·** | ä¸­ç­‰ | ä¸­ç­‰ | å¼ºï¼ˆæ·±å±‚è¯­ä¹‰ï¼‰ |
| **ç±»æ¯”ä»»åŠ¡** | âœ… ä¼˜ç§€ | âœ… ä¼˜ç§€ | âš ï¸ ä¸ç›´æ¥æ”¯æŒ |
| **å¥å­è¡¨ç¤º** | âŒ éœ€é¢å¤–æ–¹æ³• | âŒ éœ€é¢å¤–æ–¹æ³• | âœ… åŸç”Ÿæ”¯æŒ |
| **ä»£è¡¨å®ç°** | gensim | Stanford GloVe | HuggingFace |

**æ¼”è¿›æ„ä¹‰**:

- **Word2Vec**: è¯æ˜ç¥ç»è¯­è¨€æ¨¡å‹çš„æœ‰æ•ˆæ€§
- **GloVe**: ç»“åˆå…¨å±€ç»Ÿè®¡ä¸å±€éƒ¨é¢„æµ‹
- **BERT**: å¼€åˆ›é¢„è®­ç»ƒ-å¾®è°ƒèŒƒå¼ï¼Œä¸Šä¸‹æ–‡åŒ–è¡¨ç¤º

---

### 8 . è¯­ä¹‰å‘é‡ç©ºé—´åº”ç”¨å…¨æ™¯

```mermaid
graph TD
    subgraph NLPä»»åŠ¡
        Similarity[è¯­ä¹‰ç›¸ä¼¼åº¦]
        Analogy[ç±»æ¯”æ¨ç†]
        Classification[æ–‡æœ¬åˆ†ç±»]
        NER[å‘½åå®ä½“è¯†åˆ«]

        Similarity --> Search[è¯­ä¹‰æœç´¢]
        Classification --> Sentiment[æƒ…æ„Ÿåˆ†æ]
        NER --> IE[ä¿¡æ¯æŠ½å–]
    end

    subgraph ç”Ÿæˆä»»åŠ¡
        MT[æœºå™¨ç¿»è¯‘]
        Summarization[æ–‡æœ¬æ‘˜è¦]
        QA[é—®ç­”ç³»ç»Ÿ]

        MT --> SeqToSeq[Seq2Seqæ¨¡å‹]
        QA --> Retrieval[æ£€ç´¢å¢å¼º]
    end

    subgraph è·¨æ¨¡æ€ä»»åŠ¡
        ImageCap[å›¾åƒæè¿°]
        VQA[è§†è§‰é—®ç­”]
        CLIP[æ–‡æœ¬-å›¾åƒåŒ¹é…]

        ImageCap --> Vision[è®¡ç®—æœºè§†è§‰]
        CLIP --> MultiModal[å¤šæ¨¡æ€è¡¨ç¤º]
    end

    subgraph æ¨èç³»ç»Ÿ
        ItemEmbed[ç‰©å“å‘é‡åŒ–]
        UserEmbed[ç”¨æˆ·å‘é‡åŒ–]
        CF[ååŒè¿‡æ»¤]

        ItemEmbed --> Recommend[æ¨èç®—æ³•]
        UserEmbed --> Recommend
    end

    subgraph çŸ¥è¯†å›¾è°±
        EntityEmbed[å®ä½“å‘é‡åŒ–]
        RelationEmbed[å…³ç³»å‘é‡åŒ–]
        KGCompletion[çŸ¥è¯†è¡¥å…¨]

        EntityEmbed --> TransE[TransE/TransH]
    end

    Similarity -.åŸºäº.-> Cosine[ä½™å¼¦ç›¸ä¼¼åº¦]
    Analogy -.åŸºäº.-> VectorArithmetic[å‘é‡ç®—æœ¯]
    Classification -.åŸºäº.-> LinearClassifier[çº¿æ€§åˆ†ç±»å™¨]

    style Similarity fill:#4ecdc4,stroke:#333,stroke-width:2px
    style MT fill:#95e1d3,stroke:#333,stroke-width:2px
    style MultiModal fill:#ffd93d,stroke:#333,stroke-width:2px
```

---

### 9 . è¯­ä¹‰å‘é‡ç©ºé—´å±€é™æ€§ä¸æœªæ¥æ–¹å‘

| å±€é™æ€§ | å…·ä½“è¡¨ç° | è§£å†³æ–¹å‘ | ä»£è¡¨å·¥ä½œ |
|--------|---------|---------|---------|
| **é™æ€æ€§** | ä¸€è¯ä¸€å‘é‡ï¼Œæ— æ³•è¡¨ç¤ºå¤šä¹‰è¯ | **ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤º** | ELMoã€BERTã€GPT |
| **ç»„åˆæ€§** | çŸ­è¯­/å¥å­è¡¨ç¤ºä¸æ˜ç¡® | **ç»„åˆå‡½æ•°å­¦ä¹ ** | TreeRNNã€Transformer |
| **å¯è§£é‡Šæ€§** | å‘é‡ç»´åº¦éš¾ä»¥è§£é‡Š | **å¯è§£é‡ŠåµŒå…¥** | Sparse Codingã€Disentanglement |
| **åè§é—®é¢˜** | ç¤¾ä¼šåè§åµŒå…¥å‘é‡ | **å»åè§æŠ€æœ¯** | Bolukbasi 2016ã€BERTå»å |
| **ç»´åº¦é€‰æ‹©** | æœ€ä¼˜ç»´åº¦ä¸æ˜ç¡® | **è‡ªé€‚åº”ç»´åº¦** | AutoEncoderã€ç¥ç»æ¶æ„æœç´¢ |
| **è®¡ç®—æˆæœ¬** | å¤§è§„æ¨¡è®­ç»ƒèµ„æºå¯†é›† | **é«˜æ•ˆè®­ç»ƒ** | è’¸é¦ã€é‡åŒ–ã€ç¨€ç–åŒ– |
| **è·¨è¯­è¨€** | ä¸åŒè¯­è¨€ç©ºé—´ä¸å¯¹é½ | **å¤šè¯­è¨€å¯¹é½** | MUSEã€mBERTã€XLM |
| **åŠ¨æ€æ€§** | è¯ä¹‰éšæ—¶é—´æ¼”å˜ | **æ—¶åºå»ºæ¨¡** | Diachronic Word Embeddings |
| **é•¿å°¾é—®é¢˜** | ä½é¢‘è¯è¡¨ç¤ºè´¨é‡å·® | **è¿ç§»å­¦ä¹ ** | å­è¯å»ºæ¨¡ã€Few-shot |
| **ç¬¦å·åŸºç¡€** | ç¼ºä¹ç¬¦å·æ¨ç†èƒ½åŠ› | **ç¥ç»ç¬¦å·èåˆ** | Neuro-Symbolic AI |

**æœªæ¥æ–¹å‘**:

1. **è¶…å¤§è§„æ¨¡é¢„è®­ç»ƒ**: GPT-4ã€GPT-5ï¼ˆä¸‡äº¿å‚æ•°ï¼‰
2. **å¤šæ¨¡æ€èåˆ**: CLIPã€Flamingoï¼ˆç»Ÿä¸€è¡¨ç¤ºç©ºé—´ï¼‰
3. **é«˜æ•ˆè®­ç»ƒ**: LoRAã€Adapterï¼ˆå‚æ•°é«˜æ•ˆå¾®è°ƒï¼‰
4. **å¯è§£é‡Šæ€§**: Attentionå¯è§†åŒ–ã€Probing Task
5. **å»åè§**: å…¬å¹³æ€§çº¦æŸã€å¯¹æŠ—è®­ç»ƒ
6. **ç¬¦å·èåˆ**: çŸ¥è¯†å›¾è°±å¢å¼ºã€é€»è¾‘è§„åˆ™æ³¨å…¥

**å“²å­¦é—®é¢˜**: å‘é‡è¡¨ç¤ºæ˜¯å¦çœŸæ­£"ç†è§£"è¯­ä¹‰ï¼Œè¿˜æ˜¯ä»…ä»…æ˜¯ç»Ÿè®¡å…³è”çš„é«˜çº§å½¢å¼ï¼Ÿ

---

## 2 å¼•è¨€

**è¯­ä¹‰å‘é‡ç©ºé—´**ï¼ˆSemantic Vector Spaceï¼‰æ˜¯ç°ä»£AIï¼Œç‰¹åˆ«æ˜¯å¤§è¯­è¨€æ¨¡å‹çš„æ ¸å¿ƒè¡¨ç¤ºèŒƒå¼ã€‚å®ƒå°†ç¦»æ•£çš„ç¬¦å·ï¼ˆè¯ã€å¥å­ã€å›¾åƒç­‰ï¼‰æ˜ å°„åˆ°è¿ç»­çš„é«˜ç»´å‘é‡ç©ºé—´ä¸­ï¼Œä½¿å¾—**è¯­ä¹‰ä¸Šç›¸ä¼¼çš„å¯¹è±¡åœ¨å‡ ä½•ä¸Šç›¸è¿‘**ã€‚

### 1 æ ¸å¿ƒæ€æƒ³

> **å°†"æ„ä¹‰"ï¼ˆMeaningï¼‰ç¼–ç ä¸º"ä½ç½®"ï¼ˆPositionï¼‰ï¼šè¯­ä¹‰ä¸å†æ˜¯ç¬¦å·çš„å±æ€§ï¼Œè€Œæ˜¯å‘é‡ç©ºé—´ä¸­çš„å‡ ä½•å…³ç³»ã€‚**

### 2.2 å…³é”®é—®é¢˜

1. **è¡¨ç¤ºè®ºé—®é¢˜**ï¼šä»€ä¹ˆæ˜¯"æ„ä¹‰"ï¼Ÿå¦‚ä½•ç”¨å‘é‡è¡¨ç¤ºæ„ä¹‰ï¼Ÿ
2. **å‡ ä½•é—®é¢˜**ï¼šå‘é‡ç©ºé—´çš„å‡ ä½•ç»“æ„å¦‚ä½•åæ˜ è¯­ä¹‰ç»“æ„ï¼Ÿ
3. **å­¦ä¹ é—®é¢˜**ï¼šå¦‚ä½•ä»æ•°æ®ä¸­å­¦ä¹ åˆ°æœ‰æ„ä¹‰çš„å‘é‡è¡¨ç¤ºï¼Ÿ
4. **å“²å­¦é—®é¢˜**ï¼šå‘é‡è¡¨ç¤ºçœŸçš„"ç†è§£"äº†è¯­ä¹‰ï¼Œè¿˜æ˜¯åªæ˜¯ç»Ÿè®¡å…³è”ï¼Ÿ

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Vector Space Model](https://en.wikipedia.org/wiki/Vector_space_model)
- [Wikipedia: Distributional Semantics](https://en.wikipedia.org/wiki/Distributional_semantics)

---

## 3 ä»ç¬¦å·åˆ°å‘é‡ï¼šè¡¨ç¤ºçš„èŒƒå¼è½¬æ¢

### 1 ä¼ ç»Ÿç¬¦å·è¡¨ç¤º

**ç¬¦å·ä¸»ä¹‰AI**ï¼ˆSymbolic AIï¼‰å°†æ„ä¹‰è¡¨ç¤ºä¸º**ç¦»æ•£ç¬¦å·åŠå…¶å…³ç³»**ï¼š

```text
cat âŠ‘ animal  ï¼ˆçŒ«æ˜¯åŠ¨ç‰©çš„å­ç±»ï¼‰
âˆ€x (cat(x) â†’ animal(x))  ï¼ˆæ‰€æœ‰çŒ«éƒ½æ˜¯åŠ¨ç‰©ï¼‰
```

**ç‰¹ç‚¹**ï¼š

- âœ… **ç²¾ç¡®**ï¼šé€»è¾‘å…³ç³»æ˜ç¡®
- âœ… **å¯è§£é‡Š**ï¼šæ¨ç†è¿‡ç¨‹é€æ˜
- âŒ **è„†å¼±**ï¼šéš¾ä»¥å¤„ç†æ¨¡ç³Šæ€§å’Œå™ªå£°
- âŒ **çŸ¥è¯†è·å–ç“¶é¢ˆ**ï¼šéœ€è¦æ‰‹å·¥ç¼–å†™è§„åˆ™

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Symbolic AI](https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence)
- [Russell & Norvig, 2020](https://en.wikipedia.org/wiki/Artificial_Intelligence:_A_Modern_Approach) - Artificial Intelligence: A Modern Approach

### 3.2 One-Hotè¡¨ç¤º

**æœ€ç®€å•çš„å‘é‡è¡¨ç¤º**ï¼šæ¯ä¸ªè¯å¯¹åº”ä¸€ä¸ªç»´åº¦ï¼Œè¯æ±‡è¡¨å¤§å°ä¸º |V|

```text
cat  = [1, 0, 0, 0, ..., 0]  âˆˆ â„|V|
dog  = [0, 1, 0, 0, ..., 0]  âˆˆ â„|V|
animal = [0, 0, 1, 0, ..., 0]  âˆˆ â„|V|
```

**é—®é¢˜**ï¼š

- âŒ **ç»´åº¦ç¾éš¾**ï¼š|V| é€šå¸¸æ˜¯ 10â´ ~ 10âµ
- âŒ **ç¨€ç–æ€§**ï¼šæ¯ä¸ªå‘é‡åªæœ‰ä¸€ä¸ªéé›¶å…ƒç´ 
- âŒ **æ— è¯­ä¹‰**ï¼šä»»æ„ä¸¤ä¸ªè¯çš„ä½™å¼¦ç›¸ä¼¼åº¦éƒ½æ˜¯ 0

```text
cos(cat, dog) = cos(cat, animal) = 0
```

å³ï¼šcatä¸dogçš„"è·ç¦»"ç­‰äºcatä¸animalçš„"è·ç¦»"ï¼Œè¿™æ˜¾ç„¶ä¸åˆç†ã€‚

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: One-Hot Encoding](https://en.wikipedia.org/wiki/One-hot)

### 3.3 åˆ†å¸ƒå¼è¡¨ç¤ºï¼ˆDistributed Representationï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼šå°†æ¯ä¸ªè¯è¡¨ç¤ºä¸º**ä½ç»´ç¨ å¯†å‘é‡**ï¼ˆé€šå¸¸ d = 100 ~ 4096ï¼‰

```text
cat    = [0.2, -0.5, 0.8, ..., 0.3]  âˆˆ â„áµˆ
dog    = [0.3, -0.4, 0.7, ..., 0.2]  âˆˆ â„áµˆ
animal = [0.25, -0.45, 0.75, ..., 0.25]  âˆˆ â„áµˆ
```

**å…³é”®æ€§è´¨**ï¼š

```text
cos(cat, dog) â‰ˆ 0.85  ï¼ˆé«˜ï¼‰
cos(cat, animal) â‰ˆ 0.78  ï¼ˆä¸­ï¼‰
cos(cat, apple) â‰ˆ 0.12  ï¼ˆä½ï¼‰
```

**ä¼˜åŠ¿**ï¼š

- âœ… **ä½ç»´**ï¼šd â‰ª |V|
- âœ… **ç¨ å¯†**ï¼šæ‰€æœ‰ç»´åº¦éƒ½æœ‰æ„ä¹‰
- âœ… **è¯­ä¹‰**ï¼šç›¸ä¼¼è¯åœ¨å‘é‡ç©ºé—´ä¸­ç›¸è¿‘

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Hinton et al., 1986](https://en.wikipedia.org/wiki/Connectionism) - Learning Distributed Representations of Concepts
- [Wikipedia: Distributed Representation](https://en.wikipedia.org/wiki/Distributed_representation)

### 3.4 èŒƒå¼è½¬æ¢çš„æœ¬è´¨

| ç»´åº¦ | ç¬¦å·è¡¨ç¤º | å‘é‡è¡¨ç¤º | å‚è€ƒæ–‡çŒ® |
|------|---------|----------|----------|
| **è¡¨ç¤ºæ–¹å¼** | ç¦»æ•£ç¬¦å· | è¿ç»­å‘é‡ | [Bengio et al., 2013](https://arxiv.org/abs/1206.5533) |
| **è¯­ä¹‰ç¼–ç ** | é€»è¾‘å…³ç³» | å‡ ä½•å…³ç³» | [Turney & Pantel, 2010](https://www.jair.org/index.php/jair/article/view/10640) |
| **ç›¸ä¼¼åº¦** | äººå·¥å®šä¹‰ | è‡ªåŠ¨å­¦ä¹  | [Mikolov et al., 2013](https://arxiv.org/abs/1301.3781) |
| **æ³›åŒ–èƒ½åŠ›** | å¼± | å¼º | [Goodfellow et al., 2016](https://www.deeplearningbook.org/) |
| **å¯è§£é‡Šæ€§** | å¼º | å¼± | [Lipton, 2018](https://arxiv.org/abs/1606.03490) |

---

## 4 å‘é‡ç©ºé—´æ¨¡å‹çš„æ•°å­¦åŸºç¡€

### 1 å‘é‡ç©ºé—´çš„å®šä¹‰

**å®šä¹‰ï¼ˆå‘é‡ç©ºé—´ï¼‰**ï¼š

ä¸€ä¸ª**å‘é‡ç©ºé—´** V æ˜¯ä¸€ä¸ªé›†åˆï¼Œé…æœ‰ä¸¤ä¸ªè¿ç®—ï¼š

1. **å‘é‡åŠ æ³•**ï¼šğ’– + ğ’— âˆˆ V
2. **æ ‡é‡ä¹˜æ³•**ï¼šÎ± ğ’– âˆˆ V ï¼ˆÎ± âˆˆ â„ï¼‰

æ»¡è¶³ä»¥ä¸‹**å…«æ¡å…¬ç†**ï¼š

1. åŠ æ³•äº¤æ¢å¾‹ï¼šğ’– + ğ’— = ğ’— + ğ’–
2. åŠ æ³•ç»“åˆå¾‹ï¼š(ğ’– + ğ’—) + ğ’˜ = ğ’– + (ğ’— + ğ’˜)
3. åŠ æ³•é›¶å…ƒï¼šâˆƒ ğŸ, ğ’– + ğŸ = ğ’–
4. åŠ æ³•é€†å…ƒï¼šâˆƒ -ğ’–, ğ’– + (-ğ’–) = ğŸ
5. ä¹˜æ³•å•ä½å…ƒï¼š1 Â· ğ’– = ğ’–
6. ä¹˜æ³•ç»“åˆå¾‹ï¼šÎ±(Î²ğ’–) = (Î±Î²)ğ’–
7. åˆ†é…å¾‹1ï¼šÎ±(ğ’– + ğ’—) = Î±ğ’– + Î±ğ’—
8. åˆ†é…å¾‹2ï¼š(Î± + Î²)ğ’– = Î±ğ’– + Î²ğ’–

**AIä¸­çš„å‘é‡ç©ºé—´**ï¼šé€šå¸¸æ˜¯ â„áµˆï¼ˆdç»´æ¬§å‡ é‡Œå¾—ç©ºé—´ï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Vector Space](https://en.wikipedia.org/wiki/Vector_space)
- [Strang, 2016](https://en.wikipedia.org/wiki/Introduction_to_Linear_Algebra) - Introduction to Linear Algebra

### 4.2 å†…ç§¯ä¸èŒƒæ•°

**å®šä¹‰ï¼ˆå†…ç§¯ï¼‰**ï¼š

ä¸€ä¸ª**å†…ç§¯**æ˜¯å‡½æ•° âŸ¨Â·,Â·âŸ© : V Ã— V â†’ â„ï¼Œæ»¡è¶³ï¼š

1. **å¯¹ç§°æ€§**ï¼šâŸ¨ğ’–, ğ’—âŸ© = âŸ¨ğ’—, ğ’–âŸ©
2. **çº¿æ€§**ï¼šâŸ¨Î±ğ’– + Î²ğ’—, ğ’˜âŸ© = Î±âŸ¨ğ’–, ğ’˜âŸ© + Î²âŸ¨ğ’—, ğ’˜âŸ©
3. **æ­£å®šæ€§**ï¼šâŸ¨ğ’–, ğ’–âŸ© â‰¥ 0ï¼Œä¸” âŸ¨ğ’–, ğ’–âŸ© = 0 âŸº ğ’– = ğŸ

**æ¬§å‡ é‡Œå¾—å†…ç§¯**ï¼š

```text
âŸ¨ğ’–, ğ’—âŸ© = ğ’– Â· ğ’— = âˆ‘áµ¢ uáµ¢váµ¢
```

**å®šä¹‰ï¼ˆèŒƒæ•°ï¼‰**ï¼š

ç”±å†…ç§¯å¯¼å‡ºçš„**èŒƒæ•°**ï¼ˆé•¿åº¦ï¼‰ï¼š

```text
â€–ğ’–â€– = âˆšâŸ¨ğ’–, ğ’–âŸ©
```

å¯¹äºæ¬§å‡ é‡Œå¾—ç©ºé—´ï¼š

```text
â€–ğ’–â€–â‚‚ = âˆš(âˆ‘áµ¢ uáµ¢Â²)  ï¼ˆLâ‚‚èŒƒæ•°ï¼‰
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Inner Product Space](https://en.wikipedia.org/wiki/Inner_product_space)
- [Wikipedia: Norm (mathematics)](https://en.wikipedia.org/wiki/Norm_(mathematics))

### 4.3 è·ç¦»ä¸ç›¸ä¼¼åº¦åº¦é‡

#### 1 . æ¬§å‡ é‡Œå¾—è·ç¦»

```text
d(ğ’–, ğ’—) = â€–ğ’– - ğ’—â€–â‚‚ = âˆš(âˆ‘áµ¢ (uáµ¢ - váµ¢)Â²)
```

**ç‰¹ç‚¹**ï¼š

- âœ… ç›´è§‚çš„"å‡ ä½•è·ç¦»"
- âŒ å—å‘é‡é•¿åº¦å½±å“

#### 2 . ä½™å¼¦ç›¸ä¼¼åº¦

```text
cos(ğ’–, ğ’—) = âŸ¨ğ’–, ğ’—âŸ© / (â€–ğ’–â€– â€–ğ’—â€–)
```

**å€¼åŸŸ**ï¼š[-1, 1]

- cos(ğ’–, ğ’—) = 1ï¼šå®Œå…¨ç›¸åŒæ–¹å‘
- cos(ğ’–, ğ’—) = 0ï¼šæ­£äº¤ï¼ˆæ— å…³ï¼‰
- cos(ğ’–, ğ’—) = -1ï¼šå®Œå…¨ç›¸åæ–¹å‘

**ç‰¹ç‚¹**ï¼š

- âœ… ä¸å—å‘é‡é•¿åº¦å½±å“ï¼ˆåªçœ‹æ–¹å‘ï¼‰
- âœ… ç¬¦åˆäººç±»å¯¹"ç›¸ä¼¼åº¦"çš„ç›´è§‰
- âœ… **AIä¸­æœ€å¸¸ç”¨çš„ç›¸ä¼¼åº¦åº¦é‡**

#### 3 . ä½™å¼¦è·ç¦»

```text
d_cos(ğ’–, ğ’—) = 1 - cos(ğ’–, ğ’—)
```

**å€¼åŸŸ**ï¼š[0, 2]

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)
- [Wikipedia: Euclidean Distance](https://en.wikipedia.org/wiki/Euclidean_distance)

---

## 5 è¯­ä¹‰å‘é‡ç©ºé—´çš„å‡ ä½•ç»“æ„

### 1 è¯­ä¹‰å‘é‡ç©ºé—´çš„å®šä¹‰

**å®šä¹‰ï¼ˆè¯­ä¹‰å‘é‡ç©ºé—´ï¼‰**ï¼š

ä¸€ä¸ª**è¯­ä¹‰å‘é‡ç©ºé—´** ğ• æ˜¯ä¸€ä¸ªä¸‰å…ƒç»„ (â„áµˆ, Enc, Sem)ï¼Œå…¶ä¸­ï¼š

- **â„áµˆ**ï¼šdç»´æ¬§å‡ é‡Œå¾—ç©ºé—´ï¼ˆå‡ ä½•ç©ºé—´ï¼‰
- **Enc : Î£ â†’ â„áµˆ**ï¼šç¼–ç å™¨ï¼Œå°†ç¬¦å·æ˜ å°„åˆ°å‘é‡
- **Sem**ï¼šè¯­ä¹‰å…³ç³»é›†åˆï¼Œå®šä¹‰äº†ç¬¦å·é—´çš„è¯­ä¹‰å…³ç³»

**å…³é”®è¦æ±‚**ï¼š

> **å‡ ä½•å…³ç³» â‰ˆ è¯­ä¹‰å…³ç³»**

å½¢å¼åŒ–ï¼šå¯¹äºè¯­ä¹‰å…³ç³» R(a, b)ï¼Œåº”æœ‰ï¼š

```text
R(a, b) â‡’ d(Enc(a), Enc(b)) è¾ƒå°
Â¬R(a, b) â‡’ d(Enc(a), Enc(b)) è¾ƒå¤§
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Turney & Pantel, 2010](https://www.jair.org/index.php/jair/article/view/10640) - From Frequency to Meaning

### 5.2 å‡ ä½•æ€§è´¨

#### 1 . èšç±»æ€§ï¼ˆClusteringï¼‰

**è¯­ä¹‰ç›¸ä¼¼çš„è¯èšé›†åœ¨ä¸€èµ·**ï¼š

```text
{cat, dog, rabbit, ...} â† åŠ¨ç‰©èšç±»
{red, blue, green, ...} â† é¢œè‰²èšç±»
{run, walk, jump, ...}  â† åŠ¨ä½œèšç±»
```

**æ•°å­¦è¡¨è¿°**ï¼š

è®¾ C æ˜¯ä¸€ä¸ªè¯­ä¹‰ç±»åˆ«ï¼Œåˆ™ï¼š

```text
âˆ€a, b âˆˆ C : E[d(Enc(a), Enc(b))] < E[d(Enc(a), Enc(x))]
                                   x âˆ‰ C
```

#### 2 . çº¿æ€§æ€§ï¼ˆLinearityï¼‰

**è¯­ä¹‰å…³ç³»å¯ä»¥ç”¨å‘é‡è¿ç®—è¡¨ç¤º**ï¼š

ç»å…¸ä¾‹å­ï¼ˆWord2Vecï¼‰ï¼š

```text
king - man + woman â‰ˆ queen
```

æ›´ä¸€èˆ¬åœ°ï¼š

```text
vec(Paris) - vec(France) â‰ˆ vec(Berlin) - vec(Germany)
```

**æ•°å­¦è¡¨è¿°**ï¼š

å¯¹äºå…³ç³» R : A â†’ Bï¼Œå­˜åœ¨å‘é‡ ğ’“ âˆˆ â„áµˆï¼Œä½¿å¾—ï¼š

```text
R(a, b) â‡’ Enc(b) â‰ˆ Enc(a) + ğ’“
```

#### 3 . å¯åˆ†æ€§ï¼ˆSeparabilityï¼‰

**ä¸åŒè¯­ä¹‰ç±»åˆ«çº¿æ€§å¯åˆ†**ï¼š

å¯¹äºäºŒå…ƒåˆ†ç±»ä»»åŠ¡ï¼ˆå¦‚æƒ…æ„Ÿåˆ†æï¼šæ­£é¢/è´Ÿé¢ï¼‰ï¼Œå­˜åœ¨è¶…å¹³é¢ ğ’˜ âˆˆ â„áµˆï¼Œä½¿å¾—ï¼š

```text
âŸ¨ğ’˜, Enc(x)âŸ© > 0  â‡”  x âˆˆ Positive
âŸ¨ğ’˜, Enc(x)âŸ© < 0  â‡”  x âˆˆ Negative
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Mikolov et al., 2013](https://arxiv.org/abs/1301.3781) - Linguistic Regularities in Continuous Space
- [Wikipedia: Linear Separability](https://en.wikipedia.org/wiki/Linear_separability)

### 5.3 æ‹“æ‰‘ç»“æ„

è¯­ä¹‰å‘é‡ç©ºé—´ä¸ä»…æ˜¯åº¦é‡ç©ºé—´ï¼Œè¿˜å…·æœ‰**æ‹“æ‰‘ç»“æ„**ï¼š

#### 1 . æµå½¢ç»“æ„ï¼ˆManifold Structureï¼‰

**å‡è®¾**ï¼šé«˜ç»´è¯­ä¹‰å‘é‡ç©ºé—´å®é™…ä¸Šæ˜¯**ä½ç»´æµå½¢åµŒå…¥åˆ°é«˜ç»´ç©ºé—´**ã€‚

```text
çœŸå®è¯­ä¹‰ç©ºé—´ M âŠ‚ â„áµˆ  ï¼ˆM æ˜¯ä½ç»´æµå½¢ï¼‰
å†…åœ¨ç»´åº¦ â‰ª åµŒå…¥ç»´åº¦ d
```

**ç›´è§‰**ï¼šè™½ç„¶åµŒå…¥åœ¨ d=768 ç»´ç©ºé—´ï¼Œä½†å®é™…"è‡ªç”±åº¦"å¯èƒ½åªæœ‰ 10~100 ç»´ã€‚

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Manifold](https://en.wikipedia.org/wiki/Manifold)
- [Fefferman et al., 2016](https://www.pnas.org/doi/full/10.1073/pnas.1408993113) - Testing the Manifold Hypothesis

#### 2 . æ›²ç‡ï¼ˆCurvatureï¼‰

æœ€è¿‘ç ”ç©¶è¡¨æ˜ï¼Œè¯­ä¹‰ç©ºé—´å¯èƒ½å…·æœ‰**è´Ÿæ›²ç‡**ï¼ˆåŒæ›²å‡ ä½•ï¼‰ï¼š

**åŒæ›²å‡ ä½•çš„ä¼˜åŠ¿**ï¼š

- âœ… æ›´é€‚åˆè¡¨ç¤º**å±‚æ¬¡ç»“æ„**ï¼ˆå¦‚ WordNetï¼‰
- âœ… åœ¨ç›¸åŒç»´åº¦ä¸‹æœ‰**æŒ‡æ•°çº§æ›´å¤§çš„å®¹é‡**

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Nickel & Kiela, 2017](https://arxiv.org/abs/1705.08039) - PoincarÃ© Embeddings for Learning Hierarchical Representations
- [Wikipedia: Hyperbolic Geometry](https://en.wikipedia.org/wiki/Hyperbolic_geometry)

---

## 6 è¯­ä¹‰å‘é‡ç©ºé—´çš„æ„å»ºæ–¹æ³•

### 1 . åŸºäºè®¡æ•°çš„æ–¹æ³•ï¼ˆCount-basedï¼‰

#### 1 æœ¯è¯­-æ–‡æ¡£çŸ©é˜µï¼ˆTerm-Document Matrixï¼‰

**å®šä¹‰**ï¼š

```text
X âˆˆ â„|V|Ã—|D|
Xáµ¢â±¼ = è¯ wáµ¢ åœ¨æ–‡æ¡£ dâ±¼ ä¸­å‡ºç°çš„æ¬¡æ•°
```

**é™ç»´æ–¹æ³•**ï¼š

- **å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰**ï¼šX â‰ˆ U Î£ Váµ€
- **æ½œåœ¨è¯­ä¹‰åˆ†æï¼ˆLSAï¼‰**ï¼šå– U çš„å‰ k åˆ—ä½œä¸ºè¯å‘é‡

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Latent Semantic Analysis](https://en.wikipedia.org/wiki/Latent_semantic_analysis)
- [Deerwester et al., 1990](https://en.wikipedia.org/wiki/Latent_semantic_analysis) - Indexing by Latent Semantic Analysis

#### 2 è¯-ä¸Šä¸‹æ–‡çŸ©é˜µï¼ˆWord-Context Matrixï¼‰

**å®šä¹‰**ï¼š

```text
X âˆˆ â„|V|Ã—|V|
Xáµ¢â±¼ = è¯ wáµ¢ ä¸è¯ wâ±¼ åœ¨çª—å£å†…å…±ç°çš„æ¬¡æ•°
```

**å˜ä½“**ï¼š

- **åŸå§‹è®¡æ•°**ï¼šXáµ¢â±¼ = count(wáµ¢, wâ±¼)
- **ç‚¹äº’ä¿¡æ¯ï¼ˆPMIï¼‰**ï¼š

```text
PMI(wáµ¢, wâ±¼) = log P(wáµ¢, wâ±¼) / (P(wáµ¢) P(wâ±¼))
```

- **æ­£ç‚¹äº’ä¿¡æ¯ï¼ˆPPMIï¼‰**ï¼š

```text
PPMI(wáµ¢, wâ±¼) = max(0, PMI(wáµ¢, wâ±¼))
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Pointwise Mutual Information](https://en.wikipedia.org/wiki/Pointwise_mutual_information)

### 2 . åŸºäºé¢„æµ‹çš„æ–¹æ³•ï¼ˆPrediction-basedï¼‰

#### 1 Word2Vec

**æ ¸å¿ƒæ€æƒ³**ï¼šé€šè¿‡**é¢„æµ‹ä¸Šä¸‹æ–‡**æˆ–**ä»ä¸Šä¸‹æ–‡é¢„æµ‹ç›®æ ‡è¯**æ¥å­¦ä¹ å‘é‡ã€‚

**ä¸¤ç§æ¶æ„**ï¼š

1. **CBOW**ï¼ˆContinuous Bag-of-Wordsï¼‰ï¼š

    ```text
    P(wâ‚œ | wâ‚œâ‚‹â‚™, ..., wâ‚œâ‚‹â‚, wâ‚œâ‚Šâ‚, ..., wâ‚œâ‚Šâ‚™)
    ```

    ä»ä¸Šä¸‹æ–‡é¢„æµ‹ä¸­å¿ƒè¯

2. **Skip-Gram**ï¼š

    ```text
    P(wâ‚œâ‚‹â‚™, ..., wâ‚œâ‚‹â‚, wâ‚œâ‚Šâ‚, ..., wâ‚œâ‚Šâ‚™ | wâ‚œ)
    ```

ä»ä¸­å¿ƒè¯é¢„æµ‹ä¸Šä¸‹æ–‡

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Mikolov et al., 2013](https://arxiv.org/abs/1301.3781) - Efficient Estimation of Word Representations in Vector Space
- [Wikipedia: Word2vec](https://en.wikipedia.org/wiki/Word2vec)

#### 2 GloVeï¼ˆGlobal Vectorsï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼šç»“åˆå…¨å±€ç»Ÿè®¡ä¿¡æ¯ï¼ˆå…±ç°çŸ©é˜µï¼‰å’Œå±€éƒ¨é¢„æµ‹ï¼ˆWord2Vecï¼‰ã€‚

**ç›®æ ‡å‡½æ•°**ï¼š

```text
J = âˆ‘áµ¢â±¼ f(Xáµ¢â±¼) (ğ’–áµ¢áµ€ ğ’—â±¼ + báµ¢ + câ±¼ - log Xáµ¢â±¼)Â²
```

å…¶ä¸­ï¼š

- Xáµ¢â±¼ï¼šè¯ wáµ¢ å’Œ wâ±¼ çš„å…±ç°æ¬¡æ•°
- f(x)ï¼šæƒé‡å‡½æ•°ï¼Œå‰Šå¼±é«˜é¢‘è¯çš„å½±å“

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Pennington et al., 2014](https://nlp.stanford.edu/pubs/glove.pdf) - GloVe: Global Vectors for Word Representation
- [Wikipedia: GloVe](https://en.wikipedia.org/wiki/GloVe)

### 3 . åŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•ï¼ˆNeural-basedï¼‰

#### 1 ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤ºï¼ˆContextualized Representationsï¼‰

**ä¼ ç»Ÿæ–¹æ³•çš„å±€é™**ï¼šæ¯ä¸ªè¯åªæœ‰**ä¸€ä¸ªå›ºå®šå‘é‡**ï¼Œæ— æ³•å¤„ç†**ä¸€è¯å¤šä¹‰**ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š**ä¸Šä¸‹æ–‡ç›¸å…³çš„å‘é‡è¡¨ç¤º**

```text
vec("bank") åœ¨ "river bank" ä¸­ â‰  vec("bank") åœ¨ "bank account" ä¸­
```

**ä»£è¡¨æ¨¡å‹**ï¼š

1. **ELMo**ï¼ˆEmbeddings from Language Modelsï¼‰ï¼š

    ```text
    ğ’‰áµ¢ = BiLSTM(wâ‚, ..., wâ‚™)[i]
    ```

2. **BERT**ï¼ˆBidirectional Encoder Representations from Transformersï¼‰ï¼š

    ```text
    ğ’‰áµ¢ = Transformer(wâ‚, ..., wâ‚™)[i]
    ```

3. **GPT**ï¼ˆGenerative Pre-trained Transformerï¼‰ï¼š

    ```text
    ğ’‰áµ¢ = TransformerDecoder(wâ‚, ..., wáµ¢)[i]
    ```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Peters et al., 2018](https://arxiv.org/abs/1802.05365) - Deep Contextualized Word Representations
- [Devlin et al., 2019](https://arxiv.org/abs/1810.04805) - BERT
- [Radford et al., 2018](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf) - Improving Language Understanding

---

## 7 è¯­ä¹‰å‘é‡ç©ºé—´çš„æ€§è´¨

### 1 . åˆ†å¸ƒå‡è®¾ï¼ˆDistributional Hypothesisï¼‰

**æ ¸å¿ƒåŸç†**ï¼š

> **"A word is characterized by the company it keeps."**
>
> **"è¯çš„æ„ä¹‰ç”±å…¶ä¸Šä¸‹æ–‡å†³å®šã€‚"**
>
> â€” J. R. Firth (1957)

**å½¢å¼åŒ–**ï¼š

```text
Sem(wâ‚) â‰ˆ Sem(wâ‚‚)  âŸº  Context(wâ‚) â‰ˆ Context(wâ‚‚)
```

**ä¾‹å­**ï¼š

```text
"cat" å’Œ "dog" ç»å¸¸å‡ºç°åœ¨ç›¸ä¼¼ä¸Šä¸‹æ–‡ä¸­ï¼š
  - "I have a ___ as a pet."
  - "The ___ is sleeping."
  - "Feed the ___."

å› æ­¤ï¼Œvec(cat) â‰ˆ vec(dog)
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Firth, 1957](https://en.wikipedia.org/wiki/Distributional_semantics) - A Synopsis of Linguistic Theory
- [Harris, 1954](https://www.jstor.org/stable/411805) - Distributional Structure

### 2 . ç»„åˆæ€§ï¼ˆCompositionalityï¼‰

**é—®é¢˜**ï¼šå¦‚ä½•ä»è¯å‘é‡å¾—åˆ°å¥å­å‘é‡ï¼Ÿ

**ç®€å•æ–¹æ³•**ï¼š

1. **å¹³å‡**ï¼š

    ```text
    vec(sentence) = (1/n) âˆ‘áµ¢ vec(wáµ¢)
    ```

2. **åŠ æƒå¹³å‡**ï¼ˆå¦‚ TF-IDF æƒé‡ï¼‰

**é«˜çº§æ–¹æ³•**ï¼š

1. **RNN/LSTM**ï¼š

    ```text
    ğ’‰â‚œ = LSTM(ğ’‰â‚œâ‚‹â‚, vec(wâ‚œ))
    vec(sentence) = ğ’‰â‚™
    ```

2. **Transformer**ï¼š

    ```text
    ğ’‰â‚, ..., ğ’‰â‚™ = Transformer(vec(wâ‚), ..., vec(wâ‚™))
    vec(sentence) = ğ’‰â‚  ï¼ˆæˆ–å¹³å‡ï¼‰
    ```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Principle of Compositionality](https://en.wikipedia.org/wiki/Principle_of_compositionality)

### 3 . å¯å­¦ä¹ æ€§ï¼ˆLearnabilityï¼‰

**å…³é”®é—®é¢˜**ï¼šä»æœ‰é™æ•°æ®ä¸­å­¦ä¹ åˆ°çš„å‘é‡èƒ½å¦æ³›åŒ–ï¼Ÿ

**ç†è®ºä¿è¯**ï¼š

- **Johnson-Lindenstrausså¼•ç†**ï¼šé«˜ç»´å‘é‡å¯ä»¥è¿‘ä¼¼ä¿è·åœ°æŠ•å½±åˆ°ä½ç»´ç©ºé—´
- **éšæœºæŠ•å½±**ï¼šéšæœºåˆå§‹åŒ–çš„å‘é‡ç»è¿‡è®­ç»ƒå¯ä»¥å­¦ä¹ åˆ°æœ‰æ„ä¹‰çš„è¡¨ç¤º

**ç»éªŒå‘ç°**ï¼š

- âœ… å¤§è§„æ¨¡è¯­æ–™ï¼ˆå¦‚10äº¿è¯ï¼‰å¯ä»¥å­¦ä¹ åˆ°é«˜è´¨é‡çš„è¯å‘é‡
- âœ… é¢„è®­ç»ƒæ¨¡å‹å¯ä»¥è¿ç§»åˆ°ä¸‹æ¸¸ä»»åŠ¡

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Johnson-Lindenstrauss Lemma](https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma)

---

## 8 è¯­ä¹‰å‘é‡ç©ºé—´çš„ç»´åº¦é—®é¢˜

### 1 ç»´åº¦çš„é€‰æ‹©

**ç»éªŒæ³•åˆ™**ï¼š

| åº”ç”¨åœºæ™¯ | å…¸å‹ç»´åº¦ | å‚è€ƒæ¨¡å‹ |
|---------|---------|----------|
| è¯å‘é‡ï¼ˆWord2Vec, GloVeï¼‰ | 50 ~ 300 | [Mikolov et al., 2013](https://arxiv.org/abs/1301.3781) |
| å¥å­å‘é‡ï¼ˆSentence-BERTï¼‰ | 384 ~ 768 | [Reimers & Gurevych, 2019](https://arxiv.org/abs/1908.10084) |
| BERT-base | 768 | [Devlin et al., 2019](https://arxiv.org/abs/1810.04805) |
| BERT-large | 1024 | [Devlin et al., 2019](https://arxiv.org/abs/1810.04805) |
| GPT-3 | 12288 | [Brown et al., 2020](https://arxiv.org/abs/2005.14165) |

### 8.2 ç»´åº¦çš„å½±å“

**ç»´åº¦å¤ªä½**ï¼š

- âŒ è¡¨è¾¾èƒ½åŠ›ä¸è¶³ï¼Œéš¾ä»¥åŒºåˆ†ç»†å¾®è¯­ä¹‰å·®å¼‚
- âŒ ç±»æ¯”å…³ç³»ï¼ˆå¦‚ king - man + woman â‰ˆ queenï¼‰ç²¾åº¦ä¸‹é™

**ç»´åº¦å¤ªé«˜**ï¼š

- âŒ è¿‡æ‹Ÿåˆé£é™©
- âŒ è®¡ç®—å’Œå­˜å‚¨æˆæœ¬å¢åŠ 
- âŒ **ç»´åº¦ç¾éš¾**ï¼ˆCurse of Dimensionalityï¼‰

### 8.3 å†…åœ¨ç»´åº¦ï¼ˆIntrinsic Dimensionalityï¼‰

**è§‚å¯Ÿ**ï¼šè™½ç„¶åµŒå…¥ç»´åº¦ d å¾ˆé«˜ï¼ˆå¦‚768ï¼‰ï¼Œä½†**å®é™…æœ‰æ•ˆç»´åº¦å¯èƒ½è¿œå°äº d**ã€‚

**å†…åœ¨ç»´åº¦ä¼°è®¡æ–¹æ³•**ï¼š

1. **PCAåˆ†æ**ï¼šçœ‹å‰ k ä¸ªä¸»æˆåˆ†è§£é‡Šäº†å¤šå°‘æ–¹å·®
2. **å±€éƒ¨ç»´åº¦ä¼°è®¡**ï¼šä¼°è®¡æµå½¢çš„å±€éƒ¨ç»´åº¦

**ç»éªŒå‘ç°**ï¼š

- BERTçš„768ç»´å‘é‡çš„å†…åœ¨ç»´åº¦çº¦ä¸º 100~200
- è¯´æ˜å­˜åœ¨å¤§é‡å†—ä½™

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Intrinsic Dimension](https://en.wikipedia.org/wiki/Intrinsic_dimension)

---

## 9 è¯­ä¹‰å‘é‡ç©ºé—´çš„å±€é™æ€§

### 1 . é™æ€æ€§ï¼ˆStatic Embeddingsï¼‰

**é—®é¢˜**ï¼šä¼ ç»ŸWord2Vec/GloVeä¸ºæ¯ä¸ªè¯åˆ†é…**å›ºå®šå‘é‡**ï¼Œæ— æ³•å¤„ç†ï¼š

- **ä¸€è¯å¤šä¹‰**ï¼ˆPolysemyï¼‰ï¼š

```text
"bank" åœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸­æœ‰ä¸åŒå«ä¹‰
```

- **ä¸Šä¸‹æ–‡ä¾èµ–**ï¼š

```text
"good" åœ¨ "good food" å’Œ "good enough" ä¸­å«ä¹‰ä¸åŒ
```

**è§£å†³æ–¹æ¡ˆ**ï¼šä¸Šä¸‹æ–‡åŒ–è¡¨ç¤ºï¼ˆELMo, BERT, GPTï¼‰

### 2 . åè§ä¸å…¬å¹³æ€§ï¼ˆBias and Fairnessï¼‰

**é—®é¢˜**ï¼šå‘é‡ç©ºé—´ä¼š**ç»§æ‰¿è®­ç»ƒæ•°æ®ä¸­çš„ç¤¾ä¼šåè§**ã€‚

**ä¾‹å­**ï¼š

```text
vec(programmer) - vec(man) + vec(woman) â‰ˆ vec(homemaker)
```

**åŸå› **ï¼šè®­ç»ƒè¯­æ–™ä¸­çš„æ€§åˆ«åˆ»æ¿å°è±¡è¢«ç¼–ç åˆ°å‘é‡ä¸­ã€‚

**ç¼“è§£æ–¹æ³•**ï¼š

1. **å»åç½®ç®—æ³•**ï¼šè°ƒæ•´å‘é‡ä½¿å…¶åœ¨æ€§åˆ«æ–¹å‘ä¸Šæ­£äº¤
2. **å¯¹æŠ—è®­ç»ƒ**ï¼šè®©æ¨¡å‹æ— æ³•ä»å‘é‡ä¸­é¢„æµ‹æ•æ„Ÿå±æ€§
3. **æ•°æ®å¹³è¡¡**ï¼šä½¿ç”¨æ›´å¹³è¡¡çš„è®­ç»ƒæ•°æ®

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Bolukbasi et al., 2016](https://arxiv.org/abs/1607.06520) - Man is to Computer Programmer as Woman is to Homemaker?
- [Wikipedia: Algorithmic Bias](https://en.wikipedia.org/wiki/Algorithmic_bias)

### 3 . å¯è§£é‡Šæ€§ï¼ˆInterpretabilityï¼‰

**é—®é¢˜**ï¼šå‘é‡çš„**å„ä¸ªç»´åº¦æ²¡æœ‰æ˜ç¡®è¯­ä¹‰**ã€‚

**ä¾‹å­**ï¼š

```text
vec(cat)[42] = 0.73  â† è¿™ä¸ª0.73ä»£è¡¨ä»€ä¹ˆï¼Ÿ
```

**å°è¯•**ï¼š

- **å¯è§£é‡Šç»´åº¦**ï¼šæŸäº›ç»´åº¦ä¼¼ä¹å¯¹åº”ç‰¹å®šè¯­ä¹‰ï¼ˆå¦‚æ€§åˆ«ã€æ—¶æ€ï¼‰
- **æ¢æµ‹ä»»åŠ¡**ï¼ˆProbing Tasksï¼‰ï¼šè®­ç»ƒåˆ†ç±»å™¨çœ‹å‘é‡æ˜¯å¦ç¼–ç äº†ç‰¹å®šä¿¡æ¯

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Belinkov & Glass, 2019](https://arxiv.org/abs/1812.08951) - Analysis Methods in Neural Language Processing

### 4 . è®¡ç®—æˆæœ¬ï¼ˆComputational Costï¼‰

**é—®é¢˜**ï¼šé«˜ç»´å‘é‡çš„è¿ç®—æˆæœ¬é«˜æ˜‚ã€‚

| æ“ä½œ | å¤æ‚åº¦ | åœºæ™¯ |
|------|--------|------|
| å‘é‡ç‚¹ç§¯ | O(d) | ç›¸ä¼¼åº¦è®¡ç®— |
| çŸ©é˜µä¹˜æ³• | O(ndÂ²) | Transformer |
| æœ€è¿‘é‚»æœç´¢ | O(Nd) | å‘é‡æ£€ç´¢ |

**è§£å†³æ–¹æ¡ˆ**ï¼š

1. **é‡åŒ–**ï¼ˆQuantizationï¼‰ï¼šå‡å°‘æµ®ç‚¹ç²¾åº¦ï¼ˆFP32 â†’ FP16 â†’ INT8ï¼‰
2. **ç¨€ç–åŒ–**ï¼ˆSparsificationï¼‰ï¼šå¤§éƒ¨åˆ†ç»´åº¦ç½®é›¶
3. **è¿‘ä¼¼æœ€è¿‘é‚»**ï¼ˆANNï¼‰ï¼šç”¨ç´¢å¼•ç»“æ„åŠ é€Ÿæ£€ç´¢ï¼ˆå¦‚ FAISSï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Nearest Neighbor Search](https://en.wikipedia.org/wiki/Nearest_neighbor_search)
- [Johnson et al., 2019](https://arxiv.org/abs/1702.08734) - Billion-Scale Similarity Search with GPUs

---

## 10 æ€»ç»“

### 1 æ ¸å¿ƒè¦ç‚¹

1. **èŒƒå¼è½¬æ¢**ï¼šä»ç¬¦å·åˆ°å‘é‡ï¼Œä»ç¦»æ•£åˆ°è¿ç»­
2. **åˆ†å¸ƒå‡è®¾**ï¼šè¯çš„æ„ä¹‰ç”±å…¶ä¸Šä¸‹æ–‡å†³å®š
3. **å‡ ä½•ç»“æ„**ï¼šè¯­ä¹‰å…³ç³» â‡” å‡ ä½•å…³ç³»
4. **å­¦ä¹ æ–¹æ³•**ï¼šè®¡æ•°æ³•ã€é¢„æµ‹æ³•ã€ç¥ç»ç½‘ç»œæ³•
5. **ä¸Šä¸‹æ–‡åŒ–**ï¼šä»é™æ€å‘é‡åˆ°åŠ¨æ€å‘é‡
6. **å±€é™æ€§**ï¼šåè§ã€ä¸å¯è§£é‡Šã€è®¡ç®—æˆæœ¬

### 10.2 è¯­ä¹‰å‘é‡ç©ºé—´çš„æ„ä¹‰

> **è¯­ä¹‰å‘é‡ç©ºé—´æ˜¯AIä»ç¬¦å·ä¸»ä¹‰åˆ°è¿æ¥ä¸»ä¹‰è½¬å˜çš„æ ¸å¿ƒè½½ä½“ã€‚å®ƒå°†"æ„ä¹‰"ä»ç¦»æ•£çš„é€»è¾‘å‘½é¢˜è½¬åŒ–ä¸ºè¿ç»­çš„å‡ ä½•å¯¹è±¡ï¼Œä½¿å¾—æœºå™¨å­¦ä¹ æ–¹æ³•èƒ½å¤Ÿç›´æ¥å¤„ç†è¯­ä¹‰ã€‚**

### 10.3 æœªè§£é—®é¢˜

1. **ç†è®º**ï¼šä¸ºä»€ä¹ˆå‘é‡è¡¨ç¤ºèƒ½å¤Ÿæ•æ‰è¯­ä¹‰ï¼Ÿ
2. **å“²å­¦**ï¼šå‘é‡ç›¸ä¼¼åº¦çœŸçš„ä»£è¡¨"ç†è§£"å—ï¼Ÿ
3. **æŠ€æœ¯**ï¼šå¦‚ä½•æ„å»ºæ›´å¥½çš„è¯­ä¹‰ç©ºé—´ï¼ˆå¦‚åŒæ›²ç©ºé—´ã€é‡å­ç©ºé—´ï¼‰ï¼Ÿ
4. **ä¼¦ç†**ï¼šå¦‚ä½•æ¶ˆé™¤å‘é‡ä¸­çš„åè§ï¼Ÿ

---

## å‚è€ƒæ–‡çŒ®

### 10.4 åŸºç¡€ç†è®º

1. [Wikipedia: Vector Space Model](https://en.wikipedia.org/wiki/Vector_space_model)
2. [Wikipedia: Distributional Semantics](https://en.wikipedia.org/wiki/Distributional_semantics)
3. [Wikipedia: Vector Space](https://en.wikipedia.org/wiki/Vector_space)
4. [Turney & Pantel, 2010](https://www.jair.org/index.php/jair/article/view/10640) - From Frequency to Meaning: Vector Space Models of Semantics

### 10.5 è¯å‘é‡

1. [Mikolov et al., 2013](https://arxiv.org/abs/1301.3781) - Efficient Estimation of Word Representations in Vector Space
2. [Pennington et al., 2014](https://nlp.stanford.edu/pubs/glove.pdf) - GloVe: Global Vectors for Word Representation
3. [Wikipedia: Word2vec](https://en.wikipedia.org/wiki/Word2vec)
4. [Wikipedia: GloVe](https://en.wikipedia.org/wiki/GloVe)

### 10.6 ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤º

1. [Peters et al., 2018](https://arxiv.org/abs/1802.05365) - Deep Contextualized Word Representations (ELMo)
2. [Devlin et al., 2019](https://arxiv.org/abs/1810.04805) - BERT: Pre-training of Deep Bidirectional Transformers
3. [Radford et al., 2018](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf) - Improving Language Understanding by Generative Pre-Training

### 10.7 å‡ ä½•ä¸æ‹“æ‰‘

1. [Nickel & Kiela, 2017](https://arxiv.org/abs/1705.08039) - PoincarÃ© Embeddings for Learning Hierarchical Representations
2. [Wikipedia: Manifold](https://en.wikipedia.org/wiki/Manifold)
3. [Wikipedia: Hyperbolic Geometry](https://en.wikipedia.org/wiki/Hyperbolic_geometry)

### 10.8 åè§ä¸å…¬å¹³æ€§

1. [Bolukbasi et al., 2016](https://arxiv.org/abs/1607.06520) - Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings
2. [Wikipedia: Algorithmic Bias](https://en.wikipedia.org/wiki/Algorithmic_bias)

### 10.9 æ•™æ

1. [Goodfellow et al., 2016](https://www.deeplearningbook.org/) - Deep Learning
2. [Jurafsky & Martin, 2023](https://web.stanford.edu/~jurafsky/slp3/) - Speech and Language Processing (3rd ed.)

---

_æœ¬æ–‡æ¡£ç³»ç»Ÿé˜è¿°äº†è¯­ä¹‰å‘é‡ç©ºé—´çš„ç†è®ºåŸºç¡€ã€æ„å»ºæ–¹æ³•å’Œæ€§è´¨ï¼Œä¸ºç†è§£ç°ä»£AIçš„è¡¨ç¤ºå­¦ä¹ æä¾›äº†åšå®çš„æ•°å­¦å’Œæ¦‚å¿µåŸºç¡€ã€‚_

---

## å¯¼èˆª | Navigation

**ä¸Šä¸€ç¯‡**: [â† 03.6 ä¸Šä¸‹æ–‡çª—å£ä¸è®°å¿†](../03_Language_Models/03.6_Context_Window_Memory.md)
**ä¸‹ä¸€ç¯‡**: [04.2 è¿ç»­è¡¨ç¤ºç†è®º â†’](./04.2_Continuous_Representation_Theory.md)
**è¿”å›ç›®å½•**: [â†‘ AIæ¨¡å‹è§†è§’æ€»è§ˆ](../README.md)

---

## ç›¸å…³ä¸»é¢˜ | Related Topics

### 10.10 æœ¬ç« èŠ‚

- [04.2 è¿ç»­è¡¨ç¤ºç†è®º](./04.2_Continuous_Representation_Theory.md)
- [04.3 åˆ†å¸ƒå¼è¯­ä¹‰](./04.3_Distributional_Semantics.md)
- [04.4 è¯­ä¹‰ç›¸ä¼¼åº¦åº¦é‡](./04.4_Semantic_Similarity_Metrics.md)
- [04.5 å¤šæ¨¡æ€è¯­ä¹‰æ•´åˆ](./04.5_Multimodal_Semantic_Integration.md)
- [04.6 é»„æ°è¯­ä¹‰æ¨¡å‹åˆ†æ](./04.6_Huang_Semantic_Model_Analysis.md)

### 10.11 ç›¸å…³ç« èŠ‚

- [03.5 åµŒå…¥å‘é‡ç©ºé—´](../03_Language_Models/03.5_Embedding_Vector_Spaces.md)

### 10.12 è·¨è§†è§’é“¾æ¥

- [FormalLanguage_Perspective](../../FormalLanguage_Perspective/README.md)
- [Information_Theory_Perspective](../../Information_Theory_Perspective/README.md)
- [æ¦‚å¿µäº¤å‰ç´¢å¼•ï¼ˆä¸ƒè§†è§’ç‰ˆï¼‰](../../CONCEPT_CROSS_INDEX.md) - æŸ¥çœ‹ç›¸å…³æ¦‚å¿µçš„ä¸ƒè§†è§’åˆ†æï¼š
  - [äº’ä¿¡æ¯](../../CONCEPT_CROSS_INDEX.md#111-äº’ä¿¡æ¯-mutual-information-ä¸ƒè§†è§’) - è¯­ä¹‰å‘é‡ç©ºé—´çš„ä¿¡æ¯å…³è”
  - [ç†µ](../../CONCEPT_CROSS_INDEX.md#71-ç†µ-entropy-ä¸ƒè§†è§’) - å‘é‡ç©ºé—´çš„ç†µä¸åˆ†å¸ƒ
  - [DIKWPæ¨¡å‹](../../CONCEPT_CROSS_INDEX.md#61-dikwpæ¨¡å‹-ä¸ƒè§†è§’) - è¯­ä¹‰è¡¨ç¤ºçš„äº”å±‚æ¨¡å‹
