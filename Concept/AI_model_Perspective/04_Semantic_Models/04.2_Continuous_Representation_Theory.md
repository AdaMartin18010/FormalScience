# è¿ç»­è¡¨ç¤ºç†è®ºï¼ˆContinuous Representation Theoryï¼‰

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0  
> **æœ€åæ›´æ–°**: 2025-10-27  
> **æ–‡æ¡£è§„æ¨¡**: 1041è¡Œ | ç¦»æ•£ç¬¦å·ä¸è¿ç»­å‘é‡çš„ç†è®ºæ¡¥æ¥  
> **é˜…è¯»å»ºè®®**: æœ¬æ–‡æ·±å…¥æ¢è®¨è¿ç»­è¡¨ç¤ºçš„æ•°å­¦åŸºç¡€ä¸å“²å­¦æ„ä¹‰ï¼Œæ˜¯ç†è§£ç°ä»£AIçš„æ ¸å¿ƒç†è®º

---

## ç›®å½• | Table of Contents

- [è¿ç»­è¡¨ç¤ºç†è®ºï¼ˆContinuous Representation Theoryï¼‰](#è¿ç»­è¡¨ç¤ºç†è®ºcontinuous-representation-theory)
- [ç›®å½•](#ç›®å½•)
- [å¼•è¨€](#å¼•è¨€)
  - [æ ¸å¿ƒæ€æƒ³](#æ ¸å¿ƒæ€æƒ³)
  - [å…³é”®é—®é¢˜](#å…³é”®é—®é¢˜)
- [ç¦»æ•£ vs è¿ç»­ï¼šè¡¨ç¤ºçš„äºŒå…ƒæ€§](#ç¦»æ•£-vs-è¿ç»­è¡¨ç¤ºçš„äºŒå…ƒæ€§)
  - [ç¦»æ•£è¡¨ç¤ºï¼ˆDiscrete Representationï¼‰](#ç¦»æ•£è¡¨ç¤ºdiscrete-representation)
    - [ç¬¦å·ç³»ç»Ÿ](#ç¬¦å·ç³»ç»Ÿ)
    - [ç¦»æ•£æ•°å­¦åŸºç¡€](#ç¦»æ•£æ•°å­¦åŸºç¡€)
  - [è¿ç»­è¡¨ç¤ºï¼ˆContinuous Representationï¼‰](#è¿ç»­è¡¨ç¤ºcontinuous-representation)
    - [å‘é‡ç³»ç»Ÿ](#å‘é‡ç³»ç»Ÿ)
    - [è¿ç»­æ•°å­¦åŸºç¡€](#è¿ç»­æ•°å­¦åŸºç¡€)
  - [äºŒå…ƒæ€§çš„å“²å­¦æ„ä¹‰](#äºŒå…ƒæ€§çš„å“²å­¦æ„ä¹‰)
- [è¿ç»­è¡¨ç¤ºçš„æ•°å­¦åŸºç¡€](#è¿ç»­è¡¨ç¤ºçš„æ•°å­¦åŸºç¡€)
  - [1. åº¦é‡ç©ºé—´ï¼ˆMetric Spaceï¼‰](#1-åº¦é‡ç©ºé—´metric-space)
  - [2. æ‹“æ‰‘ç©ºé—´ï¼ˆTopological Spaceï¼‰](#2-æ‹“æ‰‘ç©ºé—´topological-space)
  - [3. æµå½¢ï¼ˆManifoldï¼‰](#3-æµå½¢manifold)
  - [4. å¯å¾®ç»“æ„ï¼ˆDifferentiable Structureï¼‰](#4-å¯å¾®ç»“æ„differentiable-structure)
- [ä»ç¦»æ•£åˆ°è¿ç»­çš„æ¡¥æ¢](#ä»ç¦»æ•£åˆ°è¿ç»­çš„æ¡¥æ¢)
  - [1. åµŒå…¥ï¼ˆEmbeddingï¼‰](#1-åµŒå…¥embedding)
  - [2. ç¼–ç -è§£ç æ¡†æ¶ï¼ˆEncoder-Decoderï¼‰](#2-ç¼–ç -è§£ç æ¡†æ¶encoder-decoder)
  - [3. æ¦‚ç‡æ¡¥æ¥ï¼ˆProbabilistic Bridgeï¼‰](#3-æ¦‚ç‡æ¡¥æ¥probabilistic-bridge)
  - [4. é‡‡æ ·ï¼ˆSamplingï¼‰](#4-é‡‡æ ·sampling)
- [è¿ç»­è¡¨ç¤ºçš„ä¼˜åŠ¿](#è¿ç»­è¡¨ç¤ºçš„ä¼˜åŠ¿)
  - [1. æ³›åŒ–èƒ½åŠ›ï¼ˆGeneralizationï¼‰](#1-æ³›åŒ–èƒ½åŠ›generalization)
  - [2. å¹³æ»‘æ€§ï¼ˆSmoothnessï¼‰](#2-å¹³æ»‘æ€§smoothness)
  - [3. æ’å€¼ä¸å¤–æ¨ï¼ˆInterpolation & Extrapolationï¼‰](#3-æ’å€¼ä¸å¤–æ¨interpolation-extrapolation)
    - [æ’å€¼](#æ’å€¼)
    - [å¤–æ¨](#å¤–æ¨)
  - [4. ç»„åˆæ€§ï¼ˆCompositionalityï¼‰](#4-ç»„åˆæ€§compositionality)
- [è¿ç»­è¡¨ç¤ºçš„å­¦ä¹ ç†è®º](#è¿ç»­è¡¨ç¤ºçš„å­¦ä¹ ç†è®º)
  - [1. è¡¨ç¤ºå­¦ä¹ ï¼ˆRepresentation Learningï¼‰](#1-è¡¨ç¤ºå­¦ä¹ representation-learning)
  - [2. æµå½¢å­¦ä¹ ï¼ˆManifold Learningï¼‰](#2-æµå½¢å­¦ä¹ manifold-learning)
  - [3. åº¦é‡å­¦ä¹ ï¼ˆMetric Learningï¼‰](#3-åº¦é‡å­¦ä¹ metric-learning)
  - [4. è‡ªç›‘ç£å­¦ä¹ ï¼ˆSelf-Supervised Learningï¼‰](#4-è‡ªç›‘ç£å­¦ä¹ self-supervised-learning)
- [å¯å¾®æ€§ä¸ä¼˜åŒ–](#å¯å¾®æ€§ä¸ä¼˜åŒ–)
  - [1. å¯å¾®æ€§çš„é‡è¦æ€§](#1-å¯å¾®æ€§çš„é‡è¦æ€§)
  - [2. æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰](#2-æ¢¯åº¦ä¸‹é™gradient-descent)
  - [3. åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰](#3-åå‘ä¼ æ’­backpropagation)
  - [4. è‡ªåŠ¨å¾®åˆ†ï¼ˆAutomatic Differentiationï¼‰](#4-è‡ªåŠ¨å¾®åˆ†automatic-differentiation)
- [è¿ç»­è¡¨ç¤ºçš„å±€é™æ€§](#è¿ç»­è¡¨ç¤ºçš„å±€é™æ€§)
  - [1. ç²¾ç¡®æ€§ä¸§å¤±ï¼ˆLoss of Precisionï¼‰](#1-ç²¾ç¡®æ€§ä¸§å¤±loss-of-precision)
  - [2. ç»´åº¦ç¾éš¾ï¼ˆCurse of Dimensionalityï¼‰](#2-ç»´åº¦ç¾éš¾curse-of-dimensionality)
  - [3. ä¸å¯è§£é‡Šæ€§ï¼ˆLack of Interpretabilityï¼‰](#3-ä¸å¯è§£é‡Šæ€§lack-of-interpretability)
  - [4. èµ„æºæ¶ˆè€—ï¼ˆResource Consumptionï¼‰](#4-èµ„æºæ¶ˆè€—resource-consumption)
- [æ€»ç»“](#æ€»ç»“)
  - [æ ¸å¿ƒè¦ç‚¹](#æ ¸å¿ƒè¦ç‚¹)
  - [å“²å­¦åæ€](#å“²å­¦åæ€)
  - [æœªæ¥æ–¹å‘](#æœªæ¥æ–¹å‘)
- [å‚è€ƒæ–‡çŒ®](#å‚è€ƒæ–‡çŒ®)
  - [åŸºç¡€ç†è®º](#åŸºç¡€ç†è®º)
  - [æ•°å­¦åŸºç¡€](#æ•°å­¦åŸºç¡€)
  - [æµå½¢å­¦ä¹ ](#æµå½¢å­¦ä¹ )
  - [åº¦é‡å­¦ä¹ ](#åº¦é‡å­¦ä¹ )
  - [ä¼˜åŒ–](#ä¼˜åŒ–)
  - [å“²å­¦ä¸æ‰¹è¯„](#å“²å­¦ä¸æ‰¹è¯„)

---

## å¼•è¨€

**è¿ç»­è¡¨ç¤º**ï¼ˆContinuous Representationï¼‰æ˜¯ç°ä»£AIçš„æ ¸å¿ƒèŒƒå¼è½¬æ¢ï¼šä»**ç¦»æ•£ç¬¦å·æ“ä½œ**è½¬å‘**è¿ç»­å‘é‡è®¡ç®—**ã€‚
è¿™ä¸€è½¬å˜ä¸ä»…æ”¹å˜äº†è¡¨ç¤ºæ–¹å¼ï¼Œæ›´æ”¹å˜äº†å­¦ä¹ ã€æ¨ç†å’Œæ³›åŒ–çš„æœºåˆ¶ã€‚

### æ ¸å¿ƒæ€æƒ³

> **å°†ç¦»æ•£çš„è¯­ä¹‰å¯¹è±¡ï¼ˆè¯ã€å¥å­ã€æ¦‚å¿µï¼‰æ˜ å°„åˆ°è¿ç»­çš„å‘é‡ç©ºé—´ï¼Œä½¿å¾—å¯ä»¥ç”¨å¾®ç§¯åˆ†å’Œä¼˜åŒ–ç†è®ºæ¥å¤„ç†è¯­ä¹‰ã€‚**

### å…³é”®é—®é¢˜

1. **å“²å­¦é—®é¢˜**ï¼šç¦»æ•£çš„ç¬¦å·ä¸–ç•Œå¦‚ä½•æ˜ å°„åˆ°è¿ç»­çš„æ•°å€¼ä¸–ç•Œï¼Ÿ
2. **æ•°å­¦é—®é¢˜**ï¼šè¿ç»­è¡¨ç¤ºçš„æ‹“æ‰‘å’Œå‡ ä½•æ€§è´¨æ˜¯ä»€ä¹ˆï¼Ÿ
3. **è®¡ç®—é—®é¢˜**ï¼šå¦‚ä½•å­¦ä¹ å’Œä¼˜åŒ–è¿ç»­è¡¨ç¤ºï¼Ÿ
4. **è¡¨ç¤ºè®ºé—®é¢˜**ï¼šè¿ç»­è¡¨ç¤ºçœŸçš„èƒ½æ•æ‰ç¦»æ•£è¯­ä¹‰çš„å…¨éƒ¨ä¿¡æ¯å—ï¼Ÿ

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Representation Learning](https://en.wikipedia.org/wiki/Feature_learning)
- [Bengio et al., 2013](https://arxiv.org/abs/1206.5533) - Representation Learning: A Review and New Perspectives

---

## ç¦»æ•£ vs è¿ç»­ï¼šè¡¨ç¤ºçš„äºŒå…ƒæ€§

### ç¦»æ•£è¡¨ç¤ºï¼ˆDiscrete Representationï¼‰

#### ç¬¦å·ç³»ç»Ÿ

**ä¼ ç»ŸAI**åŸºäº**ç¬¦å·**ï¼ˆSymbolsï¼‰ï¼š

```text
ğ’® = {cat, dog, animal, is-a, ...}
```

**å…³ç³»**é€šè¿‡**é€»è¾‘è§„åˆ™**å®šä¹‰ï¼š

```text
is-a(cat, animal)
âˆ€x (is-a(x, mammal) â†’ is-a(x, animal))
```

**ç‰¹ç‚¹**ï¼š

- âœ… **ç²¾ç¡®**ï¼šè¯­ä¹‰è¾¹ç•Œæ¸…æ™°
- âœ… **å¯è§£é‡Š**ï¼šè§„åˆ™æ˜ç¡®
- âœ… **ç»„åˆæ€§**ï¼šå¯ä»¥æ„é€ å¤æ‚è¡¨è¾¾å¼
- âŒ **è„†å¼±**ï¼šå¾®å°å˜åŒ–å¯èƒ½å¯¼è‡´å®Œå…¨ä¸åŒçš„ç»“æœ
- âŒ **ç¨€ç–**ï¼šéš¾ä»¥å¤„ç†æœªè§è¿‡çš„ç»„åˆ
- âŒ **å­¦ä¹ å›°éš¾**ï¼šéœ€è¦æ‰‹å·¥ç¼–å†™è§„åˆ™

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Symbolic AI](https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence)
- [Newell & Simon, 1976](https://en.wikipedia.org/wiki/Physical_symbol_system) - Computer Science as Empirical Inquiry

#### ç¦»æ•£æ•°å­¦åŸºç¡€

**é›†åˆè®º**ï¼š

```text
A = {x | P(x)}  ï¼ˆé›†åˆï¼‰
A âˆ© B, A âˆª B, A \ B  ï¼ˆé›†åˆè¿ç®—ï¼‰
```

**å›¾è®º**ï¼š

```text
G = (V, E)  ï¼ˆå›¾ï¼‰
è·¯å¾„ã€è¿é€šæ€§ã€æœ€çŸ­è·¯å¾„
```

**å½¢å¼è¯­è¨€**ï¼š

```text
Î£*  ï¼ˆç¬¦å·ä¸²çš„å…¨ä½“ï¼‰
L âŠ† Î£*  ï¼ˆå½¢å¼è¯­è¨€ï¼‰
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Discrete Mathematics](https://en.wikipedia.org/wiki/Discrete_mathematics)

### è¿ç»­è¡¨ç¤ºï¼ˆContinuous Representationï¼‰

#### å‘é‡ç³»ç»Ÿ

**ç°ä»£AI**åŸºäº**å‘é‡**ï¼ˆVectorsï¼‰ï¼š

```text
ğ• = â„áµˆ  ï¼ˆdç»´æ¬§å‡ é‡Œå¾—ç©ºé—´ï¼‰
```

**å¯¹è±¡æ˜ å°„**åˆ°å‘é‡ï¼š

```text
Enc(cat) = ğ’—_cat âˆˆ â„áµˆ
Enc(dog) = ğ’—_dog âˆˆ â„áµˆ
Enc(animal) = ğ’—_animal âˆˆ â„áµˆ
```

**å…³ç³»**é€šè¿‡**å‡ ä½•è¿ç®—**è¡¨è¾¾ï¼š

```text
cos(ğ’—_cat, ğ’—_animal) > threshold  â‡’  "cat is related to animal"
```

**ç‰¹ç‚¹**ï¼š

- âœ… **é²æ£’**ï¼šç›¸ä¼¼è¾“å…¥äº§ç”Ÿç›¸ä¼¼è¾“å‡º
- âœ… **æ³›åŒ–**ï¼šèƒ½å¤„ç†æœªè§è¿‡çš„è¾“å…¥
- âœ… **å¯å­¦ä¹ **ï¼šé€šè¿‡æ¢¯åº¦ä¸‹é™è‡ªåŠ¨å­¦ä¹ 
- âŒ **è¿‘ä¼¼**ï¼šå¤±å»ç²¾ç¡®æ€§
- âŒ **ä¸å¯è§£é‡Š**ï¼šå‘é‡ç»´åº¦æ— æ˜ç¡®è¯­ä¹‰
- âŒ **èµ„æºæ¶ˆè€—**ï¼šéœ€è¦å¤§é‡è®¡ç®—å’Œå­˜å‚¨

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Goodfellow et al., 2016](https://www.deeplearningbook.org/) - Deep Learning, Chapter 6

#### è¿ç»­æ•°å­¦åŸºç¡€

**æ‹“æ‰‘å­¦**ï¼š

```text
å¼€é›†ã€é—­é›†ã€è¿ç»­å‡½æ•°ã€ç´§è‡´æ€§
```

**å¾®ç§¯åˆ†**ï¼š

```text
å¯¼æ•°ã€æ¢¯åº¦ã€ä¼˜åŒ–
```

**æ³›å‡½åˆ†æ**ï¼š

```text
å¸Œå°”ä¼¯ç‰¹ç©ºé—´ã€å·´æ‹¿èµ«ç©ºé—´
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Topology](https://en.wikipedia.org/wiki/Topology)
- [Wikipedia: Functional Analysis](https://en.wikipedia.org/wiki/Functional_analysis)

### äºŒå…ƒæ€§çš„å“²å­¦æ„ä¹‰

| ç»´åº¦ | ç¦»æ•£ | è¿ç»­ | å‚è€ƒæ–‡çŒ® |
|------|------|------|----------|
| **æœ¬ä½“è®º** | åŸå­ä¸»ä¹‰ï¼ˆAtomismï¼‰ | æ•´ä½“ä¸»ä¹‰ï¼ˆHolismï¼‰ | [Wikipedia: Atomism](https://en.wikipedia.org/wiki/Atomism) |
| **è®¤è¯†è®º** | ç†æ€§ä¸»ä¹‰ï¼ˆRationalismï¼‰ | ç»éªŒä¸»ä¹‰ï¼ˆEmpiricismï¼‰ | [Wikipedia: Rationalism](https://en.wikipedia.org/wiki/Rationalism) |
| **æ•°å­¦** | ç»„åˆæ•°å­¦ | åˆ†æå­¦ | [Wikipedia: Mathematical Analysis](https://en.wikipedia.org/wiki/Mathematical_analysis) |
| **ç‰©ç†** | é‡å­è·ƒè¿ | ç»å…¸åŠ›å­¦ | [Wikipedia: Classical Mechanics](https://en.wikipedia.org/wiki/Classical_mechanics) |
| **è®¡ç®—** | å›¾çµæœº | æ¨¡æ‹Ÿè®¡ç®— | [Wikipedia: Analog Computer](https://en.wikipedia.org/wiki/Analog_computer) |

---

## è¿ç»­è¡¨ç¤ºçš„æ•°å­¦åŸºç¡€

### 1. åº¦é‡ç©ºé—´ï¼ˆMetric Spaceï¼‰

**å®šä¹‰**ï¼š

ä¸€ä¸ª**åº¦é‡ç©ºé—´**æ˜¯ä¸€ä¸ªäºŒå…ƒç»„ (X, d)ï¼Œå…¶ä¸­ï¼š

- X æ˜¯ä¸€ä¸ªé›†åˆ
- d : X Ã— X â†’ â„â‚Š æ˜¯åº¦é‡å‡½æ•°ï¼Œæ»¡è¶³ï¼š
  1. **éè´Ÿæ€§**ï¼šd(x, y) â‰¥ 0ï¼Œä¸” d(x, y) = 0 âŸº x = y
  2. **å¯¹ç§°æ€§**ï¼šd(x, y) = d(y, x)
  3. **ä¸‰è§’ä¸ç­‰å¼**ï¼šd(x, z) â‰¤ d(x, y) + d(y, z)

**AIä¸­çš„åº¦é‡ç©ºé—´**ï¼š

```text
(â„áµˆ, d_euclidean)  æ¬§å‡ é‡Œå¾—ç©ºé—´
(â„áµˆ, d_cosine)     ä½™å¼¦è·ç¦»ç©ºé—´
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Metric Space](https://en.wikipedia.org/wiki/Metric_space)

### 2. æ‹“æ‰‘ç©ºé—´ï¼ˆTopological Spaceï¼‰

**å®šä¹‰**ï¼š

ä¸€ä¸ª**æ‹“æ‰‘ç©ºé—´**æ˜¯ä¸€ä¸ªäºŒå…ƒç»„ (X, ğ’¯)ï¼Œå…¶ä¸­ï¼š

- X æ˜¯ä¸€ä¸ªé›†åˆ
- ğ’¯ âŠ† 2^X æ˜¯å¼€é›†æ—ï¼Œæ»¡è¶³ï¼š
  1. âˆ…, X âˆˆ ğ’¯
  2. ğ’¯ å¯¹ä»»æ„å¹¶å°é—­
  3. ğ’¯ å¯¹æœ‰é™äº¤å°é—­

**è¿ç»­å‡½æ•°**ï¼š

å‡½æ•° f : X â†’ Y æ˜¯è¿ç»­çš„ï¼Œå¦‚æœ**å¼€é›†çš„åŸåƒæ˜¯å¼€é›†**ï¼š

```text
âˆ€U âˆˆ ğ’¯_Y : fâ»Â¹(U) âˆˆ ğ’¯_X
```

**AIä¸­çš„åº”ç”¨**ï¼š

- åµŒå…¥å‡½æ•° Enc : Î£ â†’ â„áµˆ çš„è¿ç»­æ€§
- å¹³æ»‘çš„è¯­ä¹‰ç©ºé—´

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Topological Space](https://en.wikipedia.org/wiki/Topological_space)
- [Wikipedia: Continuous Function](https://en.wikipedia.org/wiki/Continuous_function)

### 3. æµå½¢ï¼ˆManifoldï¼‰

**å®šä¹‰**ï¼š

ä¸€ä¸ª**dç»´æµå½¢**æ˜¯ä¸€ä¸ªæ‹“æ‰‘ç©ºé—´ Mï¼Œå±€éƒ¨åŒèƒšäº â„áµˆã€‚

**ç›´è§‰**ï¼š

- 1ç»´æµå½¢ï¼šæ›²çº¿ï¼ˆå¦‚åœ†ï¼‰
- 2ç»´æµå½¢ï¼šæ›²é¢ï¼ˆå¦‚çƒé¢ï¼‰
- é«˜ç»´æµå½¢ï¼šé«˜ç»´"æ›²é¢"

**æµå½¢å‡è®¾**ï¼ˆManifold Hypothesisï¼‰ï¼š

> **é«˜ç»´æ•°æ®ï¼ˆå¦‚å›¾åƒã€æ–‡æœ¬ï¼‰å®é™…ä¸Šä½äºä¸€ä¸ªä½ç»´æµå½¢ä¸Šã€‚**

å½¢å¼åŒ–ï¼š

```text
æ•°æ® X âŠ‚ â„á´°  ï¼ˆDå¾ˆå¤§ï¼Œå¦‚10â¶ï¼‰
ä½† X â‰ˆ M  ï¼ˆMæ˜¯dç»´æµå½¢ï¼Œd â‰ª Dï¼‰
```

**ä¾‹å­**ï¼š

- è‡ªç„¶å›¾åƒä¸æ˜¯éšæœºåƒç´ ï¼Œè€Œæ˜¯ä½äºä½ç»´æµå½¢ä¸Š
- è‡ªç„¶è¯­è¨€å¥å­ä¸æ˜¯éšæœºè¯åºåˆ—ï¼Œè€Œæ˜¯ä½äºè¯­ä¹‰æµå½¢ä¸Š

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Manifold](https://en.wikipedia.org/wiki/Manifold)
- [Fefferman et al., 2016](https://www.pnas.org/doi/full/10.1073/pnas.1408993113) - Testing the Manifold Hypothesis

### 4. å¯å¾®ç»“æ„ï¼ˆDifferentiable Structureï¼‰

**å…‰æ»‘æµå½¢**ï¼š

å¦‚æœæµå½¢ä¸Šçš„åæ ‡å˜æ¢éƒ½æ˜¯**å…‰æ»‘çš„**ï¼ˆæ— ç©·æ¬¡å¯å¾®ï¼‰ï¼Œåˆ™ç§°ä¸º**å…‰æ»‘æµå½¢**ã€‚

**åˆ‡ç©ºé—´**ï¼ˆTangent Spaceï¼‰ï¼š

åœ¨æµå½¢ä¸Šçš„ç‚¹ pï¼Œ**åˆ‡ç©ºé—´** T_p M æ˜¯è¯¥ç‚¹çš„æ‰€æœ‰"åˆ‡å‘é‡"çš„é›†åˆã€‚

**æ¢¯åº¦**ï¼š

åœ¨æµå½¢ä¸Šå®šä¹‰å‡½æ•° f : M â†’ â„ï¼Œå…¶**æ¢¯åº¦** âˆ‡f æ˜¯åˆ‡ç©ºé—´ä¸­çš„å‘é‡ï¼ŒæŒ‡å‘ f å¢é•¿æœ€å¿«çš„æ–¹å‘ã€‚

**AIä¸­çš„åº”ç”¨**ï¼š

- æ¢¯åº¦ä¸‹é™ï¼šåœ¨å‚æ•°æµå½¢ä¸Šæ²¿æ¢¯åº¦åæ–¹å‘ç§»åŠ¨
- è‡ªç„¶æ¢¯åº¦ï¼šè€ƒè™‘å‚æ•°æµå½¢çš„å‡ ä½•ç»“æ„

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Differentiable Manifold](https://en.wikipedia.org/wiki/Differentiable_manifold)
- [Amari, 1998](https://ieeexplore.ieee.org/document/661291) - Natural Gradient Works Efficiently in Learning

---

## ä»ç¦»æ•£åˆ°è¿ç»­çš„æ¡¥æ¢

### 1. åµŒå…¥ï¼ˆEmbeddingï¼‰

**å®šä¹‰**ï¼š

**åµŒå…¥**æ˜¯ä¸€ä¸ªå‡½æ•°ï¼š

```text
Enc : Î£ â†’ â„áµˆ
```

å°†ç¦»æ•£ç¬¦å·é›† Î£ æ˜ å°„åˆ°è¿ç»­å‘é‡ç©ºé—´ â„áµˆã€‚

**å…³é”®è¦æ±‚**ï¼š

> **ä¿æŒè¯­ä¹‰ç»“æ„**

å½¢å¼åŒ–ï¼š

```text
Sem(sâ‚, sâ‚‚) â‰ˆ Sim(Enc(sâ‚), Enc(sâ‚‚))
```

å…¶ä¸­ï¼š

- Sem : Î£ Ã— Î£ â†’ [0, 1] æ˜¯è¯­ä¹‰ç›¸ä¼¼åº¦
- Sim : â„áµˆ Ã— â„áµˆ â†’ [0, 1] æ˜¯å‘é‡ç›¸ä¼¼åº¦ï¼ˆå¦‚ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Embedding](https://en.wikipedia.org/wiki/Embedding)

### 2. ç¼–ç -è§£ç æ¡†æ¶ï¼ˆEncoder-Decoderï¼‰

**ç»“æ„**ï¼š

```text
Input â†’ Encoder â†’ Latent Space â†’ Decoder â†’ Output
  â†“        â†“           â†“            â†“          â†“
 ç¦»æ•£     è¿ç»­åŒ–       è¿ç»­         ç¦»æ•£åŒ–     ç¦»æ•£
```

**ç¼–ç å™¨**ï¼ˆEncoderï¼‰ï¼š

```text
Enc : Î£* â†’ â„áµˆ
```

å°†ç¦»æ•£åºåˆ—æ˜ å°„åˆ°è¿ç»­å‘é‡ã€‚

**è§£ç å™¨**ï¼ˆDecoderï¼‰ï¼š

```text
Dec : â„áµˆ â†’ Î£*
```

å°†è¿ç»­å‘é‡æ˜ å°„å›ç¦»æ•£åºåˆ—ã€‚

**ä¾‹å­**ï¼š

- **æœºå™¨ç¿»è¯‘**ï¼š

```text
"Hello" â†’ Enc â†’ ğ’› â†’ Dec â†’ "Bonjour"
```

- **è‡ªç¼–ç å™¨**ï¼ˆAutoencoderï¼‰ï¼š

```text
ğ’™ â†’ Enc â†’ ğ’› â†’ Dec â†’ ğ’™Ì‚
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Autoencoder](https://en.wikipedia.org/wiki/Autoencoder)
- [Wikipedia: Encoder-Decoder](https://en.wikipedia.org/wiki/Autoencoder)

### 3. æ¦‚ç‡æ¡¥æ¥ï¼ˆProbabilistic Bridgeï¼‰

**Softmaxå‡½æ•°**ï¼š

å°†è¿ç»­å‘é‡è½¬æ¢ä¸ºç¦»æ•£æ¦‚ç‡åˆ†å¸ƒï¼š

```text
Softmax(ğ’›)áµ¢ = exp(záµ¢) / âˆ‘â±¼ exp(zâ±¼)
```

**æ€§è´¨**ï¼š

- è¾“å…¥ï¼šğ’› âˆˆ â„|V|ï¼ˆè¿ç»­ï¼‰
- è¾“å‡ºï¼šğ’‘ âˆˆ Î”|V|ï¼ˆç¦»æ•£æ¦‚ç‡å•çº¯å½¢ï¼‰

**åº”ç”¨**ï¼š

- **è¯­è¨€æ¨¡å‹**ï¼š

```text
ğ’‰â‚œ âˆˆ â„áµˆ â†’ Linear â†’ ğ’› âˆˆ â„|V| â†’ Softmax â†’ P(wâ‚œâ‚Šâ‚)
```

- **åˆ†ç±»å™¨**ï¼š

```text
ğ’™ âˆˆ â„áµˆ â†’ Neural Network â†’ ğ’› âˆˆ â„á´· â†’ Softmax â†’ P(y)
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Softmax Function](https://en.wikipedia.org/wiki/Softmax_function)

### 4. é‡‡æ ·ï¼ˆSamplingï¼‰

ä»è¿ç»­æ¦‚ç‡åˆ†å¸ƒç”Ÿæˆç¦»æ•£æ ·æœ¬ï¼š

**æ–¹æ³•**ï¼š

1. **åˆ†ç±»åˆ†å¸ƒé‡‡æ ·**ï¼š

    ```text
    ç»™å®š P(wâ‚), ..., P(w|V|)
    é‡‡æ · w ~ Categorical(P)
    ```

2. **Top-k é‡‡æ ·**ï¼š

    ```text
    åªä»æ¦‚ç‡æœ€é«˜çš„ k ä¸ªè¯ä¸­é‡‡æ ·
    ```

3. **Nucleus (Top-p) é‡‡æ ·**ï¼š

    ```text
    ä»ç´¯ç§¯æ¦‚ç‡è¾¾åˆ° p çš„æœ€å°è¯é›†ä¸­é‡‡æ ·
    ```

4. **æ¸©åº¦é‡‡æ ·**ï¼š

    ```text
    Softmax(ğ’›/T)  ï¼ˆTæ˜¯æ¸©åº¦å‚æ•°ï¼‰
    ```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Holtzman et al., 2019](https://arxiv.org/abs/1904.09751) - The Curious Case of Neural Text Degeneration

---

## è¿ç»­è¡¨ç¤ºçš„ä¼˜åŠ¿

### 1. æ³›åŒ–èƒ½åŠ›ï¼ˆGeneralizationï¼‰

**å…³é”®ä¼˜åŠ¿**ï¼š

> **è¿ç»­è¡¨ç¤ºè‡ªç„¶æ”¯æŒæ³›åŒ–ï¼šç›¸ä¼¼è¾“å…¥äº§ç”Ÿç›¸ä¼¼è¾“å‡ºã€‚**

**æ•°å­¦åŸç†**ï¼š

å¦‚æœ f : â„áµˆ â†’ â„ æ˜¯è¿ç»­å‡½æ•°ï¼Œåˆ™ï¼š

```text
xâ‚ â‰ˆ xâ‚‚  â‡’  f(xâ‚) â‰ˆ f(xâ‚‚)
```

**å¯¹æ¯”**ï¼š

- **ç¦»æ•£**ï¼š

```text
input = "cat"  â†’ output = "animal"
input = "catt" â†’ output = ???  ï¼ˆæ— æ³•å¤„ç†æ‹¼å†™é”™è¯¯ï¼‰
```

- **è¿ç»­**ï¼š

```text
vec("cat") â‰ˆ vec("catt")  ï¼ˆæ‹¼å†™é”™è¯¯ï¼‰
â‡’ f(vec("cat")) â‰ˆ f(vec("catt"))
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Bengio et al., 2013](https://arxiv.org/abs/1206.5533) - Representation Learning

### 2. å¹³æ»‘æ€§ï¼ˆSmoothnessï¼‰

**å®šä¹‰**ï¼š

å‡½æ•° f æ˜¯**å¹³æ»‘çš„**ï¼Œå¦‚æœï¼š

```text
â€–f(x + Î”x) - f(x)â€– â‰¤ L â€–Î”xâ€–
```

å¯¹æŸä¸ªå¸¸æ•° Lï¼ˆLipschitzå¸¸æ•°ï¼‰ã€‚

**ä¼˜åŠ¿**ï¼š

- âœ… **ç¨³å®š**ï¼šå¾®å°æ‰°åŠ¨ä¸ä¼šå¯¼è‡´å‰§çƒˆå˜åŒ–
- âœ… **å¯ä¼˜åŒ–**ï¼šæ¢¯åº¦ä¸‹é™æœ‰æ•ˆ
- âœ… **é²æ£’**ï¼šå¯¹å™ªå£°ä¸æ•æ„Ÿ

**å¯¹æ¯”**ï¼š

- **ç¦»æ•£å‡½æ•°**ï¼šå¯èƒ½æœ‰ä¸è¿ç»­è·³è·ƒ
- **è¿ç»­å‡½æ•°**ï¼šå¹³æ»‘è¿‡æ¸¡

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Lipschitz Continuity](https://en.wikipedia.org/wiki/Lipschitz_continuity)

### 3. æ’å€¼ä¸å¤–æ¨ï¼ˆInterpolation & Extrapolationï¼‰

#### æ’å€¼

åœ¨å·²çŸ¥ç‚¹ä¹‹é—´**å¹³æ»‘è¿‡æ¸¡**ï¼š

```text
å·²çŸ¥ï¼švec(cat), vec(tiger)
æ’å€¼ï¼švec(???) = 0.5 * vec(cat) + 0.5 * vec(tiger)
```

**å‡ ä½•æ„ä¹‰**ï¼šåœ¨ä¸¤ç‚¹é—´çš„çº¿æ®µä¸Šé‡‡æ ·ã€‚

#### å¤–æ¨

è¶…è¶Šå·²çŸ¥æ•°æ®èŒƒå›´**æ¨æµ‹**ï¼š

```text
vec(super_cat) = 2 * vec(cat) - vec(kitten)
```

**é£é™©**ï¼šå¤–æ¨å¯èƒ½ä¸å¯é ï¼ˆç¦»å¼€æ•°æ®æµå½¢ï¼‰ã€‚

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Interpolation](https://en.wikipedia.org/wiki/Interpolation)
- [Wikipedia: Extrapolation](https://en.wikipedia.org/wiki/Extrapolation)

### 4. ç»„åˆæ€§ï¼ˆCompositionalityï¼‰

**å‘é‡åŠ æ³•çš„è¯­ä¹‰ç»„åˆ**ï¼š

ç»å…¸ä¾‹å­ï¼š

```text
vec(king) - vec(man) + vec(woman) â‰ˆ vec(queen)
```

**ä¸€èˆ¬å½¢å¼**ï¼š

```text
vec(A + property) â‰ˆ vec(A) + vec(property)
```

**æ•°å­¦åŸºç¡€**ï¼š

- **å‘é‡ç©ºé—´çš„çº¿æ€§ç»“æ„**æ”¯æŒç»„åˆè¿ç®—
- **è¯­ä¹‰çš„çº¿æ€§è¿‘ä¼¼**ï¼ˆå±€éƒ¨çº¿æ€§ï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Mikolov et al., 2013](https://arxiv.org/abs/1301.3781) - Linguistic Regularities in Continuous Space

---

## è¿ç»­è¡¨ç¤ºçš„å­¦ä¹ ç†è®º

### 1. è¡¨ç¤ºå­¦ä¹ ï¼ˆRepresentation Learningï¼‰

**ç›®æ ‡**ï¼š

å­¦ä¹ ä¸€ä¸ªå¥½çš„è¡¨ç¤º ğ’‰ = Enc(ğ’™)ï¼Œä½¿å¾—ï¼š

1. **ä¸‹æ¸¸ä»»åŠ¡å®¹æ˜“**ï¼š

    ```text
    ç»™å®š ğ’‰ï¼Œé¢„æµ‹ y æ˜¯ç®€å•çš„ï¼ˆå¦‚çº¿æ€§åˆ†ç±»å™¨ï¼‰
    ```

2. **ä¿¡æ¯ä¿ç•™**ï¼š

    ```text
    ğ’‰ ä¿ç•™äº† ğ’™ ä¸­çš„ç›¸å…³ä¿¡æ¯
    ```

3. **ä¸å˜æ€§**ï¼š

    ```text
    ğ’‰ å¯¹ä¸ç›¸å…³å˜åŒ–ä¸æ•æ„Ÿ
    ```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Bengio et al., 2013](https://arxiv.org/abs/1206.5533) - Representation Learning: A Review and New Perspectives

### 2. æµå½¢å­¦ä¹ ï¼ˆManifold Learningï¼‰

**å‡è®¾**ï¼š

æ•°æ®ä½äºé«˜ç»´ç©ºé—´ä¸­çš„**ä½ç»´æµå½¢**ä¸Šã€‚

**ç›®æ ‡**ï¼š

å­¦ä¹ åµŒå…¥ Enc : â„á´° â†’ â„áµˆ ï¼ˆd â‰ª Dï¼‰ï¼Œä¿æŒæµå½¢ç»“æ„ã€‚

**æ–¹æ³•**ï¼š

1. **çº¿æ€§æ–¹æ³•**ï¼š
   - PCAï¼ˆä¸»æˆåˆ†åˆ†æï¼‰
   - MDSï¼ˆå¤šç»´ç¼©æ”¾ï¼‰

2. **éçº¿æ€§æ–¹æ³•**ï¼š
   - Isomap
   - Locally Linear Embedding (LLE)
   - t-SNE
   - UMAP

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Manifold Learning](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction)
- [van der Maaten & Hinton, 2008](https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf) - Visualizing Data using t-SNE

### 3. åº¦é‡å­¦ä¹ ï¼ˆMetric Learningï¼‰

**ç›®æ ‡**ï¼š

å­¦ä¹ ä¸€ä¸ª**åº¦é‡å‡½æ•°** d : â„áµˆ Ã— â„áµˆ â†’ â„â‚Šï¼Œä½¿å¾—ï¼š

```text
è¯­ä¹‰ç›¸ä¼¼ â‡’ è·ç¦»å°
è¯­ä¹‰ä¸åŒ â‡’ è·ç¦»å¤§
```

**æ–¹æ³•**ï¼š

1. **å¯¹æ¯”å­¦ä¹ **ï¼ˆContrastive Learningï¼‰ï¼š

    ```text
    L = âˆ‘ [ d(xáµ¢, xáµ¢âº)Â² + max(0, m - d(xáµ¢, xáµ¢â»))Â² ]
    ```

    - xáµ¢âºï¼šæ­£æ ·æœ¬ï¼ˆç›¸ä¼¼ï¼‰
    - xáµ¢â»ï¼šè´Ÿæ ·æœ¬ï¼ˆä¸ç›¸ä¼¼ï¼‰
    - mï¼šè¾¹ç•Œ

2. **ä¸‰å…ƒç»„æŸå¤±**ï¼ˆTriplet Lossï¼‰ï¼š

    ```text
    L = âˆ‘ max(0, d(a, p) - d(a, n) + m)
    ```

    - aï¼šé”šç‚¹
    - pï¼šæ­£æ ·æœ¬
    - nï¼šè´Ÿæ ·æœ¬

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Metric Learning](https://en.wikipedia.org/wiki/Similarity_learning)
- [Schroff et al., 2015](https://arxiv.org/abs/1503.03832) - FaceNet: A Unified Embedding for Face Recognition

### 4. è‡ªç›‘ç£å­¦ä¹ ï¼ˆSelf-Supervised Learningï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼š

ä»æ•°æ®æœ¬èº«æ„é€ ç›‘ç£ä¿¡å·ï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚

**æ–¹æ³•**ï¼š

1. **é¢„æµ‹ä¸Šä¸‹æ–‡**ï¼š

    ```text
    ç»™å®šä¸­å¿ƒè¯ï¼Œé¢„æµ‹å‘¨å›´è¯ï¼ˆWord2Vecï¼‰
    ```

2. **æ©ç é¢„æµ‹**ï¼š

    ```text
    ç»™å®š [MASK] ä¸Šä¸‹æ–‡ï¼Œé¢„æµ‹è¢«æ©ç›–çš„è¯ï¼ˆBERTï¼‰
    ```

3. **å¯¹æ¯”å­¦ä¹ **ï¼š

    ```text
    åŒä¸€æ ·æœ¬çš„ä¸åŒè§†å›¾åº”è¯¥ç›¸ä¼¼ï¼ˆSimCLRï¼‰
    ```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Self-Supervised Learning](https://en.wikipedia.org/wiki/Self-supervised_learning)
- [Chen et al., 2020](https://arxiv.org/abs/2002.05709) - A Simple Framework for Contrastive Learning of Visual Representations

---

## å¯å¾®æ€§ä¸ä¼˜åŒ–

### 1. å¯å¾®æ€§çš„é‡è¦æ€§

**å®šä¹‰**ï¼š

å‡½æ•° f : â„áµˆ â†’ â„ åœ¨ç‚¹ ğ’™ å¤„**å¯å¾®**ï¼Œå¦‚æœå­˜åœ¨çº¿æ€§æ˜ å°„ Df(ğ’™)ï¼ˆå¯¼æ•°ï¼‰ï¼Œä½¿å¾—ï¼š

```text
f(ğ’™ + ğœ¹) = f(ğ’™) + Df(ğ’™)[ğœ¹] + o(â€–ğœ¹â€–)
```

**æ¢¯åº¦**ï¼š

```text
âˆ‡f(ğ’™) = [âˆ‚f/âˆ‚xâ‚, ..., âˆ‚f/âˆ‚xâ‚]áµ€
```

**ä¸ºä»€ä¹ˆé‡è¦**ï¼š

> **å¯å¾®æ€§ä½¿å¾—æˆ‘ä»¬å¯ä»¥ç”¨æ¢¯åº¦ä¸‹é™ç­‰ä¼˜åŒ–ç®—æ³•æ¥å­¦ä¹ å‚æ•°ã€‚**

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Differentiable Function](https://en.wikipedia.org/wiki/Differentiable_function)
- [Wikipedia: Gradient](https://en.wikipedia.org/wiki/Gradient)

### 2. æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰

**åŸºæœ¬ç®—æ³•**ï¼š

```text
Î¸ â† Î¸ - Î· âˆ‡L(Î¸)
```

å…¶ä¸­ï¼š

- Î¸ï¼šå‚æ•°
- Î·ï¼šå­¦ä¹ ç‡
- L(Î¸)ï¼šæŸå¤±å‡½æ•°

**å˜ä½“**ï¼š

1. **éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰**ï¼š

    ```text
    Î¸ â† Î¸ - Î· âˆ‡L_i(Î¸)  ï¼ˆä½¿ç”¨å•ä¸ªæ ·æœ¬ï¼‰
    ```

2. **å°æ‰¹é‡SGD**ï¼š

    ```text
    Î¸ â† Î¸ - Î· (1/B) âˆ‘áµ¢âˆˆB âˆ‡L_i(Î¸)
    ```

3. **åŠ¨é‡æ³•**ï¼ˆMomentumï¼‰ï¼š

    ```text
    v â† Î² v + âˆ‡L(Î¸)
    Î¸ â† Î¸ - Î· v
    ```

4. **Adam**ï¼š

    ```text
    m â† Î²â‚ m + (1-Î²â‚) âˆ‡L(Î¸)
    v â† Î²â‚‚ v + (1-Î²â‚‚) (âˆ‡L(Î¸))Â²
    Î¸ â† Î¸ - Î· m/âˆš(v + Îµ)
    ```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent)
- [Wikipedia: Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)
- [Kingma & Ba, 2014](https://arxiv.org/abs/1412.6980) - Adam: A Method for Stochastic Optimization

### 3. åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼š

åˆ©ç”¨**é“¾å¼æ³•åˆ™**é«˜æ•ˆè®¡ç®—ç¥ç»ç½‘ç»œçš„æ¢¯åº¦ã€‚

**é“¾å¼æ³•åˆ™**ï¼š

```text
âˆ‚L/âˆ‚Î¸ = (âˆ‚L/âˆ‚z) (âˆ‚z/âˆ‚Î¸)
```

**è®¡ç®—å›¾**ï¼š

```text
Input â†’ Layer1 â†’ Layer2 â†’ ... â†’ Output â†’ Loss
  â†“        â†“        â†“              â†“        â†“
  Î¸â‚       Î¸â‚‚       Î¸â‚ƒ             Î¸â‚™       L

åå‘ä¼ æ’­ï¼š
  L â† âˆ‚L/âˆ‚output â† âˆ‚L/âˆ‚Layer2 â† ... â† âˆ‚L/âˆ‚Î¸
```

**å¤æ‚åº¦**ï¼š

- å‰å‘ä¼ æ’­ï¼šO(|E|)  ï¼ˆEæ˜¯è¾¹æ•°ï¼‰
- åå‘ä¼ æ’­ï¼šO(|E|)  ï¼ˆç›¸åŒï¼ï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Backpropagation](https://en.wikipedia.org/wiki/Backpropagation)
- [Rumelhart et al., 1986](https://www.nature.com/articles/323533a0) - Learning Representations by Back-Propagating Errors

### 4. è‡ªåŠ¨å¾®åˆ†ï¼ˆAutomatic Differentiationï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼š

è‡ªåŠ¨è®¡ç®—ä»»æ„è®¡ç®—å›¾çš„æ¢¯åº¦ï¼Œæ— éœ€æ‰‹å·¥æ¨å¯¼ã€‚

**æ¨¡å¼**ï¼š

1. **å‰å‘æ¨¡å¼**ï¼ˆForward Modeï¼‰ï¼š

    ```text
    è®¡ç®— âˆ‚y/âˆ‚xâ‚
    ```

2. **åå‘æ¨¡å¼**ï¼ˆReverse Modeï¼‰ï¼š

    ```text
    è®¡ç®— âˆ‚L/âˆ‚Î¸â‚, ..., âˆ‚L/âˆ‚Î¸â‚™  ï¼ˆç¥ç»ç½‘ç»œå¸¸ç”¨ï¼‰
    ```

**ç°ä»£æ¡†æ¶**ï¼š

- PyTorchï¼štorch.autograd
- TensorFlowï¼štf.GradientTape
- JAXï¼šjax.grad

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Automatic Differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation)
- [Baydin et al., 2018](https://arxiv.org/abs/1502.05767) - Automatic Differentiation in Machine Learning: a Survey

---

## è¿ç»­è¡¨ç¤ºçš„å±€é™æ€§

### 1. ç²¾ç¡®æ€§ä¸§å¤±ï¼ˆLoss of Precisionï¼‰

**é—®é¢˜**ï¼š

è¿ç»­è¡¨ç¤ºæ˜¯**è¿‘ä¼¼çš„**ï¼Œå¤±å»äº†ç¦»æ•£ç¬¦å·çš„ç²¾ç¡®æ€§ã€‚

**ä¾‹å­**ï¼š

```text
ç¬¦å·ï¼š2 + 2 = 4  ï¼ˆç²¾ç¡®ï¼‰
å‘é‡ï¼švec(2) + vec(2) â‰ˆ vec(4)  ï¼ˆè¿‘ä¼¼ï¼‰
```

**åæœ**ï¼š

- âŒ é€»è¾‘æ¨ç†å¯èƒ½å‡ºé”™
- âŒ ä¸é€‚åˆéœ€è¦ç²¾ç¡®ç­”æ¡ˆçš„ä»»åŠ¡ï¼ˆå¦‚ç®—æœ¯ï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Marcus, 2020](https://arxiv.org/abs/2002.06177) - The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence

### 2. ç»´åº¦ç¾éš¾ï¼ˆCurse of Dimensionalityï¼‰

**é—®é¢˜**ï¼š

é«˜ç»´ç©ºé—´ä¸­çš„è·ç¦»åº¦é‡å˜å¾—**ä¸å¯é **ã€‚

**ç°è±¡**ï¼š

åœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œæ‰€æœ‰ç‚¹å¯¹ä¹‹é—´çš„è·ç¦»è¶‹äºç›¸ç­‰ï¼š

```text
max_dist / min_dist â†’ 1  ï¼ˆå½“ d â†’ âˆï¼‰
```

**åæœ**ï¼š

- âŒ æœ€è¿‘é‚»æœç´¢æ•ˆç‡ä½ä¸‹
- âŒ ç›¸ä¼¼åº¦åº¦é‡å¤±æ•ˆ

**ç¼“è§£æ–¹æ³•**ï¼š

- é™ç»´
- å±€éƒ¨æ•æ„Ÿå“ˆå¸Œï¼ˆLSHï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Curse of Dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality)
- [Beyer et al., 1999](https://link.springer.com/chapter/10.1007/3-540-49257-7_15) - When Is "Nearest Neighbor" Meaningful?

### 3. ä¸å¯è§£é‡Šæ€§ï¼ˆLack of Interpretabilityï¼‰

**é—®é¢˜**ï¼š

å‘é‡çš„å„ä¸ªç»´åº¦**æ²¡æœ‰æ˜ç¡®è¯­ä¹‰**ã€‚

**ä¾‹å­**ï¼š

```text
vec(cat)[42] = 0.73  â† è¿™ä»£è¡¨ä»€ä¹ˆï¼Ÿ
```

**å¯¹æ¯”**ï¼š

- **ç¬¦å·**ï¼šis-a(cat, animal)  ï¼ˆæ¸…æ™°ï¼‰
- **å‘é‡**ï¼šcos(vec(cat), vec(animal)) = 0.78  ï¼ˆæ¨¡ç³Šï¼‰

**å°è¯•**ï¼š

- å¯è§£é‡Šç»´åº¦ï¼ˆä½†ä¸å¯é ï¼‰
- æ¢æµ‹ä»»åŠ¡ï¼ˆProbingï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Lipton, 2018](https://arxiv.org/abs/1606.03490) - The Mythos of Model Interpretability

### 4. èµ„æºæ¶ˆè€—ï¼ˆResource Consumptionï¼‰

**é—®é¢˜**ï¼š

é«˜ç»´å‘é‡çš„**å­˜å‚¨å’Œè®¡ç®—æˆæœ¬**é«˜æ˜‚ã€‚

| æ“ä½œ | å¤æ‚åº¦ | åœºæ™¯ |
|------|--------|------|
| å­˜å‚¨ä¸€ä¸ªå‘é‡ | O(d) | d=768, éœ€è¦3KBï¼ˆFP32ï¼‰ |
| å‘é‡ç‚¹ç§¯ | O(d) | ç›¸ä¼¼åº¦è®¡ç®— |
| çŸ©é˜µä¹˜æ³• | O(nÂ²d) | Transformeræ³¨æ„åŠ› |
| æœ€è¿‘é‚»æœç´¢ | O(Nd) | æ£€ç´¢ç³»ç»Ÿ |

**ç¼“è§£æ–¹æ³•**ï¼š

- é‡åŒ–ï¼ˆQuantizationï¼‰
- ç¨€ç–åŒ–ï¼ˆSparsificationï¼‰
- çŸ¥è¯†è’¸é¦ï¼ˆKnowledge Distillationï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Han et al., 2015](https://arxiv.org/abs/1510.00149) - Deep Compression

---

## æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **èŒƒå¼è½¬æ¢**ï¼šä»ç¦»æ•£ç¬¦å·åˆ°è¿ç»­å‘é‡
2. **æ•°å­¦åŸºç¡€**ï¼šåº¦é‡ç©ºé—´ã€æ‹“æ‰‘ç©ºé—´ã€æµå½¢
3. **æ¡¥æ¥æœºåˆ¶**ï¼šåµŒå…¥ã€ç¼–ç -è§£ç ã€Softmaxã€é‡‡æ ·
4. **ä¼˜åŠ¿**ï¼šæ³›åŒ–ã€å¹³æ»‘ã€æ’å€¼ã€ç»„åˆ
5. **å­¦ä¹ ç†è®º**ï¼šè¡¨ç¤ºå­¦ä¹ ã€æµå½¢å­¦ä¹ ã€åº¦é‡å­¦ä¹ ã€è‡ªç›‘ç£å­¦ä¹ 
6. **ä¼˜åŒ–**ï¼šå¯å¾®æ€§ã€æ¢¯åº¦ä¸‹é™ã€åå‘ä¼ æ’­ã€è‡ªåŠ¨å¾®åˆ†
7. **å±€é™æ€§**ï¼šç²¾ç¡®æ€§ä¸§å¤±ã€ç»´åº¦ç¾éš¾ã€ä¸å¯è§£é‡Šã€èµ„æºæ¶ˆè€—

### å“²å­¦åæ€

> **è¿ç»­è¡¨ç¤ºæ˜¯å¯¹ç¦»æ•£ä¸–ç•Œçš„ä¸€ç§"è½¯åŒ–"ï¼ˆSofteningï¼‰ï¼šå®ƒç”¨æ¦‚ç‡å’Œè¿‘ä¼¼æ›¿ä»£äº†ç¡®å®šæ€§å’Œç²¾ç¡®æ€§ï¼Œç”¨å‡ ä½•å’Œæ‹“æ‰‘æ›¿ä»£äº†é€»è¾‘å’Œç¬¦å·ã€‚è¿™ç§è½¬æ¢æ—¢å¸¦æ¥äº†å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¹Ÿå¼•å…¥äº†æ–°çš„æŒ‘æˆ˜ã€‚**

### æœªæ¥æ–¹å‘

1. **æ··åˆç³»ç»Ÿ**ï¼šç»“åˆç¬¦å·å’Œè¿ç»­è¡¨ç¤ºçš„ä¼˜åŠ¿
2. **å‡ ä½•æ·±åº¦å­¦ä¹ **ï¼šåˆ©ç”¨æ•°æ®çš„å‡ ä½•å’Œæ‹“æ‰‘ç»“æ„
3. **å¯è§£é‡Šè¿ç»­è¡¨ç¤º**ï¼šè®©å‘é‡ç»´åº¦å…·æœ‰æ˜ç¡®è¯­ä¹‰
4. **é«˜æ•ˆè¡¨ç¤º**ï¼šé™ä½ç»´åº¦å’Œè®¡ç®—æˆæœ¬

---

## å‚è€ƒæ–‡çŒ®

### åŸºç¡€ç†è®º

1. [Wikipedia: Representation Learning](https://en.wikipedia.org/wiki/Feature_learning)
2. [Bengio et al., 2013](https://arxiv.org/abs/1206.5533) - Representation Learning: A Review and New Perspectives
3. [Goodfellow et al., 2016](https://www.deeplearningbook.org/) - Deep Learning

### æ•°å­¦åŸºç¡€

1. [Wikipedia: Metric Space](https://en.wikipedia.org/wiki/Metric_space)
2. [Wikipedia: Topological Space](https://en.wikipedia.org/wiki/Topological_space)
3. [Wikipedia: Manifold](https://en.wikipedia.org/wiki/Manifold)
4. [Wikipedia: Differentiable Manifold](https://en.wikipedia.org/wiki/Differentiable_manifold)

### æµå½¢å­¦ä¹ 

1. [Wikipedia: Manifold Learning](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction)
2. [Fefferman et al., 2016](https://www.pnas.org/doi/full/10.1073/pnas.1408993113) - Testing the Manifold Hypothesis
3. [van der Maaten & Hinton, 2008](https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf) - Visualizing Data using t-SNE

### åº¦é‡å­¦ä¹ 

1. [Wikipedia: Metric Learning](https://en.wikipedia.org/wiki/Similarity_learning)
2. [Schroff et al., 2015](https://arxiv.org/abs/1503.03832) - FaceNet: A Unified Embedding for Face Recognition

### ä¼˜åŒ–

1. [Wikipedia: Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent)
2. [Wikipedia: Backpropagation](https://en.wikipedia.org/wiki/Backpropagation)
3. [Wikipedia: Automatic Differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation)
4. [Kingma & Ba, 2014](https://arxiv.org/abs/1412.6980) - Adam: A Method for Stochastic Optimization

### å“²å­¦ä¸æ‰¹è¯„

1. [Marcus, 2020](https://arxiv.org/abs/2002.06177) - The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence
2. [Lipton, 2018](https://arxiv.org/abs/1606.03490) - The Mythos of Model Interpretability

---

*æœ¬æ–‡æ¡£æ·±å…¥æ¢è®¨äº†è¿ç»­è¡¨ç¤ºç†è®ºçš„æ•°å­¦åŸºç¡€ã€å­¦ä¹ æœºåˆ¶å’Œå“²å­¦æ„æ¶µï¼Œä¸ºç†è§£ç°ä»£AIçš„æ ¸å¿ƒèŒƒå¼æä¾›äº†å®Œæ•´çš„ç†è®ºæ¡†æ¶ã€‚*
