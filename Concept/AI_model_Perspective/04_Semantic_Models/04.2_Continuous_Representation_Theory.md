# è¿ç»­è¡¨ç¤ºç†è®ºï¼ˆContinuous Representation Theoryï¼‰

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0  
> **æœ€åæ›´æ–°**: 2025-10-27  
> **æ–‡æ¡£è§„æ¨¡**: 1041è¡Œ | ç¦»æ•£ç¬¦å·ä¸è¿ç»­å‘é‡çš„ç†è®ºæ¡¥æ¥  
> **é˜…è¯»å»ºè®®**: æœ¬æ–‡æ·±å…¥æ¢è®¨è¿ç»­è¡¨ç¤ºçš„æ•°å­¦åŸºç¡€ä¸å“²å­¦æ„ä¹‰ï¼Œæ˜¯ç†è§£ç°ä»£AIçš„æ ¸å¿ƒç†è®º

---

## æ ¸å¿ƒæ¦‚å¿µæ·±åº¦åˆ†æ

<details>
<summary><b>ğŸ”„ğŸ“ ç‚¹å‡»å±•å¼€ï¼šè¿ç»­è¡¨ç¤ºç†è®ºå…¨æ™¯æ·±åº¦è§£æ</b></summary>

æœ¬èŠ‚æ·±å…¥å‰–æç¦»æ•£vsè¿ç»­çš„å“²å­¦äºŒå…ƒæ€§ã€åµŒå…¥æ•°å­¦åŸºç¡€ã€å¯å¾®æ€§é©å‘½ä¸è¡¨ç¤ºå­¦ä¹ èŒƒå¼ã€‚

### 1ï¸âƒ£ è¿ç»­è¡¨ç¤ºç†è®ºæ¦‚å¿µå®šä¹‰å¡

**æ¦‚å¿µåç§°**: è¿ç»­è¡¨ç¤ºï¼ˆContinuous Representationï¼‰

**å†…æ¶µï¼ˆæœ¬è´¨å±æ€§ï¼‰**:

**ğŸ”¹ æ ¸å¿ƒå®šä¹‰**:
è¿ç»­è¡¨ç¤ºæ˜¯å°†ç¦»æ•£ç¬¦å·å¯¹è±¡ï¼ˆè¯ã€å¥å­ã€æ¦‚å¿µï¼‰æ˜ å°„åˆ°è¿ç»­å‘é‡ç©ºé—´çš„è¡¨ç¤ºæ–¹å¼ï¼Œä½¿å¾—è¯­ä¹‰å…³ç³»å¯ç”¨å‡ ä½•è·ç¦»å’Œå¾®ç§¯åˆ†åˆ»ç”»ï¼Œå®ç°ä»ç¬¦å·æ“ä½œåˆ°æ•°å€¼ä¼˜åŒ–çš„èŒƒå¼è½¬å˜ã€‚

$$
\text{è¿ç»­è¡¨ç¤º} = \underbrace{\text{ç¦»æ•£ç¬¦å·}}_{\text{è¯­ä¹‰ä¸–ç•Œ}} \xrightarrow{\text{åµŒå…¥}} \underbrace{\text{è¿ç»­å‘é‡}}_{\text{å‡ ä½•ä¸–ç•Œ}} + \underbrace{\text{å¯å¾®æ€§}}_{\text{ä¼˜åŒ–èƒ½åŠ›}}
$$

**ğŸ”¹ ç¦»æ•£vsè¿ç»­æ ¸å¿ƒå¯¹æ¯”**:

| ç»´åº¦ | ç¦»æ•£è¡¨ç¤º | è¿ç»­è¡¨ç¤º | è½¬å˜æ„ä¹‰ |
|------|---------|---------|---------|
| **æ•°å­¦åŸºç¡€** | ç¦»æ•£æ•°å­¦ã€é€»è¾‘ | å¾®ç§¯åˆ†ã€æ‹“æ‰‘ã€æµå½¢ | è®¡ç®—èŒƒå¼è½¬å˜ |
| **è¡¨ç¤ºå½¢å¼** | ç¬¦å·ã€one-hot | å‘é‡ã€å®æ•° | ä¿¡æ¯å¯†åº¦æå‡ |
| **ç›¸ä¼¼åº¦** | ç²¾ç¡®åŒ¹é…ï¼ˆ0æˆ–1ï¼‰ | è¿ç»­åº¦é‡ï¼ˆ0åˆ°1ï¼‰ | æ³›åŒ–èƒ½åŠ›å¢å¼º |
| **ä¼˜åŒ–** | æœç´¢ã€æ¨ç† | æ¢¯åº¦ä¸‹é™ | å¯ä¼˜åŒ–æ€§é©å‘½ |
| **ç»´åº¦** | $\|V\|$ï¼ˆè¯è¡¨å¤§å°ï¼‰ | dï¼ˆåµŒå…¥ç»´åº¦ï¼‰<< $\|V\|$ | ç»´åº¦å‹ç¼© |
| **æ³›åŒ–** | âŒ å¼±ï¼ˆæ–°è¯æœªè§ï¼‰ | âœ… å¼ºï¼ˆå‡ ä½•æ’å€¼ï¼‰ | æ ¸å¿ƒä¼˜åŠ¿ |

**å¤–å»¶ï¼ˆèŒƒå›´è¾¹ç•Œï¼‰**:

| ç»´åº¦ | è¿ç»­è¡¨ç¤ºåŒ…å« âœ… | ä¸åŒ…å« âŒ |
|------|--------------|----------|
| **æ–¹æ³•** | Word2Vecã€BERTã€GloVe | one-hotã€ç¬¦å·é€»è¾‘ |
| **ç©ºé—´** | $\mathbb{R}^d$æ¬§æ°ç©ºé—´ã€æµå½¢ | ç¦»æ•£å›¾ã€ç¬¦å·é›†åˆ |
| **æ“ä½œ** | å‘é‡è¿ç®—ã€æ¢¯åº¦ä¼˜åŒ– | ç¬¦å·æ¨ç†ã€ç²¾ç¡®åŒ¹é… |

**å±æ€§ç»´åº¦è¡¨**:

| ç»´åº¦ | å€¼/æè¿° | è¯´æ˜ |
|------|---------|------|
| **èŒƒå¼è½¬å˜** | ç¬¦å·AIâ†’è¿æ¥ä¸»ä¹‰AI | 1980s-2010sé©å‘½ |
| **æ•°å­¦æ ¸å¿ƒ** | åµŒå…¥+åº¦é‡+æµå½¢ | å‡ ä½•åŒ–è¯­ä¹‰ |
| **å…³é”®ä¼˜åŠ¿** | å¯å¾®+æ³›åŒ–+ç»„åˆ | æ·±åº¦å­¦ä¹ åŸºç¡€ |
| **ä»£è¡¨æ–¹æ³•** | Word2Vec (2013), BERT (2018) | é‡Œç¨‹ç¢‘æ¨¡å‹ |

---

### 2ï¸âƒ£ è¿ç»­è¡¨ç¤ºç†è®ºå…¨æ™¯å›¾è°±

```mermaid
graph TB
    CRT[è¿ç»­è¡¨ç¤ºç†è®º<br/>Continuous Representation Theory]
    
    CRT --> CoreQ[æ ¸å¿ƒé—®é¢˜:<br/>å¦‚ä½•ä»ç¦»æ•£åˆ°è¿ç»­?]
    
    CoreQ --> Duality[ç¦»æ•£vsè¿ç»­äºŒå…ƒæ€§]
    
    Duality --> Discrete[ç¦»æ•£è¡¨ç¤º]
    Duality --> Continuous[è¿ç»­è¡¨ç¤º]
    
    Discrete --> D1[ç¬¦å·ç³»ç»Ÿ:<br/>words, symbols]
    Discrete --> D2[ç²¾ç¡®åŒ¹é…:<br/>0æˆ–1]
    Discrete --> D3[ç¦»æ•£æ•°å­¦:<br/>é›†åˆã€é€»è¾‘]
    Discrete --> D4[ä¼˜åŒ–å›°éš¾:<br/>æœç´¢ã€æ¨ç†]
    
    Continuous --> C1[å‘é‡ç³»ç»Ÿ:<br/>embeddings]
    Continuous --> C2[è¿ç»­ç›¸ä¼¼:<br/>0åˆ°1]
    Continuous --> C3[å¾®ç§¯åˆ†:<br/>æ‹“æ‰‘ã€æµå½¢]
    Continuous --> C4[æ¢¯åº¦ä¼˜åŒ–:<br/>å¯å¾®ã€é«˜æ•ˆ]
    
    Bridge[ç¦»æ•£â†’è¿ç»­æ¡¥æ¢]
    
    Bridge --> Embedding[åµŒå…¥<br/>Embedding]
    Bridge --> EncoderDecoder[ç¼–ç -è§£ç <br/>Encoder-Decoder]
    Bridge --> Probability[æ¦‚ç‡æ¡¥æ¥<br/>Softmax/Sampling]
    
    Embedding --> EmbFormula[Ï†: V â†’ â„^d<br/>è¯â†’å‘é‡]
    EncoderDecoder --> ED[ç¦»æ•£â†’è¿ç»­â†’ç¦»æ•£]
    Probability --> Prob[argmax P&#40;w|v&#41;]
    
    MathFoundation[æ•°å­¦åŸºç¡€]
    
    MathFoundation --> Metric[åº¦é‡ç©ºé—´<br/>d&#40;x,y&#41;]
    MathFoundation --> Topology[æ‹“æ‰‘ç©ºé—´<br/>é‚»åŸŸã€è¿ç»­æ€§]
    MathFoundation --> Manifold[æµå½¢<br/>å±€éƒ¨æ¬§æ°]
    MathFoundation --> Diff[å¯å¾®ç»“æ„<br/>æ¢¯åº¦å­˜åœ¨]
    
    Advantages[è¿ç»­è¡¨ç¤ºä¼˜åŠ¿]
    
    Advantages --> A1[æ³›åŒ–:<br/>å‡ ä½•æ’å€¼]
    Advantages --> A2[å¹³æ»‘æ€§:<br/>é‚»è¿‘â†’ç›¸ä¼¼]
    Advantages --> A3[ç»„åˆæ€§:<br/>å‘é‡è¿ç®—]
    Advantages --> A4[å¯ä¼˜åŒ–:<br/>æ¢¯åº¦ä¸‹é™]
    
    A1 --> Gen[king - man + woman â‰ˆ queen]
    A4 --> Opt[âˆ‚L/âˆ‚Î¸ â†’ åå‘ä¼ æ’­]
    
    Learning[è¡¨ç¤ºå­¦ä¹ ]
    
    Learning --> L1[è‡ªç›‘ç£:<br/>Word2Vec/BERT]
    Learning --> L2[æµå½¢å­¦ä¹ :<br/>t-SNE/UMAP]
    Learning --> L3[åº¦é‡å­¦ä¹ :<br/>Triplet Loss]
    Learning --> L4[å¯¹æ¯”å­¦ä¹ :<br/>SimCLR/CLIP]
    
    Limitations[å±€é™æ€§]
    
    Limitations --> Lim1[ç²¾ç¡®æ€§ä¸§å¤±<br/>ç¬¦å·â†’å‘é‡]
    Limitations --> Lim2[ç»´åº¦ç¾éš¾<br/>é«˜ç»´ç¨€ç–]
    Limitations --> Lim3[ä¸å¯è§£é‡Š<br/>é»‘ç›’å‘é‡]
    Limitations --> Lim4[èµ„æºæ¶ˆè€—<br/>è®¡ç®—/å†…å­˜]
    
    Philosophy[å“²å­¦æ„ä¹‰]
    Philosophy --> P1[è¯­ä¹‰å‡ ä½•åŒ–<br/>æ„ä¹‰â†’ç©ºé—´]
    Philosophy --> P2[ç±»æ¯”æ¨ç†<br/>å‘é‡è¿ç®—]
    Philosophy --> P3[éšå¼çŸ¥è¯†<br/>åˆ†å¸ƒå¼è¡¨ç¤º]
    
    style CRT fill:#9b59b6,stroke:#333,stroke-width:4px
    style Duality fill:#3498db,stroke:#333,stroke-width:4px
    style MathFoundation fill:#2ecc71,stroke:#333,stroke-width:4px
    style Limitations fill:#e74c3c,stroke:#333,stroke-width:4px
```

---

### 3ï¸âƒ£ ç¦»æ•£vsè¿ç»­åç»´æ·±åº¦å¯¹æ¯”

| ç»´åº¦ | ç¦»æ•£è¡¨ç¤º | è¿ç»­è¡¨ç¤º | è½¬å˜çš„æ·±å±‚æ„ä¹‰ |
|------|---------|---------|---------------|
| **1. æ•°å­¦åŸºç¡€** | ç¦»æ•£æ•°å­¦ã€é›†åˆè®ºã€é€»è¾‘ | å¾®ç§¯åˆ†ã€æ‹“æ‰‘ã€æµå½¢å‡ ä½• | **èŒƒå¼é©å‘½** |
| **2. è¡¨ç¤ºå½¢å¼** | one-hot: $[0,0,1,0,0]$ | embedding: $[0.2,-0.5,0.8,...]$ | ä¿¡æ¯å¯†åº¦10-1000Ã—æå‡ |
| **3. ç»´åº¦** | $\|V\|$ (å¦‚50K) | d (å¦‚300) | å‹ç¼©166Ã— |
| **4. ç›¸ä¼¼åº¦** | ç²¾ç¡®åŒ¹é…ï¼ˆ$\delta_{ij}$ï¼‰ | è¿ç»­åº¦é‡ï¼ˆcosine, L2ï¼‰ | æ³›åŒ–èƒ½åŠ›è·å¾— |
| **5. æ³›åŒ–** | âŒ æ— ï¼ˆæ–°è¯=æœªè§ï¼‰ | âœ… æœ‰ï¼ˆå‡ ä½•æ’å€¼ï¼‰ | **æ ¸å¿ƒä¼˜åŠ¿** |
| **6. å¹³æ»‘æ€§** | âŒ ç¦»æ•£è·³è·ƒ | âœ… è¿ç»­å¹³æ»‘ | ä¼˜åŒ–å‹å¥½ |
| **7. å¯å¾®æ€§** | âŒ ä¸å¯å¾® | âœ… å¯å¾® | **æ¢¯åº¦ä¼˜åŒ–æˆä¸ºå¯èƒ½** |
| **8. ç»„åˆæ€§** | ç¬¦å·æ‹¼æ¥ï¼ˆç¦»æ•£ï¼‰ | å‘é‡è¿ç®—ï¼ˆè¿ç»­ï¼‰ | ç±»æ¯”æ¨ç†èƒ½åŠ› |
| **9. è§£é‡Šæ€§** | âœ… é«˜ï¼ˆç¬¦å·æ˜ç¡®ï¼‰ | âŒ ä½ï¼ˆé»‘ç›’å‘é‡ï¼‰ | å¯è§£é‡Šæ€§ä»£ä»· |
| **10. ç²¾ç¡®æ€§** | âœ… ç²¾ç¡® | âš ï¸ è¿‘ä¼¼ | ç²¾åº¦-æ³›åŒ–æƒè¡¡ |

**æ•°å­¦è¯¦è§£**:

$$
\begin{align}
\text{ç¦»æ•£è¡¨ç¤ºï¼ˆone-hotï¼‰} &: \\
w_i &\mapsto e_i = [0,...,0,1,0,...,0] \in \{0,1\}^{|V|} \\
\text{ç›¸ä¼¼åº¦} &: \langle e_i, e_j \rangle = \delta_{ij} = \begin{cases} 1 & i=j \\ 0 & i \neq j \end{cases} \\
\\
\text{è¿ç»­è¡¨ç¤ºï¼ˆembeddingï¼‰} &: \\
w_i &\mapsto v_i = [v_{i1}, v_{i2}, ..., v_{id}] \in \mathbb{R}^d \\
\text{ç›¸ä¼¼åº¦} &: \text{sim}(v_i, v_j) = \frac{\langle v_i, v_j \rangle}{||v_i|| \cdot ||v_j||} \in [-1, 1] \\
\\
\text{ç±»æ¯”æ¨ç†ï¼ˆè¿ç»­ç‹¬æœ‰ï¼‰} &: \\
\text{king} - \text{man} + \text{woman} &\approx \text{queen} \\
v_{\text{king}} - v_{\text{man}} + v_{\text{woman}} &\approx v_{\text{queen}}
\end{align}
$$

**æ·±åº¦åˆ†æ**:

```yaml
ç¦»æ•£è¡¨ç¤ºçš„ä¸–ç•Œï¼ˆä¼ ç»ŸAI, ~1980sï¼‰:
  ç¬¦å·ä¸»ä¹‰:
    - "cat", "dog"æ˜¯åŸå­ç¬¦å·
    - æ— å†…åœ¨ç»“æ„ï¼ˆåŸå­æ€§ï¼‰
    - ç›¸ä¼¼åº¦: cat â‰  dog ï¼ˆå®Œå…¨ä¸åŒï¼‰
  
  æ•°å­¦:
    - one-hotç¼–ç : cat â†’ [0,0,1,0,...,0]
    - é«˜ç»´ç¨€ç–ï¼ˆ|V|ç»´ï¼‰
    - æ­£äº¤: âŸ¨cat, dogâŸ© = 0
  
  æ“ä½œ:
    - ç¬¦å·æ¨ç†ï¼ˆé€»è¾‘è§„åˆ™ï¼‰
    - æœç´¢ï¼ˆçŠ¶æ€ç©ºé—´ï¼‰
    - ç¦»æ•£ä¼˜åŒ–ï¼ˆNP-hardï¼‰
  
  å±€é™:
    - æ— æ³›åŒ–ï¼ˆæ–°è¯=æœªè§ï¼‰
    - æ— ç±»æ¯”ï¼ˆæ— å‘é‡è¿ç®—ï¼‰
    - ä¼˜åŒ–å›°éš¾ï¼ˆä¸å¯å¾®ï¼‰

è¿ç»­è¡¨ç¤ºçš„ä¸–ç•Œï¼ˆç°ä»£AI, 2013+ï¼‰:
  å‘é‡ä¸»ä¹‰:
    - "cat", "dog"æ˜¯å‘é‡
    - æœ‰å†…åœ¨ç»“æ„ï¼ˆåˆ†å¸ƒå¼ï¼‰
    - ç›¸ä¼¼åº¦: sim(cat, dog) = 0.7 ï¼ˆè¯­ä¹‰ç›¸è¿‘ï¼‰
  
  æ•°å­¦:
    - åµŒå…¥: cat â†’ [0.2, -0.5, 0.8, ...] âˆˆ â„^d
    - ä½ç»´ç¨ å¯†ï¼ˆd=300ï¼‰
    - éæ­£äº¤: âŸ¨cat, dogâŸ© > 0
  
  æ“ä½œ:
    - å‘é‡è¿ç®—ï¼ˆåŠ å‡ä¹˜ï¼‰
    - æ¢¯åº¦ä¼˜åŒ–ï¼ˆSGDï¼‰
    - è¿ç»­ä¼˜åŒ–ï¼ˆå‡¸/éå‡¸ï¼‰
  
  ä¼˜åŠ¿:
    - æ³›åŒ–ï¼ˆå‡ ä½•æ’å€¼ï¼‰
    - ç±»æ¯”ï¼ˆå‘é‡ä»£æ•°ï¼‰
    - å¯å¾®ï¼ˆæ¢¯åº¦ä¸‹é™ï¼‰

èŒƒå¼è½¬å˜çš„é©å‘½æ€§æ„ä¹‰:
  1. å¯å¾®æ€§é©å‘½:
     - ç¦»æ•£: ä¸å¯å¾® â†’ æœç´¢/æ¨ç†
     - è¿ç»­: å¯å¾® â†’ æ¢¯åº¦ä¼˜åŒ–
     â†’ æ·±åº¦å­¦ä¹ æˆä¸ºå¯èƒ½
  
  2. æ³›åŒ–èƒ½åŠ›:
     - ç¦»æ•£: æœªè§è¯=æ— æ³•å¤„ç†
     - è¿ç»­: å‡ ä½•æ’å€¼=åˆç†çŒœæµ‹
     â†’ OOVé—®é¢˜ç¼“è§£
  
  3. ç±»æ¯”æ¨ç†:
     - ç¦»æ•£: æ— æ³•è¡¨è¾¾ï¼ˆç¬¦å·æ“ä½œï¼‰
     - è¿ç»­: king - man + woman â‰ˆ queen
     â†’ æ–°è®¤çŸ¥èƒ½åŠ›
  
  4. ä¿¡æ¯æ•ˆç‡:
     - ç¦»æ•£: |V|ç»´ï¼ˆ50K-100Kï¼‰
     - è¿ç»­: dç»´ï¼ˆ300-1000ï¼‰
     â†’ å‚æ•°å‡å°‘100-1000Ã—

ä»ç¦»æ•£åˆ°è¿ç»­çš„æ¡¥æ¢:
  æ–¹æ³•1: åµŒå…¥å­¦ä¹ ï¼ˆWord2Vecï¼‰
    - ç›®æ ‡: è¯­ä¹‰ç›¸ä¼¼â†’å‡ ä½•æ¥è¿‘
    - æŠ€æœ¯: Skip-gram/CBOW
    - æŸå¤±: Softmax/Negative Sampling
  
  æ–¹æ³•2: ç¼–ç -è§£ç 
    - ç¦»æ•£â†’è¿ç»­: Encoder
    - è¿ç»­â†’ç¦»æ•£: Decoder + argmax
    - ä¿è¯å¯é€†æ€§
  
  æ–¹æ³•3: æ¦‚ç‡æ¡¥æ¥
    - P(w|v) = softmax(v^T w_i)
    - é‡‡æ ·: w ~ P(Â·|v)
    - è½¯æ˜ å°„ï¼ˆæ¦‚ç‡åˆ†å¸ƒï¼‰

å½“å‰å…±è¯†ï¼ˆ2024ï¼‰:
  - è¿ç»­è¡¨ç¤ºä¸»å¯¼ç°ä»£AI
  - ä½†ç¬¦å·æ¨ç†ä»æœ‰ä»·å€¼
  - ç¥ç»ç¬¦å·ï¼ˆNeurosymbolicï¼‰: æ··åˆæ–¹æ³•
  - å¤§æ¨¡å‹éšå¼å­¦ä¹ ç¬¦å·è§„åˆ™
```

---

### 4ï¸âƒ£ åµŒå…¥æ•°å­¦åŸºç¡€æ·±åº¦è§£æ

**åµŒå…¥çš„å½¢å¼åŒ–å®šä¹‰**:

$$
\begin{align}
\text{åµŒå…¥} &: \phi: \mathcal{V} \to \mathbb{R}^d \\
\text{where } \mathcal{V} &= \text{ç¦»æ•£ç¬¦å·é›†åˆï¼ˆè¯è¡¨ï¼‰} \\
\mathbb{R}^d &= \text{dç»´æ¬§æ°ç©ºé—´} \\
\\
\text{ç›®æ ‡} &: \text{ä¿æŒè¯­ä¹‰å…³ç³»} \\
\text{sim}_{\text{semantic}}(w_i, w_j) &\approx \text{sim}_{\text{geometric}}(\phi(w_i), \phi(w_j))
\end{align}
$$

**å››å¤§æ•°å­¦ç»“æ„**:

| ç»“æ„ | å®šä¹‰ | ä½œç”¨ | ç¤ºä¾‹ |
|------|------|------|------|
| **åº¦é‡ç©ºé—´** | $(X, d)$ï¼Œ$d: X \times X \to \mathbb{R}_+$ | å®šä¹‰è·ç¦» | æ¬§æ°è·ç¦»ã€ä½™å¼¦è·ç¦» |
| **æ‹“æ‰‘ç©ºé—´** | $(X, \mathcal{T})$ï¼Œ$\mathcal{T}$æ˜¯å¼€é›†æ— | å®šä¹‰é‚»åŸŸã€è¿ç»­æ€§ | é‚»è¿‘è¯èšç±» |
| **æµå½¢** | å±€éƒ¨æ¬§æ°ç©ºé—´ | æ•æ‰éçº¿æ€§ç»“æ„ | è¯ä¹‰æµå½¢ã€æ¦‚å¿µæµå½¢ |
| **å¯å¾®ç»“æ„** | åˆ‡ç©ºé—´ã€æ¢¯åº¦å­˜åœ¨ | æ”¯æŒä¼˜åŒ– | æ¢¯åº¦ä¸‹é™ã€åå‘ä¼ æ’­ |

**æ·±åº¦åˆ†æ**:

```yaml
åº¦é‡ç©ºé—´ï¼ˆMetric Spaceï¼‰:
  å®šä¹‰: (X, d)ï¼Œæ»¡è¶³:
    1. éè´Ÿæ€§: d(x,y) â‰¥ 0, d(x,y)=0 âŸº x=y
    2. å¯¹ç§°æ€§: d(x,y) = d(y,x)
    3. ä¸‰è§’ä¸ç­‰å¼: d(x,z) â‰¤ d(x,y) + d(y,z)
  
  åµŒå…¥ç©ºé—´å¸¸ç”¨åº¦é‡:
    1. æ¬§æ°è·ç¦»: d(x,y) = ||x-y||â‚‚
    2. ä½™å¼¦è·ç¦»: d(x,y) = 1 - cos(x,y)
    3. æ›¼å“ˆé¡¿è·ç¦»: d(x,y) = ||x-y||â‚
  
  æ„ä¹‰:
    - é‡åŒ–è¯­ä¹‰ç›¸ä¼¼åº¦
    - æ”¯æŒæœ€è¿‘é‚»æœç´¢
    - K-meansç­‰èšç±»ç®—æ³•åŸºç¡€

æ‹“æ‰‘ç©ºé—´ï¼ˆTopological Spaceï¼‰:
  å®šä¹‰: (X, ğ’¯)ï¼Œğ’¯æ˜¯å¼€é›†æ—
  
  æ ¸å¿ƒæ¦‚å¿µ:
    - é‚»åŸŸ: xçš„é‚»åŸŸ={y: d(x,y) < Îµ}
    - è¿ç»­æ€§: fè¿ç»­ âŸº å¼€é›†é€†åƒä»å¼€
    - ç´§è‡´æ€§: æœ‰ç•Œé—­é›†
  
  åº”ç”¨:
    - å®šä¹‰"æ¥è¿‘"
    - ä¿è¯åµŒå…¥è¿ç»­æ€§
    - t-SNE/UMAPå¯è§†åŒ–

æµå½¢ï¼ˆManifoldï¼‰:
  å®šä¹‰: å±€éƒ¨åŒèƒšäºâ„^dçš„æ‹“æ‰‘ç©ºé—´
  
  ç›´è§‚:
    - åœ°çƒè¡¨é¢: å±€éƒ¨çœ‹æ˜¯å¹³é¢ï¼ˆâ„Â²ï¼‰ï¼Œæ•´ä½“æ˜¯çƒé¢ï¼ˆSÂ²ï¼‰
    - è¯ä¹‰ç©ºé—´: å±€éƒ¨æ¬§æ°ï¼Œæ•´ä½“éçº¿æ€§
  
  æµå½¢å‡è®¾:
    - é«˜ç»´æ•°æ®ï¼ˆå¦‚è‡ªç„¶è¯­è¨€ï¼‰
    - å®é™…åˆ†å¸ƒåœ¨ä½ç»´æµå½¢ä¸Š
    - dim(æµå½¢) << dim(ambient space)
  
  ä¾‹å­:
    - è¯ä¹‰æµå½¢: åŒä¹‰è¯ç°‡å½¢æˆæµå½¢
    - å¥å­æµå½¢: è¯­ä¹‰ç›¸ä¼¼å¥å­èšé›†
  
  æ„ä¹‰:
    - è§£é‡Šé«˜ç»´æ•°æ®çš„ä½ç»´æœ¬è´¨
    - æŒ‡å¯¼é™ç»´æ–¹æ³•ï¼ˆt-SNE, UMAPï¼‰
    - æ”¯æŒéçº¿æ€§åµŒå…¥

å¯å¾®ç»“æ„ï¼ˆDifferentiable Structureï¼‰:
  å®šä¹‰: æµå½¢+å¹³æ»‘ç»“æ„
  
  æ ¸å¿ƒ:
    - åˆ‡ç©ºé—´: T_p Mï¼ˆpç‚¹çš„å±€éƒ¨çº¿æ€§åŒ–ï¼‰
    - æ¢¯åº¦: âˆ‡få­˜åœ¨
    - é»æ›¼åº¦é‡: å†…ç§¯ç»“æ„
  
  æ„ä¹‰:
    - æ”¯æŒæ¢¯åº¦ä¼˜åŒ–
    - åå‘ä¼ æ’­åŸºç¡€
    - è¿ç»­æ’å€¼

æ•°å­¦ç»“æ„çš„å±‚æ¬¡:
  é›†åˆ â†’ åº¦é‡ç©ºé—´ â†’ æ‹“æ‰‘ç©ºé—´ â†’ æµå½¢ â†’ å¯å¾®æµå½¢
  
  æ¯å±‚æ·»åŠ çš„ç»“æ„:
    - åº¦é‡: è·ç¦»
    - æ‹“æ‰‘: è¿ç»­æ€§
    - æµå½¢: å±€éƒ¨æ¬§æ°
    - å¯å¾®: æ¢¯åº¦
  
  åµŒå…¥ç©ºé—´éœ€è¦æ‰€æœ‰å±‚æ¬¡:
    - åº¦é‡: ç›¸ä¼¼åº¦
    - æ‹“æ‰‘: èšç±»
    - æµå½¢: éçº¿æ€§
    - å¯å¾®: ä¼˜åŒ–
```

---

### ğŸ”Ÿ æ ¸å¿ƒæ´å¯Ÿä¸ç»ˆæè¯„ä¼°

**äº”å¤§æ ¸å¿ƒå®šå¾‹**:

1. **ç¦»æ•£-è¿ç»­æ¡¥æ¥å®šå¾‹**
   $$
   \text{ç¬¦å·} \xrightarrow{\text{åµŒå…¥}} \text{å‘é‡} \xrightarrow{\text{å¯å¾®}} \text{æ¢¯åº¦ä¼˜åŒ–}
   $$
   - è¿ç»­è¡¨ç¤ºä½¿æ·±åº¦å­¦ä¹ æˆä¸ºå¯èƒ½

2. **æ³›åŒ–èƒ½åŠ›å®šå¾‹**
   $$
   \text{å‡ ä½•é‚»è¿‘} \Rightarrow \text{è¯­ä¹‰ç›¸ä¼¼} \Rightarrow \text{æ³›åŒ–}
   $$
   - è¿ç»­è¡¨ç¤ºçš„æ ¸å¿ƒä¼˜åŠ¿

3. **ç±»æ¯”æ¨ç†å®šå¾‹**
   $$
   \text{king} - \text{man} + \text{woman} \approx \text{queen}
   $$
   - å‘é‡è¿ç®—å®ç°è¯­ä¹‰ç±»æ¯”

4. **æµå½¢å‡è®¾å®šå¾‹**
   $$
   \text{dim}(\text{æ•°æ®æµå½¢}) \ll \text{dim}(\text{ambient space})
   $$
   - é«˜ç»´æ•°æ®çš„ä½ç»´æœ¬è´¨

5. **å¯å¾®æ€§é©å‘½å®šå¾‹**
   $$
   \frac{\partial L}{\partial \theta} \text{å­˜åœ¨} \Rightarrow \text{SGDå¯è¡Œ} \Rightarrow \text{ç«¯åˆ°ç«¯å­¦ä¹ }
   $$
   - å¯å¾®æ€§æ˜¯æ·±åº¦å­¦ä¹ çš„åŸºçŸ³

**ç»ˆææ´å¯Ÿ**:

> **"è¿ç»­è¡¨ç¤ºç†è®ºæ˜¯ç°ä»£AIçš„èŒƒå¼è½¬å˜æ ¸å¿ƒâ€”â€”ä»ç¦»æ•£ç¬¦å·æ“ä½œåˆ°è¿ç»­å‘é‡è®¡ç®—ã€‚æ ¸å¿ƒæ€æƒ³ï¼šå°†è¯­ä¹‰å¯¹è±¡ï¼ˆè¯ã€å¥ã€æ¦‚å¿µï¼‰æ˜ å°„åˆ°è¿ç»­å‘é‡ç©ºé—´$\mathbb{R}^d$ï¼Œä½¿å¾—è¯­ä¹‰å…³ç³»å¯ç”¨å‡ ä½•è·ç¦»åˆ»ç”»ã€‚æ•°å­¦åŸºç¡€ï¼šåº¦é‡ç©ºé—´ï¼ˆå®šä¹‰è·ç¦»ï¼‰ã€æ‹“æ‰‘ç©ºé—´ï¼ˆå®šä¹‰é‚»åŸŸï¼‰ã€æµå½¢ï¼ˆæ•æ‰éçº¿æ€§ï¼‰ã€å¯å¾®ç»“æ„ï¼ˆæ”¯æŒä¼˜åŒ–ï¼‰ã€‚äº”å¤§ä¼˜åŠ¿ï¼šâ‘ æ³›åŒ–ï¼ˆå‡ ä½•æ’å€¼â†’OOVå¤„ç†ï¼‰â‘¡å¹³æ»‘æ€§ï¼ˆé‚»è¿‘â†’ç›¸ä¼¼ï¼‰â‘¢ç»„åˆæ€§ï¼ˆå‘é‡è¿ç®—â†’ç±»æ¯”æ¨ç†ï¼‰â‘£å¯ä¼˜åŒ–æ€§ï¼ˆæ¢¯åº¦ä¸‹é™â†’ç«¯åˆ°ç«¯å­¦ä¹ ï¼‰â‘¤ä¿¡æ¯å‹ç¼©ï¼ˆd<<|V|ï¼Œå‚æ•°å‡å°‘100-1000Ã—ï¼‰ã€‚å…³é”®è½¬å˜ï¼šä¸å¯å¾®â†’å¯å¾®ï¼ˆä¼˜åŒ–é©å‘½ï¼‰ã€ç²¾ç¡®åŒ¹é…â†’è¿ç»­ç›¸ä¼¼ï¼ˆæ³›åŒ–é©å‘½ï¼‰ã€ç¬¦å·æ¨ç†â†’å‘é‡è¿ç®—ï¼ˆè®¡ç®—é©å‘½ï¼‰ã€‚ä»£è¡¨æ–¹æ³•ï¼šWord2Vec (2013)ã€GloVe (2014)ã€BERT (2018)ã€‚å±€é™æ€§ï¼šâ‘ ç²¾ç¡®æ€§ä¸§å¤±ï¼ˆç¬¦å·â†’å‘é‡ï¼‰â‘¡ä¸å¯è§£é‡Šï¼ˆé»‘ç›’å‘é‡ï¼‰â‘¢ç»´åº¦ç¾éš¾ï¼ˆé«˜ç»´ç¨€ç–ï¼‰â‘£èµ„æºæ¶ˆè€—ã€‚å“²å­¦æ„ä¹‰ï¼šè¯­ä¹‰å‡ ä½•åŒ–â€”â€”æ„ä¹‰å¯è¢«ç©ºé—´ã€è·ç¦»ã€è§’åº¦åˆ»ç”»ï¼›åˆ†å¸ƒå¼è¡¨ç¤ºâ€”â€”æ¯ä¸ªç»´åº¦æ•æ‰ä¸€ä¸ªè¯­ä¹‰ç‰¹å¾ï¼›éšå¼çŸ¥è¯†â€”â€”ä¸éœ€æ˜¾å¼è§„åˆ™ã€‚æµå½¢å‡è®¾ï¼šè‡ªç„¶è¯­è¨€è™½é«˜ç»´ï¼Œå®é™…åˆ†å¸ƒåœ¨ä½ç»´æµå½¢ï¼ˆ~100ç»´ï¼‰ã€‚å½“å‰è¶‹åŠ¿ï¼šè¿ç»­ä¸»å¯¼butç¬¦å·ä»·å€¼ä»å­˜â†’ç¥ç»ç¬¦å·æ··åˆï¼ˆNeurosymbolic AIï¼‰ã€‚è¿ç»­è¡¨ç¤ºæ˜¯æ·±åº¦å­¦ä¹ é©å‘½çš„æ•°å­¦åŸºç¡€ï¼Œæ²¡æœ‰å®ƒå°±æ²¡æœ‰ç°ä»£AIã€‚"**

**å…ƒè®¤çŸ¥**:
- **æ ¸å¿ƒè½¬å˜**: ç¦»æ•£â†’è¿ç»­ï¼ˆèŒƒå¼é©å‘½ï¼‰
- **æ•°å­¦åŸºç¡€**: åº¦é‡+æ‹“æ‰‘+æµå½¢+å¯å¾®
- **å…³é”®ä¼˜åŠ¿**: å¯å¾®â†’ä¼˜åŒ–ã€å‡ ä½•â†’æ³›åŒ–
- **ä»£è¡¨æ–¹æ³•**: Word2Vec, BERT
- **å“²å­¦æ„ä¹‰**: è¯­ä¹‰å‡ ä½•åŒ–ã€åˆ†å¸ƒå¼è¡¨ç¤º
- **å±€é™æ€§**: ç²¾ç¡®æ€§vsæ³›åŒ–æ€§æƒè¡¡
- **æœªæ¥æ–¹å‘**: ç¥ç»ç¬¦å·æ··åˆ

</details>

---

## ç›®å½• | Table of Contents

- [è¿ç»­è¡¨ç¤ºç†è®ºï¼ˆContinuous Representation Theoryï¼‰](#è¿ç»­è¡¨ç¤ºç†è®ºcontinuous-representation-theory)
- [ç›®å½•](#ç›®å½•)
- [å¼•è¨€](#å¼•è¨€)
  - [æ ¸å¿ƒæ€æƒ³](#æ ¸å¿ƒæ€æƒ³)
  - [å…³é”®é—®é¢˜](#å…³é”®é—®é¢˜)
- [ç¦»æ•£ vs è¿ç»­ï¼šè¡¨ç¤ºçš„äºŒå…ƒæ€§](#ç¦»æ•£-vs-è¿ç»­è¡¨ç¤ºçš„äºŒå…ƒæ€§)
  - [ç¦»æ•£è¡¨ç¤ºï¼ˆDiscrete Representationï¼‰](#ç¦»æ•£è¡¨ç¤ºdiscrete-representation)
    - [ç¬¦å·ç³»ç»Ÿ](#ç¬¦å·ç³»ç»Ÿ)
    - [ç¦»æ•£æ•°å­¦åŸºç¡€](#ç¦»æ•£æ•°å­¦åŸºç¡€)
  - [è¿ç»­è¡¨ç¤ºï¼ˆContinuous Representationï¼‰](#è¿ç»­è¡¨ç¤ºcontinuous-representation)
    - [å‘é‡ç³»ç»Ÿ](#å‘é‡ç³»ç»Ÿ)
    - [è¿ç»­æ•°å­¦åŸºç¡€](#è¿ç»­æ•°å­¦åŸºç¡€)
  - [äºŒå…ƒæ€§çš„å“²å­¦æ„ä¹‰](#äºŒå…ƒæ€§çš„å“²å­¦æ„ä¹‰)
- [è¿ç»­è¡¨ç¤ºçš„æ•°å­¦åŸºç¡€](#è¿ç»­è¡¨ç¤ºçš„æ•°å­¦åŸºç¡€)
  - [1. åº¦é‡ç©ºé—´ï¼ˆMetric Spaceï¼‰](#1-åº¦é‡ç©ºé—´metric-space)
  - [2. æ‹“æ‰‘ç©ºé—´ï¼ˆTopological Spaceï¼‰](#2-æ‹“æ‰‘ç©ºé—´topological-space)
  - [3. æµå½¢ï¼ˆManifoldï¼‰](#3-æµå½¢manifold)
  - [4. å¯å¾®ç»“æ„ï¼ˆDifferentiable Structureï¼‰](#4-å¯å¾®ç»“æ„differentiable-structure)
- [ä»ç¦»æ•£åˆ°è¿ç»­çš„æ¡¥æ¢](#ä»ç¦»æ•£åˆ°è¿ç»­çš„æ¡¥æ¢)
  - [1. åµŒå…¥ï¼ˆEmbeddingï¼‰](#1-åµŒå…¥embedding)
  - [2. ç¼–ç -è§£ç æ¡†æ¶ï¼ˆEncoder-Decoderï¼‰](#2-ç¼–ç -è§£ç æ¡†æ¶encoder-decoder)
  - [3. æ¦‚ç‡æ¡¥æ¥ï¼ˆProbabilistic Bridgeï¼‰](#3-æ¦‚ç‡æ¡¥æ¥probabilistic-bridge)
  - [4. é‡‡æ ·ï¼ˆSamplingï¼‰](#4-é‡‡æ ·sampling)
- [è¿ç»­è¡¨ç¤ºçš„ä¼˜åŠ¿](#è¿ç»­è¡¨ç¤ºçš„ä¼˜åŠ¿)
  - [1. æ³›åŒ–èƒ½åŠ›ï¼ˆGeneralizationï¼‰](#1-æ³›åŒ–èƒ½åŠ›generalization)
  - [2. å¹³æ»‘æ€§ï¼ˆSmoothnessï¼‰](#2-å¹³æ»‘æ€§smoothness)
  - [3. æ’å€¼ä¸å¤–æ¨ï¼ˆInterpolation & Extrapolationï¼‰](#3-æ’å€¼ä¸å¤–æ¨interpolation-extrapolation)
    - [æ’å€¼](#æ’å€¼)
    - [å¤–æ¨](#å¤–æ¨)
  - [4. ç»„åˆæ€§ï¼ˆCompositionalityï¼‰](#4-ç»„åˆæ€§compositionality)
- [è¿ç»­è¡¨ç¤ºçš„å­¦ä¹ ç†è®º](#è¿ç»­è¡¨ç¤ºçš„å­¦ä¹ ç†è®º)
  - [1. è¡¨ç¤ºå­¦ä¹ ï¼ˆRepresentation Learningï¼‰](#1-è¡¨ç¤ºå­¦ä¹ representation-learning)
  - [2. æµå½¢å­¦ä¹ ï¼ˆManifold Learningï¼‰](#2-æµå½¢å­¦ä¹ manifold-learning)
  - [3. åº¦é‡å­¦ä¹ ï¼ˆMetric Learningï¼‰](#3-åº¦é‡å­¦ä¹ metric-learning)
  - [4. è‡ªç›‘ç£å­¦ä¹ ï¼ˆSelf-Supervised Learningï¼‰](#4-è‡ªç›‘ç£å­¦ä¹ self-supervised-learning)
- [å¯å¾®æ€§ä¸ä¼˜åŒ–](#å¯å¾®æ€§ä¸ä¼˜åŒ–)
  - [1. å¯å¾®æ€§çš„é‡è¦æ€§](#1-å¯å¾®æ€§çš„é‡è¦æ€§)
  - [2. æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰](#2-æ¢¯åº¦ä¸‹é™gradient-descent)
  - [3. åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰](#3-åå‘ä¼ æ’­backpropagation)
  - [4. è‡ªåŠ¨å¾®åˆ†ï¼ˆAutomatic Differentiationï¼‰](#4-è‡ªåŠ¨å¾®åˆ†automatic-differentiation)
- [è¿ç»­è¡¨ç¤ºçš„å±€é™æ€§](#è¿ç»­è¡¨ç¤ºçš„å±€é™æ€§)
  - [1. ç²¾ç¡®æ€§ä¸§å¤±ï¼ˆLoss of Precisionï¼‰](#1-ç²¾ç¡®æ€§ä¸§å¤±loss-of-precision)
  - [2. ç»´åº¦ç¾éš¾ï¼ˆCurse of Dimensionalityï¼‰](#2-ç»´åº¦ç¾éš¾curse-of-dimensionality)
  - [3. ä¸å¯è§£é‡Šæ€§ï¼ˆLack of Interpretabilityï¼‰](#3-ä¸å¯è§£é‡Šæ€§lack-of-interpretability)
  - [4. èµ„æºæ¶ˆè€—ï¼ˆResource Consumptionï¼‰](#4-èµ„æºæ¶ˆè€—resource-consumption)
- [æ€»ç»“](#æ€»ç»“)
  - [æ ¸å¿ƒè¦ç‚¹](#æ ¸å¿ƒè¦ç‚¹)
  - [å“²å­¦åæ€](#å“²å­¦åæ€)
  - [æœªæ¥æ–¹å‘](#æœªæ¥æ–¹å‘)
- [å‚è€ƒæ–‡çŒ®](#å‚è€ƒæ–‡çŒ®)
  - [åŸºç¡€ç†è®º](#åŸºç¡€ç†è®º)
  - [æ•°å­¦åŸºç¡€](#æ•°å­¦åŸºç¡€)
  - [æµå½¢å­¦ä¹ ](#æµå½¢å­¦ä¹ )
  - [åº¦é‡å­¦ä¹ ](#åº¦é‡å­¦ä¹ )
  - [ä¼˜åŒ–](#ä¼˜åŒ–)
  - [å“²å­¦ä¸æ‰¹è¯„](#å“²å­¦ä¸æ‰¹è¯„)

---

## å¼•è¨€

**è¿ç»­è¡¨ç¤º**ï¼ˆContinuous Representationï¼‰æ˜¯ç°ä»£AIçš„æ ¸å¿ƒèŒƒå¼è½¬æ¢ï¼šä»**ç¦»æ•£ç¬¦å·æ“ä½œ**è½¬å‘**è¿ç»­å‘é‡è®¡ç®—**ã€‚
è¿™ä¸€è½¬å˜ä¸ä»…æ”¹å˜äº†è¡¨ç¤ºæ–¹å¼ï¼Œæ›´æ”¹å˜äº†å­¦ä¹ ã€æ¨ç†å’Œæ³›åŒ–çš„æœºåˆ¶ã€‚

### æ ¸å¿ƒæ€æƒ³

> **å°†ç¦»æ•£çš„è¯­ä¹‰å¯¹è±¡ï¼ˆè¯ã€å¥å­ã€æ¦‚å¿µï¼‰æ˜ å°„åˆ°è¿ç»­çš„å‘é‡ç©ºé—´ï¼Œä½¿å¾—å¯ä»¥ç”¨å¾®ç§¯åˆ†å’Œä¼˜åŒ–ç†è®ºæ¥å¤„ç†è¯­ä¹‰ã€‚**

### å…³é”®é—®é¢˜

1. **å“²å­¦é—®é¢˜**ï¼šç¦»æ•£çš„ç¬¦å·ä¸–ç•Œå¦‚ä½•æ˜ å°„åˆ°è¿ç»­çš„æ•°å€¼ä¸–ç•Œï¼Ÿ
2. **æ•°å­¦é—®é¢˜**ï¼šè¿ç»­è¡¨ç¤ºçš„æ‹“æ‰‘å’Œå‡ ä½•æ€§è´¨æ˜¯ä»€ä¹ˆï¼Ÿ
3. **è®¡ç®—é—®é¢˜**ï¼šå¦‚ä½•å­¦ä¹ å’Œä¼˜åŒ–è¿ç»­è¡¨ç¤ºï¼Ÿ
4. **è¡¨ç¤ºè®ºé—®é¢˜**ï¼šè¿ç»­è¡¨ç¤ºçœŸçš„èƒ½æ•æ‰ç¦»æ•£è¯­ä¹‰çš„å…¨éƒ¨ä¿¡æ¯å—ï¼Ÿ

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Representation Learning](https://en.wikipedia.org/wiki/Feature_learning)
- [Bengio et al., 2013](https://arxiv.org/abs/1206.5533) - Representation Learning: A Review and New Perspectives

---

## ç¦»æ•£ vs è¿ç»­ï¼šè¡¨ç¤ºçš„äºŒå…ƒæ€§

### ç¦»æ•£è¡¨ç¤ºï¼ˆDiscrete Representationï¼‰

#### ç¬¦å·ç³»ç»Ÿ

**ä¼ ç»ŸAI**åŸºäº**ç¬¦å·**ï¼ˆSymbolsï¼‰ï¼š

```text
ğ’® = {cat, dog, animal, is-a, ...}
```

**å…³ç³»**é€šè¿‡**é€»è¾‘è§„åˆ™**å®šä¹‰ï¼š

```text
is-a(cat, animal)
âˆ€x (is-a(x, mammal) â†’ is-a(x, animal))
```

**ç‰¹ç‚¹**ï¼š

- âœ… **ç²¾ç¡®**ï¼šè¯­ä¹‰è¾¹ç•Œæ¸…æ™°
- âœ… **å¯è§£é‡Š**ï¼šè§„åˆ™æ˜ç¡®
- âœ… **ç»„åˆæ€§**ï¼šå¯ä»¥æ„é€ å¤æ‚è¡¨è¾¾å¼
- âŒ **è„†å¼±**ï¼šå¾®å°å˜åŒ–å¯èƒ½å¯¼è‡´å®Œå…¨ä¸åŒçš„ç»“æœ
- âŒ **ç¨€ç–**ï¼šéš¾ä»¥å¤„ç†æœªè§è¿‡çš„ç»„åˆ
- âŒ **å­¦ä¹ å›°éš¾**ï¼šéœ€è¦æ‰‹å·¥ç¼–å†™è§„åˆ™

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Symbolic AI](https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence)
- [Newell & Simon, 1976](https://en.wikipedia.org/wiki/Physical_symbol_system) - Computer Science as Empirical Inquiry

#### ç¦»æ•£æ•°å­¦åŸºç¡€

**é›†åˆè®º**ï¼š

```text
A = {x | P(x)}  ï¼ˆé›†åˆï¼‰
A âˆ© B, A âˆª B, A \ B  ï¼ˆé›†åˆè¿ç®—ï¼‰
```

**å›¾è®º**ï¼š

```text
G = (V, E)  ï¼ˆå›¾ï¼‰
è·¯å¾„ã€è¿é€šæ€§ã€æœ€çŸ­è·¯å¾„
```

**å½¢å¼è¯­è¨€**ï¼š

```text
Î£*  ï¼ˆç¬¦å·ä¸²çš„å…¨ä½“ï¼‰
L âŠ† Î£*  ï¼ˆå½¢å¼è¯­è¨€ï¼‰
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Discrete Mathematics](https://en.wikipedia.org/wiki/Discrete_mathematics)

### è¿ç»­è¡¨ç¤ºï¼ˆContinuous Representationï¼‰

#### å‘é‡ç³»ç»Ÿ

**ç°ä»£AI**åŸºäº**å‘é‡**ï¼ˆVectorsï¼‰ï¼š

```text
ğ• = â„áµˆ  ï¼ˆdç»´æ¬§å‡ é‡Œå¾—ç©ºé—´ï¼‰
```

**å¯¹è±¡æ˜ å°„**åˆ°å‘é‡ï¼š

```text
Enc(cat) = ğ’—_cat âˆˆ â„áµˆ
Enc(dog) = ğ’—_dog âˆˆ â„áµˆ
Enc(animal) = ğ’—_animal âˆˆ â„áµˆ
```

**å…³ç³»**é€šè¿‡**å‡ ä½•è¿ç®—**è¡¨è¾¾ï¼š

```text
cos(ğ’—_cat, ğ’—_animal) > threshold  â‡’  "cat is related to animal"
```

**ç‰¹ç‚¹**ï¼š

- âœ… **é²æ£’**ï¼šç›¸ä¼¼è¾“å…¥äº§ç”Ÿç›¸ä¼¼è¾“å‡º
- âœ… **æ³›åŒ–**ï¼šèƒ½å¤„ç†æœªè§è¿‡çš„è¾“å…¥
- âœ… **å¯å­¦ä¹ **ï¼šé€šè¿‡æ¢¯åº¦ä¸‹é™è‡ªåŠ¨å­¦ä¹ 
- âŒ **è¿‘ä¼¼**ï¼šå¤±å»ç²¾ç¡®æ€§
- âŒ **ä¸å¯è§£é‡Š**ï¼šå‘é‡ç»´åº¦æ— æ˜ç¡®è¯­ä¹‰
- âŒ **èµ„æºæ¶ˆè€—**ï¼šéœ€è¦å¤§é‡è®¡ç®—å’Œå­˜å‚¨

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Goodfellow et al., 2016](https://www.deeplearningbook.org/) - Deep Learning, Chapter 6

#### è¿ç»­æ•°å­¦åŸºç¡€

**æ‹“æ‰‘å­¦**ï¼š

```text
å¼€é›†ã€é—­é›†ã€è¿ç»­å‡½æ•°ã€ç´§è‡´æ€§
```

**å¾®ç§¯åˆ†**ï¼š

```text
å¯¼æ•°ã€æ¢¯åº¦ã€ä¼˜åŒ–
```

**æ³›å‡½åˆ†æ**ï¼š

```text
å¸Œå°”ä¼¯ç‰¹ç©ºé—´ã€å·´æ‹¿èµ«ç©ºé—´
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Topology](https://en.wikipedia.org/wiki/Topology)
- [Wikipedia: Functional Analysis](https://en.wikipedia.org/wiki/Functional_analysis)

### äºŒå…ƒæ€§çš„å“²å­¦æ„ä¹‰

| ç»´åº¦ | ç¦»æ•£ | è¿ç»­ | å‚è€ƒæ–‡çŒ® |
|------|------|------|----------|
| **æœ¬ä½“è®º** | åŸå­ä¸»ä¹‰ï¼ˆAtomismï¼‰ | æ•´ä½“ä¸»ä¹‰ï¼ˆHolismï¼‰ | [Wikipedia: Atomism](https://en.wikipedia.org/wiki/Atomism) |
| **è®¤è¯†è®º** | ç†æ€§ä¸»ä¹‰ï¼ˆRationalismï¼‰ | ç»éªŒä¸»ä¹‰ï¼ˆEmpiricismï¼‰ | [Wikipedia: Rationalism](https://en.wikipedia.org/wiki/Rationalism) |
| **æ•°å­¦** | ç»„åˆæ•°å­¦ | åˆ†æå­¦ | [Wikipedia: Mathematical Analysis](https://en.wikipedia.org/wiki/Mathematical_analysis) |
| **ç‰©ç†** | é‡å­è·ƒè¿ | ç»å…¸åŠ›å­¦ | [Wikipedia: Classical Mechanics](https://en.wikipedia.org/wiki/Classical_mechanics) |
| **è®¡ç®—** | å›¾çµæœº | æ¨¡æ‹Ÿè®¡ç®— | [Wikipedia: Analog Computer](https://en.wikipedia.org/wiki/Analog_computer) |

---

## è¿ç»­è¡¨ç¤ºçš„æ•°å­¦åŸºç¡€

### 1. åº¦é‡ç©ºé—´ï¼ˆMetric Spaceï¼‰

**å®šä¹‰**ï¼š

ä¸€ä¸ª**åº¦é‡ç©ºé—´**æ˜¯ä¸€ä¸ªäºŒå…ƒç»„ (X, d)ï¼Œå…¶ä¸­ï¼š

- X æ˜¯ä¸€ä¸ªé›†åˆ
- d : X Ã— X â†’ â„â‚Š æ˜¯åº¦é‡å‡½æ•°ï¼Œæ»¡è¶³ï¼š
  1. **éè´Ÿæ€§**ï¼šd(x, y) â‰¥ 0ï¼Œä¸” d(x, y) = 0 âŸº x = y
  2. **å¯¹ç§°æ€§**ï¼šd(x, y) = d(y, x)
  3. **ä¸‰è§’ä¸ç­‰å¼**ï¼šd(x, z) â‰¤ d(x, y) + d(y, z)

**AIä¸­çš„åº¦é‡ç©ºé—´**ï¼š

```text
(â„áµˆ, d_euclidean)  æ¬§å‡ é‡Œå¾—ç©ºé—´
(â„áµˆ, d_cosine)     ä½™å¼¦è·ç¦»ç©ºé—´
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Metric Space](https://en.wikipedia.org/wiki/Metric_space)

### 2. æ‹“æ‰‘ç©ºé—´ï¼ˆTopological Spaceï¼‰

**å®šä¹‰**ï¼š

ä¸€ä¸ª**æ‹“æ‰‘ç©ºé—´**æ˜¯ä¸€ä¸ªäºŒå…ƒç»„ (X, ğ’¯)ï¼Œå…¶ä¸­ï¼š

- X æ˜¯ä¸€ä¸ªé›†åˆ
- ğ’¯ âŠ† 2^X æ˜¯å¼€é›†æ—ï¼Œæ»¡è¶³ï¼š
  1. âˆ…, X âˆˆ ğ’¯
  2. ğ’¯ å¯¹ä»»æ„å¹¶å°é—­
  3. ğ’¯ å¯¹æœ‰é™äº¤å°é—­

**è¿ç»­å‡½æ•°**ï¼š

å‡½æ•° f : X â†’ Y æ˜¯è¿ç»­çš„ï¼Œå¦‚æœ**å¼€é›†çš„åŸåƒæ˜¯å¼€é›†**ï¼š

```text
âˆ€U âˆˆ ğ’¯_Y : fâ»Â¹(U) âˆˆ ğ’¯_X
```

**AIä¸­çš„åº”ç”¨**ï¼š

- åµŒå…¥å‡½æ•° Enc : Î£ â†’ â„áµˆ çš„è¿ç»­æ€§
- å¹³æ»‘çš„è¯­ä¹‰ç©ºé—´

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Topological Space](https://en.wikipedia.org/wiki/Topological_space)
- [Wikipedia: Continuous Function](https://en.wikipedia.org/wiki/Continuous_function)

### 3. æµå½¢ï¼ˆManifoldï¼‰

**å®šä¹‰**ï¼š

ä¸€ä¸ª**dç»´æµå½¢**æ˜¯ä¸€ä¸ªæ‹“æ‰‘ç©ºé—´ Mï¼Œå±€éƒ¨åŒèƒšäº â„áµˆã€‚

**ç›´è§‰**ï¼š

- 1ç»´æµå½¢ï¼šæ›²çº¿ï¼ˆå¦‚åœ†ï¼‰
- 2ç»´æµå½¢ï¼šæ›²é¢ï¼ˆå¦‚çƒé¢ï¼‰
- é«˜ç»´æµå½¢ï¼šé«˜ç»´"æ›²é¢"

**æµå½¢å‡è®¾**ï¼ˆManifold Hypothesisï¼‰ï¼š

> **é«˜ç»´æ•°æ®ï¼ˆå¦‚å›¾åƒã€æ–‡æœ¬ï¼‰å®é™…ä¸Šä½äºä¸€ä¸ªä½ç»´æµå½¢ä¸Šã€‚**

å½¢å¼åŒ–ï¼š

```text
æ•°æ® X âŠ‚ â„á´°  ï¼ˆDå¾ˆå¤§ï¼Œå¦‚10â¶ï¼‰
ä½† X â‰ˆ M  ï¼ˆMæ˜¯dç»´æµå½¢ï¼Œd â‰ª Dï¼‰
```

**ä¾‹å­**ï¼š

- è‡ªç„¶å›¾åƒä¸æ˜¯éšæœºåƒç´ ï¼Œè€Œæ˜¯ä½äºä½ç»´æµå½¢ä¸Š
- è‡ªç„¶è¯­è¨€å¥å­ä¸æ˜¯éšæœºè¯åºåˆ—ï¼Œè€Œæ˜¯ä½äºè¯­ä¹‰æµå½¢ä¸Š

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Manifold](https://en.wikipedia.org/wiki/Manifold)
- [Fefferman et al., 2016](https://www.pnas.org/doi/full/10.1073/pnas.1408993113) - Testing the Manifold Hypothesis

### 4. å¯å¾®ç»“æ„ï¼ˆDifferentiable Structureï¼‰

**å…‰æ»‘æµå½¢**ï¼š

å¦‚æœæµå½¢ä¸Šçš„åæ ‡å˜æ¢éƒ½æ˜¯**å…‰æ»‘çš„**ï¼ˆæ— ç©·æ¬¡å¯å¾®ï¼‰ï¼Œåˆ™ç§°ä¸º**å…‰æ»‘æµå½¢**ã€‚

**åˆ‡ç©ºé—´**ï¼ˆTangent Spaceï¼‰ï¼š

åœ¨æµå½¢ä¸Šçš„ç‚¹ pï¼Œ**åˆ‡ç©ºé—´** T_p M æ˜¯è¯¥ç‚¹çš„æ‰€æœ‰"åˆ‡å‘é‡"çš„é›†åˆã€‚

**æ¢¯åº¦**ï¼š

åœ¨æµå½¢ä¸Šå®šä¹‰å‡½æ•° f : M â†’ â„ï¼Œå…¶**æ¢¯åº¦** âˆ‡f æ˜¯åˆ‡ç©ºé—´ä¸­çš„å‘é‡ï¼ŒæŒ‡å‘ f å¢é•¿æœ€å¿«çš„æ–¹å‘ã€‚

**AIä¸­çš„åº”ç”¨**ï¼š

- æ¢¯åº¦ä¸‹é™ï¼šåœ¨å‚æ•°æµå½¢ä¸Šæ²¿æ¢¯åº¦åæ–¹å‘ç§»åŠ¨
- è‡ªç„¶æ¢¯åº¦ï¼šè€ƒè™‘å‚æ•°æµå½¢çš„å‡ ä½•ç»“æ„

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Differentiable Manifold](https://en.wikipedia.org/wiki/Differentiable_manifold)
- [Amari, 1998](https://ieeexplore.ieee.org/document/661291) - Natural Gradient Works Efficiently in Learning

---

## ä»ç¦»æ•£åˆ°è¿ç»­çš„æ¡¥æ¢

### 1. åµŒå…¥ï¼ˆEmbeddingï¼‰

**å®šä¹‰**ï¼š

**åµŒå…¥**æ˜¯ä¸€ä¸ªå‡½æ•°ï¼š

```text
Enc : Î£ â†’ â„áµˆ
```

å°†ç¦»æ•£ç¬¦å·é›† Î£ æ˜ å°„åˆ°è¿ç»­å‘é‡ç©ºé—´ â„áµˆã€‚

**å…³é”®è¦æ±‚**ï¼š

> **ä¿æŒè¯­ä¹‰ç»“æ„**

å½¢å¼åŒ–ï¼š

```text
Sem(sâ‚, sâ‚‚) â‰ˆ Sim(Enc(sâ‚), Enc(sâ‚‚))
```

å…¶ä¸­ï¼š

- Sem : Î£ Ã— Î£ â†’ [0, 1] æ˜¯è¯­ä¹‰ç›¸ä¼¼åº¦
- Sim : â„áµˆ Ã— â„áµˆ â†’ [0, 1] æ˜¯å‘é‡ç›¸ä¼¼åº¦ï¼ˆå¦‚ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Embedding](https://en.wikipedia.org/wiki/Embedding)

### 2. ç¼–ç -è§£ç æ¡†æ¶ï¼ˆEncoder-Decoderï¼‰

**ç»“æ„**ï¼š

```text
Input â†’ Encoder â†’ Latent Space â†’ Decoder â†’ Output
  â†“        â†“           â†“            â†“          â†“
 ç¦»æ•£     è¿ç»­åŒ–       è¿ç»­         ç¦»æ•£åŒ–     ç¦»æ•£
```

**ç¼–ç å™¨**ï¼ˆEncoderï¼‰ï¼š

```text
Enc : Î£* â†’ â„áµˆ
```

å°†ç¦»æ•£åºåˆ—æ˜ å°„åˆ°è¿ç»­å‘é‡ã€‚

**è§£ç å™¨**ï¼ˆDecoderï¼‰ï¼š

```text
Dec : â„áµˆ â†’ Î£*
```

å°†è¿ç»­å‘é‡æ˜ å°„å›ç¦»æ•£åºåˆ—ã€‚

**ä¾‹å­**ï¼š

- **æœºå™¨ç¿»è¯‘**ï¼š

```text
"Hello" â†’ Enc â†’ ğ’› â†’ Dec â†’ "Bonjour"
```

- **è‡ªç¼–ç å™¨**ï¼ˆAutoencoderï¼‰ï¼š

```text
ğ’™ â†’ Enc â†’ ğ’› â†’ Dec â†’ ğ’™Ì‚
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Autoencoder](https://en.wikipedia.org/wiki/Autoencoder)
- [Wikipedia: Encoder-Decoder](https://en.wikipedia.org/wiki/Autoencoder)

### 3. æ¦‚ç‡æ¡¥æ¥ï¼ˆProbabilistic Bridgeï¼‰

**Softmaxå‡½æ•°**ï¼š

å°†è¿ç»­å‘é‡è½¬æ¢ä¸ºç¦»æ•£æ¦‚ç‡åˆ†å¸ƒï¼š

```text
Softmax(ğ’›)áµ¢ = exp(záµ¢) / âˆ‘â±¼ exp(zâ±¼)
```

**æ€§è´¨**ï¼š

- è¾“å…¥ï¼šğ’› âˆˆ â„|V|ï¼ˆè¿ç»­ï¼‰
- è¾“å‡ºï¼šğ’‘ âˆˆ Î”|V|ï¼ˆç¦»æ•£æ¦‚ç‡å•çº¯å½¢ï¼‰

**åº”ç”¨**ï¼š

- **è¯­è¨€æ¨¡å‹**ï¼š

```text
ğ’‰â‚œ âˆˆ â„áµˆ â†’ Linear â†’ ğ’› âˆˆ â„|V| â†’ Softmax â†’ P(wâ‚œâ‚Šâ‚)
```

- **åˆ†ç±»å™¨**ï¼š

```text
ğ’™ âˆˆ â„áµˆ â†’ Neural Network â†’ ğ’› âˆˆ â„á´· â†’ Softmax â†’ P(y)
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Softmax Function](https://en.wikipedia.org/wiki/Softmax_function)

### 4. é‡‡æ ·ï¼ˆSamplingï¼‰

ä»è¿ç»­æ¦‚ç‡åˆ†å¸ƒç”Ÿæˆç¦»æ•£æ ·æœ¬ï¼š

**æ–¹æ³•**ï¼š

1. **åˆ†ç±»åˆ†å¸ƒé‡‡æ ·**ï¼š

    ```text
    ç»™å®š P(wâ‚), ..., P(w|V|)
    é‡‡æ · w ~ Categorical(P)
    ```

2. **Top-k é‡‡æ ·**ï¼š

    ```text
    åªä»æ¦‚ç‡æœ€é«˜çš„ k ä¸ªè¯ä¸­é‡‡æ ·
    ```

3. **Nucleus (Top-p) é‡‡æ ·**ï¼š

    ```text
    ä»ç´¯ç§¯æ¦‚ç‡è¾¾åˆ° p çš„æœ€å°è¯é›†ä¸­é‡‡æ ·
    ```

4. **æ¸©åº¦é‡‡æ ·**ï¼š

    ```text
    Softmax(ğ’›/T)  ï¼ˆTæ˜¯æ¸©åº¦å‚æ•°ï¼‰
    ```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Holtzman et al., 2019](https://arxiv.org/abs/1904.09751) - The Curious Case of Neural Text Degeneration

---

## è¿ç»­è¡¨ç¤ºçš„ä¼˜åŠ¿

### 1. æ³›åŒ–èƒ½åŠ›ï¼ˆGeneralizationï¼‰

**å…³é”®ä¼˜åŠ¿**ï¼š

> **è¿ç»­è¡¨ç¤ºè‡ªç„¶æ”¯æŒæ³›åŒ–ï¼šç›¸ä¼¼è¾“å…¥äº§ç”Ÿç›¸ä¼¼è¾“å‡ºã€‚**

**æ•°å­¦åŸç†**ï¼š

å¦‚æœ f : â„áµˆ â†’ â„ æ˜¯è¿ç»­å‡½æ•°ï¼Œåˆ™ï¼š

```text
xâ‚ â‰ˆ xâ‚‚  â‡’  f(xâ‚) â‰ˆ f(xâ‚‚)
```

**å¯¹æ¯”**ï¼š

- **ç¦»æ•£**ï¼š

```text
input = "cat"  â†’ output = "animal"
input = "catt" â†’ output = ???  ï¼ˆæ— æ³•å¤„ç†æ‹¼å†™é”™è¯¯ï¼‰
```

- **è¿ç»­**ï¼š

```text
vec("cat") â‰ˆ vec("catt")  ï¼ˆæ‹¼å†™é”™è¯¯ï¼‰
â‡’ f(vec("cat")) â‰ˆ f(vec("catt"))
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Bengio et al., 2013](https://arxiv.org/abs/1206.5533) - Representation Learning

### 2. å¹³æ»‘æ€§ï¼ˆSmoothnessï¼‰

**å®šä¹‰**ï¼š

å‡½æ•° f æ˜¯**å¹³æ»‘çš„**ï¼Œå¦‚æœï¼š

```text
â€–f(x + Î”x) - f(x)â€– â‰¤ L â€–Î”xâ€–
```

å¯¹æŸä¸ªå¸¸æ•° Lï¼ˆLipschitzå¸¸æ•°ï¼‰ã€‚

**ä¼˜åŠ¿**ï¼š

- âœ… **ç¨³å®š**ï¼šå¾®å°æ‰°åŠ¨ä¸ä¼šå¯¼è‡´å‰§çƒˆå˜åŒ–
- âœ… **å¯ä¼˜åŒ–**ï¼šæ¢¯åº¦ä¸‹é™æœ‰æ•ˆ
- âœ… **é²æ£’**ï¼šå¯¹å™ªå£°ä¸æ•æ„Ÿ

**å¯¹æ¯”**ï¼š

- **ç¦»æ•£å‡½æ•°**ï¼šå¯èƒ½æœ‰ä¸è¿ç»­è·³è·ƒ
- **è¿ç»­å‡½æ•°**ï¼šå¹³æ»‘è¿‡æ¸¡

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Lipschitz Continuity](https://en.wikipedia.org/wiki/Lipschitz_continuity)

### 3. æ’å€¼ä¸å¤–æ¨ï¼ˆInterpolation & Extrapolationï¼‰

#### æ’å€¼

åœ¨å·²çŸ¥ç‚¹ä¹‹é—´**å¹³æ»‘è¿‡æ¸¡**ï¼š

```text
å·²çŸ¥ï¼švec(cat), vec(tiger)
æ’å€¼ï¼švec(???) = 0.5 * vec(cat) + 0.5 * vec(tiger)
```

**å‡ ä½•æ„ä¹‰**ï¼šåœ¨ä¸¤ç‚¹é—´çš„çº¿æ®µä¸Šé‡‡æ ·ã€‚

#### å¤–æ¨

è¶…è¶Šå·²çŸ¥æ•°æ®èŒƒå›´**æ¨æµ‹**ï¼š

```text
vec(super_cat) = 2 * vec(cat) - vec(kitten)
```

**é£é™©**ï¼šå¤–æ¨å¯èƒ½ä¸å¯é ï¼ˆç¦»å¼€æ•°æ®æµå½¢ï¼‰ã€‚

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Interpolation](https://en.wikipedia.org/wiki/Interpolation)
- [Wikipedia: Extrapolation](https://en.wikipedia.org/wiki/Extrapolation)

### 4. ç»„åˆæ€§ï¼ˆCompositionalityï¼‰

**å‘é‡åŠ æ³•çš„è¯­ä¹‰ç»„åˆ**ï¼š

ç»å…¸ä¾‹å­ï¼š

```text
vec(king) - vec(man) + vec(woman) â‰ˆ vec(queen)
```

**ä¸€èˆ¬å½¢å¼**ï¼š

```text
vec(A + property) â‰ˆ vec(A) + vec(property)
```

**æ•°å­¦åŸºç¡€**ï¼š

- **å‘é‡ç©ºé—´çš„çº¿æ€§ç»“æ„**æ”¯æŒç»„åˆè¿ç®—
- **è¯­ä¹‰çš„çº¿æ€§è¿‘ä¼¼**ï¼ˆå±€éƒ¨çº¿æ€§ï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Mikolov et al., 2013](https://arxiv.org/abs/1301.3781) - Linguistic Regularities in Continuous Space

---

## è¿ç»­è¡¨ç¤ºçš„å­¦ä¹ ç†è®º

### 1. è¡¨ç¤ºå­¦ä¹ ï¼ˆRepresentation Learningï¼‰

**ç›®æ ‡**ï¼š

å­¦ä¹ ä¸€ä¸ªå¥½çš„è¡¨ç¤º ğ’‰ = Enc(ğ’™)ï¼Œä½¿å¾—ï¼š

1. **ä¸‹æ¸¸ä»»åŠ¡å®¹æ˜“**ï¼š

    ```text
    ç»™å®š ğ’‰ï¼Œé¢„æµ‹ y æ˜¯ç®€å•çš„ï¼ˆå¦‚çº¿æ€§åˆ†ç±»å™¨ï¼‰
    ```

2. **ä¿¡æ¯ä¿ç•™**ï¼š

    ```text
    ğ’‰ ä¿ç•™äº† ğ’™ ä¸­çš„ç›¸å…³ä¿¡æ¯
    ```

3. **ä¸å˜æ€§**ï¼š

    ```text
    ğ’‰ å¯¹ä¸ç›¸å…³å˜åŒ–ä¸æ•æ„Ÿ
    ```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Bengio et al., 2013](https://arxiv.org/abs/1206.5533) - Representation Learning: A Review and New Perspectives

### 2. æµå½¢å­¦ä¹ ï¼ˆManifold Learningï¼‰

**å‡è®¾**ï¼š

æ•°æ®ä½äºé«˜ç»´ç©ºé—´ä¸­çš„**ä½ç»´æµå½¢**ä¸Šã€‚

**ç›®æ ‡**ï¼š

å­¦ä¹ åµŒå…¥ Enc : â„á´° â†’ â„áµˆ ï¼ˆd â‰ª Dï¼‰ï¼Œä¿æŒæµå½¢ç»“æ„ã€‚

**æ–¹æ³•**ï¼š

1. **çº¿æ€§æ–¹æ³•**ï¼š
   - PCAï¼ˆä¸»æˆåˆ†åˆ†æï¼‰
   - MDSï¼ˆå¤šç»´ç¼©æ”¾ï¼‰

2. **éçº¿æ€§æ–¹æ³•**ï¼š
   - Isomap
   - Locally Linear Embedding (LLE)
   - t-SNE
   - UMAP

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Manifold Learning](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction)
- [van der Maaten & Hinton, 2008](https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf) - Visualizing Data using t-SNE

### 3. åº¦é‡å­¦ä¹ ï¼ˆMetric Learningï¼‰

**ç›®æ ‡**ï¼š

å­¦ä¹ ä¸€ä¸ª**åº¦é‡å‡½æ•°** d : â„áµˆ Ã— â„áµˆ â†’ â„â‚Šï¼Œä½¿å¾—ï¼š

```text
è¯­ä¹‰ç›¸ä¼¼ â‡’ è·ç¦»å°
è¯­ä¹‰ä¸åŒ â‡’ è·ç¦»å¤§
```

**æ–¹æ³•**ï¼š

1. **å¯¹æ¯”å­¦ä¹ **ï¼ˆContrastive Learningï¼‰ï¼š

    ```text
    L = âˆ‘ [ d(xáµ¢, xáµ¢âº)Â² + max(0, m - d(xáµ¢, xáµ¢â»))Â² ]
    ```

    - xáµ¢âºï¼šæ­£æ ·æœ¬ï¼ˆç›¸ä¼¼ï¼‰
    - xáµ¢â»ï¼šè´Ÿæ ·æœ¬ï¼ˆä¸ç›¸ä¼¼ï¼‰
    - mï¼šè¾¹ç•Œ

2. **ä¸‰å…ƒç»„æŸå¤±**ï¼ˆTriplet Lossï¼‰ï¼š

    ```text
    L = âˆ‘ max(0, d(a, p) - d(a, n) + m)
    ```

    - aï¼šé”šç‚¹
    - pï¼šæ­£æ ·æœ¬
    - nï¼šè´Ÿæ ·æœ¬

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Metric Learning](https://en.wikipedia.org/wiki/Similarity_learning)
- [Schroff et al., 2015](https://arxiv.org/abs/1503.03832) - FaceNet: A Unified Embedding for Face Recognition

### 4. è‡ªç›‘ç£å­¦ä¹ ï¼ˆSelf-Supervised Learningï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼š

ä»æ•°æ®æœ¬èº«æ„é€ ç›‘ç£ä¿¡å·ï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚

**æ–¹æ³•**ï¼š

1. **é¢„æµ‹ä¸Šä¸‹æ–‡**ï¼š

    ```text
    ç»™å®šä¸­å¿ƒè¯ï¼Œé¢„æµ‹å‘¨å›´è¯ï¼ˆWord2Vecï¼‰
    ```

2. **æ©ç é¢„æµ‹**ï¼š

    ```text
    ç»™å®š [MASK] ä¸Šä¸‹æ–‡ï¼Œé¢„æµ‹è¢«æ©ç›–çš„è¯ï¼ˆBERTï¼‰
    ```

3. **å¯¹æ¯”å­¦ä¹ **ï¼š

    ```text
    åŒä¸€æ ·æœ¬çš„ä¸åŒè§†å›¾åº”è¯¥ç›¸ä¼¼ï¼ˆSimCLRï¼‰
    ```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Self-Supervised Learning](https://en.wikipedia.org/wiki/Self-supervised_learning)
- [Chen et al., 2020](https://arxiv.org/abs/2002.05709) - A Simple Framework for Contrastive Learning of Visual Representations

---

## å¯å¾®æ€§ä¸ä¼˜åŒ–

### 1. å¯å¾®æ€§çš„é‡è¦æ€§

**å®šä¹‰**ï¼š

å‡½æ•° f : â„áµˆ â†’ â„ åœ¨ç‚¹ ğ’™ å¤„**å¯å¾®**ï¼Œå¦‚æœå­˜åœ¨çº¿æ€§æ˜ å°„ Df(ğ’™)ï¼ˆå¯¼æ•°ï¼‰ï¼Œä½¿å¾—ï¼š

```text
f(ğ’™ + ğœ¹) = f(ğ’™) + Df(ğ’™)[ğœ¹] + o(â€–ğœ¹â€–)
```

**æ¢¯åº¦**ï¼š

```text
âˆ‡f(ğ’™) = [âˆ‚f/âˆ‚xâ‚, ..., âˆ‚f/âˆ‚xâ‚]áµ€
```

**ä¸ºä»€ä¹ˆé‡è¦**ï¼š

> **å¯å¾®æ€§ä½¿å¾—æˆ‘ä»¬å¯ä»¥ç”¨æ¢¯åº¦ä¸‹é™ç­‰ä¼˜åŒ–ç®—æ³•æ¥å­¦ä¹ å‚æ•°ã€‚**

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Differentiable Function](https://en.wikipedia.org/wiki/Differentiable_function)
- [Wikipedia: Gradient](https://en.wikipedia.org/wiki/Gradient)

### 2. æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰

**åŸºæœ¬ç®—æ³•**ï¼š

```text
Î¸ â† Î¸ - Î· âˆ‡L(Î¸)
```

å…¶ä¸­ï¼š

- Î¸ï¼šå‚æ•°
- Î·ï¼šå­¦ä¹ ç‡
- L(Î¸)ï¼šæŸå¤±å‡½æ•°

**å˜ä½“**ï¼š

1. **éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰**ï¼š

    ```text
    Î¸ â† Î¸ - Î· âˆ‡L_i(Î¸)  ï¼ˆä½¿ç”¨å•ä¸ªæ ·æœ¬ï¼‰
    ```

2. **å°æ‰¹é‡SGD**ï¼š

    ```text
    Î¸ â† Î¸ - Î· (1/B) âˆ‘áµ¢âˆˆB âˆ‡L_i(Î¸)
    ```

3. **åŠ¨é‡æ³•**ï¼ˆMomentumï¼‰ï¼š

    ```text
    v â† Î² v + âˆ‡L(Î¸)
    Î¸ â† Î¸ - Î· v
    ```

4. **Adam**ï¼š

    ```text
    m â† Î²â‚ m + (1-Î²â‚) âˆ‡L(Î¸)
    v â† Î²â‚‚ v + (1-Î²â‚‚) (âˆ‡L(Î¸))Â²
    Î¸ â† Î¸ - Î· m/âˆš(v + Îµ)
    ```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent)
- [Wikipedia: Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)
- [Kingma & Ba, 2014](https://arxiv.org/abs/1412.6980) - Adam: A Method for Stochastic Optimization

### 3. åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼š

åˆ©ç”¨**é“¾å¼æ³•åˆ™**é«˜æ•ˆè®¡ç®—ç¥ç»ç½‘ç»œçš„æ¢¯åº¦ã€‚

**é“¾å¼æ³•åˆ™**ï¼š

```text
âˆ‚L/âˆ‚Î¸ = (âˆ‚L/âˆ‚z) (âˆ‚z/âˆ‚Î¸)
```

**è®¡ç®—å›¾**ï¼š

```text
Input â†’ Layer1 â†’ Layer2 â†’ ... â†’ Output â†’ Loss
  â†“        â†“        â†“              â†“        â†“
  Î¸â‚       Î¸â‚‚       Î¸â‚ƒ             Î¸â‚™       L

åå‘ä¼ æ’­ï¼š
  L â† âˆ‚L/âˆ‚output â† âˆ‚L/âˆ‚Layer2 â† ... â† âˆ‚L/âˆ‚Î¸
```

**å¤æ‚åº¦**ï¼š

- å‰å‘ä¼ æ’­ï¼šO(|E|)  ï¼ˆEæ˜¯è¾¹æ•°ï¼‰
- åå‘ä¼ æ’­ï¼šO(|E|)  ï¼ˆç›¸åŒï¼ï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Backpropagation](https://en.wikipedia.org/wiki/Backpropagation)
- [Rumelhart et al., 1986](https://www.nature.com/articles/323533a0) - Learning Representations by Back-Propagating Errors

### 4. è‡ªåŠ¨å¾®åˆ†ï¼ˆAutomatic Differentiationï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼š

è‡ªåŠ¨è®¡ç®—ä»»æ„è®¡ç®—å›¾çš„æ¢¯åº¦ï¼Œæ— éœ€æ‰‹å·¥æ¨å¯¼ã€‚

**æ¨¡å¼**ï¼š

1. **å‰å‘æ¨¡å¼**ï¼ˆForward Modeï¼‰ï¼š

    ```text
    è®¡ç®— âˆ‚y/âˆ‚xâ‚
    ```

2. **åå‘æ¨¡å¼**ï¼ˆReverse Modeï¼‰ï¼š

    ```text
    è®¡ç®— âˆ‚L/âˆ‚Î¸â‚, ..., âˆ‚L/âˆ‚Î¸â‚™  ï¼ˆç¥ç»ç½‘ç»œå¸¸ç”¨ï¼‰
    ```

**ç°ä»£æ¡†æ¶**ï¼š

- PyTorchï¼štorch.autograd
- TensorFlowï¼štf.GradientTape
- JAXï¼šjax.grad

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Automatic Differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation)
- [Baydin et al., 2018](https://arxiv.org/abs/1502.05767) - Automatic Differentiation in Machine Learning: a Survey

---

## è¿ç»­è¡¨ç¤ºçš„å±€é™æ€§

### 1. ç²¾ç¡®æ€§ä¸§å¤±ï¼ˆLoss of Precisionï¼‰

**é—®é¢˜**ï¼š

è¿ç»­è¡¨ç¤ºæ˜¯**è¿‘ä¼¼çš„**ï¼Œå¤±å»äº†ç¦»æ•£ç¬¦å·çš„ç²¾ç¡®æ€§ã€‚

**ä¾‹å­**ï¼š

```text
ç¬¦å·ï¼š2 + 2 = 4  ï¼ˆç²¾ç¡®ï¼‰
å‘é‡ï¼švec(2) + vec(2) â‰ˆ vec(4)  ï¼ˆè¿‘ä¼¼ï¼‰
```

**åæœ**ï¼š

- âŒ é€»è¾‘æ¨ç†å¯èƒ½å‡ºé”™
- âŒ ä¸é€‚åˆéœ€è¦ç²¾ç¡®ç­”æ¡ˆçš„ä»»åŠ¡ï¼ˆå¦‚ç®—æœ¯ï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Marcus, 2020](https://arxiv.org/abs/2002.06177) - The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence

### 2. ç»´åº¦ç¾éš¾ï¼ˆCurse of Dimensionalityï¼‰

**é—®é¢˜**ï¼š

é«˜ç»´ç©ºé—´ä¸­çš„è·ç¦»åº¦é‡å˜å¾—**ä¸å¯é **ã€‚

**ç°è±¡**ï¼š

åœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œæ‰€æœ‰ç‚¹å¯¹ä¹‹é—´çš„è·ç¦»è¶‹äºç›¸ç­‰ï¼š

```text
max_dist / min_dist â†’ 1  ï¼ˆå½“ d â†’ âˆï¼‰
```

**åæœ**ï¼š

- âŒ æœ€è¿‘é‚»æœç´¢æ•ˆç‡ä½ä¸‹
- âŒ ç›¸ä¼¼åº¦åº¦é‡å¤±æ•ˆ

**ç¼“è§£æ–¹æ³•**ï¼š

- é™ç»´
- å±€éƒ¨æ•æ„Ÿå“ˆå¸Œï¼ˆLSHï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Curse of Dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality)
- [Beyer et al., 1999](https://link.springer.com/chapter/10.1007/3-540-49257-7_15) - When Is "Nearest Neighbor" Meaningful?

### 3. ä¸å¯è§£é‡Šæ€§ï¼ˆLack of Interpretabilityï¼‰

**é—®é¢˜**ï¼š

å‘é‡çš„å„ä¸ªç»´åº¦**æ²¡æœ‰æ˜ç¡®è¯­ä¹‰**ã€‚

**ä¾‹å­**ï¼š

```text
vec(cat)[42] = 0.73  â† è¿™ä»£è¡¨ä»€ä¹ˆï¼Ÿ
```

**å¯¹æ¯”**ï¼š

- **ç¬¦å·**ï¼šis-a(cat, animal)  ï¼ˆæ¸…æ™°ï¼‰
- **å‘é‡**ï¼šcos(vec(cat), vec(animal)) = 0.78  ï¼ˆæ¨¡ç³Šï¼‰

**å°è¯•**ï¼š

- å¯è§£é‡Šç»´åº¦ï¼ˆä½†ä¸å¯é ï¼‰
- æ¢æµ‹ä»»åŠ¡ï¼ˆProbingï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Lipton, 2018](https://arxiv.org/abs/1606.03490) - The Mythos of Model Interpretability

### 4. èµ„æºæ¶ˆè€—ï¼ˆResource Consumptionï¼‰

**é—®é¢˜**ï¼š

é«˜ç»´å‘é‡çš„**å­˜å‚¨å’Œè®¡ç®—æˆæœ¬**é«˜æ˜‚ã€‚

| æ“ä½œ | å¤æ‚åº¦ | åœºæ™¯ |
|------|--------|------|
| å­˜å‚¨ä¸€ä¸ªå‘é‡ | O(d) | d=768, éœ€è¦3KBï¼ˆFP32ï¼‰ |
| å‘é‡ç‚¹ç§¯ | O(d) | ç›¸ä¼¼åº¦è®¡ç®— |
| çŸ©é˜µä¹˜æ³• | O(nÂ²d) | Transformeræ³¨æ„åŠ› |
| æœ€è¿‘é‚»æœç´¢ | O(Nd) | æ£€ç´¢ç³»ç»Ÿ |

**ç¼“è§£æ–¹æ³•**ï¼š

- é‡åŒ–ï¼ˆQuantizationï¼‰
- ç¨€ç–åŒ–ï¼ˆSparsificationï¼‰
- çŸ¥è¯†è’¸é¦ï¼ˆKnowledge Distillationï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Han et al., 2015](https://arxiv.org/abs/1510.00149) - Deep Compression

---

## æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **èŒƒå¼è½¬æ¢**ï¼šä»ç¦»æ•£ç¬¦å·åˆ°è¿ç»­å‘é‡
2. **æ•°å­¦åŸºç¡€**ï¼šåº¦é‡ç©ºé—´ã€æ‹“æ‰‘ç©ºé—´ã€æµå½¢
3. **æ¡¥æ¥æœºåˆ¶**ï¼šåµŒå…¥ã€ç¼–ç -è§£ç ã€Softmaxã€é‡‡æ ·
4. **ä¼˜åŠ¿**ï¼šæ³›åŒ–ã€å¹³æ»‘ã€æ’å€¼ã€ç»„åˆ
5. **å­¦ä¹ ç†è®º**ï¼šè¡¨ç¤ºå­¦ä¹ ã€æµå½¢å­¦ä¹ ã€åº¦é‡å­¦ä¹ ã€è‡ªç›‘ç£å­¦ä¹ 
6. **ä¼˜åŒ–**ï¼šå¯å¾®æ€§ã€æ¢¯åº¦ä¸‹é™ã€åå‘ä¼ æ’­ã€è‡ªåŠ¨å¾®åˆ†
7. **å±€é™æ€§**ï¼šç²¾ç¡®æ€§ä¸§å¤±ã€ç»´åº¦ç¾éš¾ã€ä¸å¯è§£é‡Šã€èµ„æºæ¶ˆè€—

### å“²å­¦åæ€

> **è¿ç»­è¡¨ç¤ºæ˜¯å¯¹ç¦»æ•£ä¸–ç•Œçš„ä¸€ç§"è½¯åŒ–"ï¼ˆSofteningï¼‰ï¼šå®ƒç”¨æ¦‚ç‡å’Œè¿‘ä¼¼æ›¿ä»£äº†ç¡®å®šæ€§å’Œç²¾ç¡®æ€§ï¼Œç”¨å‡ ä½•å’Œæ‹“æ‰‘æ›¿ä»£äº†é€»è¾‘å’Œç¬¦å·ã€‚è¿™ç§è½¬æ¢æ—¢å¸¦æ¥äº†å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¹Ÿå¼•å…¥äº†æ–°çš„æŒ‘æˆ˜ã€‚**

### æœªæ¥æ–¹å‘

1. **æ··åˆç³»ç»Ÿ**ï¼šç»“åˆç¬¦å·å’Œè¿ç»­è¡¨ç¤ºçš„ä¼˜åŠ¿
2. **å‡ ä½•æ·±åº¦å­¦ä¹ **ï¼šåˆ©ç”¨æ•°æ®çš„å‡ ä½•å’Œæ‹“æ‰‘ç»“æ„
3. **å¯è§£é‡Šè¿ç»­è¡¨ç¤º**ï¼šè®©å‘é‡ç»´åº¦å…·æœ‰æ˜ç¡®è¯­ä¹‰
4. **é«˜æ•ˆè¡¨ç¤º**ï¼šé™ä½ç»´åº¦å’Œè®¡ç®—æˆæœ¬

---

## å‚è€ƒæ–‡çŒ®

### åŸºç¡€ç†è®º

1. [Wikipedia: Representation Learning](https://en.wikipedia.org/wiki/Feature_learning)
2. [Bengio et al., 2013](https://arxiv.org/abs/1206.5533) - Representation Learning: A Review and New Perspectives
3. [Goodfellow et al., 2016](https://www.deeplearningbook.org/) - Deep Learning

### æ•°å­¦åŸºç¡€

1. [Wikipedia: Metric Space](https://en.wikipedia.org/wiki/Metric_space)
2. [Wikipedia: Topological Space](https://en.wikipedia.org/wiki/Topological_space)
3. [Wikipedia: Manifold](https://en.wikipedia.org/wiki/Manifold)
4. [Wikipedia: Differentiable Manifold](https://en.wikipedia.org/wiki/Differentiable_manifold)

### æµå½¢å­¦ä¹ 

1. [Wikipedia: Manifold Learning](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction)
2. [Fefferman et al., 2016](https://www.pnas.org/doi/full/10.1073/pnas.1408993113) - Testing the Manifold Hypothesis
3. [van der Maaten & Hinton, 2008](https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf) - Visualizing Data using t-SNE

### åº¦é‡å­¦ä¹ 

1. [Wikipedia: Metric Learning](https://en.wikipedia.org/wiki/Similarity_learning)
2. [Schroff et al., 2015](https://arxiv.org/abs/1503.03832) - FaceNet: A Unified Embedding for Face Recognition

### ä¼˜åŒ–

1. [Wikipedia: Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent)
2. [Wikipedia: Backpropagation](https://en.wikipedia.org/wiki/Backpropagation)
3. [Wikipedia: Automatic Differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation)
4. [Kingma & Ba, 2014](https://arxiv.org/abs/1412.6980) - Adam: A Method for Stochastic Optimization

### å“²å­¦ä¸æ‰¹è¯„

1. [Marcus, 2020](https://arxiv.org/abs/2002.06177) - The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence
2. [Lipton, 2018](https://arxiv.org/abs/1606.03490) - The Mythos of Model Interpretability

---

*æœ¬æ–‡æ¡£æ·±å…¥æ¢è®¨äº†è¿ç»­è¡¨ç¤ºç†è®ºçš„æ•°å­¦åŸºç¡€ã€å­¦ä¹ æœºåˆ¶å’Œå“²å­¦æ„æ¶µï¼Œä¸ºç†è§£ç°ä»£AIçš„æ ¸å¿ƒèŒƒå¼æä¾›äº†å®Œæ•´çš„ç†è®ºæ¡†æ¶ã€‚*

---

## å¯¼èˆª | Navigation

**ä¸Šä¸€ç¯‡**: [â† 04.1 è¯­ä¹‰å‘é‡ç©ºé—´](./04.1_Semantic_Vector_Spaces.md)  
**ä¸‹ä¸€ç¯‡**: [04.3 åˆ†å¸ƒå¼è¯­ä¹‰ â†’](./04.3_Distributional_Semantics.md)  
**è¿”å›ç›®å½•**: [â†‘ AIæ¨¡å‹è§†è§’æ€»è§ˆ](../README.md)

---

## ç›¸å…³ä¸»é¢˜ | Related Topics

### æœ¬ç« èŠ‚
- [04.1 è¯­ä¹‰å‘é‡ç©ºé—´](./04.1_Semantic_Vector_Spaces.md)
- [04.3 åˆ†å¸ƒå¼è¯­ä¹‰](./04.3_Distributional_Semantics.md)
- [04.4 è¯­ä¹‰ç›¸ä¼¼åº¦åº¦é‡](./04.4_Semantic_Similarity_Metrics.md)
- [04.5 å¤šæ¨¡æ€è¯­ä¹‰æ•´åˆ](./04.5_Multimodal_Semantic_Integration.md)
- [04.6 é»„æ°è¯­ä¹‰æ¨¡å‹åˆ†æ](./04.6_Huang_Semantic_Model_Analysis.md)

### ç›¸å…³ç« èŠ‚
- [02.5 é€šç”¨é€¼è¿‘å®šç†](../02_Neural_Network_Theory/02.5_Universal_Approximation_Theorem.md)
- [03.2 ç¥ç»è¯­è¨€æ¨¡å‹](../03_Language_Models/03.2_Neural_Language_Models.md)

### è·¨è§†è§’é“¾æ¥
- [FormalLanguage_Perspective](../../FormalLanguage_Perspective/README.md)
- [Information_Theory_Perspective](../../Information_Theory_Perspective/README.md)