# å¤šæ¨¡æ€è¯­ä¹‰æ•´åˆï¼ˆMultimodal Semantic Integration)

## ç›®å½•

- [å¼•è¨€](#å¼•è¨€)
- [å¤šæ¨¡æ€å­¦ä¹ çš„ç†è®ºåŸºç¡€](#å¤šæ¨¡æ€å­¦ä¹ çš„ç†è®ºåŸºç¡€)
- [å¤šæ¨¡æ€è¡¨ç¤ºå­¦ä¹ ](#å¤šæ¨¡æ€è¡¨ç¤ºå­¦ä¹ )
- [è·¨æ¨¡æ€å¯¹é½](#è·¨æ¨¡æ€å¯¹é½)
- [å¤šæ¨¡æ€èåˆç­–ç•¥](#å¤šæ¨¡æ€èåˆç­–ç•¥)
- [ä¸»è¦å¤šæ¨¡æ€æ¶æ„](#ä¸»è¦å¤šæ¨¡æ€æ¶æ„)
- [å¤šæ¨¡æ€é¢„è®­ç»ƒæ¨¡å‹](#å¤šæ¨¡æ€é¢„è®­ç»ƒæ¨¡å‹)
- [å¤šæ¨¡æ€åº”ç”¨åœºæ™¯](#å¤šæ¨¡æ€åº”ç”¨åœºæ™¯)
- [æŒ‘æˆ˜ä¸å±€é™æ€§](#æŒ‘æˆ˜ä¸å±€é™æ€§)
- [æ€»ç»“](#æ€»ç»“)
- [å‚è€ƒæ–‡çŒ®](#å‚è€ƒæ–‡çŒ®)

---

## å¼•è¨€

**å¤šæ¨¡æ€è¯­ä¹‰æ•´åˆ**ï¼ˆMultimodal Semantic Integrationï¼‰æ˜¯æŒ‡å°†æ¥è‡ªä¸åŒæ„ŸçŸ¥æ¨¡æ€ï¼ˆæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ç­‰ï¼‰çš„ä¿¡æ¯èåˆåˆ°ç»Ÿä¸€çš„è¯­ä¹‰è¡¨ç¤ºä¸­ã€‚

### æ ¸å¿ƒåŠ¨æœº

**äººç±»è®¤çŸ¥æ˜¯å¤šæ¨¡æ€çš„**ï¼š

> **æˆ‘ä»¬é€šè¿‡è§†è§‰ã€å¬è§‰ã€è§¦è§‰ã€è¯­è¨€ç­‰å¤šç§æ„Ÿå®˜ç†è§£ä¸–ç•Œã€‚å•ä¸€æ¨¡æ€çš„ä¿¡æ¯å¾€å¾€ä¸å®Œæ•´ã€æœ‰æ­§ä¹‰ã€‚**

**ä¾‹å­**ï¼š

```text
æ–‡æœ¬ï¼š"ä¸€åªçŒ«"  ï¼ˆæ¨¡ç³Šï¼‰
å›¾åƒï¼š[çŒ«çš„å›¾ç‰‡]  ï¼ˆå…·ä½“ï¼‰
æ–‡æœ¬+å›¾åƒï¼šç²¾ç¡®ã€æ— æ­§ä¹‰çš„ç†è§£
```

### å…³é”®æŒ‘æˆ˜

1. **å¼‚è´¨æ€§**ï¼ˆHeterogeneityï¼‰ï¼šä¸åŒæ¨¡æ€çš„æ•°æ®ç»“æ„å®Œå…¨ä¸åŒ
   - æ–‡æœ¬ï¼šç¦»æ•£ç¬¦å·åºåˆ—
   - å›¾åƒï¼šåƒç´ çŸ©é˜µ
   - éŸ³é¢‘ï¼šæ³¢å½¢/é¢‘è°±

2. **è¯­ä¹‰é¸¿æ²Ÿ**ï¼ˆSemantic Gapï¼‰ï¼šä½å±‚ç‰¹å¾ â†’ é«˜å±‚è¯­ä¹‰

3. **å¯¹é½é—®é¢˜**ï¼ˆAlignmentï¼‰ï¼šå¦‚ä½•å»ºç«‹è·¨æ¨¡æ€çš„è¯­ä¹‰å¯¹åº”

4. **èåˆç­–ç•¥**ï¼ˆFusionï¼‰ï¼šå¦‚ä½•æœ‰æ•ˆç»„åˆå¤šæ¨¡æ€ä¿¡æ¯

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Multimodal Learning](https://en.wikipedia.org/wiki/Multimodal_learning)
- [BaltruÅ¡aitis et al., 2019](https://arxiv.org/abs/1705.09406) - Multimodal Machine Learning: A Survey and Taxonomy

---

## å¤šæ¨¡æ€å­¦ä¹ çš„ç†è®ºåŸºç¡€

### 1. å¤šæ¨¡æ€çš„è®¤çŸ¥ç§‘å­¦åŸºç¡€

#### å¤šæ„Ÿå®˜æ•´åˆï¼ˆMultisensory Integrationï¼‰

**ç¥ç»ç§‘å­¦å‘ç°**ï¼š

- å¤§è„‘ä¸åŒåŒºåŸŸå¤„ç†ä¸åŒæ„Ÿå®˜è¾“å…¥
- å­˜åœ¨**å¤šæ„Ÿå®˜æ•´åˆåŒº**ï¼ˆå¦‚ä¸Šé¢æ²Ÿï¼‰èåˆä¿¡æ¯

**McGurkæ•ˆåº”**ï¼š

```text
å¬è§‰ï¼š"ba"
è§†è§‰ï¼šå˜´å‹è¯´"ga"
æ„ŸçŸ¥ç»“æœï¼š"da"  ï¼ˆèåˆåçš„äº§ç‰©ï¼‰
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Multisensory Integration](https://en.wikipedia.org/wiki/Multisensory_integration)
- [McGurk & MacDonald, 1976](https://www.nature.com/articles/264746a0) - Hearing Lips and Seeing Voices

#### åŒé‡ç¼–ç ç†è®ºï¼ˆDual Coding Theoryï¼‰

**Allan Paivio** æå‡ºï¼š

> **äººç±»è®¤çŸ¥æœ‰ä¸¤ä¸ªç‹¬ç«‹ä½†ç›¸äº’å…³è”çš„ç³»ç»Ÿï¼š**
>
> 1. **è¯­è¨€ç³»ç»Ÿ**ï¼šå¤„ç†è¯­è¨€ä¿¡æ¯
> 2. **éè¯­è¨€ç³»ç»Ÿ**ï¼šå¤„ç†å›¾åƒã€æ„ŸçŸ¥ä¿¡æ¯

**æ¨è®º**ï¼š

- å¤šæ¨¡æ€ä¿¡æ¯æ›´å®¹æ˜“è®°å¿†å’Œç†è§£
- å›¾æ–‡ç»“åˆä¼˜äºçº¯æ–‡æœ¬

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Dual Coding Theory](https://en.wikipedia.org/wiki/Dual-coding_theory)
- [Paivio, 1971](https://psycnet.apa.org/record/1972-21472-000) - Imagery and Verbal Processes

### 2. ç»Ÿä¸€è¯­ä¹‰ç©ºé—´å‡è®¾

**æ ¸å¿ƒå‡è®¾**ï¼š

> **ä¸åŒæ¨¡æ€çš„ä¿¡æ¯å¯ä»¥æ˜ å°„åˆ°ä¸€ä¸ªç»Ÿä¸€çš„è¯­ä¹‰ç©ºé—´ä¸­ï¼Œåœ¨è¯¥ç©ºé—´ä¸­è¯­ä¹‰ç›¸ä¼¼çš„å¯¹è±¡å½¼æ­¤æ¥è¿‘ã€‚**

**å½¢å¼åŒ–**ï¼š

```text
Text â†’ Enc_text â†’ ğ’› âˆˆ â„áµˆ  ï¼ˆç»Ÿä¸€è¯­ä¹‰ç©ºé—´ï¼‰
Image â†’ Enc_img â†’ ğ’› âˆˆ â„áµˆ
Audio â†’ Enc_audio â†’ ğ’› âˆˆ â„áµˆ

è¯­ä¹‰ç›¸ä¼¼ â‡’ â€–ğ’›â‚ - ğ’›â‚‚â€– å°
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Ngiam et al., 2011](https://icml.cc/2011/papers/399_icmlpaper.pdf) - Multimodal Deep Learning

### 3. äº’è¡¥æ€§ä¸å†—ä½™æ€§

**ä¸¤ç§ä¿¡æ¯å…³ç³»**ï¼š

1. **äº’è¡¥æ€§**ï¼ˆComplementarityï¼‰ï¼š

    ```text
    ä¸åŒæ¨¡æ€æä¾›ä¸åŒçš„ã€äº’è¡¥çš„ä¿¡æ¯
    ä¾‹ï¼šæ–‡æœ¬æè¿°å¯¹è±¡å±æ€§ï¼Œå›¾åƒæ˜¾ç¤ºå¤–è§‚
    ```

2. **å†—ä½™æ€§**ï¼ˆRedundancyï¼‰ï¼š

    ```text
    ä¸åŒæ¨¡æ€ç¼–ç ç›¸åŒçš„ä¿¡æ¯
    ä¾‹ï¼šè§†é¢‘çš„éŸ³é¢‘å’Œç”»é¢éƒ½è¡¨æ˜"çˆ†ç‚¸å‘ç”Ÿ"
    ```

**æœ€ä¼˜ç­–ç•¥**ï¼š

- åˆ©ç”¨**äº’è¡¥æ€§**ï¼šå¢åŠ ä¿¡æ¯é‡
- åˆ©ç”¨**å†—ä½™æ€§**ï¼šæé«˜é²æ£’æ€§ï¼ˆä¸€ä¸ªæ¨¡æ€ç¼ºå¤±æˆ–æœ‰å™ªå£°æ—¶ï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [BaltruÅ¡aitis et al., 2019](https://arxiv.org/abs/1705.09406) - Multimodal Machine Learning: A Survey

---

## å¤šæ¨¡æ€è¡¨ç¤ºå­¦ä¹ 

### 1. è”åˆè¡¨ç¤ºï¼ˆJoint Representationï¼‰

**ç›®æ ‡**ï¼š

å­¦ä¹ ä¸€ä¸ªç»Ÿä¸€çš„å‘é‡ç©ºé—´ï¼ŒåŒæ—¶è¡¨ç¤ºæ‰€æœ‰æ¨¡æ€ã€‚

**æ–¹æ³•**ï¼š

#### æ·±åº¦ç»å°”å…¹æ›¼æœºï¼ˆDeep Boltzmann Machinesï¼‰

**æ—©æœŸæ–¹æ³•**ï¼š

```text
ğ’™_text  â†˜
          â†’ Shared Hidden Layer â†’ ğ’‰
ğ’™_image â†—
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Srivastava & Salakhutdinov, 2012](https://proceedings.neurips.cc/paper/2012/hash/af21d0c97db2e27e13572cbf59eb343d-Abstract.html) - Multimodal Learning with Deep Boltzmann Machines

#### æ·±åº¦ç¥ç»ç½‘ç»œ

**ç°ä»£æ–¹æ³•**ï¼š

```text
Text  â†’ BERT  â†’ ğ’‰_text  â†˜
                           Fusion â†’ ğ’›
Image â†’ ResNet â†’ ğ’‰_img   â†—
```

èåˆå±‚å¯ä»¥æ˜¯ï¼š

- æ‹¼æ¥ï¼ˆConcatenationï¼‰ï¼šğ’› = [ğ’‰_text; ğ’‰_img]
- åŠ æ³•ï¼šğ’› = ğ’‰_text + ğ’‰_img
- é—¨æ§èåˆï¼šğ’› = Î± ğ’‰_text + (1-Î±) ğ’‰_img

### 2. ååŒè¡¨ç¤ºï¼ˆCoordinated Representationï¼‰

**ç›®æ ‡**ï¼š

ä¸ºæ¯ä¸ªæ¨¡æ€å­¦ä¹ ç‹¬ç«‹çš„è¡¨ç¤ºï¼Œä½†é€šè¿‡**çº¦æŸ**ä½¿å®ƒä»¬åœ¨è¯­ä¹‰ç©ºé—´ä¸­å¯¹é½ã€‚

**æ–¹æ³•**ï¼š

#### å…¸å‹ç›¸å…³åˆ†æï¼ˆCanonical Correlation Analysis, CCAï¼‰

**ç›®æ ‡**ï¼š

æ‰¾åˆ°æŠ•å½± W_x, W_yï¼Œä½¿å¾—æŠ•å½±åçš„å‘é‡æœ€å¤§ç›¸å…³ï¼š

```text
max corr(W_x ğ’™, W_y ğ’š)
```

**æ·±åº¦CCA**ï¼š

ç”¨ç¥ç»ç½‘ç»œæ›¿ä»£çº¿æ€§æŠ•å½±ã€‚

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Canonical Correlation Analysis](https://en.wikipedia.org/wiki/Canonical_correlation)
- [Andrew et al., 2013](https://arxiv.org/abs/1304.1914) - Deep Canonical Correlation Analysis

#### å¯¹æ¯”å­¦ä¹ 

**æ ¸å¿ƒæ€æƒ³**ï¼š

æ‹‰è¿‘**åŒ¹é…å¯¹**çš„è¡¨ç¤ºï¼Œæ¨å¼€**ä¸åŒ¹é…å¯¹**çš„è¡¨ç¤ºã€‚

**CLIPçš„æŸå¤±å‡½æ•°**ï¼š

```text
L = -âˆ‘áµ¢ [ log(exp(sim(ğ’—áµ¢_img, ğ’—áµ¢_txt) / Ï„) / âˆ‘â±¼ exp(sim(ğ’—áµ¢_img, ğ’—â±¼_txt) / Ï„)) ]
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Radford et al., 2021](https://arxiv.org/abs/2103.00020) - Learning Transferable Visual Models From Natural Language Supervision

### 3. ç¼–ç å™¨-è§£ç å™¨è¡¨ç¤º

**ç›®æ ‡**ï¼š

ä¸€ä¸ªæ¨¡æ€ä½œä¸ºè¾“å…¥ï¼Œå¦ä¸€ä¸ªæ¨¡æ€ä½œä¸ºè¾“å‡ºã€‚

**ä¾‹å­**ï¼š

#### å›¾åƒæè¿°ç”Ÿæˆï¼ˆImage Captioningï¼‰

```text
Image â†’ CNN â†’ ğ’—_img â†’ LSTM â†’ "A cat sitting on a mat"
```

#### æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆï¼ˆText-to-Imageï¼‰

```text
"A cat sitting on a mat" â†’ Encoder â†’ ğ’› â†’ Decoder â†’ Image
```

**ä»£è¡¨æ¨¡å‹**ï¼š

- DALL-Eã€Stable Diffusionã€Midjourney

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Vinyals et al., 2015](https://arxiv.org/abs/1411.4555) - Show and Tell: A Neural Image Caption Generator
- [Ramesh et al., 2021](https://arxiv.org/abs/2102.12092) - Zero-Shot Text-to-Image Generation (DALL-E)

---

## è·¨æ¨¡æ€å¯¹é½

### 1. æ˜¾å¼å¯¹é½ï¼ˆExplicit Alignmentï¼‰

**å®šä¹‰**ï¼š

æ˜ç¡®å»ºç«‹ä¸åŒæ¨¡æ€å…ƒç´ ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚

**ä¾‹å­**ï¼š

#### å›¾åƒåŒºåŸŸ - æ–‡æœ¬çŸ­è¯­å¯¹é½

```text
Image: [å›¾ç‰‡ä¸­çš„çŒ«]
Text: "a cat sitting on a mat"

å¯¹é½ï¼š
  - å›¾åƒåŒºåŸŸ1ï¼ˆçŒ«ï¼‰ â†” "a cat"
  - å›¾åƒåŒºåŸŸ2ï¼ˆå«å­ï¼‰ â†” "a mat"
```

**æ–¹æ³•ï¼šæ³¨æ„åŠ›æœºåˆ¶**-

```text
Attention(Query, Key, Value)
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Anderson et al., 2018](https://arxiv.org/abs/1707.07998) - Bottom-Up and Top-Down Attention for Image Captioning

### 2. éšå¼å¯¹é½ï¼ˆImplicit Alignmentï¼‰

**å®šä¹‰**ï¼š

é€šè¿‡ç«¯åˆ°ç«¯è®­ç»ƒï¼Œæ¨¡å‹éšå¼åœ°å­¦ä¹ è·¨æ¨¡æ€å¯¹åº”ã€‚

**ä¾‹å­ï¼šTransformerçš„äº¤å‰æ³¨æ„åŠ›**-

```text
Visual Tokens: ğ’—â‚, ..., ğ’—â‚™
Text Tokens: ğ’•â‚, ..., ğ’•â‚˜

CrossAttention(ğ’•áµ¢, {ğ’—â±¼})
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Vaswani et al., 2017](https://arxiv.org/abs/1706.03762) - Attention Is All You Need

### 3. å¯¹é½æŸå¤±

**å¯¹é½ç›®æ ‡**ï¼š

åŒ¹é…å¯¹åº”è¯¥å…·æœ‰é«˜ç›¸ä¼¼åº¦ã€‚

**ä¸‰å…ƒç»„æŸå¤±**ï¼š

```text
L = max(0, d(a, p) - d(a, n) + margin)
```

å…¶ä¸­ï¼š

- aï¼šé”šç‚¹ï¼ˆå¦‚å›¾åƒï¼‰
- pï¼šæ­£æ ·æœ¬ï¼ˆåŒ¹é…çš„æ–‡æœ¬ï¼‰
- nï¼šè´Ÿæ ·æœ¬ï¼ˆä¸åŒ¹é…çš„æ–‡æœ¬ï¼‰

**å¯¹æ¯”æŸå¤±**ï¼š

```text
L = -log(exp(sim(x, yâº)) / âˆ‘_y exp(sim(x, y)))
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Schroff et al., 2015](https://arxiv.org/abs/1503.03832) - FaceNet

---

## å¤šæ¨¡æ€èåˆç­–ç•¥

### 1. æ—©æœŸèåˆï¼ˆEarly Fusionï¼‰

**å®šä¹‰**ï¼š

åœ¨ç‰¹å¾æå–ä¹‹å‰æˆ–ä¹‹åˆå°±èåˆåŸå§‹è¾“å…¥ã€‚

```text
[Image; Text] â†’ Joint Encoder â†’ ğ’›
```

**ä¼˜åŠ¿**ï¼š

- âœ… æ¨¡æ€é—´äº¤äº’æœ€å……åˆ†

**åŠ£åŠ¿**ï¼š

- âŒ éš¾ä»¥åˆ©ç”¨å•æ¨¡æ€é¢„è®­ç»ƒæ¨¡å‹
- âŒ å¯¹å™ªå£°æ•æ„Ÿ

### 2. æ™šæœŸèåˆï¼ˆLate Fusionï¼‰

**å®šä¹‰**ï¼š

æ¯ä¸ªæ¨¡æ€ç‹¬ç«‹ç¼–ç ï¼Œæœ€åèåˆé«˜å±‚è¡¨ç¤ºã€‚

```text
Image â†’ Enc_img â†’ ğ’‰_img â†˜
                           Fusion â†’ ğ’›
Text  â†’ Enc_text â†’ ğ’‰_text â†—
```

**èåˆæ–¹å¼**ï¼š

- æ‹¼æ¥ï¼šğ’› = [ğ’‰_img; ğ’‰_text]
- åŠ æƒå’Œï¼šğ’› = Î± ğ’‰_img + Î² ğ’‰_text
- MLPï¼šğ’› = MLP([ğ’‰_img; ğ’‰_text])

**ä¼˜åŠ¿**ï¼š

- âœ… å¯ä»¥åˆ©ç”¨å•æ¨¡æ€é¢„è®­ç»ƒ
- âœ… æ¨¡å—åŒ–ã€çµæ´»

**åŠ£åŠ¿**ï¼š

- âŒ æ¨¡æ€é—´äº¤äº’ä¸è¶³

### 3. æ··åˆèåˆï¼ˆHybrid Fusionï¼‰

**å®šä¹‰**ï¼š

åœ¨å¤šä¸ªå±‚æ¬¡èåˆã€‚

**ä¾‹å­ï¼šViLBERT**-

```text
Image Stream: ğ’—â‚€ â†’ Layer1 â†’ ğ’—â‚ â†’ Layer2 â†’ ...
                    â†• Cross-Attention â†•
Text Stream:  ğ’•â‚€ â†’ Layer1 â†’ ğ’•â‚ â†’ Layer2 â†’ ...
```

æ¯ä¸€å±‚éƒ½æœ‰è·¨æ¨¡æ€äº¤äº’ã€‚

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Lu et al., 2019](https://arxiv.org/abs/1908.02265) - ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations

### 4. é—¨æ§èåˆï¼ˆGated Fusionï¼‰

**åŠ¨æ€æƒé‡**ï¼š

æ ¹æ®è¾“å…¥åŠ¨æ€å†³å®šæ¯ä¸ªæ¨¡æ€çš„è´¡çŒ®ã€‚

**å…¬å¼**ï¼š

```text
Î± = Ïƒ(W [ğ’‰_img; ğ’‰_text])
ğ’› = Î± âŠ™ ğ’‰_img + (1 - Î±) âŠ™ ğ’‰_text
```

å…¶ä¸­ âŠ™ æ˜¯é€å…ƒç´ ä¹˜æ³•ã€‚

**ä¼˜åŠ¿**ï¼š

- âœ… è‡ªé€‚åº”
- âœ… å¯ä»¥å¤„ç†æ¨¡æ€ç¼ºå¤±

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Arevalo et al., 2017](https://arxiv.org/abs/1702.07826) - Gated Multimodal Units for Information Fusion

---

## ä¸»è¦å¤šæ¨¡æ€æ¶æ„

### 1. è§†è§‰-è¯­è¨€Transformer

#### CLIPï¼ˆContrastive Language-Image Pre-trainingï¼‰

**æ¶æ„**ï¼š

```text
Image â†’ Vision Transformer â†’ ğ’—_img
Text  â†’ Text Transformer   â†’ ğ’—_text

è®­ç»ƒï¼šå¯¹æ¯”å­¦ä¹ ï¼ˆåŒ¹é…çš„å›¾æ–‡å¯¹ç›¸ä¼¼åº¦é«˜ï¼‰
```

**èƒ½åŠ›**ï¼š

- âœ… é›¶æ ·æœ¬å›¾åƒåˆ†ç±»
- âœ… å›¾åƒ-æ–‡æœ¬æ£€ç´¢

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Radford et al., 2021](https://arxiv.org/abs/2103.00020) - CLIP

#### ALIGN

**ä¸CLIPç±»ä¼¼**ï¼Œä½†ï¼š

- ä½¿ç”¨**å™ªå£°æ›´å¤š**çš„æ•°æ®ï¼ˆä»ç½‘ç»œçˆ¬å–ï¼‰
- è§„æ¨¡æ›´å¤§ï¼ˆ18äº¿å›¾æ–‡å¯¹ vs CLIPçš„4äº¿ï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Jia et al., 2021](https://arxiv.org/abs/2102.05918) - Scaling Up Visual and Vision-Language Representation Learning

### 2. ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹

#### Flamingo

**æ¶æ„**ï¼š

```text
Vision Encoder (é¢„è®­ç»ƒï¼Œå†»ç»“)
    â†“
Perceiver Resamplerï¼ˆå‹ç¼©è§†è§‰tokenï¼‰
    â†“
Language Modelï¼ˆäº¤é”™æ’å…¥è§†è§‰tokenï¼‰
```

**èƒ½åŠ›**ï¼š

- âœ… Few-shotå­¦ä¹ 
- âœ… å¤šè½®å¯¹è¯ï¼ˆå¸¦å›¾åƒï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Alayrac et al., 2022](https://arxiv.org/abs/2204.14198) - Flamingo: a Visual Language Model for Few-Shot Learning

#### GPT-4Vï¼ˆGPT-4 with Visionï¼‰

**OpenAIçš„å¤šæ¨¡æ€å¤§æ¨¡å‹**ï¼š

- æ¥å—å›¾åƒå’Œæ–‡æœ¬è¾“å…¥
- ç”Ÿæˆæ–‡æœ¬è¾“å‡º

**èƒ½åŠ›**ï¼š

- âœ… å›¾åƒç†è§£
- âœ… å›¾è¡¨åˆ†æ
- âœ… OCR
- âœ… è§†è§‰æ¨ç†

**å‚è€ƒæ–‡çŒ®**ï¼š

- [OpenAI, 2023](https://openai.com/research/gpt-4v-system-card) - GPT-4V System Card

### 3. æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ

#### DALL-Eç³»åˆ—

**DALL-E**ï¼š

- åŸºäºTransformerçš„è‡ªå›å½’æ¨¡å‹
- å°†å›¾åƒç¦»æ•£åŒ–ä¸ºtoken

**DALL-E 2**ï¼š

- ä½¿ç”¨æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Modelï¼‰
- CLIPå¼•å¯¼ç”Ÿæˆ

**DALL-E 3**ï¼š

- æ›´å¥½çš„promptç†è§£
- æ›´é«˜è´¨é‡ç”Ÿæˆ

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Ramesh et al., 2021](https://arxiv.org/abs/2102.12092) - Zero-Shot Text-to-Image Generation
- [Ramesh et al., 2022](https://arxiv.org/abs/2204.06125) - Hierarchical Text-Conditional Image Generation with CLIP Latents

#### Stable Diffusion

**æ¶æ„**ï¼š

```text
Text â†’ CLIP Text Encoder â†’ Condition
        â†“
Latent Diffusion Model
        â†“
Image (via VAE Decoder)
```

**ä¼˜åŠ¿**ï¼š

- âœ… å¼€æº
- âœ… é«˜æ•ˆï¼ˆåœ¨æ½œåœ¨ç©ºé—´ä¸­æ‰©æ•£ï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Rombach et al., 2022](https://arxiv.org/abs/2112.10752) - High-Resolution Image Synthesis with Latent Diffusion Models

#### Midjourney

**å•†ä¸šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆç³»ç»Ÿ**ï¼š

- è‰ºæœ¯é£æ ¼å¼º
- ç”¨æˆ·å‹å¥½

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Midjourney Website](https://www.midjourney.com/)

---

## å¤šæ¨¡æ€é¢„è®­ç»ƒæ¨¡å‹

### 1. é¢„è®­ç»ƒä»»åŠ¡

#### å›¾åƒ-æ–‡æœ¬åŒ¹é…ï¼ˆImage-Text Matching, ITMï¼‰

**ä»»åŠ¡**ï¼š

åˆ¤æ–­å›¾åƒå’Œæ–‡æœ¬æ˜¯å¦åŒ¹é…ã€‚

```text
(Image, Text) â†’ Binary Classification (match / not match)
```

#### æ©ç è¯­è¨€å»ºæ¨¡ï¼ˆMasked Language Modeling, MLMï¼‰

**ä»»åŠ¡**ï¼š

ç»™å®šå›¾åƒï¼Œé¢„æµ‹æ–‡æœ¬ä¸­è¢«æ©ç çš„è¯ã€‚

```text
Image + "A [MASK] sitting on a mat" â†’ "cat"
```

#### å›¾åƒåŒºåŸŸåˆ†ç±»ï¼ˆMasked Region Classification, MRCï¼‰

**ä»»åŠ¡**ï¼š

ç»™å®šæ–‡æœ¬ï¼Œé¢„æµ‹å›¾åƒä¸­è¢«æ©ç åŒºåŸŸçš„ç±»åˆ«ã€‚

### 2. ä»£è¡¨æ€§é¢„è®­ç»ƒæ¨¡å‹

#### BERT for Vision-Language

**ViLBERT**ï¼š

- åŒæµæ¶æ„ï¼ˆå›¾åƒæµ + æ–‡æœ¬æµï¼‰
- äº¤å‰æ³¨æ„åŠ›

**LXMERT**ï¼š

- ä¸‰æµæ¶æ„ï¼ˆå›¾åƒã€æ–‡æœ¬ã€è·¨æ¨¡æ€ï¼‰

**UNITER**ï¼š

- å•æµæ¶æ„ï¼ˆç»Ÿä¸€Transformerï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Lu et al., 2019](https://arxiv.org/abs/1908.02265) - ViLBERT
- [Tan & Bansal, 2019](https://arxiv.org/abs/1908.07490) - LXMERT
- [Chen et al., 2020](https://arxiv.org/abs/1909.11740) - UNITER

#### å¤§è§„æ¨¡é¢„è®­ç»ƒ

**FLAVA**ï¼ˆFoundational Language And Vision Alignmentï¼‰ï¼š

- ç»Ÿä¸€æ¶æ„
- å•æ¨¡æ€ + å¤šæ¨¡æ€é¢„è®­ç»ƒ

**BEiT-3**ï¼š

- ç»Ÿä¸€çš„Masked Data Modeling
- æ–‡æœ¬ã€å›¾åƒã€å›¾æ–‡å¯¹

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Singh et al., 2022](https://arxiv.org/abs/2112.04482) - FLAVA
- [Wang et al., 2022](https://arxiv.org/abs/2208.10442) - Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks

---

## å¤šæ¨¡æ€åº”ç”¨åœºæ™¯

### 1. è§†è§‰é—®ç­”ï¼ˆVisual Question Answering, VQAï¼‰

**ä»»åŠ¡**ï¼š

```text
è¾“å…¥ï¼šImage + Question
è¾“å‡ºï¼šAnswer

ä¾‹ï¼š
Image: [çŒ«çš„å›¾ç‰‡]
Question: "What color is the cat?"
Answer: "Orange"
```

**æŒ‘æˆ˜**ï¼š

- éœ€è¦è§†è§‰ç†è§£
- éœ€è¦å¸¸è¯†æ¨ç†

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Antol et al., 2015](https://arxiv.org/abs/1505.00468) - VQA: Visual Question Answering

### 2. å›¾åƒæè¿°ç”Ÿæˆï¼ˆImage Captioningï¼‰

**ä»»åŠ¡**ï¼š

```text
è¾“å…¥ï¼šImage
è¾“å‡ºï¼šText description

ä¾‹ï¼š
Image: [çŒ«çš„å›¾ç‰‡]
Caption: "A cat is sitting on a mat."
```

**è¯„ä¼°æŒ‡æ ‡**ï¼š

- BLEUã€METEORã€CIDErã€SPICE

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Vinyals et al., 2015](https://arxiv.org/abs/1411.4555) - Show and Tell

### 3. è·¨æ¨¡æ€æ£€ç´¢

#### å›¾åƒ-æ–‡æœ¬æ£€ç´¢

**ä»»åŠ¡**ï¼š

- æ–‡æœ¬æŸ¥è¯¢ â†’ æ£€ç´¢ç›¸å…³å›¾åƒ
- å›¾åƒæŸ¥è¯¢ â†’ æ£€ç´¢ç›¸å…³æ–‡æœ¬

**æ–¹æ³•**ï¼š

åœ¨ç»Ÿä¸€è¯­ä¹‰ç©ºé—´ä¸­è®¡ç®—ç›¸ä¼¼åº¦ã€‚

#### è§†é¢‘æ£€ç´¢

**æ‰©å±•åˆ°è§†é¢‘**ï¼š

- è€ƒè™‘æ—¶é—´ç»´åº¦
- è§†é¢‘ç‰‡æ®µ-æ–‡æœ¬å¯¹é½

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Miech et al., 2019](https://arxiv.org/abs/1906.05743) - HowTo100M: Learning a Text-Video Embedding

### 4. å¤šæ¨¡æ€å¯¹è¯

**ä»»åŠ¡**ï¼š

ä¸ç”¨æˆ·è¿›è¡ŒåŒ…å«å›¾åƒçš„å¤šè½®å¯¹è¯ã€‚

**ä¾‹å­**ï¼š

```text
ç”¨æˆ·ï¼š[ä¸Šä¼ å›¾ç‰‡] "è¿™æ˜¯ä»€ä¹ˆï¼Ÿ"
åŠ©æ‰‹ï¼š"è¿™æ˜¯ä¸€åªæ©™è‰²çš„çŒ«ã€‚"
ç”¨æˆ·ï¼š"å®ƒåœ¨åšä»€ä¹ˆï¼Ÿ"
åŠ©æ‰‹ï¼š"å®ƒååœ¨ä¸€ä¸ªå«å­ä¸Šã€‚"
```

**ä»£è¡¨æ¨¡å‹**ï¼š

- GPT-4Vã€Flamingo

### 5. åŒ»å­¦å½±åƒåˆ†æ

**ä»»åŠ¡**ï¼š

ç»“åˆåŒ»å­¦å½±åƒå’Œæ–‡æœ¬æŠ¥å‘Šè¿›è¡Œè¯Šæ–­ã€‚

**ä¼˜åŠ¿**ï¼š

- å½±åƒï¼šç²¾ç¡®çš„è§†è§‰ä¿¡æ¯
- æŠ¥å‘Šï¼šä¸Šä¸‹æ–‡ã€ç—…å²

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Zhang et al., 2020](https://arxiv.org/abs/2005.12522) - Contrastive Learning of Medical Visual Representations from Paired Images and Text

---

## æŒ‘æˆ˜ä¸å±€é™æ€§

### 1. æ•°æ®å¯¹é½å›°éš¾

**é—®é¢˜**ï¼š

å¾ˆéš¾è·å¾—**ç²¾ç¡®å¯¹é½**çš„å¤šæ¨¡æ€æ•°æ®ã€‚

**ä¾‹å­**ï¼š

```text
å›¾åƒï¼š[çŒ«çš„å›¾ç‰‡]
æ–‡æœ¬ï¼š"è¿™æ˜¯ä¸€åªå¯çˆ±çš„çŒ«"

"å¯çˆ±" â†” å›¾åƒä¸­çš„å“ªä¸ªåŒºåŸŸï¼Ÿï¼ˆæ¨¡ç³Šï¼‰
```

**ç¼“è§£æ–¹æ³•**ï¼š

- å¼±ç›‘ç£å­¦ä¹ 
- è‡ªç›‘ç£å¯¹é½

### 2. æ¨¡æ€ä¸å¹³è¡¡

**é—®é¢˜**ï¼š

æŸäº›æ¨¡æ€æ¯”å…¶ä»–æ¨¡æ€æ›´"å¼º"ï¼Œå®¹æ˜“ä¸»å¯¼å­¦ä¹ ã€‚

**ä¾‹å­**ï¼š

æ–‡æœ¬é€šå¸¸æ¯”å›¾åƒåŒ…å«æ›´æ˜ç¡®çš„è¯­ä¹‰ä¿¡æ¯ã€‚

**ç¼“è§£æ–¹æ³•**ï¼š

- åŠ¨æ€æƒé‡
- å¯¹æŠ—è®­ç»ƒ

### 3. æ¨¡æ€ç¼ºå¤±

**é—®é¢˜**ï¼š

å®é™…åº”ç”¨ä¸­ï¼ŒæŸäº›æ¨¡æ€å¯èƒ½ç¼ºå¤±ã€‚

**ä¾‹å­**ï¼š

è®­ç»ƒæ—¶æœ‰å›¾åƒ+æ–‡æœ¬ï¼Œæµ‹è¯•æ—¶åªæœ‰æ–‡æœ¬ã€‚

**ç¼“è§£æ–¹æ³•**ï¼š

- é²æ£’è®­ç»ƒï¼ˆéšæœºdropæ¨¡æ€ï¼‰
- æ¨¡æ€è¡¥å…¨ï¼ˆhallucinationï¼‰

### 4. è®¡ç®—æˆæœ¬

**é—®é¢˜**ï¼š

å¤šæ¨¡æ€æ¨¡å‹é€šå¸¸éå¸¸å¤§ï¼Œè®­ç»ƒå’Œæ¨ç†æˆæœ¬é«˜ã€‚

**ä¾‹å­**ï¼š

- CLIPï¼š4äº¿å›¾æ–‡å¯¹ï¼Œæ•°åƒGPUè®­ç»ƒ
- GPT-4Vï¼šå‚æ•°é‡å’Œè®­ç»ƒæˆæœ¬æœªå…¬å¼€ï¼ˆä½†é¢„è®¡æé«˜ï¼‰

**ç¼“è§£æ–¹æ³•**ï¼š

- æ¨¡å‹å‹ç¼©
- é«˜æ•ˆæ¶æ„è®¾è®¡

### 5. åè§ä¸å…¬å¹³æ€§

**é—®é¢˜**ï¼š

å¤šæ¨¡æ€æ•°æ®ä¸­çš„åè§ä¼šè¢«æ¨¡å‹å­¦ä¹ å¹¶æ”¾å¤§ã€‚

**ä¾‹å­**ï¼š

```text
"CEO" + å›¾åƒ â†’ æ¨¡å‹å€¾å‘ç”Ÿæˆç”·æ€§å›¾åƒï¼ˆæ€§åˆ«åè§ï¼‰
```

**ç¼“è§£æ–¹æ³•**ï¼š

- æ•°æ®å»åç½®
- å¯¹æŠ—å»åç½®è®­ç»ƒ

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Zhao et al., 2021](https://arxiv.org/abs/2104.08758) - Understanding and Evaluating Racial Biases in Image Captioning

---

## æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **ç†è®ºåŸºç¡€**ï¼šè®¤çŸ¥ç§‘å­¦ã€ç»Ÿä¸€è¯­ä¹‰ç©ºé—´ã€äº’è¡¥æ€§ä¸å†—ä½™æ€§
2. **è¡¨ç¤ºå­¦ä¹ **ï¼šè”åˆè¡¨ç¤ºã€ååŒè¡¨ç¤ºã€ç¼–ç å™¨-è§£ç å™¨
3. **å¯¹é½**ï¼šæ˜¾å¼å¯¹é½ï¼ˆæ³¨æ„åŠ›ï¼‰ã€éšå¼å¯¹é½ï¼ˆç«¯åˆ°ç«¯ï¼‰
4. **èåˆç­–ç•¥**ï¼šæ—©æœŸèåˆã€æ™šæœŸèåˆã€æ··åˆèåˆã€é—¨æ§èåˆ
5. **ä¸»è¦æ¶æ„**ï¼šCLIPã€Flamingoã€GPT-4Vã€DALL-Eã€Stable Diffusion
6. **é¢„è®­ç»ƒ**ï¼šITMã€MLMã€MRC
7. **åº”ç”¨**ï¼šVQAã€å›¾åƒæè¿°ã€è·¨æ¨¡æ€æ£€ç´¢ã€å¤šæ¨¡æ€å¯¹è¯
8. **æŒ‘æˆ˜**ï¼šæ•°æ®å¯¹é½ã€æ¨¡æ€ä¸å¹³è¡¡ã€æ¨¡æ€ç¼ºå¤±ã€è®¡ç®—æˆæœ¬ã€åè§

### å‘å±•è¶‹åŠ¿

1. **ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹**ï¼šä¸€ä¸ªæ¨¡å‹å¤„ç†æ‰€æœ‰æ¨¡æ€
2. **ä»»æ„æ¨¡æ€ç»„åˆ**ï¼šä¸é™äºå›¾åƒ+æ–‡æœ¬
3. **ç«¯åˆ°ç«¯å­¦ä¹ **ï¼šå‡å°‘äººå·¥è®¾è®¡
4. **å¤§è§„æ¨¡é¢„è®­ç»ƒ**ï¼šåˆ©ç”¨æµ·é‡å¤šæ¨¡æ€æ•°æ®
5. **é«˜æ•ˆæ¶æ„**ï¼šé™ä½è®¡ç®—æˆæœ¬

### å“²å­¦åæ€

> **å¤šæ¨¡æ€è¯­ä¹‰æ•´åˆæ­ç¤ºäº†ä¸€ä¸ªæ·±åˆ»çš„æ´å¯Ÿï¼šæ„ä¹‰ä¸æ˜¯å•ä¸€çš„ã€å­¤ç«‹çš„ï¼Œè€Œæ˜¯å¤šç»´çš„ã€æ¶Œç°çš„ã€‚çœŸæ­£çš„ç†è§£éœ€è¦æ•´åˆå¤šç§æ„ŸçŸ¥é€šé“ï¼Œå°±åƒäººç±»è®¤çŸ¥ä¸€æ ·ã€‚**

### æœªæ¥æ–¹å‘

1. **å…¨æ¨¡æ€æ•´åˆ**ï¼šæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ã€è§¦è§‰ã€æ°”å‘³...
2. **å…·èº«æ™ºèƒ½**ï¼šç»“åˆæœºå™¨äººä¸ç‰©ç†äº¤äº’
3. **æŒç»­å­¦ä¹ **ï¼šä»å®æ—¶å¤šæ¨¡æ€æµä¸­å­¦ä¹ 
4. **å¯è§£é‡Šæ€§**ï¼šç†è§£å¤šæ¨¡æ€æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹
5. **ä¼¦ç†ä¸å…¬å¹³**ï¼šæ¶ˆé™¤å¤šæ¨¡æ€ç³»ç»Ÿä¸­çš„åè§

---

## å‚è€ƒæ–‡çŒ®

### ç»¼è¿°

1. [Wikipedia: Multimodal Learning](https://en.wikipedia.org/wiki/Multimodal_learning)
2. [BaltruÅ¡aitis et al., 2019](https://arxiv.org/abs/1705.09406) - Multimodal Machine Learning: A Survey and Taxonomy

### è®¤çŸ¥åŸºç¡€

1. [Wikipedia: Multisensory Integration](https://en.wikipedia.org/wiki/Multisensory_integration)
2. [Wikipedia: Dual Coding Theory](https://en.wikipedia.org/wiki/Dual-coding_theory)
3. [Paivio, 1971](https://psycnet.apa.org/record/1972-21472-000) - Imagery and Verbal Processes

### æ—©æœŸå·¥ä½œ

1. [Ngiam et al., 2011](https://icml.cc/2011/papers/399_icmlpaper.pdf) - Multimodal Deep Learning
2. [Srivastava & Salakhutdinov, 2012](https://proceedings.neurips.cc/paper/2012/hash/af21d0c97db2e27e13572cbf59eb343d-Abstract.html) - Multimodal Learning with Deep Boltzmann Machines

### ç°ä»£æ¶æ„

1. [Radford et al., 2021](https://arxiv.org/abs/2103.00020) - CLIP
2. [Jia et al., 2021](https://arxiv.org/abs/2102.05918) - ALIGN
3. [Alayrac et al., 2022](https://arxiv.org/abs/2204.14198) - Flamingo
4. [OpenAI, 2023](https://openai.com/research/gpt-4v-system-card) - GPT-4V

### æ–‡æœ¬åˆ°å›¾åƒ

1. [Ramesh et al., 2021](https://arxiv.org/abs/2102.12092) - DALL-E
2. [Ramesh et al., 2022](https://arxiv.org/abs/2204.06125) - DALL-E 2
3. [Rombach et al., 2022](https://arxiv.org/abs/2112.10752) - Stable Diffusion

### é¢„è®­ç»ƒæ¨¡å‹

1. [Lu et al., 2019](https://arxiv.org/abs/1908.02265) - ViLBERT
2. [Tan & Bansal, 2019](https://arxiv.org/abs/1908.07490) - LXMERT
3. [Chen et al., 2020](https://arxiv.org/abs/1909.11740) - UNITER
4. [Singh et al., 2022](https://arxiv.org/abs/2112.04482) - FLAVA

### åº”ç”¨

1. [Antol et al., 2015](https://arxiv.org/abs/1505.00468) - VQA: Visual Question Answering
2. [Vinyals et al., 2015](https://arxiv.org/abs/1411.4555) - Show and Tell: Image Captioning
3. [Anderson et al., 2018](https://arxiv.org/abs/1707.07998) - Bottom-Up and Top-Down Attention

### å…¬å¹³æ€§ä¸åè§

1. [Zhao et al., 2021](https://arxiv.org/abs/2104.08758) - Understanding and Evaluating Racial Biases in Image Captioning

---

*æœ¬æ–‡æ¡£å…¨é¢é˜è¿°äº†å¤šæ¨¡æ€è¯­ä¹‰æ•´åˆçš„ç†è®ºåŸºç¡€ã€å…³é”®æŠ€æœ¯å’Œå‰æ²¿åº”ç”¨ï¼Œä¸ºç†è§£å¤šæ¨¡æ€AIç³»ç»Ÿæä¾›äº†ç³»ç»Ÿçš„ç†è®ºæ¡†æ¶ã€‚*
