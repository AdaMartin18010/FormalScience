# åˆ†å¸ƒå¼è¯­ä¹‰å­¦ï¼ˆDistributional Semanticsï¼‰

## ç›®å½• | Table of Contents

- [åˆ†å¸ƒå¼è¯­ä¹‰å­¦ï¼ˆDistributional Semanticsï¼‰](#åˆ†å¸ƒå¼è¯­ä¹‰å­¦distributional-semantics)
- [ç›®å½•](#ç›®å½•)
- [å¼•è¨€](#å¼•è¨€)
  - [æ ¸å¿ƒæ€æƒ³](#æ ¸å¿ƒæ€æƒ³)
  - [ä¸ä¼ ç»Ÿè¯­ä¹‰å­¦çš„å¯¹æ¯”](#ä¸ä¼ ç»Ÿè¯­ä¹‰å­¦çš„å¯¹æ¯”)
- [åˆ†å¸ƒå‡è®¾ï¼šç†è®ºåŸºçŸ³](#åˆ†å¸ƒå‡è®¾ç†è®ºåŸºçŸ³)
  - [1. Firthçš„åŸåˆè¡¨è¿°ï¼ˆ1957ï¼‰](#1-firthçš„åŸåˆè¡¨è¿°1957)
  - [2. Harrisçš„åˆ†å¸ƒå‡è®¾ï¼ˆ1954ï¼‰](#2-harrisçš„åˆ†å¸ƒå‡è®¾1954)
  - [3. Wittgensteinçš„ä½¿ç”¨è®ºï¼ˆ1953ï¼‰](#3-wittgensteinçš„ä½¿ç”¨è®º1953)
  - [4. ç°ä»£å½¢å¼åŒ–](#4-ç°ä»£å½¢å¼åŒ–)
- [åˆ†å¸ƒå¼è¯­ä¹‰çš„å†å²å‘å±•](#åˆ†å¸ƒå¼è¯­ä¹‰çš„å†å²å‘å±•)
  - [1. æ—©æœŸï¼šå‘é‡ç©ºé—´æ¨¡å‹ï¼ˆ1970s-1990sï¼‰](#1-æ—©æœŸå‘é‡ç©ºé—´æ¨¡å‹1970s-1990s)
    - [Saltonçš„å‘é‡ç©ºé—´æ¨¡å‹ï¼ˆ1975ï¼‰](#saltonçš„å‘é‡ç©ºé—´æ¨¡å‹1975)
    - [TF-IDFï¼ˆTerm Frequency-Inverse Document Frequencyï¼‰](#tf-idfterm-frequency-inverse-document-frequency)
  - [2. ä¸­æœŸï¼šæ½œåœ¨è¯­ä¹‰åˆ†æï¼ˆ1990sï¼‰](#2-ä¸­æœŸæ½œåœ¨è¯­ä¹‰åˆ†æ1990s)
    - [LSAï¼ˆLatent Semantic Analysis, 1990ï¼‰](#lsalatent-semantic-analysis-1990)
  - [3. ç°ä»£ï¼šç¥ç»è¯åµŒå…¥ï¼ˆ2010sï¼‰](#3-ç°ä»£ç¥ç»è¯åµŒå…¥2010s)
    - [Word2Vecï¼ˆ2013ï¼‰](#word2vec2013)
    - [GloVeï¼ˆ2014ï¼‰](#glove2014)
    - [ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤ºï¼ˆ2018+ï¼‰](#ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤º2018)
- [åˆ†å¸ƒå¼è¯­ä¹‰çš„æ•°å­¦å½¢å¼åŒ–](#åˆ†å¸ƒå¼è¯­ä¹‰çš„æ•°å­¦å½¢å¼åŒ–)
  - [1. ä¸Šä¸‹æ–‡å®šä¹‰](#1-ä¸Šä¸‹æ–‡å®šä¹‰)
    - [å›ºå®šçª—å£ä¸Šä¸‹æ–‡](#å›ºå®šçª—å£ä¸Šä¸‹æ–‡)
    - [ä¾å­˜å¥æ³•ä¸Šä¸‹æ–‡](#ä¾å­˜å¥æ³•ä¸Šä¸‹æ–‡)
  - [2. å…±ç°çŸ©é˜µï¼ˆCo-occurrence Matrixï¼‰](#2-å…±ç°çŸ©é˜µco-occurrence-matrix)
    - [åŸå§‹è®¡æ•°çš„é—®é¢˜](#åŸå§‹è®¡æ•°çš„é—®é¢˜)
  - [3. åŠ æƒæ–¹æ¡ˆ](#3-åŠ æƒæ–¹æ¡ˆ)
    - [ç‚¹äº’ä¿¡æ¯ï¼ˆPointwise Mutual Information, PMIï¼‰](#ç‚¹äº’ä¿¡æ¯pointwise-mutual-information-pmi)
    - [æ­£ç‚¹äº’ä¿¡æ¯ï¼ˆPositive PMI, PPMIï¼‰](#æ­£ç‚¹äº’ä¿¡æ¯positive-pmi-ppmi)
  - [4. é™ç»´æ–¹æ³•](#4-é™ç»´æ–¹æ³•)
    - [å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰](#å¥‡å¼‚å€¼åˆ†è§£svd)
    - [éè´ŸçŸ©é˜µåˆ†è§£ï¼ˆNMFï¼‰](#éè´ŸçŸ©é˜µåˆ†è§£nmf)
- [ä»å…±ç°ç»Ÿè®¡åˆ°è¯­ä¹‰è¡¨ç¤º](#ä»å…±ç°ç»Ÿè®¡åˆ°è¯­ä¹‰è¡¨ç¤º)
  - [1. Word2Vecçš„éšå«çŸ©é˜µåˆ†è§£](#1-word2vecçš„éšå«çŸ©é˜µåˆ†è§£)
  - [2. GloVeçš„æ˜¾å¼çŸ©é˜µåˆ†è§£](#2-gloveçš„æ˜¾å¼çŸ©é˜µåˆ†è§£)
  - [3. ç»Ÿä¸€è§†è§’](#3-ç»Ÿä¸€è§†è§’)
- [åˆ†å¸ƒå¼è¯­ä¹‰çš„å¿ƒç†å­¦åŸºç¡€](#åˆ†å¸ƒå¼è¯­ä¹‰çš„å¿ƒç†å­¦åŸºç¡€)
  - [1. è”ç»“ä¸»ä¹‰ä¸ç¥ç»ç½‘ç»œ](#1-è”ç»“ä¸»ä¹‰ä¸ç¥ç»ç½‘ç»œ)
  - [2. åŸå‹ç†è®ºï¼ˆPrototype Theoryï¼‰](#2-åŸå‹ç†è®ºprototype-theory)
  - [3. æ¦‚å¿µç©ºé—´ï¼ˆConceptual Spacesï¼‰](#3-æ¦‚å¿µç©ºé—´conceptual-spaces)
- [åˆ†å¸ƒå¼è¯­ä¹‰ vs å½¢å¼è¯­ä¹‰](#åˆ†å¸ƒå¼è¯­ä¹‰-vs-å½¢å¼è¯­ä¹‰)
  - [å¯¹æ¯”](#å¯¹æ¯”)
  - [äº’è¡¥æ€§](#äº’è¡¥æ€§)
- [åˆ†å¸ƒå¼è¯­ä¹‰çš„å±€é™æ€§](#åˆ†å¸ƒå¼è¯­ä¹‰çš„å±€é™æ€§)
  - [1. åäº‹å®é—®é¢˜ï¼ˆGrounding Problemï¼‰](#1-åäº‹å®é—®é¢˜grounding-problem)
  - [2. ç»„åˆæ€§é—®é¢˜ï¼ˆCompositionality Problemï¼‰](#2-ç»„åˆæ€§é—®é¢˜compositionality-problem)
  - [3. é€»è¾‘æ¨ç†é—®é¢˜ï¼ˆLogical Reasoning Problemï¼‰](#3-é€»è¾‘æ¨ç†é—®é¢˜logical-reasoning-problem)
  - [4. åè§æ”¾å¤§é—®é¢˜ï¼ˆBias Amplificationï¼‰](#4-åè§æ”¾å¤§é—®é¢˜bias-amplification)
- [æ€»ç»“](#æ€»ç»“)
  - [æ ¸å¿ƒè¦ç‚¹](#æ ¸å¿ƒè¦ç‚¹)
  - [å“²å­¦åæ€](#å“²å­¦åæ€)
  - [æœªæ¥æ–¹å‘](#æœªæ¥æ–¹å‘)
- [å‚è€ƒæ–‡çŒ®](#å‚è€ƒæ–‡çŒ®)
  - [åŸºç¡€ç†è®º](#åŸºç¡€ç†è®º)
  - [å†å²æ–‡çŒ®](#å†å²æ–‡çŒ®)
  - [ç»å…¸æ–¹æ³•](#ç»å…¸æ–¹æ³•)
  - [ç°ä»£æ–¹æ³•](#ç°ä»£æ–¹æ³•)
  - [ç†è®ºåˆ†æ](#ç†è®ºåˆ†æ)
  - [å¿ƒç†å­¦åŸºç¡€](#å¿ƒç†å­¦åŸºç¡€)
  - [å“²å­¦ä¸æ‰¹è¯„](#å“²å­¦ä¸æ‰¹è¯„)

---

## ç›®å½•

- [å¼•è¨€](#å¼•è¨€)
- [åˆ†å¸ƒå‡è®¾ï¼šç†è®ºåŸºçŸ³](#åˆ†å¸ƒå‡è®¾ç†è®ºåŸºçŸ³)
- [åˆ†å¸ƒå¼è¯­ä¹‰çš„å†å²å‘å±•](#åˆ†å¸ƒå¼è¯­ä¹‰çš„å†å²å‘å±•)
- [åˆ†å¸ƒå¼è¯­ä¹‰çš„æ•°å­¦å½¢å¼åŒ–](#åˆ†å¸ƒå¼è¯­ä¹‰çš„æ•°å­¦å½¢å¼åŒ–)
- [ä»å…±ç°ç»Ÿè®¡åˆ°è¯­ä¹‰è¡¨ç¤º](#ä»å…±ç°ç»Ÿè®¡åˆ°è¯­ä¹‰è¡¨ç¤º)
- [åˆ†å¸ƒå¼è¯­ä¹‰çš„å¿ƒç†å­¦åŸºç¡€](#åˆ†å¸ƒå¼è¯­ä¹‰çš„å¿ƒç†å­¦åŸºç¡€)
- [åˆ†å¸ƒå¼è¯­ä¹‰ vs å½¢å¼è¯­ä¹‰](#åˆ†å¸ƒå¼è¯­ä¹‰-vs-å½¢å¼è¯­ä¹‰)
- [åˆ†å¸ƒå¼è¯­ä¹‰çš„å±€é™æ€§](#åˆ†å¸ƒå¼è¯­ä¹‰çš„å±€é™æ€§)
- [æ€»ç»“](#æ€»ç»“)
- [å‚è€ƒæ–‡çŒ®](#å‚è€ƒæ–‡çŒ®)

---

## å¼•è¨€

**åˆ†å¸ƒå¼è¯­ä¹‰å­¦**ï¼ˆDistributional Semanticsï¼‰æ˜¯ç°ä»£è‡ªç„¶è¯­è¨€å¤„ç†å’ŒAIçš„ç†è®ºåŸºç¡€ï¼Œå®ƒåŸºäºä¸€ä¸ªç®€å•è€Œæ·±åˆ»çš„æ€æƒ³ï¼š

> **"You shall know a word by the company it keeps."**
>
> **"è¯çš„æ„ä¹‰ç”±å…¶æ‰€å¤„çš„è¯­å¢ƒå†³å®šã€‚"**
>
> â€” J. R. Firth (1957)

### æ ¸å¿ƒæ€æƒ³

**åˆ†å¸ƒå‡è®¾**ï¼ˆDistributional Hypothesisï¼‰è®¤ä¸ºï¼š

> **åœ¨ç›¸ä¼¼ä¸Šä¸‹æ–‡ä¸­å‡ºç°çš„è¯å…·æœ‰ç›¸ä¼¼çš„æ„ä¹‰ã€‚**

å½¢å¼åŒ–ï¼š

```text
Context(wâ‚) â‰ˆ Context(wâ‚‚)  â‡’  Meaning(wâ‚) â‰ˆ Meaning(wâ‚‚)
```

### ä¸ä¼ ç»Ÿè¯­ä¹‰å­¦çš„å¯¹æ¯”

| ç»´åº¦ | å½¢å¼è¯­ä¹‰å­¦ | åˆ†å¸ƒå¼è¯­ä¹‰å­¦ | å‚è€ƒæ–‡çŒ® |
|------|-----------|-------------|----------|
| **æ„ä¹‰æ¥æº** | é€»è¾‘å…¬å¼ã€çœŸå€¼æ¡ä»¶ | è¯­è¨€ä½¿ç”¨çš„ç»Ÿè®¡æ¨¡å¼ | [Wittgenstein, 1953](https://en.wikipedia.org/wiki/Philosophical_Investigations) |
| **è¡¨ç¤ºæ–¹å¼** | ç¬¦å·ã€è°“è¯é€»è¾‘ | å‘é‡ã€çŸ©é˜µ | [Turney & Pantel, 2010](https://www.jair.org/index.php/jair/article/view/10640) |
| **å­¦ä¹ æ–¹å¼** | äººå·¥å®šä¹‰ | ä»æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹  | [Mikolov et al., 2013](https://arxiv.org/abs/1301.3781) |
| **å“²å­¦åŸºç¡€** | æŒ‡ç§°è®ºï¼ˆReference Theoryï¼‰ | ä½¿ç”¨è®ºï¼ˆUse Theoryï¼‰ | [Wikipedia: Meaning (philosophy of language)](https://en.wikipedia.org/wiki/Meaning_(philosophy_of_language)) |

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Distributional Semantics](https://en.wikipedia.org/wiki/Distributional_semantics)
- [Turney & Pantel, 2010](https://www.jair.org/index.php/jair/article/view/10640) - From Frequency to Meaning: Vector Space Models of Semantics

---

## åˆ†å¸ƒå‡è®¾ï¼šç†è®ºåŸºçŸ³

### 1. Firthçš„åŸåˆè¡¨è¿°ï¼ˆ1957ï¼‰

**J. R. Firth** åœ¨1957å¹´æå‡ºï¼š

> **"You shall know a word by the company it keeps."**

**å«ä¹‰**ï¼š

- è¯çš„æ„ä¹‰ä¸æ˜¯å†…åœ¨çš„ã€å›ºå®šçš„
- è¯çš„æ„ä¹‰æ¥è‡ªäºå®ƒçš„**åˆ†å¸ƒ**ï¼ˆåœ¨è¯­æ–™åº“ä¸­çš„ä½¿ç”¨æ¨¡å¼ï¼‰

**ä¾‹å­**ï¼š

```text
"cat" å¸¸å‡ºç°åœ¨ä»¥ä¸‹ä¸Šä¸‹æ–‡ä¸­ï¼š
  - "I have a ___."
  - "The ___ is sleeping."
  - "Feed the ___."
  - "___ and dog"

"dog" ä¹Ÿå¸¸å‡ºç°åœ¨ç±»ä¼¼ä¸Šä¸‹æ–‡ä¸­
â‡’ "cat" å’Œ "dog" æ„ä¹‰ç›¸è¿‘
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Firth, 1957](https://en.wikipedia.org/wiki/Distributional_semantics) - A Synopsis of Linguistic Theory 1930-1955

### 2. Harrisçš„åˆ†å¸ƒå‡è®¾ï¼ˆ1954ï¼‰

**Zellig Harris** æ›´æ—©æå‡ºäº†ç±»ä¼¼æ€æƒ³ï¼š

> **"Difference in meaning correlates with difference in distribution."**
>
> **"æ„ä¹‰çš„å·®å¼‚å¯¹åº”äºåˆ†å¸ƒçš„å·®å¼‚ã€‚"**

**æ•°å­¦ç›´è§‰**ï¼š

```text
Meaning : Words â†’ SemanticSpace
Distribution : Words â†’ ContextSpace

åˆ†å¸ƒå‡è®¾ï¼šMeaning âˆ Distribution
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Harris, 1954](https://www.jstor.org/stable/411805) - Distributional Structure

### 3. Wittgensteinçš„ä½¿ç”¨è®ºï¼ˆ1953ï¼‰

**Ludwig Wittgenstein** åœ¨ã€Šå“²å­¦ç ”ç©¶ã€‹ä¸­æå‡ºï¼š

> **"The meaning of a word is its use in the language."**
>
> **"è¯çš„æ„ä¹‰å°±æ˜¯å®ƒåœ¨è¯­è¨€ä¸­çš„ä½¿ç”¨ã€‚"**

**å“²å­¦åŸºç¡€**ï¼š

- æ‹’ç»**æŒ‡ç§°è®º**ï¼ˆè¯çš„æ„ä¹‰=å®ƒæ‰€æŒ‡çš„å¯¹è±¡ï¼‰
- æå‡º**ä½¿ç”¨è®º**ï¼ˆè¯çš„æ„ä¹‰=å®ƒçš„ä½¿ç”¨æ–¹å¼ï¼‰

**ä¸åˆ†å¸ƒå‡è®¾çš„è”ç³»**ï¼š

```text
ä½¿ç”¨ï¼ˆUseï¼‰ â†’ åˆ†å¸ƒï¼ˆDistributionï¼‰ â†’ å‘é‡ï¼ˆVectorï¼‰
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Philosophical Investigations](https://en.wikipedia.org/wiki/Philosophical_Investigations)
- [Wikipedia: Use Theory](https://en.wikipedia.org/wiki/Use_theory)

### 4. ç°ä»£å½¢å¼åŒ–

**å®šä¹‰ï¼ˆåˆ†å¸ƒå‡è®¾ï¼‰**ï¼š

è®¾ï¼š

- Î£ï¼šè¯æ±‡è¡¨
- Context(w)ï¼šè¯ w çš„ä¸Šä¸‹æ–‡åˆ†å¸ƒ

åˆ™åˆ†å¸ƒå‡è®¾æ–­è¨€ï¼š

```text
âˆ€wâ‚, wâ‚‚ âˆˆ Î£ : d_context(Context(wâ‚), Context(wâ‚‚)) â‰ˆ d_semantic(Meaning(wâ‚), Meaning(wâ‚‚))
```

å…¶ä¸­ï¼š

- d_contextï¼šä¸Šä¸‹æ–‡åˆ†å¸ƒçš„è·ç¦»åº¦é‡
- d_semanticï¼šè¯­ä¹‰è·ç¦»åº¦é‡

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Lenci, 2018](https://www.annualreviews.org/doi/10.1146/annurev-linguistics-030514-125254) - Distributional Models of Word Meaning

---

## åˆ†å¸ƒå¼è¯­ä¹‰çš„å†å²å‘å±•

### 1. æ—©æœŸï¼šå‘é‡ç©ºé—´æ¨¡å‹ï¼ˆ1970s-1990sï¼‰

#### Saltonçš„å‘é‡ç©ºé—´æ¨¡å‹ï¼ˆ1975ï¼‰

**åº”ç”¨äºä¿¡æ¯æ£€ç´¢**ï¼š

- æ–‡æ¡£è¡¨ç¤ºä¸ºè¯çš„å‘é‡
- æŸ¥è¯¢-æ–‡æ¡£åŒ¹é…ç”¨ä½™å¼¦ç›¸ä¼¼åº¦

```text
doc = [tfâ‚, tfâ‚‚, ..., tf|V|]  ï¼ˆè¯é¢‘å‘é‡ï¼‰
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Vector Space Model](https://en.wikipedia.org/wiki/Vector_space_model)
- [Salton et al., 1975](https://dl.acm.org/doi/10.1145/361219.361220) - A Vector Space Model for Automatic Indexing

#### TF-IDFï¼ˆTerm Frequency-Inverse Document Frequencyï¼‰

**å…¬å¼**ï¼š

```text
TF-IDF(w, d) = TF(w, d) Ã— IDF(w)

TF(w, d) = count(w in d) / |d|
IDF(w) = log(N / DF(w))
```

å…¶ä¸­ï¼š

- Nï¼šæ–‡æ¡£æ€»æ•°
- DF(w)ï¼šåŒ…å«è¯ w çš„æ–‡æ¡£æ•°

**ç›´è§‰**ï¼š

- âœ… åœ¨æŸæ–‡æ¡£ä¸­é¢‘ç¹å‡ºç°çš„è¯é‡è¦ï¼ˆTFï¼‰
- âœ… åœ¨æ‰€æœ‰æ–‡æ¡£ä¸­éƒ½å‡ºç°çš„è¯ä¸é‡è¦ï¼ˆIDFï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)

### 2. ä¸­æœŸï¼šæ½œåœ¨è¯­ä¹‰åˆ†æï¼ˆ1990sï¼‰

#### LSAï¼ˆLatent Semantic Analysis, 1990ï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼š

ç”¨**å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰**é™ç»´ï¼Œå‘ç°æ½œåœ¨è¯­ä¹‰ç»“æ„ã€‚

**æ–¹æ³•**ï¼š

1. æ„å»ºè¯-æ–‡æ¡£çŸ©é˜µ X âˆˆ â„|V|Ã—D
2. SVDåˆ†è§£ï¼šX â‰ˆ U Î£ Váµ€
3. ä¿ç•™å‰ k ä¸ªå¥‡å¼‚å€¼ï¼šX_k = U_k Î£_k V_k^T
4. è¯å‘é‡ï¼šU_k çš„è¡Œå‘é‡

**ä¼˜åŠ¿**ï¼š

- âœ… å‘ç°åŒä¹‰è¯ï¼ˆé€šè¿‡ä½ç§©è¿‘ä¼¼ï¼‰
- âœ… é™ä½ç»´åº¦ï¼ˆä» |V| é™åˆ° kï¼‰

**å±€é™**ï¼š

- âŒ è®¡ç®—æˆæœ¬é«˜ï¼ˆSVDæ˜¯ O(mnÂ²)ï¼‰
- âŒ éš¾ä»¥å¤„ç†æ–°è¯ï¼ˆéœ€è¦é‡æ–°åˆ†è§£ï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Latent Semantic Analysis](https://en.wikipedia.org/wiki/Latent_semantic_analysis)
- [Deerwester et al., 1990](https://www.jstor.org/stable/41407138) - Indexing by Latent Semantic Analysis

### 3. ç°ä»£ï¼šç¥ç»è¯åµŒå…¥ï¼ˆ2010sï¼‰

#### Word2Vecï¼ˆ2013ï¼‰

**é©å‘½æ€§çªç ´**ï¼š

- ç”¨ç¥ç»ç½‘ç»œå­¦ä¹ è¯å‘é‡
- æ•æ‰è¯­ä¹‰ç±»æ¯”å…³ç³»

```text
vec(king) - vec(man) + vec(woman) â‰ˆ vec(queen)
```

**ä¸¤ç§æ¶æ„**ï¼š

1. **CBOW**ï¼ˆContinuous Bag-of-Wordsï¼‰ï¼š

    ```text
    P(wâ‚œ | wâ‚œâ‚‹â‚™, ..., wâ‚œâ‚‹â‚, wâ‚œâ‚Šâ‚, ..., wâ‚œâ‚Šâ‚™)
    ```

    ä»ä¸Šä¸‹æ–‡é¢„æµ‹ä¸­å¿ƒè¯

2. **Skip-Gram**ï¼š

    ```text
    P(wâ‚œâ‚‹â‚™, ..., wâ‚œâ‚‹â‚, wâ‚œâ‚Šâ‚, ..., wâ‚œâ‚Šâ‚™ | wâ‚œ)
    ```

ä»ä¸­å¿ƒè¯é¢„æµ‹ä¸Šä¸‹æ–‡

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Mikolov et al., 2013](https://arxiv.org/abs/1301.3781) - Efficient Estimation of Word Representations in Vector Space
- [Wikipedia: Word2vec](https://en.wikipedia.org/wiki/Word2vec)

#### GloVeï¼ˆ2014ï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼š

ç»“åˆ**å…¨å±€ç»Ÿè®¡ä¿¡æ¯**ï¼ˆå…±ç°çŸ©é˜µï¼‰å’Œ**å±€éƒ¨é¢„æµ‹**ï¼ˆWord2Vecï¼‰ã€‚

**ç›®æ ‡å‡½æ•°**ï¼š

```text
J = âˆ‘áµ¢â±¼ f(Xáµ¢â±¼) (ğ’–áµ¢áµ€ ğ’—â±¼ + báµ¢ + câ±¼ - log Xáµ¢â±¼)Â²
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Pennington et al., 2014](https://nlp.stanford.edu/pubs/glove.pdf) - GloVe: Global Vectors for Word Representation

#### ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤ºï¼ˆ2018+ï¼‰

**ELMo, BERT, GPT**ï¼š

- æ¯ä¸ªè¯çš„å‘é‡**ä¾èµ–äºä¸Šä¸‹æ–‡**
- è§£å†³äº†ä¸€è¯å¤šä¹‰é—®é¢˜

```text
vec("bank", "river bank") â‰  vec("bank", "bank account")
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Peters et al., 2018](https://arxiv.org/abs/1802.05365) - Deep Contextualized Word Representations
- [Devlin et al., 2019](https://arxiv.org/abs/1810.04805) - BERT

---

## åˆ†å¸ƒå¼è¯­ä¹‰çš„æ•°å­¦å½¢å¼åŒ–

### 1. ä¸Šä¸‹æ–‡å®šä¹‰

#### å›ºå®šçª—å£ä¸Šä¸‹æ–‡

**å®šä¹‰**ï¼š

è¯ w åœ¨ä½ç½® t çš„**ä¸Šä¸‹æ–‡**æ˜¯å…¶å‰å n ä¸ªè¯ï¼š

```text
Context(wâ‚œ) = {wâ‚œâ‚‹â‚™, ..., wâ‚œâ‚‹â‚, wâ‚œâ‚Šâ‚, ..., wâ‚œâ‚Šâ‚™}
```

**ä¾‹å­**ï¼ˆn=2ï¼‰ï¼š

```text
å¥å­ï¼š"The cat sat on the mat"
Context(sat) = {cat, the, on, the}
```

#### ä¾å­˜å¥æ³•ä¸Šä¸‹æ–‡

**å®šä¹‰**ï¼š

è¯ w çš„ä¸Šä¸‹æ–‡æ˜¯ä¸å®ƒæœ‰**å¥æ³•ä¾å­˜å…³ç³»**çš„è¯ï¼š

```text
Context(w) = {(r, w') | (w, r, w') âˆˆ Dependencies}
```

**ä¾‹å­**ï¼š

```text
"The cat sat on the mat"
Context(sat) = {(nsubj, cat), (prep, on)}
```

**ä¼˜åŠ¿**ï¼š

- âœ… æ•æ‰é•¿è·ç¦»ä¾èµ–
- âœ… æ›´ç²¾ç¡®çš„è¯­æ³•ä¿¡æ¯

**å‚è€ƒæ–‡çŒ®**ï¼š

- [PadÃ³ & Lapata, 2007](https://aclanthology.org/J07-4004/) - Dependency-Based Construction of Semantic Space Models

### 2. å…±ç°çŸ©é˜µï¼ˆCo-occurrence Matrixï¼‰

**å®šä¹‰**ï¼š

**å…±ç°çŸ©é˜µ** X âˆˆ â„|V|Ã—|C| è®°å½•è¯ä¸ä¸Šä¸‹æ–‡çš„å…±ç°æ¬¡æ•°ï¼š

```text
Xáµ¢â±¼ = count(word i appears with context j)
```

**ä¸¤ç§ç±»å‹**ï¼š

1. **è¯-æ–‡æ¡£çŸ©é˜µ**ï¼šC = æ–‡æ¡£é›†
2. **è¯-è¯çŸ©é˜µ**ï¼šC = è¯æ±‡è¡¨ï¼ˆçª—å£å†…å…±ç°ï¼‰

#### åŸå§‹è®¡æ•°çš„é—®é¢˜

**é—®é¢˜**ï¼š

- âŒ é«˜é¢‘è¯ä¸»å¯¼ï¼ˆå¦‚"the", "is"ï¼‰
- âŒ ç¨€ç–æ€§ï¼ˆå¤§éƒ¨åˆ†å…ƒç´ æ˜¯0ï¼‰
- âŒ ç»´åº¦ç¾éš¾ï¼ˆ|V| Ã— |V| å¾ˆå¤§ï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼šåŠ æƒå’Œé™ç»´ã€‚

### 3. åŠ æƒæ–¹æ¡ˆ

#### ç‚¹äº’ä¿¡æ¯ï¼ˆPointwise Mutual Information, PMIï¼‰

**å®šä¹‰**ï¼š

```text
PMI(w, c) = log P(w, c) / (P(w) P(c))
```

**å«ä¹‰**ï¼š

- PMI > 0ï¼šw å’Œ c æ­£ç›¸å…³ï¼ˆå…±ç°æ¯”éšæœºæœŸæœ›å¤šï¼‰
- PMI = 0ï¼šw å’Œ c ç‹¬ç«‹
- PMI < 0ï¼šw å’Œ c è´Ÿç›¸å…³

**ä¼°è®¡**ï¼š

```text
P(w, c) â‰ˆ count(w, c) / N
P(w) â‰ˆ count(w) / N
P(c) â‰ˆ count(c) / N
```

å› æ­¤ï¼š

```text
PMI(w, c) = log count(w, c) Ã— N / (count(w) Ã— count(c))
```

#### æ­£ç‚¹äº’ä¿¡æ¯ï¼ˆPositive PMI, PPMIï¼‰

**é—®é¢˜**ï¼š

- PMIå¯¹ä½é¢‘å…±ç°ä¸å¯é ï¼ˆå¯èƒ½æ˜¯å¤§è´Ÿæ•°ï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼š

```text
PPMI(w, c) = max(0, PMI(w, c))
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Pointwise Mutual Information](https://en.wikipedia.org/wiki/Pointwise_mutual_information)
- [Church & Hanks, 1990](https://aclanthology.org/J90-1003/) - Word Association Norms, Mutual Information, and Lexicography

### 4. é™ç»´æ–¹æ³•

#### å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰

**ç›®æ ‡**ï¼š

å°†é«˜ç»´ç¨€ç–çŸ©é˜µ X é™ç»´åˆ° k ç»´ç¨ å¯†å‘é‡ã€‚

**æ–¹æ³•**ï¼š

```text
X â‰ˆ U_k Î£_k V_k^T
```

è¯å‘é‡ï¼šU_k çš„è¡Œå‘é‡ï¼ˆæˆ– U_k Î£_k çš„è¡Œå‘é‡ï¼‰ã€‚

#### éè´ŸçŸ©é˜µåˆ†è§£ï¼ˆNMFï¼‰

**çº¦æŸ**ï¼š

```text
X â‰ˆ WH  å…¶ä¸­ W, H â‰¥ 0
```

**ä¼˜åŠ¿**ï¼š

- âœ… å¯è§£é‡Šæ€§æ›´å¼ºï¼ˆéè´Ÿçº¦æŸï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Non-negative Matrix Factorization](https://en.wikipedia.org/wiki/Non-negative_matrix_factorization)

---

## ä»å…±ç°ç»Ÿè®¡åˆ°è¯­ä¹‰è¡¨ç¤º

### 1. Word2Vecçš„éšå«çŸ©é˜µåˆ†è§£

**æƒŠäººå‘ç°**ï¼ˆLevy & Goldberg, 2014ï¼‰ï¼š

> **Word2Vecçš„Skip-Gramæ¨¡å‹å®é™…ä¸Šæ˜¯åœ¨éšå¼åœ°åˆ†è§£ä¸€ä¸ªPMIçŸ©é˜µï¼**

**å½¢å¼åŒ–**ï¼š

Skip-Gramçš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–ï¼š

```text
âˆ‘áµ¢â±¼ log P(câ±¼ | wáµ¢)
```

ç»è¿‡æ¨å¯¼ï¼Œè¿™ç­‰ä»·äºï¼š

```text
ğ’–áµ¢áµ€ ğ’—â±¼ â‰ˆ PMI(wáµ¢, câ±¼) - log k
```

å…¶ä¸­ k æ˜¯è´Ÿé‡‡æ ·æ•°ã€‚

**æ„ä¹‰**ï¼š

- âœ… ç»Ÿä¸€äº†åŸºäºè®¡æ•°å’ŒåŸºäºé¢„æµ‹çš„æ–¹æ³•
- âœ… æ­ç¤ºäº†ç¥ç»ç½‘ç»œæ–¹æ³•çš„ç†è®ºåŸºç¡€

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Levy & Goldberg, 2014](https://papers.nips.cc/paper/2014/hash/feab05aa91085b7a8012516bc3533958-Abstract.html) - Neural Word Embedding as Implicit Matrix Factorization

### 2. GloVeçš„æ˜¾å¼çŸ©é˜µåˆ†è§£

**GloVe**ç›´æ¥ä¼˜åŒ–ï¼š

```text
J = âˆ‘áµ¢â±¼ f(Xáµ¢â±¼) (ğ’–áµ¢áµ€ ğ’—â±¼ + báµ¢ + câ±¼ - log Xáµ¢â±¼)Â²
```

**å«ä¹‰**ï¼š

- è¯å‘é‡çš„å†…ç§¯åº”è¯¥æ¥è¿‘å…±ç°æ¬¡æ•°çš„å¯¹æ•°
- ä½¿ç”¨æƒé‡å‡½æ•° f(x) å‰Šå¼±é«˜é¢‘è¯çš„å½±å“

**æƒé‡å‡½æ•°**ï¼š

```text
f(x) = (x / x_max)^Î±  if x < x_max
     = 1              otherwise
```

å…¸å‹å€¼ï¼šÎ±=0.75, x_max=100

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Pennington et al., 2014](https://nlp.stanford.edu/pubs/glove.pdf) - GloVe: Global Vectors for Word Representation

### 3. ç»Ÿä¸€è§†è§’

**ç»“è®º**ï¼š

> **æ— è®ºæ˜¯åŸºäºè®¡æ•°çš„æ–¹æ³•ï¼ˆLSA, PMIï¼‰ï¼Œè¿˜æ˜¯åŸºäºé¢„æµ‹çš„æ–¹æ³•ï¼ˆWord2Vec, GloVeï¼‰ï¼Œæœ¬è´¨ä¸Šéƒ½æ˜¯åœ¨ä»å…±ç°ç»Ÿè®¡ä¸­æå–è¯­ä¹‰ä¿¡æ¯ã€‚**

**ç»Ÿä¸€æ¡†æ¶**ï¼š

```text
å…±ç°ç»Ÿè®¡ â†’ çŸ©é˜µ/ç›®æ ‡å‡½æ•° â†’ å‘é‡è¡¨ç¤º
  â†“             â†“                â†“
 æ•°æ®        ä¸­é—´è¡¨ç¤º           è¯­ä¹‰
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Baroni et al., 2014](https://aclanthology.org/P14-1023/) - Don't Count, Predict! A Systematic Comparison

---

## åˆ†å¸ƒå¼è¯­ä¹‰çš„å¿ƒç†å­¦åŸºç¡€

### 1. è”ç»“ä¸»ä¹‰ä¸ç¥ç»ç½‘ç»œ

**Connectionism**ï¼ˆè¿æ¥ä¸»ä¹‰ï¼‰ï¼š

- è®¤çŸ¥ç”±ç®€å•å•å…ƒçš„å¤§è§„æ¨¡å¹¶è¡Œè¿æ¥äº§ç”Ÿ
- å¯¹åº”äº**ç¥ç»ç½‘ç»œ**çš„è®¡ç®—æ¨¡å‹

**ä¸åˆ†å¸ƒå¼è¯­ä¹‰çš„è”ç³»**ï¼š

```text
ç¥ç»å…ƒ â†” å‘é‡ç»´åº¦
è¿æ¥æƒé‡ â†” è¯å‘é‡
æ¿€æ´»æ¨¡å¼ â†” è¯­ä¹‰è¡¨ç¤º
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Connectionism](https://en.wikipedia.org/wiki/Connectionism)
- [Rumelhart & McClelland, 1986](https://mitpress.mit.edu/9780262680530/parallel-distributed-processing/) - Parallel Distributed Processing

### 2. åŸå‹ç†è®ºï¼ˆPrototype Theoryï¼‰

**Eleanor Rosch** çš„åŸå‹ç†è®ºï¼š

> **æ¦‚å¿µä¸æ˜¯ç”±å¿…è¦å……åˆ†æ¡ä»¶å®šä¹‰ï¼Œè€Œæ˜¯ç”±å…¸å‹å®ä¾‹ï¼ˆåŸå‹ï¼‰åŠå…¶ç›¸ä¼¼åº¦å®šä¹‰ã€‚**

**ä¾‹å­**ï¼š

- "é¸Ÿ"çš„åŸå‹ï¼šçŸ¥æ›´é¸Ÿã€éº»é›€
- ä¼é¹…æ˜¯"é¸Ÿ"ï¼Œä½†ä¸æ˜¯å…¸å‹çš„é¸Ÿ

**ä¸åˆ†å¸ƒå¼è¯­ä¹‰çš„è”ç³»**ï¼š

```text
åŸå‹ â†” å‘é‡ç©ºé—´ä¸­çš„èšç±»ä¸­å¿ƒ
ç›¸ä¼¼åº¦ â†” å‘é‡è·ç¦»
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Prototype Theory](https://en.wikipedia.org/wiki/Prototype_theory)
- [Rosch, 1973](https://www.sciencedirect.com/science/article/pii/S0022537173800051) - Natural Categories

### 3. æ¦‚å¿µç©ºé—´ï¼ˆConceptual Spacesï¼‰

**Peter GÃ¤rdenfors** çš„æ¦‚å¿µç©ºé—´ç†è®ºï¼š

> **æ¦‚å¿µå¯ä»¥è¡¨ç¤ºä¸ºå‡ ä½•ç©ºé—´ä¸­çš„åŒºåŸŸã€‚**

**ç»´åº¦**ï¼š

- é¢œè‰²ç©ºé—´ï¼šè‰²è°ƒã€é¥±å’Œåº¦ã€äº®åº¦
- å‘³é“ç©ºé—´ï¼šç”œã€é…¸ã€è‹¦ã€å’¸ã€é²œ

**ä¸åˆ†å¸ƒå¼è¯­ä¹‰çš„è”ç³»**ï¼š

- æ¦‚å¿µç©ºé—´ â‰ˆ è¯­ä¹‰å‘é‡ç©ºé—´
- å‡¸åŒºåŸŸ â‰ˆ è¯­ä¹‰èšç±»

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Conceptual Spaces](https://en.wikipedia.org/wiki/Conceptual_space)
- [GÃ¤rdenfors, 2000](https://mitpress.mit.edu/9780262571999/conceptual-spaces/) - Conceptual Spaces: The Geometry of Thought

---

## åˆ†å¸ƒå¼è¯­ä¹‰ vs å½¢å¼è¯­ä¹‰

### å¯¹æ¯”

| ç»´åº¦ | å½¢å¼è¯­ä¹‰å­¦ï¼ˆFormal Semanticsï¼‰ | åˆ†å¸ƒå¼è¯­ä¹‰å­¦ï¼ˆDistributional Semanticsï¼‰ |
|------|-------------------------------|----------------------------------------|
| **åŸºç¡€** | æ¨¡å‹è®ºã€é€»è¾‘å­¦ | ç»Ÿè®¡å­¦ã€å‘é‡ç©ºé—´ |
| **æ„ä¹‰** | çœŸå€¼æ¡ä»¶ã€æŒ‡ç§° | ä½¿ç”¨æ¨¡å¼ã€åˆ†å¸ƒ |
| **è¡¨ç¤º** | é€»è¾‘å…¬å¼ | å‘é‡ |
| **ç»„åˆæ€§** | Î»-æ¼”ç®—ã€å‡½æ•°åº”ç”¨ | å‘é‡è¿ç®—ï¼ˆåŠ ã€å¼ é‡ç§¯ï¼‰ |
| **æ¨ç†** | æ¼”ç»æ¨ç†ï¼ˆModus Ponensï¼‰ | ç›¸ä¼¼åº¦åŒ¹é… |
| **çœŸå‡** | äºŒå€¼ï¼ˆçœŸ/å‡ï¼‰ | è¿ç»­åº¦é‡ |
| **ä¼˜åŠ¿** | ç²¾ç¡®ã€å¯è§£é‡Š | é²æ£’ã€å¯å­¦ä¹  |
| **åŠ£åŠ¿** | è„†å¼±ã€çŸ¥è¯†è·å–ç“¶é¢ˆ | è¿‘ä¼¼ã€ä¸å¯è§£é‡Š |

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Formal Semantics](https://en.wikipedia.org/wiki/Formal_semantics_(linguistics))
- [Boleda & Herbelot, 2016](https://www.aclweb.org/anthology/J16-3001/) - Formal Distributional Semantics: Introduction to the Special Issue

### äº’è¡¥æ€§

**ç°ä»£è¶‹åŠ¿**ï¼šç»“åˆä¸¤è€…ä¼˜åŠ¿ã€‚

**ä¾‹å­**ï¼š

1. **ç¥ç»-ç¬¦å·ç³»ç»Ÿ**ï¼ˆNeurosymbolic AIï¼‰ï¼š

    ```text
    ç¬¦å·æ¨ç† + ç¥ç»è¡¨ç¤º
    ```

2. **æ¦‚ç‡ç¼–ç¨‹**ï¼š

    ```text
    é€»è¾‘ç¨‹åº + æ¦‚ç‡åˆ†å¸ƒ
    ```

3. **çŸ¥è¯†å›¾è°±åµŒå…¥**ï¼š

    ```text
    ä¸‰å…ƒç»„ (head, relation, tail) â†’ å‘é‡è¡¨ç¤º
    ```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Neuro-Symbolic AI](https://en.wikipedia.org/wiki/Neuro-symbolic_AI)

---

## åˆ†å¸ƒå¼è¯­ä¹‰çš„å±€é™æ€§

### 1. åäº‹å®é—®é¢˜ï¼ˆGrounding Problemï¼‰

**é—®é¢˜**ï¼š

> **åˆ†å¸ƒå¼è¯­ä¹‰åªä»è¯­è¨€ä¸­å­¦ä¹ ï¼Œç¼ºä¹å¯¹çœŸå®ä¸–ç•Œçš„"æ¥åœ°"ï¼ˆGroundingï¼‰ã€‚**

**ä¾‹å­**ï¼š

```text
vec(unicorn) å¯ä»¥é€šè¿‡è¯­è¨€å­¦ä¹ 
ä½†"ç‹¬è§’å…½"åœ¨çœŸå®ä¸–ç•Œä¸­ä¸å­˜åœ¨
```

**Searleçš„ä¸­æ–‡æˆ¿é—´è®ºè¯**ï¼š

- ä»…ä»ç¬¦å·æ“ä½œï¼ˆæˆ–åˆ†å¸ƒç»Ÿè®¡ï¼‰æ— æ³•è·å¾—çœŸæ­£çš„"ç†è§£"

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Symbol Grounding Problem](https://en.wikipedia.org/wiki/Symbol_grounding_problem)
- [Searle, 1980](https://en.wikipedia.org/wiki/Chinese_room) - Minds, Brains, and Programs

### 2. ç»„åˆæ€§é—®é¢˜ï¼ˆCompositionality Problemï¼‰

**é—®é¢˜**ï¼š

ç®€å•çš„å‘é‡è¿ç®—ï¼ˆå¦‚åŠ æ³•ï¼‰**ä¸è¶³ä»¥è¡¨è¾¾å¤æ‚çš„è¯­ä¹‰ç»„åˆ**ã€‚

**ä¾‹å­**ï¼š

```text
vec("not happy") â‰  -vec("happy")  ï¼ˆå¦å®šï¼‰
vec("very happy") â‰  2 Ã— vec("happy")  ï¼ˆç¨‹åº¦ï¼‰
```

**è§£å†³å°è¯•**ï¼š

- å¼ é‡ç§¯
- é€’å½’ç¥ç»ç½‘ç»œ
- Transformer

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Coecke et al., 2010](https://arxiv.org/abs/1003.4394) - Mathematical Foundations for a Compositional Distributional Model of Meaning

### 3. é€»è¾‘æ¨ç†é—®é¢˜ï¼ˆLogical Reasoning Problemï¼‰

**é—®é¢˜**ï¼š

åˆ†å¸ƒå¼è¯­ä¹‰ä¸æ”¯æŒ**ä¸¥æ ¼çš„é€»è¾‘æ¨ç†**ã€‚

**ä¾‹å­**ï¼š

```text
å‰æ1ï¼šæ‰€æœ‰äººéƒ½ä¼šæ­»
å‰æ2ï¼šè‹æ ¼æ‹‰åº•æ˜¯äºº
ç»“è®ºï¼šè‹æ ¼æ‹‰åº•ä¼šæ­»  ï¼ˆæ¼”ç»æ¨ç†ï¼‰
```

**åˆ†å¸ƒå¼è¯­ä¹‰çš„å¤±è´¥**ï¼š

```text
cos(vec("Socrates"), vec("mortal")) â‰ˆ 0.6  ï¼ˆåªæ˜¯ç›¸ä¼¼åº¦ï¼Œä¸æ˜¯å¿…ç„¶ï¼‰
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Marcus & Davis, 2019](https://arxiv.org/abs/1906.05833) - Rebooting AI: Building Artificial Intelligence We Can Trust

### 4. åè§æ”¾å¤§é—®é¢˜ï¼ˆBias Amplificationï¼‰

**é—®é¢˜**ï¼š

åˆ†å¸ƒå¼è¯­ä¹‰ä¼š**ç¼–ç å¹¶æ”¾å¤§**è®­ç»ƒæ•°æ®ä¸­çš„ç¤¾ä¼šåè§ã€‚

**ä¾‹å­**ï¼š

```text
vec(programmer) - vec(man) + vec(woman) â‰ˆ vec(homemaker)
```

**åŸå› **ï¼š

è¯­æ–™åº“åæ˜ äº†ç¤¾ä¼šçš„åˆ»æ¿å°è±¡å’Œä¸å¹³ç­‰ã€‚

**ç¼“è§£æ–¹æ³•**ï¼š

- å»åç½®ç®—æ³•
- å¯¹æŠ—è®­ç»ƒ
- æ•°æ®å¹³è¡¡

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Bolukbasi et al., 2016](https://arxiv.org/abs/1607.06520) - Man is to Computer Programmer as Woman is to Homemaker?

---

## æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **ç†è®ºåŸºçŸ³**ï¼šåˆ†å¸ƒå‡è®¾ï¼ˆè¯çš„æ„ä¹‰ç”±å…¶ä¸Šä¸‹æ–‡å†³å®šï¼‰
2. **å“²å­¦åŸºç¡€**ï¼šä½¿ç”¨è®ºï¼ˆWittgensteinï¼‰ã€åˆ†å¸ƒç»“æ„ï¼ˆHarrisï¼‰
3. **å†å²å‘å±•**ï¼šå‘é‡ç©ºé—´æ¨¡å‹ â†’ LSA â†’ Word2Vec â†’ ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤º
4. **æ•°å­¦å½¢å¼åŒ–**ï¼šå…±ç°çŸ©é˜µã€PMIã€çŸ©é˜µåˆ†è§£
5. **ç»Ÿä¸€è§†è§’**ï¼šè®¡æ•°æ–¹æ³•å’Œé¢„æµ‹æ–¹æ³•æœ¬è´¨ç›¸åŒ
6. **å¿ƒç†å­¦åŸºç¡€**ï¼šè¿æ¥ä¸»ä¹‰ã€åŸå‹ç†è®ºã€æ¦‚å¿µç©ºé—´
7. **ä¸å½¢å¼è¯­ä¹‰çš„å¯¹æ¯”**ï¼šäº’è¡¥è€Œéå¯¹ç«‹
8. **å±€é™æ€§**ï¼šæ¥åœ°é—®é¢˜ã€ç»„åˆæ€§ã€é€»è¾‘æ¨ç†ã€åè§

### å“²å­¦åæ€

> **åˆ†å¸ƒå¼è¯­ä¹‰å­¦æ­ç¤ºäº†ä¸€ä¸ªæ·±åˆ»çš„æ´å¯Ÿï¼šæ„ä¹‰ä¸æ˜¯å†…åœ¨çš„ã€å›ºå®šçš„ï¼Œè€Œæ˜¯å…³ç³»çš„ã€æ¶Œç°çš„ã€‚è¯çš„æ„ä¹‰ä¸åœ¨äºå®ƒ"æ˜¯ä»€ä¹ˆ"ï¼Œè€Œåœ¨äºå®ƒ"å¦‚ä½•è¢«ä½¿ç”¨"ã€‚**

### æœªæ¥æ–¹å‘

1. **å¤šæ¨¡æ€æ¥åœ°**ï¼šç»“åˆè§†è§‰ã€å¬è§‰ç­‰æ„ŸçŸ¥ä¿¡æ¯
2. **ç»„åˆè¯­ä¹‰**ï¼šæ›´å¥½çš„è¯­ä¹‰ç»„åˆæœºåˆ¶ï¼ˆå¦‚å¼ é‡ç½‘ç»œï¼‰
3. **ç¥ç»-ç¬¦å·èåˆ**ï¼šç»“åˆåˆ†å¸ƒå¼å’Œå½¢å¼è¯­ä¹‰çš„ä¼˜åŠ¿
4. **å»åç½®**ï¼šæ„å»ºæ›´å…¬å¹³çš„è¯­ä¹‰è¡¨ç¤º

---

## å‚è€ƒæ–‡çŒ®

### åŸºç¡€ç†è®º

1. [Wikipedia: Distributional Semantics](https://en.wikipedia.org/wiki/Distributional_semantics)
2. [Turney & Pantel, 2010](https://www.jair.org/index.php/jair/article/view/10640) - From Frequency to Meaning: Vector Space Models of Semantics
3. [Lenci, 2018](https://www.annualreviews.org/doi/10.1146/annurev-linguistics-030514-125254) - Distributional Models of Word Meaning

### å†å²æ–‡çŒ®

1. [Firth, 1957](https://en.wikipedia.org/wiki/Distributional_semantics) - A Synopsis of Linguistic Theory 1930-1955
2. [Harris, 1954](https://www.jstor.org/stable/411805) - Distributional Structure
3. [Wittgenstein, 1953](https://en.wikipedia.org/wiki/Philosophical_Investigations) - Philosophical Investigations

### ç»å…¸æ–¹æ³•

1. [Wikipedia: Vector Space Model](https://en.wikipedia.org/wiki/Vector_space_model)
2. [Wikipedia: Latent Semantic Analysis](https://en.wikipedia.org/wiki/Latent_semantic_analysis)
3. [Deerwester et al., 1990](https://www.jstor.org/stable/41407138) - Indexing by Latent Semantic Analysis

### ç°ä»£æ–¹æ³•

1. [Mikolov et al., 2013](https://arxiv.org/abs/1301.3781) - Efficient Estimation of Word Representations in Vector Space
2. [Pennington et al., 2014](https://nlp.stanford.edu/pubs/glove.pdf) - GloVe: Global Vectors for Word Representation
3. [Peters et al., 2018](https://arxiv.org/abs/1802.05365) - Deep Contextualized Word Representations
4. [Devlin et al., 2019](https://arxiv.org/abs/1810.04805) - BERT

### ç†è®ºåˆ†æ

1. [Levy & Goldberg, 2014](https://papers.nips.cc/paper/2014/hash/feab05aa91085b7a8012516bc3533958-Abstract.html) - Neural Word Embedding as Implicit Matrix Factorization
2. [Baroni et al., 2014](https://aclanthology.org/P14-1023/) - Don't Count, Predict!

### å¿ƒç†å­¦åŸºç¡€

1. [Wikipedia: Connectionism](https://en.wikipedia.org/wiki/Connectionism)
2. [Wikipedia: Prototype Theory](https://en.wikipedia.org/wiki/Prototype_theory)
3. [GÃ¤rdenfors, 2000](https://mitpress.mit.edu/9780262571999/conceptual-spaces/) - Conceptual Spaces

### å“²å­¦ä¸æ‰¹è¯„

1. [Wikipedia: Chinese Room](https://en.wikipedia.org/wiki/Chinese_room)
2. [Marcus & Davis, 2019](https://arxiv.org/abs/1906.05833) - Rebooting AI
3. [Bolukbasi et al., 2016](https://arxiv.org/abs/1607.06520) - Man is to Computer Programmer as Woman is to Homemaker?

---

*æœ¬æ–‡æ¡£ç³»ç»Ÿé˜è¿°äº†åˆ†å¸ƒå¼è¯­ä¹‰å­¦çš„ç†è®ºåŸºç¡€ã€å†å²å‘å±•å’Œå“²å­¦æ„æ¶µï¼Œä¸ºç†è§£ç°ä»£AIçš„è¯­ä¹‰è¡¨ç¤ºæä¾›äº†å®Œæ•´çš„ç†è®ºæ¡†æ¶ã€‚*
