# åˆ†å¸ƒå¼è¯­ä¹‰å­¦ï¼ˆDistributional Semanticsï¼‰

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0  
> **æœ€åæ›´æ–°**: 2025-10-27  
> **æ–‡æ¡£è§„æ¨¡**: 874è¡Œ | åˆ†å¸ƒå‡è®¾ä¸è¯­ä¹‰è¡¨ç¤ºç†è®º  
> **é˜…è¯»å»ºè®®**: æœ¬æ–‡ç³»ç»Ÿä»‹ç»åˆ†å¸ƒå¼è¯­ä¹‰å­¦ä»ä¼ ç»Ÿåˆ°ç°ä»£çš„æ¼”è¿›ï¼Œæ˜¯ç†è§£è¯åµŒå…¥çš„ç†è®ºåŸºç¡€

---

## æ ¸å¿ƒæ¦‚å¿µæ·±åº¦åˆ†æ

<details>
<summary><b>ğŸ“šğŸ”¤ ç‚¹å‡»å±•å¼€ï¼šåˆ†å¸ƒå¼è¯­ä¹‰å­¦å…¨æ™¯æ·±åº¦è§£æ</b></summary>

æœ¬èŠ‚æ·±å…¥å‰–æFirthåˆ†å¸ƒå‡è®¾ã€ä»VSMåˆ°Word2Vecçš„æ¼”è¿›ã€PPMI vsç¥ç»åµŒå…¥ä¸å“²å­¦åŸºç¡€ã€‚

### 1ï¸âƒ£ åˆ†å¸ƒå¼è¯­ä¹‰å­¦æ¦‚å¿µå®šä¹‰å¡

**æ¦‚å¿µåç§°**: åˆ†å¸ƒå¼è¯­ä¹‰å­¦ï¼ˆDistributional Semanticsï¼‰

**å†…æ¶µï¼ˆæœ¬è´¨å±æ€§ï¼‰**:

**ğŸ”¹ æ ¸å¿ƒå®šä¹‰**:
åˆ†å¸ƒå¼è¯­ä¹‰å­¦åŸºäºåˆ†å¸ƒå‡è®¾â€”â€”"è¯çš„æ„ä¹‰ç”±å…¶æ‰€å¤„çš„è¯­å¢ƒå†³å®š"ï¼ˆFirth, 1957ï¼‰ï¼Œé€šè¿‡ç»Ÿè®¡è¯åœ¨å¤§è§„æ¨¡è¯­æ–™ä¸­çš„ä¸Šä¸‹æ–‡å…±ç°æ¨¡å¼æ¥å­¦ä¹ è¯çš„è¯­ä¹‰è¡¨ç¤ºã€‚

$$
\text{Distributional Semantics} = \underbrace{\text{Context}(w)}_{\text{ä¸Šä¸‹æ–‡å…±ç°}} \Rightarrow \underbrace{\text{Vector}(w)}_{\text{è¯­ä¹‰è¡¨ç¤º}} \Rightarrow \underbrace{\text{Similarity}}_{\text{è¯­ä¹‰å…³ç³»}}
$$

**FirthåŸåˆè¡¨è¿°**ï¼ˆ1957ï¼‰:
> "You shall know a word by the company it keeps."
> "è¯çš„æ„ä¹‰ç”±å…¶æ‰€å¤„çš„è¯­å¢ƒå†³å®šã€‚"

**ğŸ”¹ åˆ†å¸ƒå‡è®¾å½¢å¼åŒ–**:

| ç‰ˆæœ¬ | è¡¨è¿° | æ¥æº | æ•°å­¦å½¢å¼ |
|------|------|------|---------|
| **Firth** | "company it keeps" | 1957 | Context(w) â†’ Meaning(w) |
| **Harris** | "ç›¸ä¼¼åˆ†å¸ƒâ†’ç›¸ä¼¼æ„ä¹‰" | 1954 | Context(wâ‚) â‰ˆ Context(wâ‚‚) â‡’ Meaning(wâ‚) â‰ˆ Meaning(wâ‚‚) |
| **Wittgenstein** | "æ„ä¹‰å³ä½¿ç”¨" | 1953 | Meaning = Usage in language game |
| **ç°ä»£** | "å…±ç°â†’å‘é‡â†’ç›¸ä¼¼åº¦" | 2010s | $\text{sim}(v_{w_1}, v_{w_2}) \propto P(\text{context similar})$ |

**å¤–å»¶ï¼ˆèŒƒå›´è¾¹ç•Œï¼‰**:

| ç»´åº¦ | åˆ†å¸ƒå¼è¯­ä¹‰åŒ…å« âœ… | ä¸åŒ…å« âŒ |
|------|--------------|----------|
| **æ–¹æ³•** | VSM, LSA, Word2Vec, GloVe | å½¢å¼è¯­ä¹‰ã€çŸ¥è¯†å›¾è°± |
| **æ•°æ®** | è¯­æ–™ç»Ÿè®¡ã€å…±ç°çŸ©é˜µ | è¯å…¸å®šä¹‰ã€é€»è¾‘è§„åˆ™ |
| **è¡¨ç¤º** | å‘é‡ã€åµŒå…¥ | ç¬¦å·ã€é€»è¾‘å¼ |

**å±æ€§ç»´åº¦è¡¨**:

| ç»´åº¦ | å€¼/æè¿° | è¯´æ˜ |
|------|---------|------|
| **ç†è®ºåŸºç¡€** | Firthåˆ†å¸ƒå‡è®¾ (1957) | æ ¸å¿ƒå“²å­¦ |
| **æ¼”è¿›å†ç¨‹** | VSM (1970s) â†’ LSA (1990s) â†’ Word2Vec (2013) | ä¸‰ä»£æ¼”åŒ– |
| **æ ¸å¿ƒä¼˜åŠ¿** | æ•°æ®é©±åŠ¨ã€å¯å­¦ä¹ ã€å¯æ‰©å±• | vs äººå·¥å®šä¹‰ |
| **å±€é™æ€§** | Groundingé—®é¢˜ã€é€»è¾‘æ¨ç†å¼± | å“²å­¦æŒ‘æˆ˜ |

---

### 2ï¸âƒ£ åˆ†å¸ƒå¼è¯­ä¹‰å­¦å…¨æ™¯å›¾è°±

```mermaid
graph TB
    DS[åˆ†å¸ƒå¼è¯­ä¹‰å­¦<br/>Distributional Semantics]
    
    DS --> CoreIdea[æ ¸å¿ƒæ€æƒ³:<br/>You shall know a word by the company it keeps]
    
    CoreIdea --> DH[åˆ†å¸ƒå‡è®¾<br/>Distributional Hypothesis]
    
    DH --> Firth[Firth 1957:<br/>company it keeps]
    DH --> Harris[Harris 1954:<br/>ç›¸ä¼¼åˆ†å¸ƒâ†’ç›¸ä¼¼æ„ä¹‰]
    DH --> Witt[Wittgenstein 1953:<br/>æ„ä¹‰å³ä½¿ç”¨]
    
    Evolution[å†å²æ¼”è¿›]
    
    Evolution --> Era1[ç¬¬ä¸€ä»£:<br/>å‘é‡ç©ºé—´æ¨¡å‹<br/>1970s-1990s]
    Evolution --> Era2[ç¬¬äºŒä»£:<br/>æ½œåœ¨è¯­ä¹‰åˆ†æ<br/>1990s-2000s]
    Evolution --> Era3[ç¬¬ä¸‰ä»£:<br/>ç¥ç»è¯åµŒå…¥<br/>2010s+]
    
    Era1 --> VSM[VSM<br/>Salton 1975]
    Era1 --> TFIDF[TF-IDF<br/>åŠ æƒç»Ÿè®¡]
    
    Era2 --> LSA[LSA<br/>SVDé™ç»´]
    Era2 --> HAL[HAL<br/>çª—å£å…±ç°]
    
    Era3 --> W2V[Word2Vec 2013<br/>ç¥ç»ç½‘ç»œ]
    Era3 --> GloVe[GloVe 2014<br/>å…¨å±€ç»Ÿè®¡]
    Era3 --> BERT[BERT 2018<br/>ä¸Šä¸‹æ–‡åŒ–]
    
    Math[æ•°å­¦å½¢å¼åŒ–]
    
    Math --> Context[ä¸Šä¸‹æ–‡å®šä¹‰]
    Math --> CoMatrix[å…±ç°çŸ©é˜µ]
    Math --> Weighting[åŠ æƒæ–¹æ¡ˆ]
    Math --> Dimension[é™ç»´æ–¹æ³•]
    
    Context --> FixedWindow[å›ºå®šçª—å£:<br/>w_{i-k}, ..., w_{i+k}]
    Context --> Dependency[ä¾å­˜å¥æ³•:<br/>è¯­æ³•å…³ç³»]
    
    CoMatrix --> RawCount[åŸå§‹è®¡æ•°:<br/>C&#40;w,c&#41;]
    
    Weighting --> PMI[ç‚¹äº’ä¿¡æ¯:<br/>PMI&#40;w,c&#41;]
    Weighting --> PPMI[æ­£PMI:<br/>max&#40;PMI,0&#41;]
    
    PMI --> PMIFormula[log P&#40;w,c&#41; / P&#40;w&#41;P&#40;c&#41;]
    
    Dimension --> SVD[SVD:<br/>çŸ©é˜µåˆ†è§£]
    Dimension --> NMF[NMF:<br/>éè´Ÿåˆ†è§£]
    
    Theory[ç†è®ºè”ç³»]
    
    Theory --> W2VTheory[Word2Vec = éšå¼çŸ©é˜µåˆ†è§£<br/>Levy & Goldberg 2014]
    Theory --> GloVeTheory[GloVe = æ˜¾å¼çŸ©é˜µåˆ†è§£<br/>åŠ æƒæœ€å°äºŒä¹˜]
    Theory --> Unified[ç»Ÿä¸€è§†è§’:<br/>å…±ç°ç»Ÿè®¡ â‰ˆ ç¥ç»åµŒå…¥]
    
    Limitations[å±€é™æ€§]
    
    Limitations --> Grounding[Groundingé—®é¢˜:<br/>ç¬¦å·-æ„ŸçŸ¥é¸¿æ²Ÿ]
    Limitations --> Compositionality[ç»„åˆæ€§é—®é¢˜:<br/>çŸ­è¯­æ„ä¹‰]
    Limitations --> Logic[é€»è¾‘æ¨ç†å¼±:<br/>è•´å«ã€çŸ›ç›¾]
    Limitations --> Bias[åè§æ”¾å¤§:<br/>è¯­æ–™åè§]
    
    Philosophy[å“²å­¦åŸºç¡€]
    Philosophy --> Connectionism[è”ç»“ä¸»ä¹‰:<br/>åˆ†å¸ƒå¼è¡¨ç¤º]
    Philosophy --> Prototype[åŸå‹ç†è®º:<br/>å®¶æ—ç›¸ä¼¼]
    Philosophy --> ConceptSpace[æ¦‚å¿µç©ºé—´:<br/>å‡ ä½•åŒ–è¯­ä¹‰]
    
    style DS fill:#9b59b6,stroke:#333,stroke-width:4px
    style Evolution fill:#3498db,stroke:#333,stroke-width:4px
    style Math fill:#2ecc71,stroke:#333,stroke-width:4px
    style Limitations fill:#e74c3c,stroke:#333,stroke-width:4px
```

---

### 3ï¸âƒ£ åˆ†å¸ƒå¼è¯­ä¹‰ä¸‰ä»£æ¼”è¿›æ·±åº¦å¯¹æ¯”

| ç»´åº¦ | ç¬¬ä¸€ä»£VSM (1970s) | ç¬¬äºŒä»£LSA (1990s) | ç¬¬ä¸‰ä»£ç¥ç»åµŒå…¥ (2010s+) | æ¼”è¿›æ„ä¹‰ |
|------|----------------|----------------|-------------------|---------|
| **æ ¸å¿ƒæ–¹æ³•** | TF-IDFå‘é‡ | SVDé™ç»´ | Skip-gram/CBOW | ä»ç¨€ç–åˆ°ç¨ å¯† |
| **è¡¨ç¤ºå½¢å¼** | ç¨€ç–å‘é‡ | ç¨ å¯†å‘é‡ï¼ˆSVDï¼‰ | ç¨ å¯†å‘é‡ï¼ˆç¥ç»ï¼‰ | è®¡ç®—æ•ˆç‡æå‡ |
| **ç»´åº¦** | $\|V\|$ï¼ˆé«˜ç»´ï¼‰| d~300ï¼ˆä¸­ç»´ï¼‰ | d~300ï¼ˆä¸­ç»´ï¼‰ | ç»´åº¦å‹ç¼© |
| **å…±ç°ç»Ÿè®¡** | æ˜¾å¼è®¡æ•° | æ˜¾å¼çŸ©é˜µåˆ†è§£ | éšå¼ç¥ç»å­¦ä¹  | ä»æ˜¾å¼åˆ°éšå¼ |
| **è®­ç»ƒ** | âŒ æ— å­¦ä¹  | SVDï¼ˆä¸€æ¬¡ï¼‰ | SGDï¼ˆè¿­ä»£ï¼‰ | ä»æ‰¹å¤„ç†åˆ°åœ¨çº¿ |
| **å¯æ‰©å±•æ€§** | ä¸­ï¼ˆçŸ©é˜µå¤§ï¼‰ | ä½ï¼ˆSVDæ…¢ï¼‰ | âœ…âœ…âœ… é«˜ï¼ˆGPUå¹¶è¡Œï¼‰ | è§„æ¨¡é©å‘½ |
| **è¯­ä¹‰æ•æ‰** | è¯é¢‘ä¸ºä¸» | æ½œåœ¨è¯­ä¹‰ | æ·±å±‚è¯­ä¹‰ | è¯­ä¹‰æ·±åº¦æå‡ |
| **ç±»æ¯”æ¨ç†** | âŒ ä¸æ”¯æŒ | âš ï¸ éƒ¨åˆ†æ”¯æŒ | âœ… å¼ºæ”¯æŒ | king-man+woman=queen |
| **ä¸Šä¸‹æ–‡åŒ–** | âŒ é™æ€ | âŒ é™æ€ | âœ… åŠ¨æ€ï¼ˆBERT+ï¼‰ | å¤šä¹‰è¯å¤„ç† |
| **ä»£è¡¨å·¥å…·** | Lucene, TF-IDF | MATLAB SVD | Word2Vec, BERT | å·¥å…·ç”Ÿæ€ |

**æ•°å­¦è¯¦è§£**:

$$
\begin{align}
\text{ç¬¬ä¸€ä»£VSMï¼ˆTF-IDFï¼‰} &: \\
\text{TF-IDF}(w, d) &= \text{TF}(w, d) \times \text{IDF}(w) \\
\text{TF}(w, d) &= \frac{\text{count}(w, d)}{\sum_{w'} \text{count}(w', d)} \\
\text{IDF}(w) &= \log \frac{|D|}{|\{d: w \in d\}|} \\
\\
\text{ç¬¬äºŒä»£LSAï¼ˆSVDï¼‰} &: \\
X &= U \Sigma V^T \quad \text{ï¼ˆSVDåˆ†è§£ï¼‰} \\
X_k &= U_k \Sigma_k V_k^T \quad \text{ï¼ˆä¿ç•™å‰kç»´ï¼‰} \\
v_w &= U_k[w, :] \quad \text{ï¼ˆè¯å‘é‡ï¼‰} \\
\\
\text{ç¬¬ä¸‰ä»£Word2Vecï¼ˆSkip-gramï¼‰} &: \\
\max_\theta &\sum_{w \in \mathcal{V}} \sum_{c \in \text{Context}(w)} \log P(c | w; \theta) \\
P(c | w) &= \frac{\exp(v_w^T v_c)}{\sum_{c'} \exp(v_w^T v_{c'})}
\end{align}
$$

**æ·±åº¦åˆ†æ**:

```yaml
ç¬¬ä¸€ä»£: å‘é‡ç©ºé—´æ¨¡å‹ï¼ˆ1970s-1990sï¼‰
  Salton's VSM (1975):
    æ ¸å¿ƒæ€æƒ³:
      - å°†æ–‡æ¡£/è¯è¡¨ç¤ºä¸ºå‘é‡
      - å‘é‡ç»´åº¦=è¯è¡¨å¤§å°
      - ç›¸ä¼¼åº¦=ä½™å¼¦ç›¸ä¼¼åº¦
    
    TF-IDFæƒé‡:
      - TFï¼ˆè¯é¢‘ï¼‰: é‡è¦è¯å‡ºç°å¤š
      - IDFï¼ˆé€†æ–‡æ¡£é¢‘ç‡ï¼‰: ç½•è§è¯æ›´é‡è¦
      - å¹³è¡¡å±€éƒ¨é‡è¦æ€§ä¸å…¨å±€åŒºåˆ†æ€§
    
    ä¼˜åŠ¿:
      - ç®€å•ç›´è§‚
      - å¯è§£é‡Šæ€§å¼º
      - ä¿¡æ¯æ£€ç´¢æœ‰æ•ˆ
    
    å±€é™:
      - ç¨€ç–é«˜ç»´
      - æ— è¯­ä¹‰æ³›åŒ–ï¼ˆ"car"ä¸"automobile"ç‹¬ç«‹ï¼‰
      - ç»´åº¦ç¾éš¾

ç¬¬äºŒä»£: æ½œåœ¨è¯­ä¹‰åˆ†æï¼ˆ1990s-2000sï¼‰
  LSA/LSI (Landauer & Dumais, 1997):
    æ ¸å¿ƒæ€æƒ³:
      - å…±ç°çŸ©é˜µXï¼ˆè¯Ã—æ–‡æ¡£ï¼‰
      - SVDé™ç»´: X = UÎ£V^T
      - ä¿ç•™å‰kä¸ªå¥‡å¼‚å€¼ï¼ˆk~300ï¼‰
    
    é©å‘½æ€§è´¡çŒ®:
      - ç¨ å¯†è¡¨ç¤ºï¼ˆvs ç¨€ç–ï¼‰
      - æ½œåœ¨è¯­ä¹‰ï¼ˆvs è¡¨å±‚è¯é¢‘ï¼‰
      - æ³›åŒ–èƒ½åŠ›ï¼ˆåŒä¹‰è¯èšç±»ï¼‰
    
    æ•°å­¦ä¼˜é›…æ€§:
      - æœ€ä¼˜ä½ç§©é€¼è¿‘ï¼ˆFrobeniusèŒƒæ•°ï¼‰
      - ||X - X_k||_Fæœ€å°
      - ç†è®ºä¿è¯
    
    å±€é™:
      - SVDè®¡ç®—O(mnÂ²)ï¼ˆæ…¢ï¼‰
      - éå¢é‡ï¼ˆæ–°æ–‡æ¡£éœ€é‡ç®—ï¼‰
      - è´Ÿå€¼å­˜åœ¨ï¼ˆæ¦‚ç‡è§£é‡Šå›°éš¾ï¼‰

ç¬¬ä¸‰ä»£: ç¥ç»è¯åµŒå…¥ï¼ˆ2010s+ï¼‰
  Word2Vec (Mikolov et al., 2013):
    æ ¸å¿ƒæ€æƒ³:
      - ç¥ç»ç½‘ç»œé¢„æµ‹ä¸Šä¸‹æ–‡
      - Skip-gram: è¯â†’ä¸Šä¸‹æ–‡
      - CBOW: ä¸Šä¸‹æ–‡â†’è¯
    
    Levy & Goldberg (2014)ç†è®º:
      - Word2Vec â‰ˆ éšå¼çŸ©é˜µåˆ†è§£
      - ç­‰ä»·äºåˆ†è§£Shifted PPMIçŸ©é˜µ
      - PMI(w,c) - log k (k=è´Ÿé‡‡æ ·æ•°)
    
    é©å‘½æ€§ä¼˜åŠ¿:
      - å¯æ‰©å±•ï¼ˆSGD, GPUå¹¶è¡Œï¼‰
      - å¢é‡å­¦ä¹ ï¼ˆåœ¨çº¿æ›´æ–°ï¼‰
      - ç±»æ¯”æ¨ç†ï¼ˆå‘é‡è¿ç®—ï¼‰
      - è¯­ä¹‰ç»„åˆï¼ˆking - man + woman â‰ˆ queenï¼‰
    
    æŠ€æœ¯åˆ›æ–°:
      - è´Ÿé‡‡æ ·ï¼ˆNegative Samplingï¼‰
      - å±‚æ¬¡Softmax
      - äºšé‡‡æ ·ï¼ˆé«˜é¢‘è¯ä¸‹é‡‡æ ·ï¼‰
  
  GloVe (Pennington et al., 2014):
    æ ¸å¿ƒæ€æƒ³:
      - æ˜¾å¼å…¨å±€å…±ç°ç»Ÿè®¡
      - åŠ æƒæœ€å°äºŒä¹˜ç›®æ ‡
      - ç»“åˆå±€éƒ¨çª—å£+å…¨å±€ç»Ÿè®¡
    
    æŸå¤±å‡½æ•°:
      J = Î£ f(X_ij)(v_i^T v_j - log X_ij)Â²
      f(x) = (x/x_max)^Î± if x < x_max else 1
    
    ä¼˜åŠ¿:
      - åˆ©ç”¨å…¨å±€ç»Ÿè®¡ï¼ˆvs Word2Vecå±€éƒ¨ï¼‰
      - å¯è§£é‡Šæ€§ï¼ˆæ˜¾å¼å…±ç°ï¼‰
      - ç†è®ºé€æ˜
  
  BERT (Devlin et al., 2018):
    æ ¸å¿ƒé©å‘½:
      - ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤ºï¼ˆvs é™æ€ï¼‰
      - åŒä¸€è¯ä¸åŒä¸Šä¸‹æ–‡â†’ä¸åŒå‘é‡
      - è§£å†³å¤šä¹‰è¯é—®é¢˜
    
    ç¤ºä¾‹:
      "bank"åœ¨"river bank"vs"savings bank"
      â†’ ä¸¤ä¸ªä¸åŒçš„å‘é‡
    
    æ„ä¹‰:
      - åˆ†å¸ƒå¼è¯­ä¹‰çš„ç»ˆæå½¢å¼
      - çœŸæ­£æ•æ‰"æ„ä¹‰å³ä½¿ç”¨"

æ¼”è¿›çš„æ·±å±‚é€»è¾‘:
  ç¨€ç–â†’ç¨ å¯†:
    - TF-IDF: ç¨€ç–ï¼ˆ|V|ç»´ï¼Œ99%é›¶å…ƒç´ ï¼‰
    - Word2Vec: ç¨ å¯†ï¼ˆ300ç»´ï¼Œå…¨éé›¶ï¼‰
    â†’ ä¿¡æ¯å‹ç¼©+è®¡ç®—æ•ˆç‡
  
  æ˜¾å¼â†’éšå¼:
    - LSA: æ˜¾å¼çŸ©é˜µåˆ†è§£
    - Word2Vec: éšå¼ç¥ç»å­¦ä¹ 
    â†’ ç«¯åˆ°ç«¯ä¼˜åŒ–
  
  é™æ€â†’åŠ¨æ€:
    - Word2Vec: æ¯è¯ä¸€å‘é‡
    - BERT: æ¯è¯Ã—ä¸Šä¸‹æ–‡ä¸€å‘é‡
    â†’ å¤šä¹‰è¯å¤„ç†

ç»Ÿä¸€è§†è§’ï¼ˆLevy et al., 2015ï¼‰:
  ç»“è®º: ç»å…¸æ–¹æ³•â‰ˆç¥ç»æ–¹æ³•
    - Word2Vec â‰ˆ Shifted PPMIçŸ©é˜µåˆ†è§£
    - GloVe â‰ˆ åŠ æƒå…±ç°çŸ©é˜µåˆ†è§£
    â†’ æœ¬è´¨éƒ½æ˜¯å…±ç°ç»Ÿè®¡
  
  åŒºåˆ«åœ¨äº:
    - ä¼˜åŒ–ç›®æ ‡ï¼ˆæ˜¾å¼vséšå¼ï¼‰
    - è®¡ç®—æ•ˆç‡ï¼ˆæ‰¹å¤„ç†vsåœ¨çº¿ï¼‰
    - å·¥ç¨‹å®ç°ï¼ˆSVD vs SGDï¼‰
```

---

### 4ï¸âƒ£ PPMI vs ç¥ç»åµŒå…¥æ·±åº¦å¯¹æ¯”

**ç‚¹äº’ä¿¡æ¯ï¼ˆPMIï¼‰å½¢å¼åŒ–**:

$$
\begin{align}
\text{PMI}(w, c) &= \log \frac{P(w, c)}{P(w) P(c)} \\
&= \log \frac{\#(w, c) \cdot |D|}{\#(w) \cdot \#(c)} \\
\\
\text{PPMI}(w, c) &= \max(0, \text{PMI}(w, c))
\end{align}
$$

**PPMI vs Word2Vecç†è®ºè”ç³»**ï¼ˆLevy & Goldberg, 2014ï¼‰:

$$
\begin{align}
\text{Word2Vecç›®æ ‡} &\approx \text{çŸ©é˜µåˆ†è§£} \\
v_w^T v_c &\approx \text{PMI}(w, c) - \log k \\
\text{where } k &= \text{è´Ÿé‡‡æ ·æ•°}
\end{align}
$$

| ç»´åº¦ | PPMIçŸ©é˜µåˆ†è§£ | Word2Vecç¥ç»åµŒå…¥ | å…³é”®å·®å¼‚ |
|------|------------|----------------|---------|
| **ç»Ÿè®¡** | æ˜¾å¼å…±ç°çŸ©é˜µ | éšå¼ç¥ç»é¢„æµ‹ | æ˜¾å¼vséšå¼ |
| **ä¼˜åŒ–** | SVDï¼ˆæ‰¹å¤„ç†ï¼‰ | SGDï¼ˆåœ¨çº¿ï¼‰ | æ‰¹vsåœ¨çº¿ |
| **å¯æ‰©å±•æ€§** | ä½ï¼ˆO(nÂ³)ï¼‰ | é«˜ï¼ˆGPUå¹¶è¡Œï¼‰ | è§„æ¨¡é™åˆ¶ |
| **è´Ÿå€¼** | âœ… æœ‰ï¼ˆPMIå¯è´Ÿï¼‰ | âŒ æ— ï¼ˆåµŒå…¥å®æ•°ï¼‰ | æ¦‚ç‡è§£é‡Š |
| **ç†è®ºä¿è¯** | âœ… å¼ºï¼ˆæœ€ä¼˜ä½ç§©ï¼‰ | âš ï¸ å¼±ï¼ˆå±€éƒ¨æœ€ä¼˜ï¼‰ | ç†è®ºvså®è·µ |
| **å®è·µæ€§èƒ½** | ä¸­ | âœ…âœ…âœ… å¼º | å®è·µä¸»å¯¼ |

**æ·±åº¦åˆ†æ**:

```yaml
PPMIï¼ˆæ­£ç‚¹äº’ä¿¡æ¯ï¼‰:
  å®šä¹‰:
    PMI(w,c) = log [P(w,c) / (P(w)Â·P(c))]
    æµ‹é‡: å®é™…å…±ç° vs ç‹¬ç«‹å‡è®¾
  
  è§£é‡Š:
    PMI > 0: wå’Œcæ­£ç›¸å…³ï¼ˆå…±ç°å¤šäºé¢„æœŸï¼‰
    PMI = 0: wå’Œcç‹¬ç«‹
    PMI < 0: wå’Œcè´Ÿç›¸å…³ï¼ˆå…±ç°å°‘äºé¢„æœŸï¼‰
  
  PPMI = max(0, PMI):
    æˆªæ–­è´Ÿå€¼ï¼ˆè´Ÿå…±ç°ä¿¡æ¯å¯é æ€§ä½ï¼‰
  
  ä¼˜åŠ¿:
    - ç†è®ºé€æ˜ï¼ˆä¿¡æ¯è®ºï¼‰
    - å¯è§£é‡Šæ€§å¼º
    - æ•°å­¦ä¼˜é›…
  
  é—®é¢˜:
    - ç¨€ç–æ€§ï¼ˆå¤§éƒ¨åˆ†PPMI=0ï¼‰
    - è®¡ç®—æ˜‚è´µï¼ˆ|V|Ã—|V|çŸ©é˜µï¼‰
    - SVDæ…¢ï¼ˆO(nÂ³)ï¼‰

Word2Vecçš„éšå¼PPMI:
  Levy & Goldberg (2014)è¯æ˜:
    Word2Vec Skip-gram with Negative Sampling
    â‰ˆ åˆ†è§£çŸ©é˜µMï¼Œå…¶ä¸­
    M_ij = PMI(w_i, c_j) - log k
    k = è´Ÿé‡‡æ ·æ•°
  
  å«ä¹‰:
    - Word2Vecä¸æ˜¯"é»‘ç›’"
    - å®è´¨æ˜¯çŸ©é˜µåˆ†è§£
    - ä½†é€šè¿‡ç¥ç»ç½‘ç»œéšå¼å®ç°
  
  ä¼˜åŠ¿:
    - ä¸éœ€æ˜¾å¼æ„é€ å·¨å¤§çŸ©é˜µ
    - SGDåœ¨çº¿ä¼˜åŒ–
    - GPUå¹¶è¡ŒåŠ é€Ÿ
    - å¯æ‰©å±•åˆ°äº¿çº§è¯è¡¨

å®è·µå¯¹æ¯”ï¼ˆLevy et al., 2015ï¼‰:
  å®éªŒç»“è®º:
    ç»è¿‡è¶…å‚æ•°è°ƒä¼˜å:
      PPMI+SVD â‰ˆ Word2Vec â‰ˆ GloVe
    
    æ€§èƒ½å·®å¼‚ä¸»è¦æ¥è‡ª:
      - è¶…å‚æ•°è®¾ç½®
      - è¯­æ–™å¤§å°
      - ä¸Šä¸‹æ–‡çª—å£
      è€Œéç®—æ³•æœ¬è´¨
  
  æ·±å±‚å¯ç¤º:
    - æ ¸å¿ƒéƒ½æ˜¯å…±ç°ç»Ÿè®¡
    - ç¥ç»æ–¹æ³•çš„ä¼˜åŠ¿åœ¨å·¥ç¨‹å®ç°
    - ä¸æ˜¯æ–°åŸç†ï¼Œæ˜¯æ–°å·¥å…·

å½“å‰å…±è¯†ï¼ˆ2024ï¼‰:
  - Word2Vecä¸»å¯¼å®è·µï¼ˆæ˜“ç”¨+å¿«é€Ÿï¼‰
  - PPMIä¿ç•™ç†è®ºä»·å€¼ï¼ˆå¯è§£é‡Šï¼‰
  - BERTè¶…è¶Šä¸¤è€…ï¼ˆä¸Šä¸‹æ–‡åŒ–ï¼‰
```

---

### ğŸ”Ÿ æ ¸å¿ƒæ´å¯Ÿä¸ç»ˆæè¯„ä¼°

**äº”å¤§æ ¸å¿ƒå®šå¾‹**:

1. **Firthåˆ†å¸ƒå‡è®¾å®šå¾‹**ï¼ˆ1957ï¼‰
   $$
   \text{Context}(w_1) \approx \text{Context}(w_2) \Rightarrow \text{Meaning}(w_1) \approx \text{Meaning}(w_2)
   $$
   - "You shall know a word by the company it keeps"

2. **å…±ç°-è¯­ä¹‰å¯¹åº”å®šå¾‹**
   $$
   \text{Co-occurrence patterns} \xrightarrow{\text{å­¦ä¹ }} \text{Semantic vectors}
   $$
   - ç»Ÿè®¡å…±ç°æ•æ‰è¯­ä¹‰å…³ç³»

3. **Word2VecçŸ©é˜µåˆ†è§£ç­‰ä»·å®šå¾‹**ï¼ˆLevy & Goldberg 2014ï¼‰
   $$
   v_w^T v_c \approx \text{PMI}(w, c) - \log k
   $$
   - ç¥ç»åµŒå…¥â‰ˆéšå¼çŸ©é˜µåˆ†è§£

4. **ç±»æ¯”æ¨ç†å®šå¾‹**
   $$
   v_{\text{king}} - v_{\text{man}} + v_{\text{woman}} \approx v_{\text{queen}}
   $$
   - å‘é‡è¿ç®—å®ç°è¯­ä¹‰ç±»æ¯”

5. **ä¸Šä¸‹æ–‡åŒ–é©å‘½å®šå¾‹**ï¼ˆBERT 2018ï¼‰
   $$
   \text{é™æ€åµŒå…¥} \Rightarrow \text{åŠ¨æ€åµŒå…¥}(w, \text{context})
   $$
   - å¤šä¹‰è¯çš„ç»ˆæè§£å†³

**ç»ˆææ´å¯Ÿ**:

> **"åˆ†å¸ƒå¼è¯­ä¹‰å­¦æ˜¯ç°ä»£NLPçš„ç†è®ºåŸºçŸ³ï¼ŒåŸºäºFirthçš„æ·±åˆ»æ´è§ï¼š'è¯çš„æ„ä¹‰ç”±å…¶æ‰€å¤„çš„è¯­å¢ƒå†³å®š'ï¼ˆ1957ï¼‰ã€‚æ ¸å¿ƒå‡è®¾ï¼šåœ¨ç›¸ä¼¼ä¸Šä¸‹æ–‡ä¸­å‡ºç°çš„è¯å…·æœ‰ç›¸ä¼¼æ„ä¹‰ï¼ˆåˆ†å¸ƒå‡è®¾ï¼‰ã€‚ä¸‰ä»£æ¼”è¿›ï¼šâ‘ VSM/TF-IDFï¼ˆ1970sï¼‰ï¼šç¨€ç–å‘é‡ã€è¯é¢‘ç»Ÿè®¡â‘¡LSA/SVDï¼ˆ1990sï¼‰ï¼šç¨ å¯†è¡¨ç¤ºã€æ½œåœ¨è¯­ä¹‰ã€çŸ©é˜µåˆ†è§£â‘¢Word2Vec/GloVe/BERTï¼ˆ2010s+ï¼‰ï¼šç¥ç»åµŒå…¥ã€ç±»æ¯”æ¨ç†ã€ä¸Šä¸‹æ–‡åŒ–ã€‚æ•°å­¦æ ¸å¿ƒï¼šå…±ç°çŸ©é˜µâ†’PPMIåŠ æƒâ†’é™ç»´/ç¥ç»å­¦ä¹ â†’è¯­ä¹‰å‘é‡ã€‚Levy & Goldberg (2014)è¯æ˜Word2Vecâ‰ˆéšå¼PMIçŸ©é˜µåˆ†è§£ï¼Œæ­ç¤ºç¥ç»æ–¹æ³•æœ¬è´¨ä»æ˜¯å…±ç°ç»Ÿè®¡ã€‚å…³é”®çªç ´ï¼šâ‘ ä»ç¨€ç–åˆ°ç¨ å¯†ï¼ˆè®¡ç®—æ•ˆç‡ï¼‰â‘¡ä»æ˜¾å¼åˆ°éšå¼ï¼ˆç«¯åˆ°ç«¯å­¦ä¹ ï¼‰â‘¢ä»é™æ€åˆ°åŠ¨æ€ï¼ˆBERTå¤šä¹‰è¯å¤„ç†ï¼‰ã€‚ç±»æ¯”æ¨ç†èƒ½åŠ›ï¼šking - man + woman â‰ˆ queenï¼Œæ˜¯åˆ†å¸ƒå¼è¯­ä¹‰ç‹¬æœ‰çš„æ¶Œç°èƒ½åŠ›ã€‚å±€é™æ€§ï¼šâ‘ Groundingé—®é¢˜ï¼ˆç¬¦å·-æ„ŸçŸ¥é¸¿æ²Ÿï¼‰â‘¡ç»„åˆæ€§å¼±ï¼ˆçŸ­è¯­æ„ä¹‰ï¼‰â‘¢é€»è¾‘æ¨ç†å·®ï¼ˆè•´å«ã€çŸ›ç›¾ï¼‰â‘£åè§æ”¾å¤§ï¼ˆè¯­æ–™åè§ï¼‰ã€‚å“²å­¦åŸºç¡€ï¼šè”ç»“ä¸»ä¹‰ã€åŸå‹ç†è®ºã€Wittgensteinä½¿ç”¨è®ºã€‚ç»Ÿä¸€è§†è§’ï¼šæ‰€æœ‰æ–¹æ³•æœ¬è´¨éƒ½æ˜¯å…±ç°ç»Ÿè®¡çš„ä¸åŒå½¢å¼ï¼Œå·®å¼‚åœ¨å·¥ç¨‹å®ç°è€Œéæ ¸å¿ƒåŸç†ã€‚å½“å‰ä¸»å¯¼ï¼šBERTç­‰ä¸Šä¸‹æ–‡åŒ–åµŒå…¥ï¼Œä½†Word2Vecä»æ˜¯é™æ€åµŒå…¥æ ‡å‡†ã€‚åˆ†å¸ƒå¼è¯­ä¹‰å­¦å°†è¯­ä¹‰å‡ ä½•åŒ–ï¼Œä½¿NLPä»ç¬¦å·æ“ä½œè½¬å‘å‘é‡è®¡ç®—ï¼Œæ˜¯æ·±åº¦å­¦ä¹ é©å‘½çš„ç†è®ºåŸºç¡€ã€‚"**

**å…ƒè®¤çŸ¥**:
- **æ ¸å¿ƒå“²å­¦**: Firthåˆ†å¸ƒå‡è®¾ï¼ˆ1957ï¼‰
- **æ¼”è¿›è·¯å¾„**: ç¨€ç–â†’ç¨ å¯†ã€æ˜¾å¼â†’éšå¼ã€é™æ€â†’åŠ¨æ€
- **ç†è®ºè”ç³»**: ç¥ç»â‰ˆçŸ©é˜µåˆ†è§£ï¼ˆLevy 2014ï¼‰
- **ä»£è¡¨æ–¹æ³•**: Word2Vec, GloVe, BERT
- **å…³é”®èƒ½åŠ›**: ç±»æ¯”æ¨ç†ã€è¯­ä¹‰ç›¸ä¼¼
- **å±€é™æ€§**: Groundingã€ç»„åˆæ€§ã€é€»è¾‘æ¨ç†
- **æœªæ¥æ–¹å‘**: ç¥ç»ç¬¦å·æ··åˆã€å¤šæ¨¡æ€Grounding

</details>

---

## ğŸ“‹ ç›®å½•

- [æ ¸å¿ƒæ¦‚å¿µæ·±åº¦åˆ†æ](#æ ¸å¿ƒæ¦‚å¿µæ·±åº¦åˆ†æ)
- [ç›®å½• | Table of Contents](#ç›®å½•-table-of-contents)
- [å¼•è¨€](#å¼•è¨€)
  - [æ ¸å¿ƒæ€æƒ³](#æ ¸å¿ƒæ€æƒ³)
  - [ä¸ä¼ ç»Ÿè¯­ä¹‰å­¦çš„å¯¹æ¯”](#ä¸ä¼ ç»Ÿè¯­ä¹‰å­¦çš„å¯¹æ¯”)
- [åˆ†å¸ƒå‡è®¾ï¼šç†è®ºåŸºçŸ³](#åˆ†å¸ƒå‡è®¾ç†è®ºåŸºçŸ³)
  - [1. Firthçš„åŸåˆè¡¨è¿°ï¼ˆ1957ï¼‰](#1-firthçš„åŸåˆè¡¨è¿°1957)
  - [2. Harrisçš„åˆ†å¸ƒå‡è®¾ï¼ˆ1954ï¼‰](#2-harrisçš„åˆ†å¸ƒå‡è®¾1954)
  - [3. Wittgensteinçš„ä½¿ç”¨è®ºï¼ˆ1953ï¼‰](#3-wittgensteinçš„ä½¿ç”¨è®º1953)
  - [4. ç°ä»£å½¢å¼åŒ–](#4-ç°ä»£å½¢å¼åŒ–)
- [åˆ†å¸ƒå¼è¯­ä¹‰çš„å†å²å‘å±•](#åˆ†å¸ƒå¼è¯­ä¹‰çš„å†å²å‘å±•)
  - [1. æ—©æœŸï¼šå‘é‡ç©ºé—´æ¨¡å‹ï¼ˆ1970s-1990sï¼‰](#1-æ—©æœŸå‘é‡ç©ºé—´æ¨¡å‹1970s-1990s)
    - [Saltonçš„å‘é‡ç©ºé—´æ¨¡å‹ï¼ˆ1975ï¼‰](#saltonçš„å‘é‡ç©ºé—´æ¨¡å‹1975)
    - [TF-IDFï¼ˆTerm Frequency-Inverse Document Frequencyï¼‰](#tf-idfterm-frequency-inverse-document-frequency)
  - [2. ä¸­æœŸï¼šæ½œåœ¨è¯­ä¹‰åˆ†æï¼ˆ1990sï¼‰](#2-ä¸­æœŸæ½œåœ¨è¯­ä¹‰åˆ†æ1990s)
    - [LSAï¼ˆLatent Semantic Analysis, 1990ï¼‰](#lsalatent-semantic-analysis-1990)
  - [3. ç°ä»£ï¼šç¥ç»è¯åµŒå…¥ï¼ˆ2010sï¼‰](#3-ç°ä»£ç¥ç»è¯åµŒå…¥2010s)
    - [Word2Vecï¼ˆ2013ï¼‰](#word2vec2013)
    - [GloVeï¼ˆ2014ï¼‰](#glove2014)
    - [ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤ºï¼ˆ2018+ï¼‰](#ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤º2018)
- [åˆ†å¸ƒå¼è¯­ä¹‰çš„æ•°å­¦å½¢å¼åŒ–](#åˆ†å¸ƒå¼è¯­ä¹‰çš„æ•°å­¦å½¢å¼åŒ–)
  - [1. ä¸Šä¸‹æ–‡å®šä¹‰](#1-ä¸Šä¸‹æ–‡å®šä¹‰)
    - [å›ºå®šçª—å£ä¸Šä¸‹æ–‡](#å›ºå®šçª—å£ä¸Šä¸‹æ–‡)
    - [ä¾å­˜å¥æ³•ä¸Šä¸‹æ–‡](#ä¾å­˜å¥æ³•ä¸Šä¸‹æ–‡)
  - [2. å…±ç°çŸ©é˜µï¼ˆCo-occurrence Matrixï¼‰](#2-å…±ç°çŸ©é˜µco-occurrence-matrix)
    - [åŸå§‹è®¡æ•°çš„é—®é¢˜](#åŸå§‹è®¡æ•°çš„é—®é¢˜)
  - [3. åŠ æƒæ–¹æ¡ˆ](#3-åŠ æƒæ–¹æ¡ˆ)
    - [ç‚¹äº’ä¿¡æ¯ï¼ˆPointwise Mutual Information, PMIï¼‰](#ç‚¹äº’ä¿¡æ¯pointwise-mutual-information-pmi)
    - [æ­£ç‚¹äº’ä¿¡æ¯ï¼ˆPositive PMI, PPMIï¼‰](#æ­£ç‚¹äº’ä¿¡æ¯positive-pmi-ppmi)
  - [4. é™ç»´æ–¹æ³•](#4-é™ç»´æ–¹æ³•)
    - [å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰](#å¥‡å¼‚å€¼åˆ†è§£svd)
    - [éè´ŸçŸ©é˜µåˆ†è§£ï¼ˆNMFï¼‰](#éè´ŸçŸ©é˜µåˆ†è§£nmf)
- [ä»å…±ç°ç»Ÿè®¡åˆ°è¯­ä¹‰è¡¨ç¤º](#ä»å…±ç°ç»Ÿè®¡åˆ°è¯­ä¹‰è¡¨ç¤º)
  - [1. Word2Vecçš„éšå«çŸ©é˜µåˆ†è§£](#1-word2vecçš„éšå«çŸ©é˜µåˆ†è§£)
  - [2. GloVeçš„æ˜¾å¼çŸ©é˜µåˆ†è§£](#2-gloveçš„æ˜¾å¼çŸ©é˜µåˆ†è§£)
  - [3. ç»Ÿä¸€è§†è§’](#3-ç»Ÿä¸€è§†è§’)
- [åˆ†å¸ƒå¼è¯­ä¹‰çš„å¿ƒç†å­¦åŸºç¡€](#åˆ†å¸ƒå¼è¯­ä¹‰çš„å¿ƒç†å­¦åŸºç¡€)
  - [1. è”ç»“ä¸»ä¹‰ä¸ç¥ç»ç½‘ç»œ](#1-è”ç»“ä¸»ä¹‰ä¸ç¥ç»ç½‘ç»œ)
  - [2. åŸå‹ç†è®ºï¼ˆPrototype Theoryï¼‰](#2-åŸå‹ç†è®ºprototype-theory)
  - [3. æ¦‚å¿µç©ºé—´ï¼ˆConceptual Spacesï¼‰](#3-æ¦‚å¿µç©ºé—´conceptual-spaces)
- [åˆ†å¸ƒå¼è¯­ä¹‰ vs å½¢å¼è¯­ä¹‰](#åˆ†å¸ƒå¼è¯­ä¹‰-vs-å½¢å¼è¯­ä¹‰)
  - [å¯¹æ¯”](#å¯¹æ¯”)
  - [äº’è¡¥æ€§](#äº’è¡¥æ€§)
- [åˆ†å¸ƒå¼è¯­ä¹‰çš„å±€é™æ€§](#åˆ†å¸ƒå¼è¯­ä¹‰çš„å±€é™æ€§)
  - [1. åäº‹å®é—®é¢˜ï¼ˆGrounding Problemï¼‰](#1-åäº‹å®é—®é¢˜grounding-problem)
  - [2. ç»„åˆæ€§é—®é¢˜ï¼ˆCompositionality Problemï¼‰](#2-ç»„åˆæ€§é—®é¢˜compositionality-problem)
  - [3. é€»è¾‘æ¨ç†é—®é¢˜ï¼ˆLogical Reasoning Problemï¼‰](#3-é€»è¾‘æ¨ç†é—®é¢˜logical-reasoning-problem)
  - [4. åè§æ”¾å¤§é—®é¢˜ï¼ˆBias Amplificationï¼‰](#4-åè§æ”¾å¤§é—®é¢˜bias-amplification)
- [æ€»ç»“](#æ€»ç»“)
  - [æ ¸å¿ƒè¦ç‚¹](#æ ¸å¿ƒè¦ç‚¹)
  - [å“²å­¦åæ€](#å“²å­¦åæ€)
  - [æœªæ¥æ–¹å‘](#æœªæ¥æ–¹å‘)
- [å‚è€ƒæ–‡çŒ®](#å‚è€ƒæ–‡çŒ®)
  - [åŸºç¡€ç†è®º](#åŸºç¡€ç†è®º)
  - [å†å²æ–‡çŒ®](#å†å²æ–‡çŒ®)
  - [ç»å…¸æ–¹æ³•](#ç»å…¸æ–¹æ³•)
  - [ç°ä»£æ–¹æ³•](#ç°ä»£æ–¹æ³•)
  - [ç†è®ºåˆ†æ](#ç†è®ºåˆ†æ)
  - [å¿ƒç†å­¦åŸºç¡€](#å¿ƒç†å­¦åŸºç¡€)
  - [å“²å­¦ä¸æ‰¹è¯„](#å“²å­¦ä¸æ‰¹è¯„)
- [å¯¼èˆª | Navigation](#å¯¼èˆª-navigation)
- [ç›¸å…³ä¸»é¢˜ | Related Topics](#ç›¸å…³ä¸»é¢˜-related-topics)
  - [æœ¬ç« èŠ‚](#æœ¬ç« èŠ‚)
  - [ç›¸å…³ç« èŠ‚](#ç›¸å…³ç« èŠ‚)
  - [è·¨è§†è§’é“¾æ¥](#è·¨è§†è§’é“¾æ¥)

---

## å¼•è¨€

**åˆ†å¸ƒå¼è¯­ä¹‰å­¦**ï¼ˆDistributional Semanticsï¼‰æ˜¯ç°ä»£è‡ªç„¶è¯­è¨€å¤„ç†å’ŒAIçš„ç†è®ºåŸºç¡€ï¼Œå®ƒåŸºäºä¸€ä¸ªç®€å•è€Œæ·±åˆ»çš„æ€æƒ³ï¼š

> **"You shall know a word by the company it keeps."**
>
> **"è¯çš„æ„ä¹‰ç”±å…¶æ‰€å¤„çš„è¯­å¢ƒå†³å®šã€‚"**
>
> â€” J. R. Firth (1957)

### æ ¸å¿ƒæ€æƒ³

**åˆ†å¸ƒå‡è®¾**ï¼ˆDistributional Hypothesisï¼‰è®¤ä¸ºï¼š

> **åœ¨ç›¸ä¼¼ä¸Šä¸‹æ–‡ä¸­å‡ºç°çš„è¯å…·æœ‰ç›¸ä¼¼çš„æ„ä¹‰ã€‚**

å½¢å¼åŒ–ï¼š

```text
Context(wâ‚) â‰ˆ Context(wâ‚‚)  â‡’  Meaning(wâ‚) â‰ˆ Meaning(wâ‚‚)
```

### ä¸ä¼ ç»Ÿè¯­ä¹‰å­¦çš„å¯¹æ¯”

| ç»´åº¦ | å½¢å¼è¯­ä¹‰å­¦ | åˆ†å¸ƒå¼è¯­ä¹‰å­¦ | å‚è€ƒæ–‡çŒ® |
|------|-----------|-------------|----------|
| **æ„ä¹‰æ¥æº** | é€»è¾‘å…¬å¼ã€çœŸå€¼æ¡ä»¶ | è¯­è¨€ä½¿ç”¨çš„ç»Ÿè®¡æ¨¡å¼ | [Wittgenstein, 1953](https://en.wikipedia.org/wiki/Philosophical_Investigations) |
| **è¡¨ç¤ºæ–¹å¼** | ç¬¦å·ã€è°“è¯é€»è¾‘ | å‘é‡ã€çŸ©é˜µ | [Turney & Pantel, 2010](https://www.jair.org/index.php/jair/article/view/10640) |
| **å­¦ä¹ æ–¹å¼** | äººå·¥å®šä¹‰ | ä»æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹  | [Mikolov et al., 2013](https://arxiv.org/abs/1301.3781) |
| **å“²å­¦åŸºç¡€** | æŒ‡ç§°è®ºï¼ˆReference Theoryï¼‰ | ä½¿ç”¨è®ºï¼ˆUse Theoryï¼‰ | [Wikipedia: Meaning (philosophy of language)](https://en.wikipedia.org/wiki/Meaning_(philosophy_of_language)) |

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Distributional Semantics](https://en.wikipedia.org/wiki/Distributional_semantics)
- [Turney & Pantel, 2010](https://www.jair.org/index.php/jair/article/view/10640) - From Frequency to Meaning: Vector Space Models of Semantics

---

## åˆ†å¸ƒå‡è®¾ï¼šç†è®ºåŸºçŸ³

### 1. Firthçš„åŸåˆè¡¨è¿°ï¼ˆ1957ï¼‰

**J. R. Firth** åœ¨1957å¹´æå‡ºï¼š

> **"You shall know a word by the company it keeps."**

**å«ä¹‰**ï¼š

- è¯çš„æ„ä¹‰ä¸æ˜¯å†…åœ¨çš„ã€å›ºå®šçš„
- è¯çš„æ„ä¹‰æ¥è‡ªäºå®ƒçš„**åˆ†å¸ƒ**ï¼ˆåœ¨è¯­æ–™åº“ä¸­çš„ä½¿ç”¨æ¨¡å¼ï¼‰

**ä¾‹å­**ï¼š

```text
"cat" å¸¸å‡ºç°åœ¨ä»¥ä¸‹ä¸Šä¸‹æ–‡ä¸­ï¼š
  - "I have a ___."
  - "The ___ is sleeping."
  - "Feed the ___."
  - "___ and dog"

"dog" ä¹Ÿå¸¸å‡ºç°åœ¨ç±»ä¼¼ä¸Šä¸‹æ–‡ä¸­
â‡’ "cat" å’Œ "dog" æ„ä¹‰ç›¸è¿‘
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Firth, 1957](https://en.wikipedia.org/wiki/Distributional_semantics) - A Synopsis of Linguistic Theory 1930-1955

### 2. Harrisçš„åˆ†å¸ƒå‡è®¾ï¼ˆ1954ï¼‰

**Zellig Harris** æ›´æ—©æå‡ºäº†ç±»ä¼¼æ€æƒ³ï¼š

> **"Difference in meaning correlates with difference in distribution."**
>
> **"æ„ä¹‰çš„å·®å¼‚å¯¹åº”äºåˆ†å¸ƒçš„å·®å¼‚ã€‚"**

**æ•°å­¦ç›´è§‰**ï¼š

```text
Meaning : Words â†’ SemanticSpace
Distribution : Words â†’ ContextSpace

åˆ†å¸ƒå‡è®¾ï¼šMeaning âˆ Distribution
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Harris, 1954](https://www.jstor.org/stable/411805) - Distributional Structure

### 3. Wittgensteinçš„ä½¿ç”¨è®ºï¼ˆ1953ï¼‰

**Ludwig Wittgenstein** åœ¨ã€Šå“²å­¦ç ”ç©¶ã€‹ä¸­æå‡ºï¼š

> **"The meaning of a word is its use in the language."**
>
> **"è¯çš„æ„ä¹‰å°±æ˜¯å®ƒåœ¨è¯­è¨€ä¸­çš„ä½¿ç”¨ã€‚"**

**å“²å­¦åŸºç¡€**ï¼š

- æ‹’ç»**æŒ‡ç§°è®º**ï¼ˆè¯çš„æ„ä¹‰=å®ƒæ‰€æŒ‡çš„å¯¹è±¡ï¼‰
- æå‡º**ä½¿ç”¨è®º**ï¼ˆè¯çš„æ„ä¹‰=å®ƒçš„ä½¿ç”¨æ–¹å¼ï¼‰

**ä¸åˆ†å¸ƒå‡è®¾çš„è”ç³»**ï¼š

```text
ä½¿ç”¨ï¼ˆUseï¼‰ â†’ åˆ†å¸ƒï¼ˆDistributionï¼‰ â†’ å‘é‡ï¼ˆVectorï¼‰
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Philosophical Investigations](https://en.wikipedia.org/wiki/Philosophical_Investigations)
- [Wikipedia: Use Theory](https://en.wikipedia.org/wiki/Use_theory)

### 4. ç°ä»£å½¢å¼åŒ–

**å®šä¹‰ï¼ˆåˆ†å¸ƒå‡è®¾ï¼‰**ï¼š

è®¾ï¼š

- Î£ï¼šè¯æ±‡è¡¨
- Context(w)ï¼šè¯ w çš„ä¸Šä¸‹æ–‡åˆ†å¸ƒ

åˆ™åˆ†å¸ƒå‡è®¾æ–­è¨€ï¼š

```text
âˆ€wâ‚, wâ‚‚ âˆˆ Î£ : d_context(Context(wâ‚), Context(wâ‚‚)) â‰ˆ d_semantic(Meaning(wâ‚), Meaning(wâ‚‚))
```

å…¶ä¸­ï¼š

- d_contextï¼šä¸Šä¸‹æ–‡åˆ†å¸ƒçš„è·ç¦»åº¦é‡
- d_semanticï¼šè¯­ä¹‰è·ç¦»åº¦é‡

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Lenci, 2018](https://www.annualreviews.org/doi/10.1146/annurev-linguistics-030514-125254) - Distributional Models of Word Meaning

---

## åˆ†å¸ƒå¼è¯­ä¹‰çš„å†å²å‘å±•

### 1. æ—©æœŸï¼šå‘é‡ç©ºé—´æ¨¡å‹ï¼ˆ1970s-1990sï¼‰

#### Saltonçš„å‘é‡ç©ºé—´æ¨¡å‹ï¼ˆ1975ï¼‰

**åº”ç”¨äºä¿¡æ¯æ£€ç´¢**ï¼š

- æ–‡æ¡£è¡¨ç¤ºä¸ºè¯çš„å‘é‡
- æŸ¥è¯¢-æ–‡æ¡£åŒ¹é…ç”¨ä½™å¼¦ç›¸ä¼¼åº¦

```text
doc = [tfâ‚, tfâ‚‚, ..., tf|V|]  ï¼ˆè¯é¢‘å‘é‡ï¼‰
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Vector Space Model](https://en.wikipedia.org/wiki/Vector_space_model)
- [Salton et al., 1975](https://dl.acm.org/doi/10.1145/361219.361220) - A Vector Space Model for Automatic Indexing

#### TF-IDFï¼ˆTerm Frequency-Inverse Document Frequencyï¼‰

**å…¬å¼**ï¼š

```text
TF-IDF(w, d) = TF(w, d) Ã— IDF(w)

TF(w, d) = count(w in d) / |d|
IDF(w) = log(N / DF(w))
```

å…¶ä¸­ï¼š

- Nï¼šæ–‡æ¡£æ€»æ•°
- DF(w)ï¼šåŒ…å«è¯ w çš„æ–‡æ¡£æ•°

**ç›´è§‰**ï¼š

- âœ… åœ¨æŸæ–‡æ¡£ä¸­é¢‘ç¹å‡ºç°çš„è¯é‡è¦ï¼ˆTFï¼‰
- âœ… åœ¨æ‰€æœ‰æ–‡æ¡£ä¸­éƒ½å‡ºç°çš„è¯ä¸é‡è¦ï¼ˆIDFï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)

### 2. ä¸­æœŸï¼šæ½œåœ¨è¯­ä¹‰åˆ†æï¼ˆ1990sï¼‰

#### LSAï¼ˆLatent Semantic Analysis, 1990ï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼š

ç”¨**å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰**é™ç»´ï¼Œå‘ç°æ½œåœ¨è¯­ä¹‰ç»“æ„ã€‚

**æ–¹æ³•**ï¼š

1. æ„å»ºè¯-æ–‡æ¡£çŸ©é˜µ X âˆˆ â„|V|Ã—D
2. SVDåˆ†è§£ï¼šX â‰ˆ U Î£ Váµ€
3. ä¿ç•™å‰ k ä¸ªå¥‡å¼‚å€¼ï¼šX_k = U_k Î£_k V_k^T
4. è¯å‘é‡ï¼šU_k çš„è¡Œå‘é‡

**ä¼˜åŠ¿**ï¼š

- âœ… å‘ç°åŒä¹‰è¯ï¼ˆé€šè¿‡ä½ç§©è¿‘ä¼¼ï¼‰
- âœ… é™ä½ç»´åº¦ï¼ˆä» |V| é™åˆ° kï¼‰

**å±€é™**ï¼š

- âŒ è®¡ç®—æˆæœ¬é«˜ï¼ˆSVDæ˜¯ O(mnÂ²)ï¼‰
- âŒ éš¾ä»¥å¤„ç†æ–°è¯ï¼ˆéœ€è¦é‡æ–°åˆ†è§£ï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Latent Semantic Analysis](https://en.wikipedia.org/wiki/Latent_semantic_analysis)
- [Deerwester et al., 1990](https://www.jstor.org/stable/41407138) - Indexing by Latent Semantic Analysis

### 3. ç°ä»£ï¼šç¥ç»è¯åµŒå…¥ï¼ˆ2010sï¼‰

#### Word2Vecï¼ˆ2013ï¼‰

**é©å‘½æ€§çªç ´**ï¼š

- ç”¨ç¥ç»ç½‘ç»œå­¦ä¹ è¯å‘é‡
- æ•æ‰è¯­ä¹‰ç±»æ¯”å…³ç³»

```text
vec(king) - vec(man) + vec(woman) â‰ˆ vec(queen)
```

**ä¸¤ç§æ¶æ„**ï¼š

1. **CBOW**ï¼ˆContinuous Bag-of-Wordsï¼‰ï¼š

    ```text
    P(wâ‚œ | wâ‚œâ‚‹â‚™, ..., wâ‚œâ‚‹â‚, wâ‚œâ‚Šâ‚, ..., wâ‚œâ‚Šâ‚™)
    ```

    ä»ä¸Šä¸‹æ–‡é¢„æµ‹ä¸­å¿ƒè¯

2. **Skip-Gram**ï¼š

    ```text
    P(wâ‚œâ‚‹â‚™, ..., wâ‚œâ‚‹â‚, wâ‚œâ‚Šâ‚, ..., wâ‚œâ‚Šâ‚™ | wâ‚œ)
    ```

ä»ä¸­å¿ƒè¯é¢„æµ‹ä¸Šä¸‹æ–‡

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Mikolov et al., 2013](https://arxiv.org/abs/1301.3781) - Efficient Estimation of Word Representations in Vector Space
- [Wikipedia: Word2vec](https://en.wikipedia.org/wiki/Word2vec)

#### GloVeï¼ˆ2014ï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼š

ç»“åˆ**å…¨å±€ç»Ÿè®¡ä¿¡æ¯**ï¼ˆå…±ç°çŸ©é˜µï¼‰å’Œ**å±€éƒ¨é¢„æµ‹**ï¼ˆWord2Vecï¼‰ã€‚

**ç›®æ ‡å‡½æ•°**ï¼š

```text
J = âˆ‘áµ¢â±¼ f(Xáµ¢â±¼) (ğ’–áµ¢áµ€ ğ’—â±¼ + báµ¢ + câ±¼ - log Xáµ¢â±¼)Â²
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Pennington et al., 2014](https://nlp.stanford.edu/pubs/glove.pdf) - GloVe: Global Vectors for Word Representation

#### ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤ºï¼ˆ2018+ï¼‰

**ELMo, BERT, GPT**ï¼š

- æ¯ä¸ªè¯çš„å‘é‡**ä¾èµ–äºä¸Šä¸‹æ–‡**
- è§£å†³äº†ä¸€è¯å¤šä¹‰é—®é¢˜

```text
vec("bank", "river bank") â‰  vec("bank", "bank account")
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Peters et al., 2018](https://arxiv.org/abs/1802.05365) - Deep Contextualized Word Representations
- [Devlin et al., 2019](https://arxiv.org/abs/1810.04805) - BERT

---

## åˆ†å¸ƒå¼è¯­ä¹‰çš„æ•°å­¦å½¢å¼åŒ–

### 1. ä¸Šä¸‹æ–‡å®šä¹‰

#### å›ºå®šçª—å£ä¸Šä¸‹æ–‡

**å®šä¹‰**ï¼š

è¯ w åœ¨ä½ç½® t çš„**ä¸Šä¸‹æ–‡**æ˜¯å…¶å‰å n ä¸ªè¯ï¼š

```text
Context(wâ‚œ) = {wâ‚œâ‚‹â‚™, ..., wâ‚œâ‚‹â‚, wâ‚œâ‚Šâ‚, ..., wâ‚œâ‚Šâ‚™}
```

**ä¾‹å­**ï¼ˆn=2ï¼‰ï¼š

```text
å¥å­ï¼š"The cat sat on the mat"
Context(sat) = {cat, the, on, the}
```

#### ä¾å­˜å¥æ³•ä¸Šä¸‹æ–‡

**å®šä¹‰**ï¼š

è¯ w çš„ä¸Šä¸‹æ–‡æ˜¯ä¸å®ƒæœ‰**å¥æ³•ä¾å­˜å…³ç³»**çš„è¯ï¼š

```text
Context(w) = {(r, w') | (w, r, w') âˆˆ Dependencies}
```

**ä¾‹å­**ï¼š

```text
"The cat sat on the mat"
Context(sat) = {(nsubj, cat), (prep, on)}
```

**ä¼˜åŠ¿**ï¼š

- âœ… æ•æ‰é•¿è·ç¦»ä¾èµ–
- âœ… æ›´ç²¾ç¡®çš„è¯­æ³•ä¿¡æ¯

**å‚è€ƒæ–‡çŒ®**ï¼š

- [PadÃ³ & Lapata, 2007](https://aclanthology.org/J07-4004/) - Dependency-Based Construction of Semantic Space Models

### 2. å…±ç°çŸ©é˜µï¼ˆCo-occurrence Matrixï¼‰

**å®šä¹‰**ï¼š

**å…±ç°çŸ©é˜µ** X âˆˆ â„|V|Ã—|C| è®°å½•è¯ä¸ä¸Šä¸‹æ–‡çš„å…±ç°æ¬¡æ•°ï¼š

```text
Xáµ¢â±¼ = count(word i appears with context j)
```

**ä¸¤ç§ç±»å‹**ï¼š

1. **è¯-æ–‡æ¡£çŸ©é˜µ**ï¼šC = æ–‡æ¡£é›†
2. **è¯-è¯çŸ©é˜µ**ï¼šC = è¯æ±‡è¡¨ï¼ˆçª—å£å†…å…±ç°ï¼‰

#### åŸå§‹è®¡æ•°çš„é—®é¢˜

**é—®é¢˜**ï¼š

- âŒ é«˜é¢‘è¯ä¸»å¯¼ï¼ˆå¦‚"the", "is"ï¼‰
- âŒ ç¨€ç–æ€§ï¼ˆå¤§éƒ¨åˆ†å…ƒç´ æ˜¯0ï¼‰
- âŒ ç»´åº¦ç¾éš¾ï¼ˆ|V| Ã— |V| å¾ˆå¤§ï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼šåŠ æƒå’Œé™ç»´ã€‚

### 3. åŠ æƒæ–¹æ¡ˆ

#### ç‚¹äº’ä¿¡æ¯ï¼ˆPointwise Mutual Information, PMIï¼‰

**å®šä¹‰**ï¼š

```text
PMI(w, c) = log P(w, c) / (P(w) P(c))
```

**å«ä¹‰**ï¼š

- PMI > 0ï¼šw å’Œ c æ­£ç›¸å…³ï¼ˆå…±ç°æ¯”éšæœºæœŸæœ›å¤šï¼‰
- PMI = 0ï¼šw å’Œ c ç‹¬ç«‹
- PMI < 0ï¼šw å’Œ c è´Ÿç›¸å…³

**ä¼°è®¡**ï¼š

```text
P(w, c) â‰ˆ count(w, c) / N
P(w) â‰ˆ count(w) / N
P(c) â‰ˆ count(c) / N
```

å› æ­¤ï¼š

```text
PMI(w, c) = log count(w, c) Ã— N / (count(w) Ã— count(c))
```

#### æ­£ç‚¹äº’ä¿¡æ¯ï¼ˆPositive PMI, PPMIï¼‰

**é—®é¢˜**ï¼š

- PMIå¯¹ä½é¢‘å…±ç°ä¸å¯é ï¼ˆå¯èƒ½æ˜¯å¤§è´Ÿæ•°ï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼š

```text
PPMI(w, c) = max(0, PMI(w, c))
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Pointwise Mutual Information](https://en.wikipedia.org/wiki/Pointwise_mutual_information)
- [Church & Hanks, 1990](https://aclanthology.org/J90-1003/) - Word Association Norms, Mutual Information, and Lexicography

### 4. é™ç»´æ–¹æ³•

#### å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰

**ç›®æ ‡**ï¼š

å°†é«˜ç»´ç¨€ç–çŸ©é˜µ X é™ç»´åˆ° k ç»´ç¨ å¯†å‘é‡ã€‚

**æ–¹æ³•**ï¼š

```text
X â‰ˆ U_k Î£_k V_k^T
```

è¯å‘é‡ï¼šU_k çš„è¡Œå‘é‡ï¼ˆæˆ– U_k Î£_k çš„è¡Œå‘é‡ï¼‰ã€‚

#### éè´ŸçŸ©é˜µåˆ†è§£ï¼ˆNMFï¼‰

**çº¦æŸ**ï¼š

```text
X â‰ˆ WH  å…¶ä¸­ W, H â‰¥ 0
```

**ä¼˜åŠ¿**ï¼š

- âœ… å¯è§£é‡Šæ€§æ›´å¼ºï¼ˆéè´Ÿçº¦æŸï¼‰

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Non-negative Matrix Factorization](https://en.wikipedia.org/wiki/Non-negative_matrix_factorization)

---

## ä»å…±ç°ç»Ÿè®¡åˆ°è¯­ä¹‰è¡¨ç¤º

### 1. Word2Vecçš„éšå«çŸ©é˜µåˆ†è§£

**æƒŠäººå‘ç°**ï¼ˆLevy & Goldberg, 2014ï¼‰ï¼š

> **Word2Vecçš„Skip-Gramæ¨¡å‹å®é™…ä¸Šæ˜¯åœ¨éšå¼åœ°åˆ†è§£ä¸€ä¸ªPMIçŸ©é˜µï¼**

**å½¢å¼åŒ–**ï¼š

Skip-Gramçš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–ï¼š

```text
âˆ‘áµ¢â±¼ log P(câ±¼ | wáµ¢)
```

ç»è¿‡æ¨å¯¼ï¼Œè¿™ç­‰ä»·äºï¼š

```text
ğ’–áµ¢áµ€ ğ’—â±¼ â‰ˆ PMI(wáµ¢, câ±¼) - log k
```

å…¶ä¸­ k æ˜¯è´Ÿé‡‡æ ·æ•°ã€‚

**æ„ä¹‰**ï¼š

- âœ… ç»Ÿä¸€äº†åŸºäºè®¡æ•°å’ŒåŸºäºé¢„æµ‹çš„æ–¹æ³•
- âœ… æ­ç¤ºäº†ç¥ç»ç½‘ç»œæ–¹æ³•çš„ç†è®ºåŸºç¡€

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Levy & Goldberg, 2014](https://papers.nips.cc/paper/2014/hash/feab05aa91085b7a8012516bc3533958-Abstract.html) - Neural Word Embedding as Implicit Matrix Factorization

### 2. GloVeçš„æ˜¾å¼çŸ©é˜µåˆ†è§£

**GloVe**ç›´æ¥ä¼˜åŒ–ï¼š

```text
J = âˆ‘áµ¢â±¼ f(Xáµ¢â±¼) (ğ’–áµ¢áµ€ ğ’—â±¼ + báµ¢ + câ±¼ - log Xáµ¢â±¼)Â²
```

**å«ä¹‰**ï¼š

- è¯å‘é‡çš„å†…ç§¯åº”è¯¥æ¥è¿‘å…±ç°æ¬¡æ•°çš„å¯¹æ•°
- ä½¿ç”¨æƒé‡å‡½æ•° f(x) å‰Šå¼±é«˜é¢‘è¯çš„å½±å“

**æƒé‡å‡½æ•°**ï¼š

```text
f(x) = (x / x_max)^Î±  if x < x_max
     = 1              otherwise
```

å…¸å‹å€¼ï¼šÎ±=0.75, x_max=100

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Pennington et al., 2014](https://nlp.stanford.edu/pubs/glove.pdf) - GloVe: Global Vectors for Word Representation

### 3. ç»Ÿä¸€è§†è§’

**ç»“è®º**ï¼š

> **æ— è®ºæ˜¯åŸºäºè®¡æ•°çš„æ–¹æ³•ï¼ˆLSA, PMIï¼‰ï¼Œè¿˜æ˜¯åŸºäºé¢„æµ‹çš„æ–¹æ³•ï¼ˆWord2Vec, GloVeï¼‰ï¼Œæœ¬è´¨ä¸Šéƒ½æ˜¯åœ¨ä»å…±ç°ç»Ÿè®¡ä¸­æå–è¯­ä¹‰ä¿¡æ¯ã€‚**

**ç»Ÿä¸€æ¡†æ¶**ï¼š

```text
å…±ç°ç»Ÿè®¡ â†’ çŸ©é˜µ/ç›®æ ‡å‡½æ•° â†’ å‘é‡è¡¨ç¤º
  â†“             â†“                â†“
 æ•°æ®        ä¸­é—´è¡¨ç¤º           è¯­ä¹‰
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Baroni et al., 2014](https://aclanthology.org/P14-1023/) - Don't Count, Predict! A Systematic Comparison

---

## åˆ†å¸ƒå¼è¯­ä¹‰çš„å¿ƒç†å­¦åŸºç¡€

### 1. è”ç»“ä¸»ä¹‰ä¸ç¥ç»ç½‘ç»œ

**Connectionism**ï¼ˆè¿æ¥ä¸»ä¹‰ï¼‰ï¼š

- è®¤çŸ¥ç”±ç®€å•å•å…ƒçš„å¤§è§„æ¨¡å¹¶è¡Œè¿æ¥äº§ç”Ÿ
- å¯¹åº”äº**ç¥ç»ç½‘ç»œ**çš„è®¡ç®—æ¨¡å‹

**ä¸åˆ†å¸ƒå¼è¯­ä¹‰çš„è”ç³»**ï¼š

```text
ç¥ç»å…ƒ â†” å‘é‡ç»´åº¦
è¿æ¥æƒé‡ â†” è¯å‘é‡
æ¿€æ´»æ¨¡å¼ â†” è¯­ä¹‰è¡¨ç¤º
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Connectionism](https://en.wikipedia.org/wiki/Connectionism)
- [Rumelhart & McClelland, 1986](https://mitpress.mit.edu/9780262680530/parallel-distributed-processing/) - Parallel Distributed Processing

### 2. åŸå‹ç†è®ºï¼ˆPrototype Theoryï¼‰

**Eleanor Rosch** çš„åŸå‹ç†è®ºï¼š

> **æ¦‚å¿µä¸æ˜¯ç”±å¿…è¦å……åˆ†æ¡ä»¶å®šä¹‰ï¼Œè€Œæ˜¯ç”±å…¸å‹å®ä¾‹ï¼ˆåŸå‹ï¼‰åŠå…¶ç›¸ä¼¼åº¦å®šä¹‰ã€‚**

**ä¾‹å­**ï¼š

- "é¸Ÿ"çš„åŸå‹ï¼šçŸ¥æ›´é¸Ÿã€éº»é›€
- ä¼é¹…æ˜¯"é¸Ÿ"ï¼Œä½†ä¸æ˜¯å…¸å‹çš„é¸Ÿ

**ä¸åˆ†å¸ƒå¼è¯­ä¹‰çš„è”ç³»**ï¼š

```text
åŸå‹ â†” å‘é‡ç©ºé—´ä¸­çš„èšç±»ä¸­å¿ƒ
ç›¸ä¼¼åº¦ â†” å‘é‡è·ç¦»
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Prototype Theory](https://en.wikipedia.org/wiki/Prototype_theory)
- [Rosch, 1973](https://www.sciencedirect.com/science/article/pii/S0022537173800051) - Natural Categories

### 3. æ¦‚å¿µç©ºé—´ï¼ˆConceptual Spacesï¼‰

**Peter GÃ¤rdenfors** çš„æ¦‚å¿µç©ºé—´ç†è®ºï¼š

> **æ¦‚å¿µå¯ä»¥è¡¨ç¤ºä¸ºå‡ ä½•ç©ºé—´ä¸­çš„åŒºåŸŸã€‚**

**ç»´åº¦**ï¼š

- é¢œè‰²ç©ºé—´ï¼šè‰²è°ƒã€é¥±å’Œåº¦ã€äº®åº¦
- å‘³é“ç©ºé—´ï¼šç”œã€é…¸ã€è‹¦ã€å’¸ã€é²œ

**ä¸åˆ†å¸ƒå¼è¯­ä¹‰çš„è”ç³»**ï¼š

- æ¦‚å¿µç©ºé—´ â‰ˆ è¯­ä¹‰å‘é‡ç©ºé—´
- å‡¸åŒºåŸŸ â‰ˆ è¯­ä¹‰èšç±»

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Conceptual Spaces](https://en.wikipedia.org/wiki/Conceptual_space)
- [GÃ¤rdenfors, 2000](https://mitpress.mit.edu/9780262571999/conceptual-spaces/) - Conceptual Spaces: The Geometry of Thought

---

## åˆ†å¸ƒå¼è¯­ä¹‰ vs å½¢å¼è¯­ä¹‰

### å¯¹æ¯”

| ç»´åº¦ | å½¢å¼è¯­ä¹‰å­¦ï¼ˆFormal Semanticsï¼‰ | åˆ†å¸ƒå¼è¯­ä¹‰å­¦ï¼ˆDistributional Semanticsï¼‰ |
|------|-------------------------------|----------------------------------------|
| **åŸºç¡€** | æ¨¡å‹è®ºã€é€»è¾‘å­¦ | ç»Ÿè®¡å­¦ã€å‘é‡ç©ºé—´ |
| **æ„ä¹‰** | çœŸå€¼æ¡ä»¶ã€æŒ‡ç§° | ä½¿ç”¨æ¨¡å¼ã€åˆ†å¸ƒ |
| **è¡¨ç¤º** | é€»è¾‘å…¬å¼ | å‘é‡ |
| **ç»„åˆæ€§** | Î»-æ¼”ç®—ã€å‡½æ•°åº”ç”¨ | å‘é‡è¿ç®—ï¼ˆåŠ ã€å¼ é‡ç§¯ï¼‰ |
| **æ¨ç†** | æ¼”ç»æ¨ç†ï¼ˆModus Ponensï¼‰ | ç›¸ä¼¼åº¦åŒ¹é… |
| **çœŸå‡** | äºŒå€¼ï¼ˆçœŸ/å‡ï¼‰ | è¿ç»­åº¦é‡ |
| **ä¼˜åŠ¿** | ç²¾ç¡®ã€å¯è§£é‡Š | é²æ£’ã€å¯å­¦ä¹  |
| **åŠ£åŠ¿** | è„†å¼±ã€çŸ¥è¯†è·å–ç“¶é¢ˆ | è¿‘ä¼¼ã€ä¸å¯è§£é‡Š |

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Formal Semantics](https://en.wikipedia.org/wiki/Formal_semantics_(linguistics))
- [Boleda & Herbelot, 2016](https://www.aclweb.org/anthology/J16-3001/) - Formal Distributional Semantics: Introduction to the Special Issue

### äº’è¡¥æ€§

**ç°ä»£è¶‹åŠ¿**ï¼šç»“åˆä¸¤è€…ä¼˜åŠ¿ã€‚

**ä¾‹å­**ï¼š

1. **ç¥ç»-ç¬¦å·ç³»ç»Ÿ**ï¼ˆNeurosymbolic AIï¼‰ï¼š

    ```text
    ç¬¦å·æ¨ç† + ç¥ç»è¡¨ç¤º
    ```

2. **æ¦‚ç‡ç¼–ç¨‹**ï¼š

    ```text
    é€»è¾‘ç¨‹åº + æ¦‚ç‡åˆ†å¸ƒ
    ```

3. **çŸ¥è¯†å›¾è°±åµŒå…¥**ï¼š

    ```text
    ä¸‰å…ƒç»„ (head, relation, tail) â†’ å‘é‡è¡¨ç¤º
    ```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Neuro-Symbolic AI](https://en.wikipedia.org/wiki/Neuro-symbolic_AI)

---

## åˆ†å¸ƒå¼è¯­ä¹‰çš„å±€é™æ€§

### 1. åäº‹å®é—®é¢˜ï¼ˆGrounding Problemï¼‰

**é—®é¢˜**ï¼š

> **åˆ†å¸ƒå¼è¯­ä¹‰åªä»è¯­è¨€ä¸­å­¦ä¹ ï¼Œç¼ºä¹å¯¹çœŸå®ä¸–ç•Œçš„"æ¥åœ°"ï¼ˆGroundingï¼‰ã€‚**

**ä¾‹å­**ï¼š

```text
vec(unicorn) å¯ä»¥é€šè¿‡è¯­è¨€å­¦ä¹ 
ä½†"ç‹¬è§’å…½"åœ¨çœŸå®ä¸–ç•Œä¸­ä¸å­˜åœ¨
```

**Searleçš„ä¸­æ–‡æˆ¿é—´è®ºè¯**ï¼š

- ä»…ä»ç¬¦å·æ“ä½œï¼ˆæˆ–åˆ†å¸ƒç»Ÿè®¡ï¼‰æ— æ³•è·å¾—çœŸæ­£çš„"ç†è§£"

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Wikipedia: Symbol Grounding Problem](https://en.wikipedia.org/wiki/Symbol_grounding_problem)
- [Searle, 1980](https://en.wikipedia.org/wiki/Chinese_room) - Minds, Brains, and Programs

### 2. ç»„åˆæ€§é—®é¢˜ï¼ˆCompositionality Problemï¼‰

**é—®é¢˜**ï¼š

ç®€å•çš„å‘é‡è¿ç®—ï¼ˆå¦‚åŠ æ³•ï¼‰**ä¸è¶³ä»¥è¡¨è¾¾å¤æ‚çš„è¯­ä¹‰ç»„åˆ**ã€‚

**ä¾‹å­**ï¼š

```text
vec("not happy") â‰  -vec("happy")  ï¼ˆå¦å®šï¼‰
vec("very happy") â‰  2 Ã— vec("happy")  ï¼ˆç¨‹åº¦ï¼‰
```

**è§£å†³å°è¯•**ï¼š

- å¼ é‡ç§¯
- é€’å½’ç¥ç»ç½‘ç»œ
- Transformer

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Coecke et al., 2010](https://arxiv.org/abs/1003.4394) - Mathematical Foundations for a Compositional Distributional Model of Meaning

### 3. é€»è¾‘æ¨ç†é—®é¢˜ï¼ˆLogical Reasoning Problemï¼‰

**é—®é¢˜**ï¼š

åˆ†å¸ƒå¼è¯­ä¹‰ä¸æ”¯æŒ**ä¸¥æ ¼çš„é€»è¾‘æ¨ç†**ã€‚

**ä¾‹å­**ï¼š

```text
å‰æ1ï¼šæ‰€æœ‰äººéƒ½ä¼šæ­»
å‰æ2ï¼šè‹æ ¼æ‹‰åº•æ˜¯äºº
ç»“è®ºï¼šè‹æ ¼æ‹‰åº•ä¼šæ­»  ï¼ˆæ¼”ç»æ¨ç†ï¼‰
```

**åˆ†å¸ƒå¼è¯­ä¹‰çš„å¤±è´¥**ï¼š

```text
cos(vec("Socrates"), vec("mortal")) â‰ˆ 0.6  ï¼ˆåªæ˜¯ç›¸ä¼¼åº¦ï¼Œä¸æ˜¯å¿…ç„¶ï¼‰
```

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Marcus & Davis, 2019](https://arxiv.org/abs/1906.05833) - Rebooting AI: Building Artificial Intelligence We Can Trust

### 4. åè§æ”¾å¤§é—®é¢˜ï¼ˆBias Amplificationï¼‰

**é—®é¢˜**ï¼š

åˆ†å¸ƒå¼è¯­ä¹‰ä¼š**ç¼–ç å¹¶æ”¾å¤§**è®­ç»ƒæ•°æ®ä¸­çš„ç¤¾ä¼šåè§ã€‚

**ä¾‹å­**ï¼š

```text
vec(programmer) - vec(man) + vec(woman) â‰ˆ vec(homemaker)
```

**åŸå› **ï¼š

è¯­æ–™åº“åæ˜ äº†ç¤¾ä¼šçš„åˆ»æ¿å°è±¡å’Œä¸å¹³ç­‰ã€‚

**ç¼“è§£æ–¹æ³•**ï¼š

- å»åç½®ç®—æ³•
- å¯¹æŠ—è®­ç»ƒ
- æ•°æ®å¹³è¡¡

**å‚è€ƒæ–‡çŒ®**ï¼š

- [Bolukbasi et al., 2016](https://arxiv.org/abs/1607.06520) - Man is to Computer Programmer as Woman is to Homemaker?

---

## æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **ç†è®ºåŸºçŸ³**ï¼šåˆ†å¸ƒå‡è®¾ï¼ˆè¯çš„æ„ä¹‰ç”±å…¶ä¸Šä¸‹æ–‡å†³å®šï¼‰
2. **å“²å­¦åŸºç¡€**ï¼šä½¿ç”¨è®ºï¼ˆWittgensteinï¼‰ã€åˆ†å¸ƒç»“æ„ï¼ˆHarrisï¼‰
3. **å†å²å‘å±•**ï¼šå‘é‡ç©ºé—´æ¨¡å‹ â†’ LSA â†’ Word2Vec â†’ ä¸Šä¸‹æ–‡åŒ–è¡¨ç¤º
4. **æ•°å­¦å½¢å¼åŒ–**ï¼šå…±ç°çŸ©é˜µã€PMIã€çŸ©é˜µåˆ†è§£
5. **ç»Ÿä¸€è§†è§’**ï¼šè®¡æ•°æ–¹æ³•å’Œé¢„æµ‹æ–¹æ³•æœ¬è´¨ç›¸åŒ
6. **å¿ƒç†å­¦åŸºç¡€**ï¼šè¿æ¥ä¸»ä¹‰ã€åŸå‹ç†è®ºã€æ¦‚å¿µç©ºé—´
7. **ä¸å½¢å¼è¯­ä¹‰çš„å¯¹æ¯”**ï¼šäº’è¡¥è€Œéå¯¹ç«‹
8. **å±€é™æ€§**ï¼šæ¥åœ°é—®é¢˜ã€ç»„åˆæ€§ã€é€»è¾‘æ¨ç†ã€åè§

### å“²å­¦åæ€

> **åˆ†å¸ƒå¼è¯­ä¹‰å­¦æ­ç¤ºäº†ä¸€ä¸ªæ·±åˆ»çš„æ´å¯Ÿï¼šæ„ä¹‰ä¸æ˜¯å†…åœ¨çš„ã€å›ºå®šçš„ï¼Œè€Œæ˜¯å…³ç³»çš„ã€æ¶Œç°çš„ã€‚è¯çš„æ„ä¹‰ä¸åœ¨äºå®ƒ"æ˜¯ä»€ä¹ˆ"ï¼Œè€Œåœ¨äºå®ƒ"å¦‚ä½•è¢«ä½¿ç”¨"ã€‚**

### æœªæ¥æ–¹å‘

1. **å¤šæ¨¡æ€æ¥åœ°**ï¼šç»“åˆè§†è§‰ã€å¬è§‰ç­‰æ„ŸçŸ¥ä¿¡æ¯
2. **ç»„åˆè¯­ä¹‰**ï¼šæ›´å¥½çš„è¯­ä¹‰ç»„åˆæœºåˆ¶ï¼ˆå¦‚å¼ é‡ç½‘ç»œï¼‰
3. **ç¥ç»-ç¬¦å·èåˆ**ï¼šç»“åˆåˆ†å¸ƒå¼å’Œå½¢å¼è¯­ä¹‰çš„ä¼˜åŠ¿
4. **å»åç½®**ï¼šæ„å»ºæ›´å…¬å¹³çš„è¯­ä¹‰è¡¨ç¤º

---

## å‚è€ƒæ–‡çŒ®

### åŸºç¡€ç†è®º

1. [Wikipedia: Distributional Semantics](https://en.wikipedia.org/wiki/Distributional_semantics)
2. [Turney & Pantel, 2010](https://www.jair.org/index.php/jair/article/view/10640) - From Frequency to Meaning: Vector Space Models of Semantics
3. [Lenci, 2018](https://www.annualreviews.org/doi/10.1146/annurev-linguistics-030514-125254) - Distributional Models of Word Meaning

### å†å²æ–‡çŒ®

1. [Firth, 1957](https://en.wikipedia.org/wiki/Distributional_semantics) - A Synopsis of Linguistic Theory 1930-1955
2. [Harris, 1954](https://www.jstor.org/stable/411805) - Distributional Structure
3. [Wittgenstein, 1953](https://en.wikipedia.org/wiki/Philosophical_Investigations) - Philosophical Investigations

### ç»å…¸æ–¹æ³•

1. [Wikipedia: Vector Space Model](https://en.wikipedia.org/wiki/Vector_space_model)
2. [Wikipedia: Latent Semantic Analysis](https://en.wikipedia.org/wiki/Latent_semantic_analysis)
3. [Deerwester et al., 1990](https://www.jstor.org/stable/41407138) - Indexing by Latent Semantic Analysis

### ç°ä»£æ–¹æ³•

1. [Mikolov et al., 2013](https://arxiv.org/abs/1301.3781) - Efficient Estimation of Word Representations in Vector Space
2. [Pennington et al., 2014](https://nlp.stanford.edu/pubs/glove.pdf) - GloVe: Global Vectors for Word Representation
3. [Peters et al., 2018](https://arxiv.org/abs/1802.05365) - Deep Contextualized Word Representations
4. [Devlin et al., 2019](https://arxiv.org/abs/1810.04805) - BERT

### ç†è®ºåˆ†æ

1. [Levy & Goldberg, 2014](https://papers.nips.cc/paper/2014/hash/feab05aa91085b7a8012516bc3533958-Abstract.html) - Neural Word Embedding as Implicit Matrix Factorization
2. [Baroni et al., 2014](https://aclanthology.org/P14-1023/) - Don't Count, Predict!

### å¿ƒç†å­¦åŸºç¡€

1. [Wikipedia: Connectionism](https://en.wikipedia.org/wiki/Connectionism)
2. [Wikipedia: Prototype Theory](https://en.wikipedia.org/wiki/Prototype_theory)
3. [GÃ¤rdenfors, 2000](https://mitpress.mit.edu/9780262571999/conceptual-spaces/) - Conceptual Spaces

### å“²å­¦ä¸æ‰¹è¯„

1. [Wikipedia: Chinese Room](https://en.wikipedia.org/wiki/Chinese_room)
2. [Marcus & Davis, 2019](https://arxiv.org/abs/1906.05833) - Rebooting AI
3. [Bolukbasi et al., 2016](https://arxiv.org/abs/1607.06520) - Man is to Computer Programmer as Woman is to Homemaker?

---

*æœ¬æ–‡æ¡£ç³»ç»Ÿé˜è¿°äº†åˆ†å¸ƒå¼è¯­ä¹‰å­¦çš„ç†è®ºåŸºç¡€ã€å†å²å‘å±•å’Œå“²å­¦æ„æ¶µï¼Œä¸ºç†è§£ç°ä»£AIçš„è¯­ä¹‰è¡¨ç¤ºæä¾›äº†å®Œæ•´çš„ç†è®ºæ¡†æ¶ã€‚*

---

## å¯¼èˆª | Navigation

**ä¸Šä¸€ç¯‡**: [â† 04.2 è¿ç»­è¡¨ç¤ºç†è®º](./04.2_Continuous_Representation_Theory.md)  
**ä¸‹ä¸€ç¯‡**: [04.4 è¯­ä¹‰ç›¸ä¼¼åº¦åº¦é‡ â†’](./04.4_Semantic_Similarity_Metrics.md)  
**è¿”å›ç›®å½•**: [â†‘ AIæ¨¡å‹è§†è§’æ€»è§ˆ](../README.md)

---

## ç›¸å…³ä¸»é¢˜ | Related Topics

### æœ¬ç« èŠ‚
- [04.1 è¯­ä¹‰å‘é‡ç©ºé—´](./04.1_Semantic_Vector_Spaces.md)
- [04.2 è¿ç»­è¡¨ç¤ºç†è®º](./04.2_Continuous_Representation_Theory.md)
- [04.4 è¯­ä¹‰ç›¸ä¼¼åº¦åº¦é‡](./04.4_Semantic_Similarity_Metrics.md)
- [04.5 å¤šæ¨¡æ€è¯­ä¹‰æ•´åˆ](./04.5_Multimodal_Semantic_Integration.md)
- [04.6 é»„æ°è¯­ä¹‰æ¨¡å‹åˆ†æ](./04.6_Huang_Semantic_Model_Analysis.md)

### ç›¸å…³ç« èŠ‚
- [03.1 ç»Ÿè®¡è¯­è¨€æ¨¡å‹](../03_Language_Models/03.1_Statistical_Language_Models.md)
- [03.5 åµŒå…¥å‘é‡ç©ºé—´](../03_Language_Models/03.5_Embedding_Vector_Spaces.md)

### è·¨è§†è§’é“¾æ¥
- [FormalLanguage_Perspective: è¯­ä¹‰ç†è®º](../../FormalLanguage_Perspective/README.md)
- [Information_Theory_Perspective](../../Information_Theory_Perspective/README.md)