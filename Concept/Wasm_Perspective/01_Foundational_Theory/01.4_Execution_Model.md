# 1.4 执行模型 (Execution Model)

## 目录

- [核心命题](#核心命题)
- [抽象机器](#抽象机器)
- [确定性保证](#确定性保证)
- [并发模型](#并发模型)
- [性能模型](#性能模型)
- [批判性分析](#批判性分析)

---

## 核心命题

### 主定理

**确定性执行**：
\[
\forall M, I : (M, I, S) \xrightarrow{_} V_1 \wedge (M, I, S) \xrightarrow{_} V_2 \implies V_1 = V_2
\]
_相同输入必产生相同输出（无环境依赖）。_

**可观测等价性**：
\[
\llbracket M_1 \rrbracket = \llbracket M_2 \rrbracket \iff \forall I : \text{observe}(M_1, I) = \text{observe}(M_2, I)
\]

**实时性界限**：
\[
\exists k : \forall \text{instr} : \text{Cycles}(\text{instr}) \leq k \quad \text{（可预测性）}
\]

---

## 抽象机器

### 状态空间

**全局状态**：
\[
\Sigma = (\text{Stack}, \text{CallStack}, \text{Memory}, \text{Globals}, \text{Table})
\]

**组件定义**：
\[
\begin{align*}
\text{Stack} &: \text{Val}^* \\
\text{CallStack} &: \text{Frame}^_\\
\text{Memory} &: \text{Addr} \rightharpoonup \mathbb{Z}_8 \\
\text{Globals} &: \text{GIdx} \to \text{Val} \\
\text{Table} &: \text{TIdx} \to (\mathbb{N} \rightharpoonup \text{FuncRef})
\end{align_}
\]

**栈帧结构**：
\[
\text{Frame} = \{
  \text{locals} : \text{Val}^*,
  \text{module} : \text{ModuleInst},
  \text{arity} : \mathbb{N}
\}
\]

### 状态转移

**单步转移**：
\[
\langle \Sigma, I \rangle \rightarrow \langle \Sigma', I' \rangle
\]

**多步转移**：
\[
\xrightarrow{_} \; = (\rightarrow)^_ \quad \text{（传递闭包）}
\]

**终止状态**：
\[
\text{Final}(\Sigma) \iff \Sigma.\text{CallStack} = \epsilon \wedge \Sigma.\text{Stack} = V^*
\]

**陷阱状态**：
\[
\text{Trap}(\Sigma) \iff \text{no transition possible} \wedge \neg \text{Final}(\Sigma)
\]

### 指令执行

**算术指令**：
\[
\begin{prooftree}
\AxiomC{$\Sigma.\text{Stack} = v_2 : v_1 : S$}
\UnaryInfC{$\langle \Sigma, \texttt{i32.add} \rangle \rightarrow \langle \Sigma[\text{Stack} := (v_1 +_{32} v_2) : S], \epsilon \rangle$}
\end{prooftree}
\]

**内存指令**：
\[
\begin{prooftree}
\AxiomC{$\Sigma.\text{Stack} = i : S$}
\AxiomC{$\Sigma.\text{Memory}[i..i+3] = b^4$}
\BinaryInfC{$\langle \Sigma, \texttt{i32.load} \rangle \rightarrow \langle \Sigma[\text{Stack} := \text{bytes2i32}(b^4) : S], \epsilon \rangle$}
\end{prooftree}
\]

**越界陷阱**：
\[
\begin{prooftree}
\AxiomC{$\Sigma.\text{Stack} = i : S$}
\AxiomC{$i + 4 > |\Sigma.\text{Memory}|$}
\BinaryInfC{$\langle \Sigma, \texttt{i32.load} \rangle \rightarrow \text{trap}$}
\end{prooftree}
\]

**控制流**：
\[
\begin{prooftree}
\AxiomC{$\Sigma.\text{Stack} = 0 : S$}
\UnaryInfC{$\langle \Sigma, \texttt{if } I_1 \texttt{ else } I_2 \rangle \rightarrow \langle \Sigma[\text{Stack} := S], I_2 \rangle$}
\end{prooftree}
\]

\[
\begin{prooftree}
\AxiomC{$\Sigma.\text{Stack} = c : S, \quad c \neq 0$}
\UnaryInfC{$\langle \Sigma, \texttt{if } I_1 \texttt{ else } I_2 \rangle \rightarrow \langle \Sigma[\text{Stack} := S], I_1 \rangle$}
\end{prooftree}
\]

---

## 确定性保证

### 浮点确定性

**IEEE-754 严格模式**：
\[
\forall x, y : \texttt{f32.add}(x, y) = \text{IEEE754-add}(x, y)
\]

**特殊值处理**：
\[
\begin{align*}
\texttt{NaN} + x &= \texttt{NaN} \\
\infty - \infty &= \texttt{NaN} \\
0 / 0 &= \texttt{NaN}
\end{align*}
\]

**规范化要求**：

- 无快速数学优化（`-ffast-math` 禁用）
- 无 FMA 融合（除非显式 `Relaxed SIMD`）
- 舍入模式固定为"最近偶数"

**定理（浮点确定性）**：
\[
\forall M, I : \text{float-ops}(M, I) \text{ 跨平台相同}
\]

**批判**：
> 这是区块链等场景的必需，但牺牲了 10-30% 性能（相对原生 SIMD）。

### 内存模型确定性

**线性内存语义**：
\[
\forall a : \text{load}(a, t) = \sum_{k=0}^{\text{sizeof}(t)-1} \text{mem}[a+k] \times 256^k
\]
（小端序，确定）

**增长语义**：
\[
\text{memory.grow}(n) : |\text{mem}| \to |\text{mem}| + n \times 64\text{KiB} \quad \text{（原子操作）}
\]

**无缩容保证**：
\[
\forall t : |\text{mem}(t)| \leq |\text{mem}(t+1)|
\]

### 指令周期可预测性

**表1：指令延迟上界（Skylake, cycles）**

| 指令 | 最小 | 最大 | 原因 |
|------|------|------|------|
| `i32.add` | 1 | 1 | ALU 单周期 |
| `i32.mul` | 3 | 3 | 乘法器流水线 |
| `f64.div` | 4 | 13 | 依赖输入值 |
| `memory.load` | 3 | 200 | 缓存命中/缺失 |
| `call` | 5 | 10 | 间接调用更慢 |

**不确定性来源**：

1. 缓存层次结构
2. 分支预测器
3. 微架构资源竞争

**批判**：
> 抽象机器确定，物理机器不确定。实时系统需更严格的约束（WCET 分析）。

---

## 并发模型

### 线程抽象

**线程 = Wasm 实例 + 共享内存**：
\[
\text{Thread} = (\text{Instance}, \text{SharedMem})
\]

**共享内存模型**：
\[
\text{SharedMem} : \text{Addr} \rightharpoonup_{\text{atomic}} \mathbb{Z}_8
\]

### 内存顺序

**Wasm 内存模型（基于 C++11）**：

**顺序一致性（Sequentially Consistent）**：
\[
\forall \text{ops} : \exists \text{total-order} : \text{consistent}(\text{total-order})
\]

**原子操作**：
\[
\begin{align*}
\texttt{i32.atomic.load} &: \text{acquire 语义} \\
\texttt{i32.atomic.store} &: \text{release 语义} \\
\texttt{i32.atomic.rmw.add} &: \text{acquire-release 语义}
\end{align*}
\]

**内存屏障**：
\[
\texttt{atomic.fence} : \text{全屏障（fence seq\_cst）}
\]

### 数据竞争

**定义**：
\[
\text{DataRace}(op_1, op_2) \iff
\begin{cases}
\text{concurrent}(op_1, op_2) \\
\wedge \; \text{same-location}(op_1, op_2) \\
\wedge \; (\text{write}(op_1) \vee \text{write}(op_2)) \\
\wedge \; \neg (\text{atomic}(op_1) \wedge \text{atomic}(op_2))
\end{cases}
\]

**定理（DRF-SC）**：
\[
\text{NoDataRace}(P) \implies \text{SequentialConsistency}(P)
\]

**批判**：
> 共享内存 + 原子指令 = C++11 内存模型的子集。继承了其复杂性，但未提供更高层抽象（如 CSP、Actor）。

---

## 性能模型

### 成本模型

**指令成本**：
\[
C(\text{instr}) = C_{\text{decode}} + C_{\text{exec}} + C_{\text{writeback}}
\]

**内存成本**：
\[
C(\text{load}) =
\begin{cases}
3 & \text{L1 hit} \\
12 & \text{L2 hit} \\
36 & \text{L3 hit} \\
200 & \text{DRAM}
\end{cases}
\]

**分支成本**：
\[
C(\text{branch}) =
\begin{cases}
1 & \text{predicted correctly} \\
15-20 & \text{mispredicted}
\end{cases}
\]

### 性能预测模型

**吞吐模型**（Roofline Model）：
\[
\text{Throughput} = \min\left(\text{Peak}_{\text{compute}}, \frac{\text{Peak}_{\text{bandwidth}}}{\text{AI}}\right)
\]
其中 AI = Arithmetic Intensity（运算强度）。

**SIMD 加速比**：
\[
\text{Speedup}_{\text{SIMD}} = \frac{\text{lanes}}{\text{overhead}} \approx \frac{4-16}{1.2}
\]

**批判**：
> 预测模型假设理想流水线，现实中存在资源冲突、缓存抖动、TLB 缺失等非确定因素。

---

## 陷阱机制

### 陷阱分类

| 陷阱类型 | 触发条件 | 可恢复性 |
|---------|---------|---------|
| **整数除零** | `i32.div_s(x, 0)` | 否 |
| **整数溢出** | `i32.div_s(INT_MIN, -1)` | 否 |
| **越界访问** | `load(addr)` 且 `addr >= mem-size` | 否 |
| **间接调用失败** | `call_indirect(i)` 且类型不匹配 | 否 |
| **未对齐访问** | （推荐对齐，不强制） | N/A |

**陷阱语义**：
\[
\text{trap} \rightarrow \text{终止当前调用栈，返回 Error}
\]

**批判性观察**：
> Wasm 无异常机制（Exception Handling 提案仍在推进），所有错误均为致命陷阱。这简化了验证，但限制了错误处理灵活性。

---

## 栈式执行的形式化

### 栈机器 vs 寄存器机器

**栈机器优势**：

- 零地址指令（紧凑编码）
- 验证简单（栈深度静态可知）
- 可移植性（无寄存器分配）

**寄存器机器优势**：

- 更接近硬件
- 寄存器分配优化空间大

**转换定理**：
\[
\forall P_{\text{stack}} : \exists P_{\text{reg}} : \llbracket P_{\text{stack}} \rrbracket = \llbracket P_{\text{reg}} \rrbracket
\]

**性能开销**：
\[
\text{Overhead}_{\text{stack→reg}} \approx 5-10\% \quad \text{（JIT 编译后）}
\]

---

## 执行策略

### 解释执行

**伪代码**：

```python
def interpret(instructions, state):
    pc = 0
    while pc < len(instructions):
        instr = instructions[pc]
        match instr:
            case I32Const(n):
                state.stack.push(n)
            case I32Add:
                b = state.stack.pop()
                a = state.stack.pop()
                state.stack.push((a + b) % 2**32)
            case Call(funcidx):
                func = state.module.funcs[funcidx]
                interpret(func.body, new_frame())
            ...
        pc += 1
```

**性能**：
\[
\text{Slowdown}_{\text{interpreter}} \approx 10-100\times \text{ vs native}
\]

### 基线 JIT（Baseline Compilation）

**策略**：简单指令线性映射

```
i32.add  →  ADD eax, ebx
i32.mul  →  IMUL eax, ebx
```

**编译时间**：
\[
T_{\text{baseline}} = O(n) \approx 5-10 \text{ ms/MB}
\]

**性能**：
\[
\text{Perf}_{\text{baseline}} \approx 0.5-0.7 \times \text{native}
\]

### 优化 JIT（Optimizing Compilation）

**优化 pass**：

1. 寄存器分配（线性扫描）
2. 死代码消除
3. 常量折叠
4. 公共子表达式消除

**编译时间**：
\[
T_{\text{optimizing}} = O(n \log n) \approx 30-100 \text{ ms/MB}
\]

**性能**：
\[
\text{Perf}_{\text{optimizing}} \approx 0.85-0.95 \times \text{native}
\]

### AOT（Ahead-of-Time Compilation）

**优势**：

- 启动延迟为零
- 可应用全局优化（PGO、LTO）

**性能**：
\[
\text{Perf}_{\text{AOT}} \approx 0.90-0.98 \times \text{native}
\]

**批判**：
> AOT 牺牲了动态性（无法热替换代码），是性能与灵活性的权衡。

---

## 批判性分析

### 抽象税（Abstraction Tax）

**命题**：
\[
\forall \text{abstraction} : \exists \text{overhead} > 0
\]

**Wasm 抽象税来源**：

1. **验证开销**：\( O(n) \) 时间，1-2 ms/MB
2. **栈→寄存器转换**：5-10% 性能损失
3. **间接跳转**：分支预测器失效
4. **安全检查**：边界检查、类型检查

**总开销**：
\[
\text{Overhead}_{\text{total}} \approx 5-15\%
\]

**哲学反思**：
> 抽象税是普遍计算抽象的必然代价。问题不是"是否存在"，而是"是否可接受"。

### 确定性的幻觉

**命题**：
\[
\text{DeterministicAbstract} \not\Rightarrow \text{DeterministicPhysical}
\]

**反例**：

1. **Spectre**：推测执行导致侧信道泄漏
2. **Rowhammer**：物理比特翻转
3. **时钟漂移**：不同节点时间不同步

**批判**：
> Wasm 保证的是"语义确定性"，而非"物理确定性"。从数学到硬件的映射，存在不可消除的鸿沟。

### 并发模型的复杂性

**C++11 内存模型的继承问题**：

- 9 种内存顺序（Relaxed, Acquire, Release, ...）
- 程序员难以正确使用
- 编译器优化可能违反直觉

**批判**：
> 共享内存并发是"最难正确"的并发模型。Wasm 本可选择 CSP、Actor 等更高层抽象，但选择了兼容 C/C++。

---

## 案例研究：循环展开的正确性

### 源代码

```wasm
(loop $L
  local.get $i
  i32.const 1
  i32.add
  local.set $i

  local.get $i
  i32.const 100
  i32.lt_s
  br_if $L
)
```

### 展开后

```wasm
(block
  local.get $i
  i32.const 4
  i32.add
  local.set $i

  local.get $i
  i32.const 100
  i32.lt_s
  br_if 0

  ... (重复4次)
)
```

### 等价性证明

**定义观测等价**：
\[
O_1 \sim O_2 \iff \forall s : \text{final-state}(O_1, s) = \text{final-state}(O_2, s)
\]

**证明草图**：

1. 归纳基：\( i = 0 \) 时，两者均执行 100 次
2. 归纳步：假设 \( i = k \) 时等价，证明 \( i = k+1 \) 时等价
3. 应用环不变式：\( 0 \leq i \leq 100 \)

---

## 参考文献

1. **[Haas17]** Andreas Haas et al. "Bringing the Web up to Speed with WebAssembly." PLDI, 2017.
2. **[Boehm08]** Hans-J. Boehm and Sarita V. Adve. "Foundations of the C++ Concurrency Memory Model." PLDI, 2008.
3. **[Lattner04]** Chris Lattner and Vikram Adve. "LLVM: A Compilation Framework." CGO, 2004.
4. **[Watt18]** Conrad Watt et al. "Weakening WebAssembly." OOPSLA, 2019.

---

**结论**：
> Wasm 的执行模型在抽象层面实现了确定性与可预测性，但从抽象到物理的映射不可避免地引入非确定性。它是工程实用主义与理论理想主义的妥协：追求"足够确定"，而非"绝对确定"。
