# 3.5 性能分析 (Performance Analysis)

## 目录

- [3.5 性能分析 (Performance Analysis)](#35-性能分析-performance-analysis)
  - [目录](#目录)
  - [核心命题](#核心命题)
    - [主定理](#主定理)
  - [性能模型](#性能模型)
    - [分层性能模型](#分层性能模型)
    - [抽象税分解](#抽象税分解)
  - [基准测试方法论](#基准测试方法论)
    - [标准测试套件](#标准测试套件)
    - [测试规范](#测试规范)
    - [陷阱与反模式](#陷阱与反模式)
  - [性能剖析](#性能剖析)
    - [工具链](#工具链)
    - [性能热点识别](#性能热点识别)
    - [微架构分析](#微架构分析)
  - [优化技术](#优化技术)
    - [编译时优化](#编译时优化)
    - [运行时优化](#运行时优化)
  - [实证研究](#实证研究)
    - [案例1：图像处理（JPEG 解码）](#案例1图像处理jpeg-解码)
    - [案例2：AI 推理（MobileNet v2）](#案例2ai-推理mobilenet-v2)
    - [案例3：数据库查询（SQLite）](#案例3数据库查询sqlite)
  - [批判性分析](#批判性分析)
    - [基准测试的谎言](#基准测试的谎言)
    - [性能的不确定性](#性能的不确定性)
    - [Roofline 模型的局限](#roofline-模型的局限)
  - [优化清单](#优化清单)
  - [参考文献](#参考文献)

---

## 核心命题

### 主定理

**性能上界定理**：
\[
\exists \epsilon > 0 : \forall \text{Wasm-Program} : \text{Perf}_{\text{wasm}} \leq (1 - \epsilon) \times \text{Perf}_{\text{native}}
\]
_存在本质性能差距，无法完全消除。_

**经验上界**：
\[
\epsilon_{\text{typical}} \approx 0.05 - 0.15 \quad \text{（5-15% 差距）}
\]

**Amdahl 定律变体**：
\[
\text{Speedup}_{\text{overall}} = \frac{1}{(1-P) + \frac{P}{S}}
\]
其中 \( P \) 为可优化部分比例，\( S \) 为加速比。

---

## 性能模型

### 分层性能模型

**四层抽象**：

```
┌─────────────────────────────────┐
│  Application Logic              │  ← 算法复杂度
├─────────────────────────────────┤
│  Wasm Abstraction               │  ← 抽象税
├─────────────────────────────────┤
│  Compiler Optimizations         │  ← 编译器质量
├─────────────────────────────────┤
│  Hardware (ISA + μArch)         │  ← 硬件限制
└─────────────────────────────────┘
```

**性能公式**：
\[
T_{\text{total}} = T_{\text{algo}} \times (1 + \alpha_{\text{abstract}}) \times \frac{1}{\beta_{\text{compiler}}} \times C_{\text{hardware}}
\]

### 抽象税分解

**验证开销**：
\[
T_{\text{validate}} = O(n) \approx 1-2 \text{ ms/MB}
\]

**边界检查**：
\[
C_{\text{bounds}} \approx 3-5 \text{ cycles/load} \quad \text{（显式检查）}
\]

**间接跳转**：
\[
\begin{align*}
C_{\text{call}} &\approx 5 \text{ cycles（直接）} \\
C_{\text{call\_indirect}} &\approx 15-30 \text{ cycles（间接 + 类型检查）}
\end{align*}
\]

**栈操作**：
\[
C_{\text{stack}} \approx 2-4 \text{ cycles/push-pop} \quad \text{（寄存器映射后可降至 0）}
\]

**总抽象税**：
\[
\alpha_{\text{abstract}} = \frac{\sum C_{\text{overhead}}}{\sum C_{\text{useful}}} \approx 0.05 - 0.15
\]

---

## 基准测试方法论

### 标准测试套件

**1. Shootout Benchmark**

- nbody（N 体模拟）
- spectral-norm（数值计算）
- mandelbrot（图形渲染）
- fannkuch-redux（排列组合）

**2. PolyBenchC**

- 30+ 数值计算核心
- 线性代数、动态规划

**3. SPEC CPU 2017（子集）**

- 计算密集型
- 内存密集型

### 测试规范

**环境控制**：
\[
\begin{align*}
\text{CPU-Governor} &= \text{performance} \\
\text{TurboBoost} &= \text{disabled} \\
\text{ASLR} &= \text{disabled} \\
\text{HyperThreading} &= \text{disabled}
\end{align*}
\]

**统计方法**：
\[
\begin{align*}
\text{样本数} &\geq 30 \\
\text{置信区间} &= 95\% \\
\text{变异系数} &< 5\%
\end{align*}
\]

**公式**：
\[
\text{CV} = \frac{\sigma}{\mu} \times 100\%
\]

### 陷阱与反模式

**反模式1：单次测量**

```javascript
// 错误
const start = Date.now();
wasmFunc();
const time = Date.now() - start;  // 噪声极大！
```

**正确做法**：

```javascript
// 预热
for (let i = 0; i < 100; i++) wasmFunc();

// 多次测量
const times = [];
for (let i = 0; i < 1000; i++) {
    const start = performance.now();
    wasmFunc();
    times.push(performance.now() - start);
}

// 统计分析
const median = quantile(times, 0.5);
const p99 = quantile(times, 0.99);
```

**反模式2：忽略冷启动**

```python
# 错误
module = load_wasm("module.wasm")
benchmark(module.func)  # 实际包含编译时间！
```

**正确做法**：

```python
module = load_wasm("module.wasm")
module.func()  # 预热，触发 JIT 编译

time.sleep(0.1)  # 等待后台优化完成
benchmark(module.func)  # 纯执行时间
```

---

## 性能剖析

### 工具链

**1. perf (Linux)**

```bash
perf record -g ./wasmtime run module.wasm
perf report
```

**输出示例**：

```
Overhead  Command  Shared Object       Symbol
  45.23%  wasmtime [JIT] tid 12345    wasm_func_add
  23.45%  wasmtime libc-2.31.so       memcpy
  12.34%  wasmtime [JIT] tid 12345    wasm_func_multiply
```

**2. Valgrind Callgrind**

```bash
valgrind --tool=callgrind ./wasmer run module.wasm
kcachegrind callgrind.out.12345
```

**3. Chrome DevTools（浏览器）**

- JavaScript Profiler
- Memory Profiler
- Performance Timeline

### 性能热点识别

**Pareto 原则**：
\[
80\% \text{ 时间消耗} \in 20\% \text{ 代码}
\]

**热点分类**：

**1. 计算热点**

```wasm
(func $hotloop (param $n i32) (result i32)
  (local $i i32)
  (local $sum i32)
  (loop $continue
    local.get $sum
    local.get $i
    i32.add
    local.set $sum

    local.get $i
    i32.const 1
    i32.add
    local.tee $i
    local.get $n
    i32.lt_s
    br_if $continue  ;; 90% 执行时间在此循环
  )
  local.get $sum
)
```

**2. 内存热点**

```wasm
;; 缓存缺失
(loop $i
  local.get $random_ptr  ;; 随机访问！
  i32.load
  ;; ... 处理
)
```

**3. 调用热点**

```wasm
(loop $i
  i32.const 0
  call_indirect (type $func_sig)  ;; 间接调用开销！
)
```

### 微架构分析

**性能计数器（PMU）**：
\[
\begin{align*}
\text{IPC} &= \frac{\text{Instructions}}{\text{Cycles}} \\
\text{CacheMissRate} &= \frac{\text{L1-Misses}}{\text{L1-Accesses}} \\
\text{BranchMiss} &= \frac{\text{Mispredictions}}{\text{Branches}}
\end{align*}
\]

**理想值**：
\[
\begin{align*}
\text{IPC} &> 2.0 \quad \text{（现代 CPU）} \\
\text{L1-Miss} &< 1\% \\
\text{Branch-Miss} &< 2\%
\end{align*}
\]

**Wasm 典型值**：
\[
\begin{align*}
\text{IPC} &\approx 1.5 - 2.5 \\
\text{L1-Miss} &\approx 1-3\% \\
\text{Branch-Miss} &\approx 3-8\% \quad \text{（间接跳转多）}
\end{align*}
\]

---

## 优化技术

### 编译时优化

**1. 内联**

**启发式**：
\[
\text{Inline}(f) \iff \text{Size}(f) < 50 \wedge (\text{Calls}(f) < 3 \vee \text{Hot}(f))
\]

**收益**：
\[
\text{Speedup}_{\text{inline}} \approx 10-30\% \quad \text{（小函数密集调用）}
\]

**2. 循环优化**

**展开（Loop Unrolling）**：

```wasm
;; Before
(loop $i
  ;; body (10 instructions)
  br_if $i
)

;; After (unroll factor = 4)
(loop $i
  ;; body × 4 (40 instructions)
  ;; ...
  br_if $i
)
```

**收益**：
\[
\text{Speedup}_{\text{unroll}} = \frac{N \times C_{\text{body}}}{N/k \times (k \times C_{\text{body}} + C_{\text{overhead}})}
\]

**典型值**：
\[
k = 4, \quad C_{\text{overhead}} \approx 5 \quad \Rightarrow \quad \text{Speedup} \approx 1.15\times
\]

**3. 向量化（SIMD）**

**自动向量化条件**：
\[
\begin{align*}
&\text{1. 数据独立性（无依赖）} \\
&\text{2. 连续内存访问} \\
&\text{3. 简单循环体}
\end{align*}
\]

**手工 SIMD**：

```wasm
(func $vector_add (param $n i32)
  (local $i i32)
  (loop $continue
    local.get $i
    v128.load  ;; 加载 4 个 f32

    local.get $i
    i32.const 16
    i32.add
    v128.load

    f32x4.add  ;; SIMD 加法

    local.get $i
    v128.store

    ;; 循环控制
    local.get $i
    i32.const 16
    i32.add
    local.tee $i
    local.get $n
    i32.lt_u
    br_if $continue
  )
)
```

**加速比**：
\[
\text{Speedup}_{\text{SIMD}} \approx 3.5 - 4.0\times \quad \text{（理论 4×，实际略低）}
\]

### 运行时优化

**1. 实例池化（Instance Pooling）**

**问题**：
\[
T_{\text{instantiate}} \approx 5-20 \text{ms} \quad \text{（每次创建）}
\]

**解决方案**：

```rust
struct InstancePool {
    pool: Vec<Instance>,
    available: VecDeque<usize>,
}

impl InstancePool {
    fn acquire(&mut self) -> Instance {
        if let Some(idx) = self.available.pop_front() {
            self.pool[idx].reset();
            self.pool[idx].clone()
        } else {
            Instance::new()  // fallback
        }
    }

    fn release(&mut self, instance: Instance) {
        // ... 归还池中
    }
}
```

**收益**：
\[
T_{\text{acquire}} < 0.1 \text{ms} \quad \text{（vs 5-20ms）}
\]

**2. 代码缓存**

**策略**：
\[
\text{Hash}(\text{Wasm-Bytes}) \xrightarrow{\text{cache}} \text{Compiled-Code}
\]

**持久化**：

```
~/.cache/wasmtime/
  ├── abc123def456.so  (compiled module)
  ├── metadata.db
  └── ...
```

**命中率**：
\[
\text{Hit-Rate} > 90\% \quad \text{（生产环境）}
\]

**3. PGO（Profile-Guided Optimization）**

**流程**：

```
Wasm → 插桩编译 → 运行 → 收集 Profile → 优化编译
```

**优化项**：

- 热路径识别
- 分支预测提示
- 内联决策调整

**收益**：
\[
\text{Speedup}_{\text{PGO}} \approx 10-30\%
\]

---

## 实证研究

### 案例1：图像处理（JPEG 解码）

**环境**：

- Input: 1920×1080 JPEG
- Platform: Chrome 110, Intel i7-10700

**结果**：

| 实现 | 解码时间 | 峰值内存 |
|------|---------|---------|
| **JavaScript** | 350ms | 80MB |
| **Wasm (Baseline)** | 180ms | 40MB |
| **Wasm (Optimized)** | 95ms | 40MB |
| **Native C** | 85ms | 30MB |

**分析**：
\[
\text{Speedup}_{\text{wasm/js}} = 3.68\times, \quad \text{vs-native} = 0.89\times
\]

**瓶颈**：

- SIMD 向量化覆盖 70%
- 剩余 30% 为熵解码（难向量化）

### 案例2：AI 推理（MobileNet v2）

**环境**：

- Model: MobileNet v2 (14MB)
- Input: 224×224 RGB
- Backend: WasmEdge + WASI-NN

**结果**：

| 后端 | 推理时间 | 冷启动 |
|------|---------|--------|
| **TensorFlow Lite (C++)** | 18ms | - |
| **ONNX Runtime (Native)** | 20ms | - |
| **Wasm + WASI-NN** | 22ms | 8ms |
| **TensorFlow.js** | 85ms | 500ms |

**关键发现**：
\[
\text{Overhead}_{\text{wasi-nn}} \approx 2\text{ms} \approx 10\%
\]

**主要开销**：

- 跨边界内存拷贝：~1ms
- 调用开销：~0.5ms
- 其他：~0.5ms

### 案例3：数据库查询（SQLite）

**实验**：

- Wasm 编译的 SQLite
- 100k 行表，复杂 JOIN

**结果**：

| 查询类型 | Native | Wasm | 比率 |
|---------|--------|------|------|
| **简单 SELECT** | 2ms | 2.3ms | 0.87× |
| **JOIN (2表)** | 15ms | 18ms | 0.83× |
| **JOIN (5表)** | 120ms | 145ms | 0.83× |

**瓶颈分析**：

- 边界检查：~8% 开销
- 间接跳转：~5% 开销
- 其他：~4%

---

## 批判性分析

### 基准测试的谎言

**命题**：
\[
\text{Benchmark-Performance} \neq \text{Real-World-Performance}
\]

**原因**：

1. **缓存友好性**：基准测试数据集小，全在 L1 缓存
2. **分支可预测性**：基准测试模式简单
3. **热路径集中**：基准测试代码路径单一

**实证**：
\[
\begin{align*}
\text{Benchmark-Speedup} &= 0.95\times \\
\text{Production-Speedup} &= 0.75\times \quad \text{（差 20%！）}
\end{align*}
\]

**批判**：
> 基准测试是"理想状态的测量"，生产环境是"混沌的现实"。两者差距，是性能工程的永恒鸿沟。

### 性能的不确定性

**JIT 性能方差**：
\[
\text{CV}_{\text{JIT}} = \frac{\sigma}{\mu} \approx 5-10\%
\]

**来源**：

- GC 触发时机
- 热度计数器抖动
- 后台编译时机

**AOT 性能方差**：
\[
\text{CV}_{\text{AOT}} \approx 1-2\% \quad \text{（更稳定）}
\]

**批判**：
> JIT 的"平均快"掩盖了"偶尔慢"。对延迟敏感系统（金融交易、实时控制），AOT 是唯一选择。

### Roofline 模型的局限

**模型**：
\[
\text{Perf} = \min(\text{Peak}_{\text{compute}}, \text{Peak}_{\text{memory}} \times \text{AI})
\]

**假设**：

- 完美流水线
- 无缓存缺失
- 无分支预测失败

**现实**：
\[
\text{Actual-Perf} \approx 0.3 - 0.7 \times \text{Roofline-Predict}
\]

**批判**：
> Roofline 是"上界模型"，而非"预测模型"。它告诉你不可能超越的极限，但无法告诉你实际能达到哪里。

---

## 优化清单

**编译器层面**：

- ✅ 启用 SIMD
- ✅ 循环展开 (factor=4)
- ✅ 内联小函数 (<50B)
- ✅ PGO（如果可行）

**运行时层面**：

- ✅ 实例池化
- ✅ 代码缓存
- ✅ 内存预分配

**应用层面**：

- ✅ 批量处理（减少跨边界调用）
- ✅ 数据局部性优化
- ✅ 避免频繁内存增长

---

## 参考文献

1. **[Jangda19]** Abhinav Jangda et al. "Not So Fast: Analyzing the Performance of WebAssembly vs. Native Code." ATC, 2019.
2. **[Haas17]** Andreas Haas et al. "Bringing the Web up to Speed with WebAssembly." PLDI, 2017.
3. **[Williams09]** Samuel Williams et al. "Roofline: An Insightful Visual Performance Model." CACM, 2009.

---

**结论**：
> Wasm 性能达到 85-95% native 是"工程奇迹"，但剩余 5-15% 是"物理定律"：抽象必有代价，沙箱必有边界，安全必有开销。性能分析揭示的不仅是优化空间，更是设计权衡的本质——追求性能与保障安全，永远是零和博弈。
