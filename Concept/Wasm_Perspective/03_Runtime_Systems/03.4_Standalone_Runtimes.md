# 3.4 独立运行时 (Standalone Runtimes)

## 目录

- [核心命题](#核心命题)
- [Wasmtime 架构](#wasmtime-架构)
- [Wasmer 生态](#wasmer-生态)
- [WAMR 嵌入式](#wamr-嵌入式)
- [性能对比](#性能对比)
- [应用场景](#应用场景)
- [批判性分析](#批判性分析)

---

## 核心命题

### 主定理

**通用计算平台定理**：
\[
\text{Standalone-Runtime} \implies \text{Wasm} \equiv \text{Universal-Binary-Format}
\]

**可嵌入性原则**：
\[
\forall \text{Host-App} : \exists \text{Binding}(\text{Runtime}, \text{Host-App})
\]

**性能目标**：
\[
\begin{align*}
\text{Perf}_{\text{standalone}} &> 0.85 \times \text{native} \\
T_{\text{startup}} &< 100\text{ms} \quad \text{（中等模块）} \\
\text{Memory}_{\text{overhead}} &< 20\text{MB}
\end{align*}
\]

---

## Wasmtime 架构

### 设计哲学

**核心原则**：
\[
\text{Security} > \text{Performance} > \text{Compatibility}
\]

**架构分层**：
```
┌────────────────────────────────┐
│  Embedder API (C/Rust/Python)  │
├────────────────────────────────┤
│  Runtime (Instance Management) │
├────────────────────────────────┤
│  Cranelift (Code Generator)    │
├────────────────────────────────┤
│  Validator + Loader            │
└────────────────────────────────┘
```

### Cranelift 编译器

**特点**：
- 纯 Rust 实现
- 快速编译优先
- 无 LLVM 依赖

**编译流程**：
```
Wasm → CIL (Cranelift IL) → 优化 → 机器码
  ↓         ↓                 ↓        ↓
5ms      10ms             20ms      5ms
```

**优化 Pass**：
\[
\begin{align*}
&\text{1. GVN（全局值编号）} \\
&\text{2. LICM（循环不变代码外提）} \\
&\text{3. SimplifyCFG（控制流简化）} \\
&\text{4. RegAlloc（寄存器分配）}
\end{align*}
\]

**编译速度**：
\[
T_{\text{Cranelift}} = O(n \log n) \approx 20-30 \text{ MB/s}
\]

**性能**：
\[
\text{Perf}_{\text{Cranelift}} \approx 0.85-0.90 \times \text{native}
\]

### WASI 实现

**系统能力抽象**：
```rust
pub trait WasiCtx {
    fn fd_read(&mut self, fd: Fd, iovs: &[IoSlice]) -> Result<usize>;
    fn fd_write(&mut self, fd: Fd, iovs: &[IoSlice]) -> Result<usize>;
    fn path_open(&mut self, dirfd: Fd, path: &str, ...) -> Result<Fd>;
    // ...
}
```

**权限模型**：
\[
\text{Capability} = \{\text{FD}, \text{Preopened-Dir}\}
\]

**示例配置**：
```rust
let mut wasi = WasiCtxBuilder::new()
    .inherit_stdio()
    .preopened_dir(Dir::open("/sandbox")?, "/")
    .build();
```

**性能开销**：
\[
\text{Overhead}_{\text{WASI}} \approx 2-5\% \quad \text{（vs 原生系统调用）}
\]

### 内存管理

**线性内存实现**：
```rust
struct Memory {
    base: *mut u8,
    current_pages: u32,
    maximum_pages: Option<u32>,
    mmap: MmapMut,  // 使用 OS mmap
}
```

**保护机制**：
\[
\text{Memory-Layout} = \text{Accessible} + \text{Guard-Pages}
\]

**边界检查策略**：
- **显式检查**（默认）：每次访问插入检查
- **隐式陷阱**（优化）：利用操作系统信号处理

**性能对比**：
\[
\text{Speedup}_{\text{implicit}} \approx 10-30\% \quad \text{（内存密集代码）}
\]

---

## Wasmer 生态

### 多后端策略

**编译器选择**：
```
┌──────────┐
│  Wasmer  │
└────┬─────┘
     ├─→ Singlepass (快速编译)
     ├─→ Cranelift (平衡)
     └─→ LLVM (高性能)
```

**性能对比**：

| 后端 | 编译时间 | 执行性能 | 内存占用 |
|------|---------|---------|---------|
| **Singlepass** | 50 MB/s | 0.60× | 低 |
| **Cranelift** | 25 MB/s | 0.85× | 中 |
| **LLVM** | 2 MB/s | 0.95× | 高 |

### 包管理系统（WAPM）

**概念**：
\[
\text{WAPM} = \text{npm} + \text{Docker} \quad \text{（for Wasm）}
\]

**包格式**：
```toml
[package]
name = "cowsay"
version = "0.2.0"
description = "Cowsay for WebAssembly"

[[module]]
name = "cowsay"
source = "cowsay.wasm"
interfaces = ["wasi"]
```

**安装与运行**：
```bash
wapm install cowsay
wapm run cowsay "Hello Wasm!"
```

**批判**：
> WAPM 的价值在于"分发标准化"，但生态规模远不及 Docker Hub。网络效应是技术优越性无法跨越的鸿沟。

### 语言绑定

**C API**：
```c
wasm_engine_t* engine = wasm_engine_new();
wasm_store_t* store = wasm_store_new(engine);
wasm_module_t* module = wasm_module_new(store, &binary);
wasm_instance_t* instance = wasm_instance_new(store, module, imports);
```

**Python 绑定**：
```python
from wasmer import engine, Store, Module, Instance

store = Store(engine.JIT(Compiler))
module = Module(store, open('module.wasm', 'rb').read())
instance = Instance(module)
result = instance.exports.add(5, 3)
```

**性能开销**：
\[
\text{Overhead}_{\text{binding}} < 100 \text{ns/call}
\]

---

## WAMR 嵌入式

### 设计目标

**资源约束**：
\[
\begin{align*}
\text{Memory} &< 100\text{KB（运行时）} \\
\text{Footprint} &< 500\text{KB（二进制）} \\
\text{Startup} &< 10\text{ms}
\end{align*}
\]

**三种执行模式**：

**1. 解释器模式**
- 内存：~85KB
- 性能：0.05-0.10× native
- 用途：极限嵌入式（如 MCU）

**2. AOT 模式**
- 编译：离线完成
- 性能：0.70-0.85× native
- 用途：工业 IoT

**3. JIT 模式**
- 内存：~1MB
- 性能：0.60-0.75× native
- 用途：边缘网关

### LLVM AOT 工具链

**编译流程**：
```bash
wamrc --target=armv7 \
      --opt-level=3 \
      --size-level=1 \
      -o output.aot \
      input.wasm
```

**生成代码**：
\[
\text{AOT-File} = \text{Machine-Code} + \text{Metadata} + \text{Relocation-Table}
\]

**加载时间**：
\[
T_{\text{AOT-load}} \approx 1-2\text{ms} \quad \text{（vs 10-50ms JIT）}
\]

### 硬件支持

**架构覆盖**：
- x86_64, x86
- ARMv7, AArch64
- MIPS, RISC-V
- Xtensa（ESP32）

**优化特性**：
```c
// SIMD 支持（ARM NEON）
#ifdef __ARM_NEON
    float32x4_t v1 = vld1q_f32(ptr1);
    float32x4_t v2 = vld1q_f32(ptr2);
    float32x4_t result = vaddq_f32(v1, v2);
    vst1q_f32(ptr_out, result);
#endif
```

**性能提升**：
\[
\text{Speedup}_{\text{NEON}} \approx 3-4\times \quad \text{（浮点运算）}
\]

---

## 性能对比

### 编译性能

**基准：1MB Wasm 模块**

| 运行时 | 模式 | 编译时间 | 内存峰值 |
|--------|------|---------|---------|
| **Wasmtime** | Cranelift | 50ms | 30MB |
| **Wasmer** | Singlepass | 20ms | 20MB |
| **Wasmer** | LLVM | 2000ms | 100MB |
| **WAMR** | JIT | 80ms | 15MB |
| **WAMR** | AOT | 0ms (预编译) | 5MB |

### 执行性能

**Shootout Benchmark（相对 Native = 1.00）**

| 测试 | Wasmtime | Wasmer(LLVM) | WAMR(AOT) | WasmEdge |
|------|---------|--------------|-----------|----------|
| **nbody** | 0.88 | 0.95 | 0.82 | 0.91 |
| **mandelbrot** | 0.85 | 0.93 | 0.79 | 0.89 |
| **fasta** | 0.90 | 0.96 | 0.84 | 0.92 |
| **spectral-norm** | 0.87 | 0.94 | 0.81 | 0.90 |

### 内存占用

**静态二进制大小**：

| 运行时 | 大小 | 依赖 |
|--------|------|------|
| **Wasmtime** | ~15MB | libstd (Rust) |
| **Wasmer** | ~20MB | libstd + LLVM |
| **WAMR** | ~500KB | libc only |
| **WasmEdge** | ~80MB | LLVM + Extensions |

---

## 应用场景

### 1. Serverless / FaaS

**优势**：
\[
\begin{align*}
\text{Cold-Start} &< 50\text{ms} \quad \text{（vs 数秒 Docker）} \\
\text{Density} &\approx 10\times \quad \text{（vs 容器）}
\end{align*}
\]

**案例：Fastly Compute@Edge**
- 启动：<1ms
- 内存：~2MB/实例
- 性能：~90% native

### 2. 插件系统

**隔离保证**：
\[
\text{Plugin} \in \text{Sandbox} \implies \neg \text{Crash}(\text{Host})
\]

**示例：Envoy Proxy**
```yaml
http_filters:
  - name: envoy.filters.http.wasm
    typed_config:
      config:
        vm_config:
          runtime: "envoy.wasm.runtime.v8"
          code:
            local: { filename: "filter.wasm" }
```

**性能开销**：
\[
\text{Overhead}_{\text{wasm-filter}} \approx 5-15\mu\text{s/request}
\]

### 3. 边缘计算

**资源约束**：
\[
\begin{align*}
\text{Device-RAM} &< 100\text{MB} \\
\text{Network-Latency} &> 50\text{ms} \\
\text{CPU} &= \text{ARMv7 @800MHz}
\end{align*}
\]

**适配策略**：
- WAMR 解释器模式
- AOT 离线编译
- 增量更新（diff）

**案例：CDN 边缘节点**
- 逻辑更新：<1s（vs 数分钟重部署）
- 内存占用：<10MB
- CPU 开销：<5%

### 4. 区块链智能合约

**确定性要求**：
\[
\forall \text{Node}_i, \text{Node}_j : \text{Exec}(\text{Contract}, \text{Input}) \text{ 相同}
\]

**Wasm 优势**：
- 浮点确定性（IEEE-754 严格）
- 燃料计量（Gas Metering）
- 沙箱安全

**案例：**
- EOSIO（C++ → Wasm）
- NEAR Protocol（Rust → Wasm）
- Polkadot（Substrate）

**性能**：
\[
\text{TPS}_{\text{wasm}} \approx 5000-10000 \quad \text{（vs EVM 20-50）}
\]

---

## 批判性分析

### 碎片化的生态

**命题**：
\[
|\text{Runtimes}| > 10 \implies \text{生态碎片化}
\]

**现状**：
- Wasmtime, Wasmer, WAMR, WasmEdge, Wasm3, ...
- 不同 WASI 版本（Preview1 vs Preview2）
- 非标准扩展（各家 AI、Crypto 接口）

**批判**：
> "标准"的多样性实现了"反标准"。每个运行时都声称遵循规范，但实际互操作性有限。这是开源生态的悖论。

### 性能天花板

**抽象税分解**：
\[
\begin{align*}
\text{Overhead}_{\text{total}} &= \text{验证} + \text{边界检查} + \text{间接跳转} \\
&\approx 2\% + 3\% + 10\% \\
&= 15\%
\end{align*}
\]

**本质限制**：
\[
\exists \text{理论下界} : \text{Perf}_{\text{wasm}} \leq 0.90 \times \text{native}
\]

**批判**：
> 无论编译器如何优化，沙箱抽象的本质开销无法消除。追求"接近原生"是渐近目标，永无法达到 1.0×。

### 生态网络效应缺失

**对比 Docker**：
\[
\begin{align*}
\text{Docker-Hub-Images} &> 10^7 \\
\text{WAPM-Packages} &< 10^3
\end{align*}
\]

**原因分析**：
1. 时间积累（Docker 2013 vs Wasm 2017）
2. 企业支持（Docker Inc. vs W3C 社区）
3. 杀手应用（容器编排 vs ？）

**批判**：
> Wasm standalone 运行时技术上优越（启动快、密度高），但生态上落后数个数量级。技术不会自动胜出，网络效应才是护城河。

---

## 实证案例

### Shopify Functions

**架构**：
```
Shopify Core (Ruby)
    ↓ (调用)
Wasmtime Runtime
    ↓ (执行)
Merchant Function (Wasm)
```

**性能数据**：
- 函数执行：<5ms（P99）
- 冷启动：<1ms
- 实例密度：10k+/node

**关键优化**：
- 实例池化（Instance Pooling）
- 共享内存（预分配）
- AOT 预编译

### Cloudflare Workers

**对比传统 V8 Isolates**：

| 指标 | Workers(JS) | Workers(Wasm) |
|------|------------|---------------|
| **冷启动** | <5ms | <5ms |
| **CPU 限制** | 50ms | 50ms |
| **内存限制** | 128MB | 128MB |
| **性能** | 基准 | 1.5-3× (计算密集) |

---

## 未来方向

### 1. 组件模型（Component Model）
```wasm
(component
  (import "http" (instance $http
    (export "request" (func ...))
  ))
  (export "handle" (func ...))
)
```

### 2. 异步支持
```wasm
(import "wasi" "async-poll"
  (func $poll (param promise) (result ready)))
```

### 3. 原生线程
- pthread 映射
- 真正的并行执行

---

## 参考文献

1. **[Wasmtime]** Bytecode Alliance. "Wasmtime: A Fast and Secure Runtime." https://wasmtime.dev/
2. **[Wasmer]** Wasmer. "The Universal WebAssembly Runtime." https://wasmer.io/
3. **[WAMR]** Bytecode Alliance. "WebAssembly Micro Runtime." https://github.com/bytecodealliance/wasm-micro-runtime

---

**结论**：
> 独立运行时将 Wasm 从浏览器解放，推向"通用计算平台"的愿景。但生态碎片化、性能天花板、网络效应缺失，三重挑战并存。它证明了技术可能性，但未证明商业必然性。Wasm 的未来，不在沙箱的完美，而在生态的繁荣。
