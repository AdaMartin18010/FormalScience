#!/usr/bin/env python3
"""
ä¿®å¤ Markdown æ–‡ä»¶çš„ç›®å½•å’Œåºå·é—®é¢˜
- è‡ªåŠ¨ç”Ÿæˆç¼ºå¤±çš„ç›®å½•
- ä¿®å¤ä¸»é¢˜ä¸å­ä¸»é¢˜åºå·ä¸ä¸€è‡´çš„é—®é¢˜
"""

import os
import re
from pathlib import Path
from typing import List, Tuple, Optional

class MarkdownTOCFixer:
    def __init__(self, base_path: str):
        self.base_path = Path(base_path)
        self.issues = []
        self.fixed = []
        
    def extract_headings(self, content: str) -> List[Tuple[int, str, str]]:
        """æå–æ‰€æœ‰æ ‡é¢˜ (level, text, anchor)"""
        headings = []
        lines = content.split('\n')
        
        for line in lines:
            # è·³è¿‡ä»£ç å—ä¸­çš„å†…å®¹
            if line.strip().startswith('```'):
                continue
                
            match = re.match(r'^(#{1,6})\s+(.+)$', line)
            if match:
                level = len(match.group(1))
                text = match.group(2).strip()
                # ç§»é™¤å¯èƒ½çš„ emoji å’Œç‰¹æ®Šå­—ç¬¦ï¼Œç”Ÿæˆ anchor
                anchor = self.generate_anchor(text)
                headings.append((level, text, anchor))
        
        return headings
    
    def generate_anchor(self, text: str) -> str:
        """ç”Ÿæˆ GitHub é£æ ¼çš„ anchor"""
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™ä¸­è‹±æ–‡ã€æ•°å­—ã€ç©ºæ ¼ã€ä¸‹åˆ’çº¿
        text = re.sub(r'[^\w\s\u4e00-\u9fff_-]', '', text)
        # è½¬æ¢ä¸ºå°å†™ï¼Œç©ºæ ¼æ›¿æ¢ä¸ºè¿å­—ç¬¦
        anchor = text.lower().replace(' ', '-').replace('_', '-')
        # ç§»é™¤å¤šä½™çš„è¿å­—ç¬¦
        anchor = re.sub(r'-+', '-', anchor)
        return anchor.strip('-')
    
    def find_toc_section(self, content: str) -> Optional[Tuple[int, int]]:
        """æŸ¥æ‰¾ç°æœ‰çš„ç›®å½•éƒ¨åˆ† (start_line, end_line)"""
        lines = content.split('\n')
        
        # å¸¸è§çš„ç›®å½•æ ‡é¢˜æ¨¡å¼
        toc_patterns = [
            r'^##\s*ğŸ“‹\s*ç›®å½•',
            r'^##\s*ç›®å½•',
            r'^##\s*Table of Contents',
            r'^##\s*ğŸ“–\s*ç›®å½•',
            r'^<details>.*ç›®å½•.*</details>',
        ]
        
        start_line = None
        for i, line in enumerate(lines):
            for pattern in toc_patterns:
                if re.search(pattern, line, re.IGNORECASE):
                    start_line = i
                    break
            if start_line is not None:
                break
        
        if start_line is None:
            return None
        
        # æŸ¥æ‰¾ç›®å½•ç»“æŸä½ç½®ï¼ˆä¸‹ä¸€ä¸ªéåˆ—è¡¨è¡Œæˆ–ä¸‹ä¸€ä¸ª ## æ ‡é¢˜ï¼‰
        end_line = start_line + 1
        for i in range(start_line + 1, len(lines)):
            line = lines[i].strip()
            # é‡åˆ°ä¸‹ä¸€ä¸ªä¸»æ ‡é¢˜æˆ–åˆ†éš”ç¬¦ï¼Œç›®å½•ç»“æŸ
            if line.startswith('##') and not line.startswith('###'):
                end_line = i
                break
            if line.startswith('---') and i > start_line + 2:
                end_line = i
                break
            if line.startswith('<details>') or line.startswith('</details>'):
                end_line = i + 1
                break
        
        return (start_line, end_line)
    
    def generate_toc(self, headings: List[Tuple[int, str, str]], 
                     skip_first: bool = True) -> str:
        """ç”Ÿæˆç›®å½•å†…å®¹"""
        if not headings:
            return ""
        
        toc_lines = ["## ğŸ“‹ ç›®å½•\n"]
        
        # è·³è¿‡ç¬¬ä¸€ä¸ªæ ‡é¢˜ï¼ˆé€šå¸¸æ˜¯æ–‡ä»¶æ ‡é¢˜ï¼‰
        start_idx = 1 if skip_first and headings else 0
        
        for level, text, anchor in headings[start_idx:]:
            # åªåŒ…å« 2-4 çº§æ ‡é¢˜
            if level < 2 or level > 4:
                continue
            
            indent = "  " * (level - 2)
            toc_lines.append(f"{indent}- [{text}](#{anchor})")
        
        toc_lines.append("")
        return "\n".join(toc_lines)
    
    def check_numbering_consistency(self, content: str) -> List[str]:
        """æ£€æŸ¥åºå·ä¸€è‡´æ€§"""
        issues = []
        lines = content.split('\n')
        
        # æ£€æŸ¥æ ‡é¢˜åºå·æ¨¡å¼
        numbered_headings = []
        for i, line in enumerate(lines):
            match = re.match(r'^(#{2,6})\s+(\d+\.)+\s*(.+)$', line)
            if match:
                level = len(match.group(1))
                number = match.group(2)
                text = match.group(3)
                numbered_headings.append((i, level, number, text))
        
        if not numbered_headings:
            return issues
        
        # æ£€æŸ¥åºå·è¿ç»­æ€§
        level_counters = {}
        for i, (line_num, level, number, text) in enumerate(numbered_headings):
            parts = [int(x) for x in number.rstrip('.').split('.')]
            
            if level not in level_counters:
                level_counters[level] = []
            
            level_counters[level].append((line_num, parts, text))
            
            # ç®€å•æ£€æŸ¥ï¼šåŒçº§æ ‡é¢˜åºå·åº”è¯¥é€’å¢
            if len(level_counters[level]) > 1:
                prev_parts = level_counters[level][-2][1]
                curr_parts = parts
                
                # æ£€æŸ¥æœ€åä¸€ä½æ˜¯å¦é€’å¢
                if len(curr_parts) == len(prev_parts):
                    if curr_parts[-1] != prev_parts[-1] + 1:
                        issues.append(f"Line {line_num+1}: åºå·ä¸è¿ç»­ {'.'.join(map(str, prev_parts))} -> {'.'.join(map(str, curr_parts))}")
        
        return issues
    
    def needs_toc(self, content: str, headings: List[Tuple[int, str, str]]) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æ·»åŠ ç›®å½•"""
        # å¦‚æœæ ‡é¢˜æ•°é‡ >= 5ï¼Œå»ºè®®æ·»åŠ ç›®å½•
        if len(headings) >= 5:
            return True
        
        # å¦‚æœæ–‡ä»¶è¶…è¿‡ 500 è¡Œï¼Œå»ºè®®æ·»åŠ ç›®å½•
        if len(content.split('\n')) >= 500:
            return True
        
        return False
    
    def insert_toc(self, content: str, toc: str) -> str:
        """åœ¨é€‚å½“ä½ç½®æ’å…¥ç›®å½•"""
        lines = content.split('\n')
        
        # æŸ¥æ‰¾æ’å…¥ä½ç½®ï¼šåœ¨å…ƒæ•°æ®å—ä¹‹åï¼Œç¬¬ä¸€ä¸ª ## æ ‡é¢˜ä¹‹å‰
        insert_pos = 0
        in_metadata = False
        
        for i, line in enumerate(lines):
            # æ£€æµ‹å…ƒæ•°æ®å—
            if i == 0 and line.strip().startswith('>'):
                in_metadata = True
            
            if in_metadata:
                # å…ƒæ•°æ®å—ç»“æŸ
                if line.strip() == '---':
                    insert_pos = i + 1
                    break
                if not line.strip().startswith('>') and line.strip() != '':
                    in_metadata = False
            
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ª ## æ ‡é¢˜
            if line.startswith('## '):
                insert_pos = i
                break
        
        # æ’å…¥ç›®å½•
        lines.insert(insert_pos, '\n---\n')
        lines.insert(insert_pos + 1, toc)
        lines.insert(insert_pos + 2, '\n---\n')
        
        return '\n'.join(lines)
    
    def fix_file(self, filepath: Path) -> dict:
        """ä¿®å¤å•ä¸ªæ–‡ä»¶"""
        result = {
            'path': str(filepath.relative_to(self.base_path)),
            'has_toc': False,
            'needs_toc': False,
            'toc_updated': False,
            'numbering_issues': [],
            'action': 'skip'
        }
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå–æ ‡é¢˜
            headings = self.extract_headings(content)
            
            if not headings:
                result['action'] = 'skip - no headings'
                return result
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›®å½•
            toc_section = self.find_toc_section(content)
            result['has_toc'] = toc_section is not None
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç›®å½•
            result['needs_toc'] = self.needs_toc(content, headings)
            
            # æ£€æŸ¥åºå·ä¸€è‡´æ€§
            result['numbering_issues'] = self.check_numbering_consistency(content)
            
            # å†³å®šæ˜¯å¦éœ€è¦ä¿®å¤
            needs_fix = False
            new_content = content
            
            # æƒ…å†µ1ï¼šéœ€è¦ç›®å½•ä½†æ²¡æœ‰
            if result['needs_toc'] and not result['has_toc']:
                toc = self.generate_toc(headings)
                new_content = self.insert_toc(new_content, toc)
                result['toc_updated'] = True
                result['action'] = 'added TOC'
                needs_fix = True
            
            # æƒ…å†µ2ï¼šå·²æœ‰ç›®å½•ï¼Œæ›´æ–°
            elif result['has_toc']:
                toc = self.generate_toc(headings)
                lines = new_content.split('\n')
                start, end = toc_section
                
                # æ›¿æ¢æ—§ç›®å½•
                new_lines = lines[:start] + toc.split('\n') + lines[end:]
                new_content = '\n'.join(new_lines)
                result['toc_updated'] = True
                result['action'] = 'updated TOC'
                needs_fix = True
            
            # ä¿å­˜ä¿®æ”¹
            if needs_fix:
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                self.fixed.append(result)
            
            # è®°å½•é—®é¢˜
            if result['numbering_issues']:
                self.issues.append(result)
            
            return result
            
        except Exception as e:
            result['action'] = f'error: {str(e)}'
            return result
    
    def scan_and_fix(self, dry_run: bool = False) -> dict:
        """æ‰«æå¹¶ä¿®å¤æ‰€æœ‰ Markdown æ–‡ä»¶"""
        stats = {
            'total': 0,
            'fixed': 0,
            'issues': 0,
            'skipped': 0
        }
        
        results = []
        
        # é€’å½’éå†æ‰€æœ‰ .md æ–‡ä»¶
        for md_file in self.base_path.rglob('*.md'):
            # è·³è¿‡æŸäº›ç‰¹æ®Šæ–‡ä»¶
            if any(skip in str(md_file) for skip in [
                'node_modules', '.git', 'venv', '__pycache__'
            ]):
                continue
            
            stats['total'] += 1
            
            if not dry_run:
                result = self.fix_file(md_file)
                results.append(result)
                
                if result['action'].startswith('added') or result['action'].startswith('updated'):
                    stats['fixed'] += 1
                elif result['numbering_issues']:
                    stats['issues'] += 1
                else:
                    stats['skipped'] += 1
        
        return {
            'stats': stats,
            'results': results,
            'fixed_files': self.fixed,
            'issue_files': self.issues
        }

def main():
    import json
    
    # è·å– Concept ç›®å½•çš„è·¯å¾„
    base_path = Path(__file__).parent
    
    print("=" * 80)
    print("Markdown ç›®å½•å’Œåºå·ä¿®å¤å·¥å…·")
    print("=" * 80)
    print(f"\næ‰«æç›®å½•: {base_path}")
    print("\nå¼€å§‹å¤„ç†...\n")
    
    fixer = MarkdownTOCFixer(str(base_path))
    report = fixer.scan_and_fix(dry_run=False)
    
    # è¾“å‡ºç»Ÿè®¡
    print("\n" + "=" * 80)
    print("å¤„ç†å®Œæˆï¼")
    print("=" * 80)
    print(f"\næ€»æ–‡ä»¶æ•°: {report['stats']['total']}")
    print(f"å·²ä¿®å¤: {report['stats']['fixed']}")
    print(f"æœ‰é—®é¢˜: {report['stats']['issues']}")
    print(f"è·³è¿‡: {report['stats']['skipped']}")
    
    # è¾“å‡ºä¿®å¤çš„æ–‡ä»¶
    if report['fixed_files']:
        print("\n" + "-" * 80)
        print("å·²ä¿®å¤çš„æ–‡ä»¶:")
        print("-" * 80)
        for item in report['fixed_files'][:20]:  # åªæ˜¾ç¤ºå‰20ä¸ª
            print(f"  âœ… {item['path']} - {item['action']}")
        if len(report['fixed_files']) > 20:
            print(f"  ... è¿˜æœ‰ {len(report['fixed_files']) - 20} ä¸ªæ–‡ä»¶")
    
    # è¾“å‡ºæœ‰åºå·é—®é¢˜çš„æ–‡ä»¶
    if report['issue_files']:
        print("\n" + "-" * 80)
        print("å‘ç°åºå·é—®é¢˜çš„æ–‡ä»¶ï¼ˆéœ€è¦æ‰‹åŠ¨æ£€æŸ¥ï¼‰:")
        print("-" * 80)
        for item in report['issue_files'][:10]:
            print(f"  âš ï¸  {item['path']}")
            for issue in item['numbering_issues'][:3]:
                print(f"     - {issue}")
        if len(report['issue_files']) > 10:
            print(f"  ... è¿˜æœ‰ {len(report['issue_files']) - 10} ä¸ªæ–‡ä»¶")
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    report_file = base_path / 'TOC_FIX_REPORT.json'
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    print("\n" + "=" * 80)

if __name__ == '__main__':
    main()

