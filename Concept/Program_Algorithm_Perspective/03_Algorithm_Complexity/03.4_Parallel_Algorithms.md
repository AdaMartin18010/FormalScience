# 03.4 并行算法与Work-Span模型

## 📊 核心概念深度分析

<details>
<summary><b>⚡🔬 点击展开：并行算法核心洞察</b></summary>

**终极洞察**: 并行计算=用处理器数换时间。Work-Span模型：算法的双维度刻画①Work W(n)=总操作数（单处理器时间）②Span S(n)=关键路径长度（无限处理器时间）③并行度P(n)=W/S（可用并行性）④实际时间T_p(n)=W/p+S（p个处理器）。Greedy调度定理：T_p≤W/p+S（任何贪心调度达到此界）。并行算法设计：①分治（递归并行）：快排、归并、Strassen矩阵乘法②前缀和（Scan）：O(n) work, O(log n) span，并行算法的瑞士军刀③树型计算：归约、广播④流水线：任务并行。复杂度类：NC（Nick's Class）=O(log^k n) span + 多项式work，高效可并行化问题。P-完全问题：难以并行化（如电路求值、线性规划）。Work-Stealing调度：Cilk/Rust Rayon的基础，期望时间T_p≤W/p+O(S)。缓存高效：Cache-Oblivious并行算法，无需知道缓存参数。关键：Work-Span模型精确刻画并行性能，指导多核/GPU/集群算法设计。

</details>

---

## 📚 目录

- [概述](#概述)
- [1. 并行计算模型](#1-并行计算模型)
  - [1.1 PRAM 模型（Parallel Random Access Machine）](#11-pram-模型parallel-random-access-machine)
  - [1.2 Work-Span 模型](#12-work-span-模型)
  - [1.3 形式化定义](#13-形式化定义)
- [2. 并行算法设计技术](#2-并行算法设计技术)
  - [2.1 分治（Divide and Conquer）](#21-分治divide-and-conquer)
  - [2.2 前缀和（Prefix Sum / Scan）](#22-前缀和prefix-sum--scan)
  - [2.3 矩阵乘法](#23-矩阵乘法)
- [3. 调度理论](#3-调度理论)
  - [3.1 Work-Stealing 调度](#31-work-stealing-调度)
  - [3.2 Greedy 调度的Coq证明](#32-greedy-调度的coq证明)
- [4. 实战案例](#4-实战案例)
  - [4.1 快速排序（Parallel Quicksort）](#41-快速排序parallel-quicksort)
  - [4.2 并行BFS（Breadth-First Search）](#42-并行bfsbreadth-first-search)
- [5. 与国际课程对标](#5-与国际课程对标)
  - [5.1 大学课程映射](#51-大学课程映射)
  - [5.2 教材对应](#52-教材对应)
- [6. 工具与生态](#6-工具与生态)
  - [6.1 并行编程框架](#61-并行编程框架)
  - [6.2 形式化工具](#62-形式化工具)
- [7. 高级主题](#7-高级主题)
  - [7.1 Cache-Oblivious 并行算法](#71-cache-oblivious-并行算法)
  - [7.2 外部存储并行算法](#72-外部存储并行算法)
  - [7.3 量子并行算法](#73-量子并行算法)
- [8. 扩展阅读](#8-扩展阅读)
  - [8.1 学术论文](#81-学术论文)
  - [8.2 在线资源](#82-在线资源)
  - [8.3 本地项目引用](#83-本地项目引用)
- [附录 A：Wikipedia 概念对照](#附录-awikipedia-概念对照)

---

## 概述

**并行算法**（Parallel Algorithms）研究如何利用多个处理器同时计算以加速问题求解。核心问题：
> 给定 P 个处理器，如何设计算法使总时间最小？

本文系统介绍：

1. **Work-Span 模型**：并行复杂度的理论基础
2. **并行算法设计技术**：分治、前缀和、列表排序
3. **调度理论**：Work-Stealing, Greedy Scheduling
4. **形式化验证**：Coq/Lean4 中的并行性证明

---

## 1. 并行计算模型

### 1.1 PRAM 模型（Parallel Random Access Machine）

**定义**：

```text
PRAM = ⟨P个处理器, 共享内存, 同步时钟⟩

每个时间步：
  1. 每个处理器从共享内存读取数据
  2. 执行本地计算
  3. 写回共享内存

变种（根据读写冲突处理）：
  - EREW (Exclusive Read Exclusive Write)：无冲突
  - CREW (Concurrent Read Exclusive Write)：允许同时读
  - CRCW (Concurrent Read Concurrent Write)：允许同时读写
    - COMMON：写入相同值
    - ARBITRARY：任意一个写入成功
    - PRIORITY：优先级最高的写入
```

**示例**：并行求和（CREW PRAM）

```text
输入：A[1..n]
输出：sum = Σᵢ A[i]

算法（二叉树归约）：
  for d = 1 to ⌈log₂ n⌉:
    parfor i = 1 to ⌊n / 2^d⌋:
      B[i] = A[2i-1] + A[2i]
    A := B

时间：O(log n)  （使用 n/2 个处理器）
工作：O(n)      （总操作数）
```

### 1.2 Work-Span 模型

**核心概念**：

```text
Work (T₁)：
  - 单处理器执行的总时间
  - 等价于串行算法的时间复杂度

Span (T_∞)：
  - 无限处理器的执行时间
  - 等价于关键路径长度（critical path）
  - 也称为 Depth

并行度（Parallelism）：
  T₁ / T_∞
  
  表示算法可以从并行中获益的程度
```

**Brent定理**（调度下界）：

```text
定理：使用 P 个处理器，任何调度的执行时间满足：
  T_P ≥ max(T₁/P, T_∞)

证明：
  - T₁/P：平均每个处理器需要 T₁/P 时间（工作量下界）
  - T_∞：关键路径无法并行化（依赖性下界）
```

**贪心调度（Greedy Scheduling）**：

```text
定理：贪心调度保证：
  T_P ≤ T₁/P + T_∞

证明草图：
  - 将时间步分为两类：
    1. "完整步"（Complete Step）：P 个处理器都在工作
    2. "不完整步"（Incomplete Step）：< P 个处理器在工作
  
  - 完整步数 ≤ T₁/P（工作量限制）
  - 不完整步数 ≤ T_∞（关键路径限制，每步至少减少1深度）
  
  - 因此 T_P ≤ T₁/P + T_∞

推论（线性加速）：
  如果 T₁/T_∞ ≫ P，则 T_P ≈ T₁/P（近似线性加速）
```

### 1.3 形式化定义

```text
并行算法的抽象语法：

e ::= n                    (常量)
    | x                    (变量)
    | e₁ op e₂             (顺序运算)
    | spawn e₁; e₂         (派生并行任务)
    | sync                 (同步等待)
    | parfor(i, 1, n, e)   (并行循环)

Work-Span 语义：

⟦n⟧ = (1, 1)              (Work=1, Span=1)

⟦e₁ op e₂⟧ = let (W₁, S₁) = ⟦e₁⟧
               let (W₂, S₂) = ⟦e₂⟧
             in (W₁ + W₂ + 1, S₁ + S₂ + 1)

⟦spawn e₁; e₂⟧ = let (W₁, S₁) = ⟦e₁⟧
                  let (W₂, S₂) = ⟦e₂⟧
                in (W₁ + W₂, max(S₁, S₂))
                  （并行执行，工作量相加，Span 取最大）

⟦parfor(i, 1, n, e)⟧ = let (W, S) = ⟦e⟧ per iteration
                     in (n × W, S)
                       （n 个任务并行，总工作量 n×W，Span = S）
```

---

## 2. 并行算法设计技术

### 2.1 分治（Divide and Conquer）

#### 并行归并排序

**算法**：

```pseudocode
parallel_merge_sort(A[1..n]):
  if n <= 1:
    return A
  
  mid = n / 2
  spawn L = parallel_merge_sort(A[1..mid])
  spawn R = parallel_merge_sort(A[mid+1..n])
  sync
  
  return parallel_merge(L, R)
```

**分析**：

```text
Work（T₁）：
  W(n) = 2W(n/2) + O(n)  （归并需要 O(n）工作）
  W(n) = O(n log n)      （Master Theorem）

Span（T_∞）：
  S(n) = S(n/2) + O(log n)  （并行归并的 Span）
  S(n) = O(log² n)

并行度：
  P = W/S = (n log n) / (log² n) = n / log n
  
  结论：当 P ≪ n/log n 时，可获得近似线性加速
```

**并行归并（Parallel Merge）**：

```pseudocode
parallel_merge(A[1..m], B[1..n]):
  if m + n <= threshold:
    return serial_merge(A, B)
  
  # 取 A 的中位数
  mid_A = A[m/2]
  
  # 在 B 中二分查找 mid_A 的位置
  pos_B = binary_search(B, mid_A)
  
  # 并行归并左右两部分
  spawn left = parallel_merge(A[1..m/2], B[1..pos_B])
  spawn right = parallel_merge(A[m/2+1..m], B[pos_B+1..n])
  sync
  
  return concat(left, right)
```

**Span 分析**：

```text
S(m, n) = S(m/2, k) + O(log n)  （k ≤ n）
S(m, n) = O(log m × log n)

因此归并排序的总 Span：
  S_sort(n) = S_sort(n/2) + O(log² n) = O(log³ n)
  
优化（Cole 1988）：可以达到 O(log n) Span！
```

### 2.2 前缀和（Prefix Sum / Scan）

**问题**：

```text
输入：A[1..n]
输出：B[i] = Σⱼ₌₁ⁱ A[j]  对所有 i

示例：
  A = [3, 1, 4, 1, 5]
  B = [3, 4, 8, 9, 14]
```

**串行算法**：O(n) 时间，O(1) 空间

**并行算法（Up-Down Tree）**：

```pseudocode
parallel_scan(A[1..n]):
  # Up-sweep phase（自底向上）
  for d = 0 to log₂ n - 1:
    parfor i where 2^(d+1) | i:
      A[i] = A[i - 2^d] + A[i]
  
  # Down-sweep phase（自顶向下）
  A[n] = 0  # 初始化根为0
  for d = log₂ n - 1 downto 0:
    parfor i where 2^(d+1) | i:
      temp = A[i - 2^d]
      A[i - 2^d] = A[i]
      A[i] = A[i] + temp
  
  return A
```

**复杂度**：

```text
Work：
  - Up-sweep: Σᵈ n/2^(d+1) = O(n)
  - Down-sweep: O(n)
  - 总计：O(n)

Span：
  - Up-sweep: O(log n) 层
  - Down-sweep: O(log n) 层
  - 总计：O(log n)

并行度：P = n / log n
```

**应用**：

```text
1. Compact（数组压缩）：
   输入：[3, 0, 0, 5, 0, 7]  （0 表示删除）
   Flags：[1, 0, 0, 1, 0, 1]
   Scan：[1, 1, 1, 2, 2, 3]
   输出：[3, 5, 7]

2. Quicksort 分割：
   并行计算 < pivot 和 ≥ pivot 的元素位置

3. 树遍历（Euler Tour）：
   并行计算树节点的深度、子树大小等
```

### 2.3 矩阵乘法

#### 天真并行算法

```pseudocode
parallel_matmul(A[n×n], B[n×n]):
  parfor i = 1 to n:
    parfor j = 1 to n:
      C[i][j] = Σₖ A[i][k] * B[k][j]
  
  return C
```

**复杂度**：

```text
Work：O(n³)
Span：O(n)  （内层求和串行）
并行度：O(n²)
```

#### Strassen 并行算法

```pseudocode
parallel_strassen(A[n×n], B[n×n]):
  if n <= threshold:
    return serial_matmul(A, B)
  
  # 分块
  A₁₁, A₁₂, A₂₁, A₂₂ = partition(A)
  B₁₁, B₁₂, B₂₁, B₂₂ = partition(B)
  
  # 并行计算 7 个矩阵乘法
  spawn M₁ = parallel_strassen(A₁₁ + A₂₂, B₁₁ + B₂₂)
  spawn M₂ = parallel_strassen(A₂₁ + A₂₂, B₁₁)
  spawn M₃ = parallel_strassen(A₁₁, B₁₂ - B₂₂)
  spawn M₄ = parallel_strassen(A₂₂, B₂₁ - B₁₁)
  spawn M₅ = parallel_strassen(A₁₁ + A₁₂, B₂₂)
  spawn M₆ = parallel_strassen(A₂₁ - A₁₁, B₁₁ + B₁₂)
  spawn M₇ = parallel_strassen(A₁₂ - A₂₂, B₂₁ + B₂₂)
  sync
  
  # 组合结果
  C₁₁ = M₁ + M₄ - M₅ + M₇
  C₁₂ = M₃ + M₅
  C₂₁ = M₂ + M₄
  C₂₂ = M₁ - M₂ + M₃ + M₆
  
  return combine(C₁₁, C₁₂, C₂₁, C₂₂)
```

**复杂度**：

```text
Work：
  W(n) = 7W(n/2) + O(n²)
  W(n) = O(n^log₂ 7) ≈ O(n^2.807)

Span：
  S(n) = S(n/2) + O(log n)  （加法矩阵并行）
  S(n) = O(log² n)

并行度：P = n^2.807 / log² n
```

---

## 3. 调度理论

### 3.1 Work-Stealing 调度

**算法**：

```text
每个处理器维护一个双端队列（deque）：
  - 本地任务放在队列头部
  - 处理器空闲时，从其他处理器队列尾部"偷取"任务

优点：
  - 低同步开销（大部分时间本地操作）
  - 动态负载均衡
  - 局部性好（本地任务优先）
```

**性能保证**：

```text
定理（Blumofe & Leiserson 1999）：
  Work-Stealing 调度的期望执行时间满足：
    E[T_P] ≤ T₁/P + O(T_∞)
  
  证明草图：
    - 将时间步分为两类：
      1. 至少 P/2 个处理器在工作（"重"步）
      2. < P/2 个处理器在工作（"轻"步）
    
    - 重步数 ≤ 2T₁/P（工作量限制）
    - 轻步数分析：
      * 每个轻步，至少有 P/2 个处理器空闲
      * 每个空闲处理器尝试偷取任务
      * 成功偷取的概率与关键路径长度相关
      * 期望轻步数 = O(P × T_∞)
    
    - 因此 E[T_P] = O(T₁/P + P × T_∞ / P) = O(T₁/P + T_∞)
```

**实现**（Cilk-style）：

```c
// 处理器主循环
void worker_loop(int id) {
  while (true) {
    Task* task = deque_pop_top(local_deque[id]);  // 本地弹出
    
    if (task == NULL) {
      // 尝试偷取任务
      task = steal_random();
      if (task == NULL) break;  // 全局完成
    }
    
    execute(task);
  }
}

Task* steal_random() {
  int victim = random_processor_id();
  return deque_pop_bottom(local_deque[victim]);  // 从尾部偷取
}
```

### 3.2 Greedy 调度的Coq证明

```coq
Require Import Coq.Arith.Arith.
Require Import Coq.Lists.List.

(* 任务依赖图（DAG） *)
Record DAG := {
  nodes : list nat;
  edges : list (nat * nat);  (* 依赖关系 *)
}.

(* Work 和 Span 定义 *)
Definition Work (g : DAG) : nat :=
  length (nodes g).

Definition Span (g : DAG) : nat :=
  (* 最长路径长度，需要通过拓扑排序计算 *)
  0.  (* 简化 *)

(* 调度 *)
Definition Schedule := nat -> list nat.  (* 时间步 -> 执行的节点 *)

(* Greedy 调度性质 *)
Definition is_greedy (s : Schedule) (P : nat) : Prop :=
  forall t : nat,
    length (s t) <= P /\  (* 不超过处理器数 *)
    (length (s t) < P -> (* 如果不满，则无可用任务 *)
       forall n, In n (nodes g) -> executed_before t s n \/ depends_on_pending t s n).

(* Brent 定理 *)
Theorem brent_theorem (g : DAG) (P : nat) (s : Schedule) :
  is_greedy s P ->
  let T_1 := Work g in
  let T_inf := Span g in
  let T_P := schedule_length s in
  T_P >= max (Nat.div T_1 P) T_inf.
Proof.
  intros H_greedy T_1 T_inf T_P.
  (* 证明工作量下界 *)
  assert (H_work : T_P >= Nat.div T_1 P).
  {
    (* 总工作量 = Σₜ |s(t)| ≤ T_P × P *)
    (* 因此 T_1 ≤ T_P × P，即 T_P ≥ T_1 / P *)
    unfold Work, T_1. unfold schedule_length, T_P.
    (* ... 详细证明 ... *)
    admit.
  }
  
  (* 证明关键路径下界 *)
  assert (H_span : T_P >= T_inf).
  {
    (* 关键路径上每个节点至少需要 1 个时间步 *)
    (* ... 详细证明 ... *)
    admit.
  }
  
  apply Nat.max_lub; assumption.
Admitted.
```

---

## 4. 实战案例

### 4.1 快速排序（Parallel Quicksort）

```rust
use rayon::prelude::*;

fn parallel_quicksort<T: Ord + Send>(arr: &mut [T]) {
    if arr.len() <= 1 {
        return;
    }
    
    let pivot_idx = partition(arr);
    let (left, right) = arr.split_at_mut(pivot_idx);
    
    // 并行递归排序左右两部分
    rayon::join(
        || parallel_quicksort(left),
        || parallel_quicksort(right),
    );
}

fn partition<T: Ord>(arr: &mut [T]) -> usize {
    let pivot_idx = arr.len() / 2;
    arr.swap(pivot_idx, arr.len() - 1);
    
    let mut i = 0;
    for j in 0..arr.len() - 1 {
        if arr[j] <= arr[arr.len() - 1] {
            arr.swap(i, j);
            i += 1;
        }
    }
    arr.swap(i, arr.len() - 1);
    i
}

// 测试
fn main() {
    let mut data = vec![5, 2, 8, 1, 9, 3, 7, 4, 6];
    parallel_quicksort(&mut data);
    println!("{:?}", data);  // [1, 2, 3, 4, 5, 6, 7, 8, 9]
}
```

**复杂度**：

```text
Work（期望）：O(n log n)
Span（期望）：O(log² n)  （每层 O(log n)，共 log n 层）
并行度：O(n / log n)

最坏情况：
  Work：O(n²)
  Span：O(n)
```

### 4.2 并行BFS（Breadth-First Search）

```go
package main

import (
    "sync"
)

type Graph struct {
    adj [][]int  // 邻接表
}

func ParallelBFS(g *Graph, start int) []int {
    n := len(g.adj)
    level := make([]int, n)
    for i := range level {
        level[i] = -1
    }
    level[start] = 0
    
    frontier := []int{start}
    currentLevel := 0
    
    for len(frontier) > 0 {
        nextFrontier := make(chan int, n)
        var wg sync.WaitGroup
        
        // 并行处理当前层的所有节点
        for _, u := range frontier {
            wg.Add(1)
            go func(u int) {
                defer wg.Done()
                for _, v := range g.adj[u] {
                    // 原子地检查并更新 level[v]
                    if atomic.CompareAndSwapInt32(&level[v], -1, currentLevel+1) {
                        nextFrontier <- v
                    }
                }
            }(u)
        }
        
        wg.Wait()
        close(nextFrontier)
        
        // 收集下一层节点
        frontier = make([]int, 0)
        for v := range nextFrontier {
            frontier = append(frontier, v)
        }
        
        currentLevel++
    }
    
    return level
}
```

**复杂度**：

```text
Work：O(V + E)  （与串行BFS相同）
Span：O(D × log V)  （D = 图的直径）

解释：
  - 每层并行处理，共 D 层
  - 每层内，处理 frontier 需要 O(log |frontier|) 时间（合并操作）
```

---

## 5. 与国际课程对标

### 5.1 大学课程映射

| 课程 | 相关章节 |
|------|---------|
| **MIT 6.046J 算法设计与分析** | Work-Span 模型，并行排序 |
| **CMU 15-418 并行计算机架构与编程** | Work-Stealing, PRAM |
| **Stanford CS149 并行计算** | 调度理论，矩阵乘法 |
| **UC Berkeley CS267 高性能计算** | 并行BFS，前缀和 |
| **UIUC CS420 并行编程** | Cilk, OpenMP |

### 5.2 教材对应

| 教材 | 相关章节 |
|------|---------|
| **CLRS** (Introduction to Algorithms) | Ch 27 (Multithreaded Algorithms) |
| **JaJa "Introduction to Parallel Algorithms"** | PRAM 模型，前缀和 |
| **Blelloch "Programming Parallel Algorithms"** | Scan, Work-Span |
| **Herlihy & Shavit "The Art of Multiprocessor Programming"** | 并发数据结构 |

---

## 6. 工具与生态

### 6.1 并行编程框架

| 框架 | 语言 | 特点 | Work-Stealing |
|------|------|------|---------------|
| **Cilk Plus** | C/C++ | `spawn/sync`，编译器内置 | ✅ |
| **Rayon** | Rust | 数据并行，`par_iter` | ✅ |
| **OpenMP** | C/C++/Fortran | `#pragma omp parallel for` | ⚠️ 依赖实现 |
| **TBB** | C++ | Intel 线程构建块 | ✅ |
| **Go** | Go | `goroutine`，CSP模型 | ⚠️ M:N 调度 |

### 6.2 形式化工具

| 工具 | 用途 | 示例 |
|------|------|------|
| **Coq** | Work-Span 证明 | §3.2 |
| **Isabelle/HOL** | 调度算法验证 | - |
| **CIVL** | 并发程序验证 | MPI 程序验证 |

---

## 7. 高级主题

### 7.1 Cache-Oblivious 并行算法

**定义**：

```text
Cache-Oblivious 算法：
  - 不知道缓存大小 Z 和缓存行大小 L
  - 自动适应任何内存层次结构

并行 + Cache-Oblivious：
  - 既要并行高效（低 Span）
  - 又要缓存高效（低 Cache Miss）
```

**示例**：矩阵转置

```pseudocode
parallel_transpose(A[n×n]):
  if n <= base_case:
    for i, j: B[j][i] = A[i][j]
    return
  
  spawn parallel_transpose(A[0:n/2, 0:n/2])
  spawn parallel_transpose(A[0:n/2, n/2:n])
  spawn parallel_transpose(A[n/2:n, 0:n/2])
  spawn parallel_transpose(A[n/2:n, n/2:n])
  sync
```

**复杂度**：

```text
Work：O(n²)
Span：O(log n)
Cache Miss：O(n² / L + n² / √Z)  （最优）
```

### 7.2 外部存储并行算法

**PDEM 模型**（Parallel Disk External Memory）：

```text
参数：
  P : 处理器数量
  D : 磁盘数量
  M : 内存大小（每个处理器）
  B : 磁盘块大小

并行排序（PDEM）：
  T_I/O = O((N / (PDB)) log_{M/B} (N / P))
  T_CPU = O((N / P) log N)
```

### 7.3 量子并行算法

**Grover 搜索**：

```text
经典并行：
  Work：O(N)
  Span：O(N / P)

量子：
  Work：O(√N)
  Span：O(√N)  （本质串行）

量子 + 经典并行：
  使用 P 个量子计算机并行搜索：
  Span：O(√(N / P))
```

---

## 8. 扩展阅读

### 8.1 学术论文

1. **Work-Stealing**: Blumofe & Leiserson. "Scheduling Multithreaded Computations by Work Stealing." JACM 1999.
2. **Scan**: Blelloch, G. "Prefix Sums and Their Applications." CMU Tech Report 1990.
3. **PRAM**: JaJa, J. "An Introduction to Parallel Algorithms." 1992.

### 8.2 在线资源

- **并行算法教程**：<http://www.cs.cmu.edu/~scandal/nesl.html>
- **Work-Span 分析**：<https://ocw.mit.edu/courses/6-046j-design-and-analysis-of-algorithms-spring-2015/>

### 8.3 本地项目引用

- **算法复杂度**：[./03.1_Multidimensional_Complexity.md](./03.1_Multidimensional_Complexity.md)
- **下界技术**：[./03.3_Lower_Bound_Techniques.md](./03.3_Lower_Bound_Techniques.md)
- **并发模型**：[../../FormalLanguage_Perspective/05_Computational_Models/](../../FormalLanguage_Perspective/05_Computational_Models/)

---

## 附录 A：Wikipedia 概念对照

| 概念 | Wikipedia 条目 | 本文章节 |
|------|---------------|----------|
| Parallel Algorithm | <https://en.wikipedia.org/wiki/Parallel_algorithm> | §1 |
| PRAM | <https://en.wikipedia.org/wiki/Parallel_random-access_machine> | §1.1 |
| Work-Span Model | <https://en.wikipedia.org/wiki/Analysis_of_parallel_algorithms> | §1.2 |
| Work Stealing | <https://en.wikipedia.org/wiki/Work_stealing> | §3.1 |
| Parallel Prefix | <https://en.wikipedia.org/wiki/Prefix_sum> | §2.2 |

---

**版本**：v1.0  
**最后更新**：2025-10-29  
**维护者**：FormalScience Project  
**许可**：MIT
