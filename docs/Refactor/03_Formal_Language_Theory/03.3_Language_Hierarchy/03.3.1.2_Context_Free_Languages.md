# 03.3.1.2 ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ (Context-Free Languages)

## ğŸ“š æ¦‚è¿°ä¸å®šä¹‰

ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€æ˜¯ä¹”å§†æ–¯åŸºå±‚æ¬¡ç»“æ„ä¸­çš„ç¬¬äºŒç±»è¯­è¨€ï¼ˆ2å‹è¯­è¨€ï¼‰ï¼Œåœ¨å½¢å¼è¯­è¨€ç†è®ºå’Œè®¡ç®—æœºç§‘å­¦ä¸­å…·æœ‰é‡è¦æ„ä¹‰ã€‚

### å®šä¹‰ä¸ç‰¹å¾

**å®šä¹‰ 1.1** (ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€)
è¯­è¨€ $L$ æ˜¯ä¸Šä¸‹æ–‡æ— å…³çš„ï¼Œå½“ä¸”ä»…å½“å­˜åœ¨ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³• $G$ï¼Œä½¿å¾— $L = L(G)$ã€‚

**ç‰¹å¾**:

- å…·æœ‰é€’å½’ç»“æ„
- èƒ½å¤Ÿè¡¨ç¤ºåµŒå¥—åŒ¹é…å…³ç³»ï¼ˆå¦‚æ‹¬å·åŒ¹é…ï¼‰
- æ”¯æŒä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•å’Œä¸‹æ¨è‡ªåŠ¨æœºå»ºæ¨¡
- å…·æœ‰æ³µå¼•ç†

### ä¸å…¶ä»–è¯­è¨€ç±»çš„å…³ç³»

ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€åœ¨ä¹”å§†æ–¯åŸºè°±ç³»ä¸­å¤„äºä¸­é—´å±‚æ¬¡ï¼š

- $\mathcal{L}_\text{Regular} \subset \mathcal{L}_\text{Context-Free} \subset \mathcal{L}_\text{Context-Sensitive}$
- æ¯”æ­£åˆ™è¯­è¨€è¡¨è¾¾èƒ½åŠ›æ›´å¼ºï¼Œèƒ½å¤„ç†åµŒå¥—ç»“æ„
- æ¯”ä¸Šä¸‹æ–‡ç›¸å…³è¯­è¨€è¡¨è¾¾èƒ½åŠ›æ›´å¼±ï¼Œä¸èƒ½å¤„ç†äº¤å‰ä¾èµ–

### åŸºæœ¬æ€§è´¨

- **é€’å½’æ€§**: å¯ä»¥é€šè¿‡é€’å½’ç»“æ„è¡¨ç¤º
- **åµŒå¥—æ€§**: èƒ½å¤„ç†åµŒå¥—ä¾èµ–å…³ç³»
- **é—­åŒ…æ€§**: åœ¨å¹¶ã€è¿æ¥ã€æ˜Ÿé—­åŒ…ç­‰æ“ä½œä¸‹ä¿æŒå°é—­
- **å¯åˆ¤å®šæ€§**: æˆå‘˜èµ„æ ¼ã€ç©ºæ€§é—®é¢˜å¯åˆ¤å®šï¼Œç­‰ä»·æ€§é—®é¢˜ä¸å¯åˆ¤å®š

## ğŸ” è¡¨ç¤ºæ–¹æ³•

### ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•

**å®šä¹‰ 2.1** (ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•)
ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•æ˜¯å››å…ƒç»„ $G = (V, \Sigma, P, S)$ï¼Œå…¶ä¸­ï¼š

- $V$ æ˜¯éç»ˆç»“ç¬¦é›†
- $\Sigma$ æ˜¯ç»ˆç»“ç¬¦é›†
- $P$ æ˜¯äº§ç”Ÿå¼è§„åˆ™é›†ï¼Œæ¯ä¸ªè§„åˆ™å½¢å¼ä¸º $A \to \alpha$ï¼Œå…¶ä¸­ $A \in V$ ä¸” $\alpha \in (V \cup \Sigma)^*$
- $S \in V$ æ˜¯å¼€å§‹ç¬¦å·

**ä¾‹å­**:
æ–‡æ³• $G = (\{S\}, \{a, b\}, P, S)$ï¼Œå…¶ä¸­ $P = \{S \to aSb \mid \varepsilon\}$ï¼Œç”Ÿæˆè¯­è¨€ $L(G) = \{a^n b^n \mid n \geq 0\}$ã€‚

### ä¸‹æ¨è‡ªåŠ¨æœº

**å®šä¹‰ 2.2** (ä¸‹æ¨è‡ªåŠ¨æœºï¼ŒPDA)
ä¸‹æ¨è‡ªåŠ¨æœºæ˜¯ä¸ƒå…ƒç»„ $M = (Q, \Sigma, \Gamma, \delta, q_0, Z_0, F)$ï¼Œå…¶ä¸­ï¼š

- $Q$ æ˜¯çŠ¶æ€é›†
- $\Sigma$ æ˜¯è¾“å…¥å­—æ¯è¡¨
- $\Gamma$ æ˜¯æ ˆå­—æ¯è¡¨
- $\delta: Q \times (\Sigma \cup \{\varepsilon\}) \times \Gamma \to 2^{Q \times \Gamma^*}$ æ˜¯è½¬ç§»å‡½æ•°
- $q_0 \in Q$ æ˜¯åˆå§‹çŠ¶æ€
- $Z_0 \in \Gamma$ æ˜¯åˆå§‹æ ˆç¬¦å·
- $F \subseteq Q$ æ˜¯æ¥å—çŠ¶æ€é›†

**å®šç† 2.3** (PDAç­‰ä»·æ€§)
è¯­è¨€ $L$ æ˜¯ä¸Šä¸‹æ–‡æ— å…³çš„ï¼Œå½“ä¸”ä»…å½“å­˜åœ¨PDA $M$ï¼Œä½¿å¾— $L = L(M)$ã€‚

### æ´¾ç”Ÿæ ‘ä¸å¥å‹

**å®šä¹‰ 2.4** (æ´¾ç”Ÿæ ‘)
æ´¾ç”Ÿæ ‘æ˜¯è¡¨ç¤ºå¥å­æ¨å¯¼è¿‡ç¨‹çš„æ ‘å½¢ç»“æ„ï¼š

- æ ¹èŠ‚ç‚¹æ˜¯å¼€å§‹ç¬¦å·
- å†…éƒ¨èŠ‚ç‚¹æ˜¯éç»ˆç»“ç¬¦
- å¶èŠ‚ç‚¹æ˜¯ç»ˆç»“ç¬¦æˆ– $\varepsilon$
- æ¯ä¸ªå†…éƒ¨èŠ‚ç‚¹åŠå…¶ç›´æ¥å­èŠ‚ç‚¹å¯¹åº”ä¸€ä¸ªäº§ç”Ÿå¼åº”ç”¨

**å®šä¹‰ 2.5** (å¥å‹)
åœ¨æ¨å¯¼è¿‡ç¨‹ä¸­å‡ºç°çš„å­—ç¬¦ä¸²ç§°ä¸ºå¥å‹ã€‚å¦‚æœå¥å‹ä¸­åªåŒ…å«ç»ˆç»“ç¬¦ï¼Œåˆ™ç§°ä¸ºå¥å­ã€‚

## ğŸ§  ç†è®ºåŸºç¡€

### æ–‡æ³•è½¬æ¢å’Œè§„èŒƒå½¢å¼

**å®šç† 3.1** (ChomskyèŒƒå¼)
æ¯ä¸ªä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•éƒ½å¯ä»¥è½¬æ¢ä¸ºChomskyèŒƒå¼ï¼Œå…¶ä¸­æ¯ä¸ªäº§ç”Ÿå¼å½¢å¼ä¸ºï¼š

- $A \to BC$ (å…¶ä¸­ $A, B, C \in V$)
- $A \to a$ (å…¶ä¸­ $A \in V, a \in \Sigma$)

**å®šç† 3.2** (GreibachèŒƒå¼)
æ¯ä¸ªä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•éƒ½å¯ä»¥è½¬æ¢ä¸ºGreibachèŒƒå¼ï¼Œå…¶ä¸­æ¯ä¸ªäº§ç”Ÿå¼å½¢å¼ä¸ºï¼š

- $A \to a\alpha$ (å…¶ä¸­ $A \in V, a \in \Sigma, \alpha \in V^*$)

**ç®—æ³• 3.3** (æ¶ˆé™¤Îµ-äº§ç”Ÿå¼)

```rust
fn eliminate_epsilon_productions(grammar: &CFG) -> CFG {
    // 1. æ‰¾å‡ºæ‰€æœ‰å¯ä»¥æ¨å¯¼å‡ºÎµçš„éç»ˆç»“ç¬¦
    let mut nullable = HashSet::new();
    let mut changed = true;
    
    while changed {
        changed = false;
        for (A, productions) in &grammar.productions {
            if !nullable.contains(A) {
                for rhs in productions {
                    if rhs.is_empty() || rhs.iter().all(|symbol| nullable.contains(symbol)) {
                        nullable.insert(A.clone());
                        changed = true;
                        break;
                    }
                }
            }
        }
    }
    
    // 2. æ„é€ æ–°çš„äº§ç”Ÿå¼è§„åˆ™
    let mut new_productions = HashMap::new();
    
    for (A, productions) in &grammar.productions {
        let mut new_prods = Vec::new();
        
        for rhs in productions {
            // åŸå§‹äº§ç”Ÿå¼ï¼ˆå¦‚æœä¸æ˜¯Îµäº§ç”Ÿå¼ï¼‰
            if !rhs.is_empty() {
                new_prods.push(rhs.clone());
            }
            
            // ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„ç»„åˆ
            if !rhs.is_empty() {
                let nullable_positions: Vec<_> = rhs.iter()
                    .enumerate()
                    .filter(|(_, symbol)| nullable.contains(*symbol))
                    .map(|(i, _)| i)
                    .collect();
                
                // ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„å­é›†
                for mask in 1..(1 << nullable_positions.len()) {
                    let mut new_rhs = rhs.clone();
                    for (bit_pos, &symbol_pos) in nullable_positions.iter().enumerate().rev() {
                        if (mask >> bit_pos) & 1 == 1 {
                            new_rhs.remove(symbol_pos);
                        }
                    }
                    if !new_rhs.is_empty() && !new_prods.contains(&new_rhs) {
                        new_prods.push(new_rhs);
                    }
                }
            }
        }
        
        new_productions.insert(A.clone(), new_prods);
    }
    
    // 3. æ„é€ æ–°çš„æ–‡æ³•
    CFG {
        non_terminals: grammar.non_terminals.clone(),
        terminals: grammar.terminals.clone(),
        productions: new_productions,
        start_symbol: grammar.start_symbol.clone()
    }
}
```

### é—­åŒ…æ€§è´¨

**å®šç† 3.4** (é—­åŒ…æ€§è´¨)
ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ç±»åœ¨ä»¥ä¸‹æ“ä½œä¸‹å°é—­ï¼š

1. **å¹¶è¿ç®—**: å¦‚æœ $L_1, L_2$ æ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ï¼Œåˆ™ $L_1 \cup L_2$ ä¹Ÿæ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€
2. **è¿æ¥è¿ç®—**: å¦‚æœ $L_1, L_2$ æ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ï¼Œåˆ™ $L_1 \cdot L_2$ ä¹Ÿæ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€
3. **æ˜Ÿé—­åŒ…**: å¦‚æœ $L$ æ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ï¼Œåˆ™ $L^*$ ä¹Ÿæ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€
4. **åŒæ€æ˜ å°„**: å¦‚æœ $L$ æ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ï¼Œ$h$ æ˜¯åŒæ€ï¼Œåˆ™ $h(L)$ ä¹Ÿæ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€
5. **é€†åŒæ€æ˜ å°„**: å¦‚æœ $L$ æ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ï¼Œ$h$ æ˜¯åŒæ€ï¼Œåˆ™ $h^{-1}(L)$ ä¹Ÿæ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€

**ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ç±»åœ¨ä»¥ä¸‹æ“ä½œä¸‹ä¸å°é—­**ï¼š

1. **äº¤è¿ç®—**: å­˜åœ¨ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ $L_1, L_2$ï¼Œä½¿å¾— $L_1 \cap L_2$ ä¸æ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€
2. **è¡¥è¿ç®—**: å­˜åœ¨ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ $L$ï¼Œä½¿å¾— $\Sigma^* - L$ ä¸æ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€
3. **å·®è¿ç®—**: å­˜åœ¨ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ $L_1, L_2$ï¼Œä½¿å¾— $L_1 - L_2$ ä¸æ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€

### æ³µå¼•ç†åŠåº”ç”¨

**å®šç† 3.5** (ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€æ³µå¼•ç†)
å¯¹äºä»»æ„ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ $L$ï¼Œå­˜åœ¨å¸¸æ•° $p > 0$ï¼Œä½¿å¾—å¯¹äºä»»æ„ $w \in L$ï¼Œè‹¥ $|w| \geq p$ï¼Œåˆ™ $w$ å¯ä»¥åˆ†è§£ä¸º $w = uvxyz$ï¼Œæ»¡è¶³ï¼š

1. $|vxy| \leq p$
2. $|vy| > 0$
3. å¯¹äºä»»æ„ $i \geq 0$ï¼Œéƒ½æœ‰ $uv^ixy^iz \in L$

**åº”ç”¨**:
æ³µå¼•ç†ç”¨äºè¯æ˜æŸä¸ªè¯­è¨€ä¸æ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ã€‚

**ä¾‹å­**:
è¯æ˜ $L = \{a^n b^n c^n \mid n \geq 1\}$ ä¸æ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ã€‚

**è¯æ˜**:
å‡è®¾ $L$ æ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ï¼Œåˆ™å­˜åœ¨æ³µå¼•ç†å¸¸æ•° $p$ã€‚è€ƒè™‘å­—ç¬¦ä¸² $w = a^p b^p c^p \in L$ã€‚

æ ¹æ®æ³µå¼•ç†ï¼Œ$w$ å¯ä»¥åˆ†è§£ä¸º $w = uvxyz$ï¼Œå…¶ä¸­ $|vxy| \leq p$ ä¸” $|vy| > 0$ã€‚ç”±äº $|vxy| \leq p$ï¼Œ$vxy$ ä¸å¯èƒ½åŒæ—¶åŒ…å«ä¸‰ç§å­—ç¬¦ã€‚

åˆ†æƒ…å†µè®¨è®ºï¼š

1. å¦‚æœ $vy$ åªåŒ…å« $a$ï¼Œåˆ™ $uv^2xy^2z$ åŒ…å«è¿‡å¤šçš„ $a$
2. å¦‚æœ $vy$ åªåŒ…å« $b$ï¼Œåˆ™ $uv^2xy^2z$ åŒ…å«è¿‡å¤šçš„ $b$
3. å¦‚æœ $vy$ åªåŒ…å« $c$ï¼Œåˆ™ $uv^2xy^2z$ åŒ…å«è¿‡å¤šçš„ $c$
4. å¦‚æœ $vy$ åŒ…å« $a$ å’Œ $b$ï¼Œåˆ™ $uv^2xy^2z$ ä¸­ $a$ å’Œ $b$ çš„é¡ºåºä¼šæ··ä¹±
5. å¦‚æœ $vy$ åŒ…å« $b$ å’Œ $c$ï¼Œåˆ™ $uv^2xy^2z$ ä¸­ $b$ å’Œ $c$ çš„é¡ºåºä¼šæ··ä¹±

æ‰€æœ‰æƒ…å†µéƒ½å¯¼è‡´ $uv^2xy^2z \notin L$ï¼ŒçŸ›ç›¾ã€‚å› æ­¤ï¼Œ$L$ ä¸æ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ã€‚

### åˆ¤å®šæ€§é—®é¢˜

**å®šç† 3.6** (åˆ¤å®šé—®é¢˜)
å¯¹äºä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ï¼Œæœ‰ä»¥ä¸‹åˆ¤å®šæ€§ç»“æœï¼š

1. **æˆå‘˜èµ„æ ¼é—®é¢˜**: å¯åˆ¤å®šï¼ˆCYKç®—æ³•ï¼Œæ—¶é—´å¤æ‚åº¦ $O(n^3)$ï¼‰
2. **ç©ºæ€§é—®é¢˜**: å¯åˆ¤å®š
3. **æœ‰é™æ€§é—®é¢˜**: å¯åˆ¤å®š
4. **ç­‰ä»·æ€§é—®é¢˜**: ä¸å¯åˆ¤å®š
5. **åŒ…å«æ€§é—®é¢˜**: ä¸å¯åˆ¤å®š
6. **æ­§ä¹‰æ€§é—®é¢˜**: ä¸å¯åˆ¤å®š

## ğŸ”„ è¯­æ³•åˆ†ææ–¹æ³•

### è‡ªé¡¶å‘ä¸‹åˆ†æ

**å®šä¹‰ 4.1** (è‡ªé¡¶å‘ä¸‹åˆ†æ)
è‡ªé¡¶å‘ä¸‹åˆ†æä»å¼€å§‹ç¬¦å·å‡ºå‘ï¼Œé€šè¿‡åº”ç”¨äº§ç”Ÿå¼è§„åˆ™é€æ­¥æ¨å¯¼å‡ºè¾“å…¥å­—ç¬¦ä¸²ã€‚

**é€’å½’ä¸‹é™åˆ†æ**:

```rust
fn recursive_descent_parse(input: &str, grammar: &CFG) -> bool {
    fn parse_nonterminal(nt: &NonTerminal, pos: usize, input: &[Token]) -> Option<usize> {
        for production in &grammar.productions[nt] {
            let mut current_pos = pos;
            let mut success = true;
            
            for symbol in production {
                match symbol {
                    Symbol::Terminal(term) => {
                        if current_pos < input.len() && &input[current_pos] == term {
                            current_pos += 1;
                        } else {
                            success = false;
                            break;
                        }
                    },
                    Symbol::NonTerminal(nt) => {
                        if let Some(new_pos) = parse_nonterminal(nt, current_pos, input) {
                            current_pos = new_pos;
                        } else {
                            success = false;
                            break;
                        }
                    }
                }
            }
            
            if success {
                return Some(current_pos);
            }
        }
        
        None
    }
    
    let tokens = tokenize(input);
    parse_nonterminal(&grammar.start_symbol, 0, &tokens) == Some(tokens.len())
}
```

### è‡ªåº•å‘ä¸Šåˆ†æ

**å®šä¹‰ 4.2** (è‡ªåº•å‘ä¸Šåˆ†æ)
è‡ªåº•å‘ä¸Šåˆ†æä»è¾“å…¥å­—ç¬¦ä¸²å¼€å§‹ï¼Œé€šè¿‡å½’çº¦æ“ä½œé€æ­¥å½’çº¦åˆ°å¼€å§‹ç¬¦å·ã€‚

**ç§»è¿›-å½’çº¦åˆ†æ**:

```rust
fn shift_reduce_parse(input: &str, grammar: &CFG) -> bool {
    let tokens = tokenize(input);
    let mut stack = Vec::new();
    let mut pos = 0;
    
    while pos < tokens.len() || !stack.is_empty() {
        // å°è¯•å½’çº¦
        let mut reduced = false;
        
        for (nt, productions) in &grammar.productions {
            for production in productions {
                if stack.len() >= production.len() {
                    let stack_suffix = &stack[stack.len() - production.len()..];
                    
                    if symbols_match(stack_suffix, production) {
                        // æ‰§è¡Œå½’çº¦
                        stack.truncate(stack.len() - production.len());
                        stack.push(Symbol::NonTerminal(nt.clone()));
                        reduced = true;
                        break;
                    }
                }
            }
            
            if reduced {
                break;
            }
        }
        
        // å¦‚æœæ— æ³•å½’çº¦ä¸”è¿˜æœ‰è¾“å…¥ï¼Œåˆ™ç§»è¿›
        if !reduced {
            if pos < tokens.len() {
                stack.push(Symbol::Terminal(tokens[pos].clone()));
                pos += 1;
            } else {
                return false; // æ— æ³•ç»§ç»­åˆ†æ
            }
        }
        
        // æ£€æŸ¥æ˜¯å¦å·²å®Œæˆè§£æ
        if stack.len() == 1 && stack[0] == Symbol::NonTerminal(grammar.start_symbol.clone()) {
            return pos == tokens.len();
        }
    }
    
    false
}
```

### LLä¸LRåˆ†æ

**å®šä¹‰ 4.3** (LLåˆ†æ)
LL(k)åˆ†ææ˜¯è‡ªé¡¶å‘ä¸‹çš„é¢„æµ‹åˆ†ææ–¹æ³•ï¼Œé€šè¿‡æŸ¥çœ‹è¾“å…¥çš„å‰kä¸ªç¬¦å·å†³å®šä½¿ç”¨å“ªæ¡äº§ç”Ÿå¼ã€‚

**LL(1)åˆ†æè¡¨æ„å»º**:

```rust
fn build_ll1_table(grammar: &CFG) -> LL1Table {
    let mut table = HashMap::new();
    
    // è®¡ç®—FIRSTå’ŒFOLLOWé›†åˆ
    let first_sets = compute_first_sets(grammar);
    let follow_sets = compute_follow_sets(grammar, &first_sets);
    
    for (nt, productions) in &grammar.productions {
        for production in productions {
            let first_of_rhs = compute_first_of_sequence(production, &first_sets);
            
            for terminal in &first_of_rhs {
                if terminal != &EPSILON {
                    table.insert((nt.clone(), terminal.clone()), production.clone());
                } else {
                    // å¯¹äºÎµäº§ç”Ÿå¼ï¼Œåœ¨FOLLOW(A)ä¸­çš„æ¯ä¸ªç»ˆç»“ç¬¦ä¸Šåº”ç”¨è¯¥äº§ç”Ÿå¼
                    for follow_term in &follow_sets[nt] {
                        table.insert((nt.clone(), follow_term.clone()), production.clone());
                    }
                }
            }
        }
    }
    
    table
}
```

**å®šä¹‰ 4.4** (LRåˆ†æ)
LR(k)åˆ†ææ˜¯è‡ªåº•å‘ä¸Šçš„åˆ†ææ–¹æ³•ï¼Œé€šè¿‡æŸ¥çœ‹å·²å¤„ç†çš„è¾“å…¥å’Œæœªå¤„ç†è¾“å…¥çš„å‰kä¸ªç¬¦å·å†³å®šç§»è¿›æˆ–å½’çº¦æ“ä½œã€‚

**LR(0)é¡¹é›†æ„å»º**:

```rust
fn build_lr0_items(grammar: &CFG) -> Vec<LR0ItemSet> {
    let mut item_sets = Vec::new();
    let mut unmarked_sets = Vec::new();
    
    // åˆ›å»ºåˆå§‹é¡¹é›†
    let initial_item = LR0Item { 
        production: &grammar.productions[&grammar.start_symbol][0], 
        dot_position: 0 
    };
    let initial_set = closure(&HashSet::from([initial_item]), grammar);
    
    item_sets.push(initial_set.clone());
    unmarked_sets.push(initial_set);
    
    // ä¸æ–­å¤„ç†æœªæ ‡è®°çš„é¡¹é›†
    while let Some(item_set) = unmarked_sets.pop() {
        // è·å–æ‰€æœ‰å¯èƒ½çš„ä¸‹ä¸€ä¸ªç¬¦å·
        let mut next_symbols = HashSet::new();
        for item in &item_set {
            if item.dot_position < item.production.len() {
                next_symbols.insert(&item.production[item.dot_position]);
            }
        }
        
        // å¯¹æ¯ä¸ªç¬¦å·æ„å»ºgotoé›†åˆ
        for symbol in next_symbols {
            let goto_set = goto(&item_set, symbol, grammar);
            
            if !goto_set.is_empty() {
                // æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒçš„é¡¹é›†
                if let Some(index) = item_sets.iter().position(|set| set == &goto_set) {
                    // æ·»åŠ è½¬æ¢
                    transitions.insert((item_sets.len() - 1, symbol.clone()), index);
                } else {
                    // æ·»åŠ æ–°çš„é¡¹é›†
                    transitions.insert((item_sets.len() - 1, symbol.clone()), item_sets.len());
                    item_sets.push(goto_set.clone());
                    unmarked_sets.push(goto_set);
                }
            }
        }
    }
    
    item_sets
}
```

## ğŸ’¼ åº”ç”¨åœºæ™¯

### ç¨‹åºè¯­è¨€è¯­æ³•

ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€æ˜¯å®šä¹‰å’Œè§£æç¼–ç¨‹è¯­è¨€è¯­æ³•çš„åŸºç¡€ï¼Œé€šè¿‡BNFæˆ–EBNFè¡¨ç¤ºè¯­æ³•è§„åˆ™ã€‚

```rust
// è¡¨è¾¾å¼è¯­æ³•çš„å®ç°
fn parse_expression(tokens: &[Token], pos: &mut usize) -> Result<Expr, ParseError> {
    parse_binary_expr(tokens, pos, 0)
}

fn parse_binary_expr(tokens: &[Token], pos: &mut usize, precedence: u8) -> Result<Expr, ParseError> {
    let mut left = parse_primary(tokens, pos)?;
    
    while *pos < tokens.len() {
        let op = match &tokens[*pos] {
            Token::Plus => BinaryOp::Add,
            Token::Minus => BinaryOp::Sub,
            Token::Star => BinaryOp::Mul,
            Token::Slash => BinaryOp::Div,
            _ => break
        };
        
        let op_precedence = get_precedence(&op);
        if op_precedence < precedence {
            break;
        }
        
        *pos += 1; // æ¶ˆè€—æ“ä½œç¬¦
        
        let right = parse_binary_expr(tokens, pos, op_precedence + 1)?;
        left = Expr::Binary(Box::new(left), op, Box::new(right));
    }
    
    Ok(left)
}
```

### è‡ªç„¶è¯­è¨€ç»“æ„

ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•è¢«ç”¨äºæ¨¡æ‹Ÿè‡ªç„¶è¯­è¨€çš„å¥æ³•ç»“æ„ï¼Œæ˜¯è®¡ç®—è¯­è¨€å­¦çš„åŸºç¡€ã€‚

```rust
// ç®€å•å¥æ³•åˆ†æå™¨
fn parse_sentence(tokens: &[Word]) -> Option<SyntaxTree> {
    // S -> NP VP
    let np = parse_noun_phrase(tokens, 0)?;
    let vp = parse_verb_phrase(tokens, np.end_pos)?;
    
    if vp.end_pos == tokens.len() {
        Some(SyntaxTree {
            label: "S",
            children: vec![np.tree, vp.tree],
            start_pos: 0,
            end_pos: tokens.len()
        })
    } else {
        None
    }
}

fn parse_noun_phrase(tokens: &[Word], start_pos: usize) -> Option<ParseResult> {
    // NP -> Det N | N
    if start_pos >= tokens.len() {
        return None;
    }
    
    if tokens[start_pos].pos == POS::Determiner {
        if start_pos + 1 < tokens.len() && tokens[start_pos + 1].pos == POS::Noun {
            let det_tree = SyntaxTree {
                label: "Det",
                children: vec![],
                start_pos,
                end_pos: start_pos + 1
            };
            
            let n_tree = SyntaxTree {
                label: "N",
                children: vec![],
                start_pos: start_pos + 1,
                end_pos: start_pos + 2
            };
            
            let np_tree = SyntaxTree {
                label: "NP",
                children: vec![det_tree, n_tree],
                start_pos,
                end_pos: start_pos + 2
            };
            
            return Some(ParseResult {
                tree: np_tree,
                end_pos: start_pos + 2
            });
        }
    } else if tokens[start_pos].pos == POS::Noun {
        let n_tree = SyntaxTree {
            label: "N",
            children: vec![],
            start_pos,
            end_pos: start_pos + 1
        };
        
        let np_tree = SyntaxTree {
            label: "NP",
            children: vec![n_tree],
            start_pos,
            end_pos: start_pos + 1
        };
        
        return Some(ParseResult {
            tree: np_tree,
            end_pos: start_pos + 1
        });
    }
    
    None
}
```

### è¡¨è¾¾å¼æ±‚å€¼

ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ç”¨äºå®šä¹‰å’Œè§£æç®—æœ¯ã€é€»è¾‘æˆ–å…¶ä»–è¡¨è¾¾å¼ã€‚

```rust
// ç®—æœ¯è¡¨è¾¾å¼æ±‚å€¼å™¨
fn evaluate_expression(expr: &str) -> Result<f64, EvalError> {
    let tokens = tokenize(expr)?;
    let mut pos = 0;
    let ast = parse_expression(&tokens, &mut pos)?;
    
    if pos < tokens.len() {
        return Err(EvalError::UnexpectedToken);
    }
    
    evaluate_ast(&ast)
}

fn evaluate_ast(ast: &Expr) -> Result<f64, EvalError> {
    match ast {
        Expr::Number(n) => Ok(*n),
        Expr::Binary(left, op, right) => {
            let left_val = evaluate_ast(left)?;
            let right_val = evaluate_ast(right)?;
            
            match op {
                BinaryOp::Add => Ok(left_val + right_val),
                BinaryOp::Sub => Ok(left_val - right_val),
                BinaryOp::Mul => Ok(left_val * right_val),
                BinaryOp::Div => {
                    if right_val == 0.0 {
                        Err(EvalError::DivisionByZero)
                    } else {
                        Ok(left_val / right_val)
                    }
                }
            }
        }
    }
}
```

## ğŸ”— ç›¸å…³å†…å®¹

- [03.3.1 ä¹”å§†æ–¯åŸºè°±ç³»](./03.3.1_Chomsky_Hierarchy.md) - å½¢å¼è¯­è¨€å±‚æ¬¡æ¦‚è¿°
- [03.3.1.1 æ­£åˆ™è¯­è¨€](./03.3.1.1_Regular_Languages.md) - ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€çš„å­é›†
- [03.3.1.3 ä¸Šä¸‹æ–‡ç›¸å…³è¯­è¨€](./03.3.1.3_Context_Sensitive_Languages.md) - ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€çš„è¶…é›†
- [03.2.2 ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•](../03.2_Formal_Grammars/03.2.2_Context_Free_Grammar.md) - ç”Ÿæˆä¸Šä¸‹æ–‡æ— å…³è¯­è¨€çš„æ–‡æ³•
- [03.4.2 ä¸‹æ¨è‡ªåŠ¨æœº](../03.4_Automata_Theory/03.4.2_Pushdown_Automata.md) - è¯†åˆ«ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€çš„è®¡ç®—æ¨¡å‹

---

**æ›´æ–°æ—¶é—´**: 2024-12-30  
**ç‰ˆæœ¬**: 1.0  
**çŠ¶æ€**: å®Œæˆåˆç¨¿
