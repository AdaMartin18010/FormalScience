# 03.3.2 è¯­è¨€åˆ†ç±»

## ğŸ“‹ æ¦‚è¿°

è¯­è¨€åˆ†ç±»æ˜¯å½¢å¼è¯­è¨€ç†è®ºçš„æ ¸å¿ƒï¼ŒåŸºäºä¹”å§†æ–¯åŸºè°±ç³»å¯¹å½¢å¼è¯­è¨€è¿›è¡Œç³»ç»Ÿåˆ†ç±»ã€‚æœ¬æ–‡æ¡£å»ºç«‹ä¸¥æ ¼çš„è¯­è¨€åˆ†ç±»ç†è®ºæ¡†æ¶ï¼ŒåŒ…å«å½¢å¼åŒ–å®šä¹‰ã€å®šç†è¯æ˜å’Œå®é™…åº”ç”¨ã€‚

## ğŸ¯ æ ¸å¿ƒç›®æ ‡

1. å»ºç«‹ä¸¥æ ¼çš„è¯­è¨€åˆ†ç±»æ¦‚å¿µå’Œå½¢å¼åŒ–å®šä¹‰
2. è¯æ˜è¯­è¨€åˆ†ç±»çš„åŸºæœ¬å®šç†
3. æä¾›å®Œæ•´çš„ä»£ç å®ç°
4. å±•ç¤ºè¯­è¨€åˆ†ç±»åœ¨å½¢å¼ç§‘å­¦ä¸­çš„åº”ç”¨

## ğŸ“š ç›®å½•

1. [åŸºæœ¬æ¦‚å¿µ](#1-åŸºæœ¬æ¦‚å¿µ)
2. [å½¢å¼åŒ–å®šä¹‰](#2-å½¢å¼åŒ–å®šä¹‰)
3. [å®šç†ä¸è¯æ˜](#3-å®šç†ä¸è¯æ˜)
4. [ä»£ç å®ç°](#4-ä»£ç å®ç°)
5. [åº”ç”¨ç¤ºä¾‹](#5-åº”ç”¨ç¤ºä¾‹)
6. [ç›¸å…³ç†è®º](#6-ç›¸å…³ç†è®º)
7. [å‚è€ƒæ–‡çŒ®](#7-å‚è€ƒæ–‡çŒ®)

## 1. åŸºæœ¬æ¦‚å¿µ

### 1.1 è¯­è¨€åˆ†ç±»çš„å±‚æ¬¡ç»“æ„

**å®šä¹‰ 1.1.1** (è¯­è¨€åˆ†ç±»å±‚æ¬¡)
å½¢å¼è¯­è¨€æŒ‰ç…§ç”Ÿæˆèƒ½åŠ›å¯ä»¥åˆ†ä¸ºå››ä¸ªå±‚æ¬¡ï¼š

1. **0å‹è¯­è¨€**ï¼šé€’å½’å¯æšä¸¾è¯­è¨€
2. **1å‹è¯­è¨€**ï¼šä¸Šä¸‹æ–‡ç›¸å…³è¯­è¨€
3. **2å‹è¯­è¨€**ï¼šä¸Šä¸‹æ–‡æ— å…³è¯­è¨€
4. **3å‹è¯­è¨€**ï¼šæ­£åˆ™è¯­è¨€

### 1.2 è¯­è¨€åŒ…å«å…³ç³»

**å®šä¹‰ 1.2.1** (è¯­è¨€åŒ…å«å…³ç³»)
è®¾ $\mathcal{L}_i$ è¡¨ç¤º $i$ å‹è¯­è¨€ç±»ï¼Œåˆ™ï¼š
$$\mathcal{L}_3 \subset \mathcal{L}_2 \subset \mathcal{L}_1 \subset \mathcal{L}_0$$

### 1.3 è¯­è¨€å¤æ‚åº¦

**å®šä¹‰ 1.3.1** (è¯­è¨€å¤æ‚åº¦)
è¯­è¨€çš„å¤æ‚åº¦ç”±å…¶æ‰€å±çš„ä¹”å§†æ–¯åŸºå±‚æ¬¡å†³å®šï¼Œå±‚æ¬¡è¶Šé«˜ï¼Œå¤æ‚åº¦è¶Šä½ã€‚

## 2. å½¢å¼åŒ–å®šä¹‰

### 2.1 æ­£åˆ™è¯­è¨€ (3å‹è¯­è¨€)

**å®šä¹‰ 2.1.1** (æ­£åˆ™è¯­è¨€)
è¯­è¨€ $L$ æ˜¯æ­£åˆ™è¯­è¨€ï¼Œå½“ä¸”ä»…å½“å­˜åœ¨æ­£åˆ™è¡¨è¾¾å¼ $R$ ä½¿å¾— $L = L(R)$ã€‚

**å®šä¹‰ 2.1.2** (æ­£åˆ™è¡¨è¾¾å¼)
æ­£åˆ™è¡¨è¾¾å¼é€’å½’å®šä¹‰ä¸ºï¼š

1. $\emptyset$ æ˜¯æ­£åˆ™è¡¨è¾¾å¼ï¼Œ$L(\emptyset) = \emptyset$
2. $\varepsilon$ æ˜¯æ­£åˆ™è¡¨è¾¾å¼ï¼Œ$L(\varepsilon) = \{\varepsilon\}$
3. å¯¹ä»»æ„ $a \in \Sigma$ï¼Œ$a$ æ˜¯æ­£åˆ™è¡¨è¾¾å¼ï¼Œ$L(a) = \{a\}$
4. å¦‚æœ $R_1, R_2$ æ˜¯æ­£åˆ™è¡¨è¾¾å¼ï¼Œåˆ™ï¼š
   - $R_1 + R_2$ æ˜¯æ­£åˆ™è¡¨è¾¾å¼ï¼Œ$L(R_1 + R_2) = L(R_1) \cup L(R_2)$
   - $R_1 \cdot R_2$ æ˜¯æ­£åˆ™è¡¨è¾¾å¼ï¼Œ$L(R_1 \cdot R_2) = L(R_1) \cdot L(R_2)$
   - $R_1^*$ æ˜¯æ­£åˆ™è¡¨è¾¾å¼ï¼Œ$L(R_1^*) = L(R_1)^*$

### 2.2 ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ (2å‹è¯­è¨€)

**å®šä¹‰ 2.2.1** (ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€)
è¯­è¨€ $L$ æ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ï¼Œå½“ä¸”ä»…å½“å­˜åœ¨ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³• $G$ ä½¿å¾— $L = L(G)$ã€‚

**å®šä¹‰ 2.2.2** (ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•)
ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³• $G = (V, \Sigma, P, S)$ æ»¡è¶³ï¼š

- æ‰€æœ‰äº§ç”Ÿå¼å½¢å¦‚ $A \to \alpha$ï¼Œå…¶ä¸­ $A \in V$ï¼Œ$\alpha \in (V \cup \Sigma)^*$

### 2.3 ä¸Šä¸‹æ–‡ç›¸å…³è¯­è¨€ (1å‹è¯­è¨€)

**å®šä¹‰ 2.3.1** (ä¸Šä¸‹æ–‡ç›¸å…³è¯­è¨€)
è¯­è¨€ $L$ æ˜¯ä¸Šä¸‹æ–‡ç›¸å…³è¯­è¨€ï¼Œå½“ä¸”ä»…å½“å­˜åœ¨ä¸Šä¸‹æ–‡ç›¸å…³æ–‡æ³• $G$ ä½¿å¾— $L = L(G)$ã€‚

**å®šä¹‰ 2.3.2** (ä¸Šä¸‹æ–‡ç›¸å…³æ–‡æ³•)
ä¸Šä¸‹æ–‡ç›¸å…³æ–‡æ³• $G = (V, \Sigma, P, S)$ æ»¡è¶³ï¼š

- æ‰€æœ‰äº§ç”Ÿå¼å½¢å¦‚ $\alpha A \beta \to \alpha \gamma \beta$ï¼Œå…¶ä¸­ $A \in V$ï¼Œ$\alpha, \beta \in (V \cup \Sigma)^*$ï¼Œ$\gamma \in (V \cup \Sigma)^+$

### 2.4 é€’å½’å¯æšä¸¾è¯­è¨€ (0å‹è¯­è¨€)

**å®šä¹‰ 2.4.1** (é€’å½’å¯æšä¸¾è¯­è¨€)
è¯­è¨€ $L$ æ˜¯é€’å½’å¯æšä¸¾è¯­è¨€ï¼Œå½“ä¸”ä»…å½“å­˜åœ¨æ— é™åˆ¶æ–‡æ³• $G$ ä½¿å¾— $L = L(G)$ã€‚

**å®šä¹‰ 2.4.2** (æ— é™åˆ¶æ–‡æ³•)
æ— é™åˆ¶æ–‡æ³• $G = (V, \Sigma, P, S)$ æ»¡è¶³ï¼š

- äº§ç”Ÿå¼å½¢å¦‚ $\alpha \to \beta$ï¼Œå…¶ä¸­ $\alpha, \beta \in (V \cup \Sigma)^*$ï¼Œ$\alpha$ åŒ…å«è‡³å°‘ä¸€ä¸ªéç»ˆç»“ç¬¦

## 3. å®šç†ä¸è¯æ˜

### 3.1 è¯­è¨€åŒ…å«å…³ç³»å®šç†

**å®šç† 3.1.1** (ä¹”å§†æ–¯åŸºå±‚æ¬¡åŒ…å«å…³ç³»)
$$\mathcal{L}_3 \subset \mathcal{L}_2 \subset \mathcal{L}_1 \subset \mathcal{L}_0$$

**è¯æ˜**ï¼š

1. **$\mathcal{L}_3 \subset \mathcal{L}_2$**ï¼š
   æ¯ä¸ªæ­£åˆ™æ–‡æ³•éƒ½æ˜¯ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•ï¼ˆäº§ç”Ÿå¼å½¢å¦‚ $A \to aB$ æˆ– $A \to a$ï¼‰ã€‚

2. **$\mathcal{L}_2 \subset \mathcal{L}_1$**ï¼š
   æ¯ä¸ªä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•éƒ½æ˜¯ä¸Šä¸‹æ–‡ç›¸å…³æ–‡æ³•ï¼ˆäº§ç”Ÿå¼å½¢å¦‚ $A \to \alpha$ ç­‰ä»·äº $\varepsilon A \varepsilon \to \varepsilon \alpha \varepsilon$ï¼‰ã€‚

3. **$\mathcal{L}_1 \subset \mathcal{L}_0$**ï¼š
   æ¯ä¸ªä¸Šä¸‹æ–‡ç›¸å…³æ–‡æ³•éƒ½æ˜¯æ— é™åˆ¶æ–‡æ³•ã€‚

### 3.2 æ³µå¼•ç†

**å®šç† 3.2.1** (æ­£åˆ™è¯­è¨€æ³µå¼•ç†)
è®¾ $L$ æ˜¯æ­£åˆ™è¯­è¨€ï¼Œåˆ™å­˜åœ¨å¸¸æ•° $p > 0$ï¼Œä½¿å¾—å¯¹ä»»æ„ $w \in L$ ä¸” $|w| \geq p$ï¼Œå­˜åœ¨åˆ†è§£ $w = xyz$ æ»¡è¶³ï¼š

1. $|xy| \leq p$
2. $|y| > 0$
3. å¯¹æ‰€æœ‰ $i \geq 0$ï¼Œ$xy^iz \in L$

**è¯æ˜**ï¼š
è®¾ $M = (Q, \Sigma, \delta, q_0, F)$ æ˜¯æ¥å— $L$ çš„DFAï¼Œ$p = |Q|$ã€‚

å¯¹ä»»æ„ $w \in L$ ä¸” $|w| \geq p$ï¼Œè€ƒè™‘ $M$ æ¥å— $w$ æ—¶çš„çŠ¶æ€åºåˆ—ï¼š
$$q_0 \xrightarrow{w_1} q_1 \xrightarrow{w_2} q_2 \cdots \xrightarrow{w_n} q_n$$

ç”±äº $|Q| = p$ï¼Œç”±é¸½å·¢åŸç†ï¼Œå­˜åœ¨ $i < j \leq p$ ä½¿å¾— $q_i = q_j$ã€‚

è®¾ $w = xyz$ï¼Œå…¶ä¸­ï¼š

- $x = w_1 \cdots w_i$
- $y = w_{i+1} \cdots w_j$
- $z = w_{j+1} \cdots w_n$

åˆ™å¯¹ä»»æ„ $k \geq 0$ï¼Œ$xy^kz \in L$ã€‚

**å®šç† 3.2.2** (ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€æ³µå¼•ç†)
è®¾ $L$ æ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ï¼Œåˆ™å­˜åœ¨å¸¸æ•° $p > 0$ï¼Œä½¿å¾—å¯¹ä»»æ„ $w \in L$ ä¸” $|w| \geq p$ï¼Œå­˜åœ¨åˆ†è§£ $w = uvxyz$ æ»¡è¶³ï¼š

1. $|vxy| \leq p$
2. $|vy| > 0$
3. å¯¹æ‰€æœ‰ $i \geq 0$ï¼Œ$uv^ixy^iz \in L$

### 3.3 è¯­è¨€åˆ¤å®šå®šç†

**å®šç† 3.3.1** (æ­£åˆ™è¯­è¨€åˆ¤å®š)
è¯­è¨€ $L$ æ˜¯æ­£åˆ™è¯­è¨€å½“ä¸”ä»…å½“å­˜åœ¨æœ‰é™è‡ªåŠ¨æœº $M$ ä½¿å¾— $L = L(M)$ã€‚

**å®šç† 3.3.2** (ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€åˆ¤å®š)
è¯­è¨€ $L$ æ˜¯ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€å½“ä¸”ä»…å½“å­˜åœ¨ä¸‹æ¨è‡ªåŠ¨æœº $M$ ä½¿å¾— $L = L(M)$ã€‚

**å®šç† 3.3.3** (é€’å½’å¯æšä¸¾è¯­è¨€åˆ¤å®š)
è¯­è¨€ $L$ æ˜¯é€’å½’å¯æšä¸¾è¯­è¨€å½“ä¸”ä»…å½“å­˜åœ¨å›¾çµæœº $M$ ä½¿å¾— $L = L(M)$ã€‚

## 4. ä»£ç å®ç°

### 4.1 Rust å®ç°

```rust
use std::collections::{HashMap, HashSet};
use std::fmt;

/// è¯­è¨€ç±»å‹æšä¸¾
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum LanguageType {
    Regular,           // 3å‹è¯­è¨€
    ContextFree,       // 2å‹è¯­è¨€
    ContextSensitive,  // 1å‹è¯­è¨€
    RecursivelyEnumerable, // 0å‹è¯­è¨€
}

/// è¯­è¨€åˆ†ç±»å™¨
pub struct LanguageClassifier;

impl LanguageClassifier {
    /// åˆ¤æ–­è¯­è¨€ç±»å‹
    pub fn classify_language(language: &Language) -> LanguageType {
        if Self::is_regular(language) {
            LanguageType::Regular
        } else if Self::is_context_free(language) {
            LanguageType::ContextFree
        } else if Self::is_context_sensitive(language) {
            LanguageType::ContextSensitive
        } else {
            LanguageType::RecursivelyEnumerable
        }
    }
    
    /// æ£€æŸ¥æ˜¯å¦ä¸ºæ­£åˆ™è¯­è¨€
    pub fn is_regular(language: &Language) -> bool {
        // ä½¿ç”¨æ³µå¼•ç†æ£€æŸ¥
        Self::pumping_lemma_test(language, 3)
    }
    
    /// æ£€æŸ¥æ˜¯å¦ä¸ºä¸Šä¸‹æ–‡æ— å…³è¯­è¨€
    pub fn is_context_free(language: &Language) -> bool {
        // ä½¿ç”¨ä¸Šä¸‹æ–‡æ— å…³æ³µå¼•ç†æ£€æŸ¥
        Self::context_free_pumping_lemma_test(language, 5)
    }
    
    /// æ£€æŸ¥æ˜¯å¦ä¸ºä¸Šä¸‹æ–‡ç›¸å…³è¯­è¨€
    pub fn is_context_sensitive(language: &Language) -> bool {
        // æ£€æŸ¥äº§ç”Ÿå¼å½¢å¼
        language.productions.iter().all(|prod| {
            Self::is_context_sensitive_production(prod)
        })
    }
    
    /// æ­£åˆ™è¯­è¨€æ³µå¼•ç†æµ‹è¯•
    fn pumping_lemma_test(language: &Language, p: usize) -> bool {
        for word in language.get_words_up_to_length(p + 1) {
            if word.len() >= p {
                if !Self::satisfies_pumping_lemma(language, &word, p) {
                    return false;
                }
            }
        }
        true
    }
    
    /// ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€æ³µå¼•ç†æµ‹è¯•
    fn context_free_pumping_lemma_test(language: &Language, p: usize) -> bool {
        for word in language.get_words_up_to_length(p + 1) {
            if word.len() >= p {
                if !Self::satisfies_context_free_pumping_lemma(language, &word, p) {
                    return false;
                }
            }
        }
        true
    }
    
    /// æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ³µå¼•ç†
    fn satisfies_pumping_lemma(language: &Language, word: &str, p: usize) -> bool {
        for i in 0..=p {
            for j in i + 1..=p {
                let x = &word[..i];
                let y = &word[i..j];
                let z = &word[j..];
                
                if !y.is_empty() {
                    let mut satisfied = false;
                    for k in 0..=2 {
                        let pumped = format!("{}{}{}", x, y.repeat(k), z);
                        if language.contains(&pumped) {
                            satisfied = true;
                            break;
                        }
                    }
                    if satisfied {
                        return true;
                    }
                }
            }
        }
        false
    }
    
    /// æ£€æŸ¥æ˜¯å¦æ»¡è¶³ä¸Šä¸‹æ–‡æ— å…³æ³µå¼•ç†
    fn satisfies_context_free_pumping_lemma(language: &Language, word: &str, p: usize) -> bool {
        for i in 0..word.len() {
            for j in i + 1..word.len() {
                for k in j + 1..word.len() {
                    let u = &word[..i];
                    let v = &word[i..j];
                    let x = &word[j..k];
                    let y = &word[k..];
                    
                    if !v.is_empty() || !x.is_empty() {
                        let mut satisfied = false;
                        for m in 0..=2 {
                            for n in 0..=2 {
                                let pumped = format!("{}{}{}{}{}", u, v.repeat(m), x, y.repeat(n), &word[k..]);
                                if language.contains(&pumped) {
                                    satisfied = true;
                                    break;
                                }
                            }
                        }
                        if satisfied {
                            return true;
                        }
                    }
                }
            }
        }
        false
    }
    
    /// æ£€æŸ¥æ˜¯å¦ä¸ºä¸Šä¸‹æ–‡ç›¸å…³äº§ç”Ÿå¼
    fn is_context_sensitive_production(production: &Production) -> bool {
        let left = &production.left;
        let right = &production.right;
        
        // æ£€æŸ¥å·¦éƒ¨æ˜¯å¦åŒ…å«éç»ˆç»“ç¬¦
        let has_nonterminal = left.chars().any(|c| c.is_uppercase());
        
        // æ£€æŸ¥é•¿åº¦æ¡ä»¶
        let left_len = left.len();
        let right_len = right.len();
        
        has_nonterminal && right_len >= left_len
    }
}

/// äº§ç”Ÿå¼
#[derive(Debug, Clone)]
pub struct Production {
    pub left: String,
    pub right: String,
}

impl Production {
    pub fn new(left: String, right: String) -> Self {
        Self { left, right }
    }
}

/// è¯­è¨€
#[derive(Debug, Clone)]
pub struct Language {
    pub alphabet: HashSet<char>,
    pub productions: Vec<Production>,
    pub start_symbol: char,
    pub words: HashSet<String>,
}

impl Language {
    pub fn new(alphabet: HashSet<char>, start_symbol: char) -> Self {
        Self {
            alphabet,
            productions: Vec::new(),
            start_symbol,
            words: HashSet::new(),
        }
    }
    
    pub fn add_production(&mut self, left: String, right: String) {
        self.productions.push(Production::new(left, right));
    }
    
    pub fn contains(&self, word: &str) -> bool {
        self.words.contains(word)
    }
    
    pub fn get_words_up_to_length(&self, max_length: usize) -> Vec<String> {
        self.words.iter()
            .filter(|word| word.len() <= max_length)
            .cloned()
            .collect()
    }
    
    /// ç”Ÿæˆè¯­è¨€çš„æ‰€æœ‰å•è¯ï¼ˆæœ‰é™é•¿åº¦ï¼‰
    pub fn generate_words(&mut self, max_length: usize) {
        self.words.clear();
        self.words.insert(String::new()); // ç©ºå­—ç¬¦ä¸²
        
        for length in 1..=max_length {
            let mut new_words = HashSet::new();
            
            for word in &self.words {
                if word.len() == length - 1 {
                    for &symbol in &self.alphabet {
                        let mut new_word = word.clone();
                        new_word.push(symbol);
                        new_words.insert(new_word);
                    }
                }
            }
            
            self.words.extend(new_words);
        }
    }
}

/// è¯­è¨€å±‚æ¬¡åˆ†æå™¨
pub struct LanguageHierarchyAnalyzer;

impl LanguageHierarchyAnalyzer {
    /// åˆ†æè¯­è¨€å±‚æ¬¡å…³ç³»
    pub fn analyze_hierarchy(languages: &[Language]) -> HashMap<String, LanguageType> {
        let mut results = HashMap::new();
        
        for (i, language) in languages.iter().enumerate() {
            let language_name = format!("Language_{}", i);
            let language_type = LanguageClassifier::classify_language(language);
            results.insert(language_name, language_type);
        }
        
        results
    }
    
    /// éªŒè¯å±‚æ¬¡åŒ…å«å…³ç³»
    pub fn verify_hierarchy_inclusion() -> bool {
        // éªŒè¯ L3 âŠ‚ L2 âŠ‚ L1 âŠ‚ L0
        let regular_lang = Self::create_regular_language();
        let context_free_lang = Self::create_context_free_language();
        let context_sensitive_lang = Self::create_context_sensitive_language();
        let recursively_enumerable_lang = Self::create_recursively_enumerable_language();
        
        let regular_type = LanguageClassifier::classify_language(&regular_lang);
        let context_free_type = LanguageClassifier::classify_language(&context_free_lang);
        let context_sensitive_type = LanguageClassifier::classify_language(&context_sensitive_lang);
        let recursively_enumerable_type = LanguageClassifier::classify_language(&recursively_enumerable_lang);
        
        regular_type == LanguageType::Regular &&
        context_free_type == LanguageType::ContextFree &&
        context_sensitive_type == LanguageType::ContextSensitive &&
        recursively_enumerable_type == LanguageType::RecursivelyEnumerable
    }
    
    /// åˆ›å»ºæ­£åˆ™è¯­è¨€ç¤ºä¾‹
    fn create_regular_language() -> Language {
        let mut alphabet = HashSet::new();
        alphabet.insert('a');
        alphabet.insert('b');
        
        let mut language = Language::new(alphabet, 'S');
        language.add_production("S".to_string(), "aA".to_string());
        language.add_production("A".to_string(), "bA".to_string());
        language.add_production("A".to_string(), "Îµ".to_string());
        
        language.generate_words(5);
        language
    }
    
    /// åˆ›å»ºä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ç¤ºä¾‹
    fn create_context_free_language() -> Language {
        let mut alphabet = HashSet::new();
        alphabet.insert('a');
        alphabet.insert('b');
        
        let mut language = Language::new(alphabet, 'S');
        language.add_production("S".to_string(), "aSb".to_string());
        language.add_production("S".to_string(), "Îµ".to_string());
        
        language.generate_words(5);
        language
    }
    
    /// åˆ›å»ºä¸Šä¸‹æ–‡ç›¸å…³è¯­è¨€ç¤ºä¾‹
    fn create_context_sensitive_language() -> Language {
        let mut alphabet = HashSet::new();
        alphabet.insert('a');
        alphabet.insert('b');
        alphabet.insert('c');
        
        let mut language = Language::new(alphabet, 'S');
        language.add_production("S".to_string(), "aSb".to_string());
        language.add_production("aSb".to_string(), "aabb".to_string());
        
        language.generate_words(5);
        language
    }
    
    /// åˆ›å»ºé€’å½’å¯æšä¸¾è¯­è¨€ç¤ºä¾‹
    fn create_recursively_enumerable_language() -> Language {
        let mut alphabet = HashSet::new();
        alphabet.insert('a');
        alphabet.insert('b');
        
        let mut language = Language::new(alphabet, 'S');
        language.add_production("S".to_string(), "aSb".to_string());
        language.add_production("aSb".to_string(), "ab".to_string());
        language.add_production("ab".to_string(), "ba".to_string());
        
        language.generate_words(5);
        language
    }
}

/// è¯­è¨€å¤æ‚åº¦åˆ†æå™¨
pub struct LanguageComplexityAnalyzer;

impl LanguageComplexityAnalyzer {
    /// åˆ†æè¯­è¨€å¤æ‚åº¦
    pub fn analyze_complexity(language: &Language) -> f64 {
        let mut complexity = 0.0;
        
        // åŸºäºäº§ç”Ÿå¼æ•°é‡
        complexity += language.productions.len() as f64 * 0.1;
        
        // åŸºäºäº§ç”Ÿå¼é•¿åº¦
        for production in &language.productions {
            complexity += (production.left.len() + production.right.len()) as f64 * 0.05;
        }
        
        // åŸºäºå­—æ¯è¡¨å¤§å°
        complexity += language.alphabet.len() as f64 * 0.2;
        
        complexity
    }
    
    /// æ¯”è¾ƒè¯­è¨€å¤æ‚åº¦
    pub fn compare_complexity(languages: &[Language]) -> Vec<(String, f64)> {
        let mut results = Vec::new();
        
        for (i, language) in languages.iter().enumerate() {
            let language_name = format!("Language_{}", i);
            let complexity = Self::analyze_complexity(language);
            results.push((language_name, complexity));
        }
        
        results.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
        results
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_language_classification() {
        let regular_lang = LanguageHierarchyAnalyzer::create_regular_language();
        let context_free_lang = LanguageHierarchyAnalyzer::create_context_free_language();
        
        assert_eq!(LanguageClassifier::classify_language(&regular_lang), LanguageType::Regular);
        assert_eq!(LanguageClassifier::classify_language(&context_free_lang), LanguageType::ContextFree);
    }
    
    #[test]
    fn test_hierarchy_inclusion() {
        assert!(LanguageHierarchyAnalyzer::verify_hierarchy_inclusion());
    }
    
    #[test]
    fn test_complexity_analysis() {
        let languages = vec![
            LanguageHierarchyAnalyzer::create_regular_language(),
            LanguageHierarchyAnalyzer::create_context_free_language(),
        ];
        
        let complexities = LanguageComplexityAnalyzer::compare_complexity(&languages);
        assert!(!complexities.is_empty());
    }
}
```

### 4.2 Haskell å®ç°

```haskell
-- è¯­è¨€åˆ†ç±»
module LanguageClassification where

import Data.Set (Set)
import qualified Data.Set as Set
import Data.Map (Map)
import qualified Data.Map as Map

-- è¯­è¨€ç±»å‹
data LanguageType = 
    Regular
  | ContextFree
  | ContextSensitive
  | RecursivelyEnumerable
  deriving (Eq, Show)

-- äº§ç”Ÿå¼
data Production = Production {
    left :: String,
    right :: String
} deriving (Eq, Show)

-- è¯­è¨€
data Language = Language {
    alphabet :: Set Char,
    productions :: [Production],
    startSymbol :: Char,
    words :: Set String
} deriving (Eq, Show)

-- è¯­è¨€åˆ†ç±»å™¨
classifyLanguage :: Language -> LanguageType
classifyLanguage lang
  | isRegular lang = Regular
  | isContextFree lang = ContextFree
  | isContextSensitive lang = ContextSensitive
  | otherwise = RecursivelyEnumerable

-- æ£€æŸ¥æ˜¯å¦ä¸ºæ­£åˆ™è¯­è¨€
isRegular :: Language -> Bool
isRegular lang = pumpingLemmaTest lang 3

-- æ£€æŸ¥æ˜¯å¦ä¸ºä¸Šä¸‹æ–‡æ— å…³è¯­è¨€
isContextFree :: Language -> Bool
isContextFree lang = contextFreePumpingLemmaTest lang 5

-- æ£€æŸ¥æ˜¯å¦ä¸ºä¸Šä¸‹æ–‡ç›¸å…³è¯­è¨€
isContextSensitive :: Language -> Bool
isContextSensitive lang = all isContextSensitiveProduction (productions lang)

-- æ­£åˆ™è¯­è¨€æ³µå¼•ç†æµ‹è¯•
pumpingLemmaTest :: Language -> Int -> Bool
pumpingLemmaTest lang p = all (satisfiesPumpingLemma lang p) longWords
  where
    longWords = filter (\w -> length w >= p) (Set.toList (words lang))

-- ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€æ³µå¼•ç†æµ‹è¯•
contextFreePumpingLemmaTest :: Language -> Int -> Bool
contextFreePumpingLemmaTest lang p = all (satisfiesContextFreePumpingLemma lang p) longWords
  where
    longWords = filter (\w -> length w >= p) (Set.toList (words lang))

-- æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ³µå¼•ç†
satisfiesPumpingLemma :: Language -> Int -> String -> Bool
satisfiesPumpingLemma lang p word = any checkDecomposition decompositions
  where
    decompositions = [(take i word, take (j-i) (drop i word), drop j word) | 
                      i <- [0..p], j <- [i+1..p]]
    checkDecomposition (x, y, z) = 
      not (null y) && any (\k -> Set.member (x ++ concat (replicate k y) ++ z) (words lang)) [0..2]

-- æ£€æŸ¥æ˜¯å¦æ»¡è¶³ä¸Šä¸‹æ–‡æ— å…³æ³µå¼•ç†
satisfiesContextFreePumpingLemma :: Language -> Int -> String -> Bool
satisfiesContextFreePumpingLemma lang p word = any checkDecomposition decompositions
  where
    decompositions = [(take i word, take (j-i) (drop i word), take (k-j) (drop j word), drop k word) |
                      i <- [0..length word], j <- [i+1..length word], k <- [j+1..length word]]
    checkDecomposition (u, v, x, y) = 
      (not (null v) || not (null x)) && 
      any (\m -> any (\n -> Set.member (u ++ concat (replicate m v) ++ x ++ concat (replicate n y)) (words lang)) [0..2]) [0..2]

-- æ£€æŸ¥æ˜¯å¦ä¸ºä¸Šä¸‹æ–‡ç›¸å…³äº§ç”Ÿå¼
isContextSensitiveProduction :: Production -> Bool
isContextSensitiveProduction prod = 
  hasNonterminal (left prod) && length (right prod) >= length (left prod)
  where
    hasNonterminal = any isUpper

-- è¯­è¨€å±‚æ¬¡åˆ†æå™¨
analyzeHierarchy :: [Language] -> Map String LanguageType
analyzeHierarchy langs = Map.fromList $ zip languageNames languageTypes
  where
    languageNames = map (\i -> "Language_" ++ show i) [0..length langs - 1]
    languageTypes = map classifyLanguage langs

-- éªŒè¯å±‚æ¬¡åŒ…å«å…³ç³»
verifyHierarchyInclusion :: Bool
verifyHierarchyInclusion = 
  classifyLanguage regularLang == Regular &&
  classifyLanguage contextFreeLang == ContextFree &&
  classifyLanguage contextSensitiveLang == ContextSensitive &&
  classifyLanguage recursivelyEnumerableLang == RecursivelyEnumerable
  where
    regularLang = createRegularLanguage
    contextFreeLang = createContextFreeLanguage
    contextSensitiveLang = createContextSensitiveLanguage
    recursivelyEnumerableLang = createRecursivelyEnumerableLanguage

-- åˆ›å»ºç¤ºä¾‹è¯­è¨€
createRegularLanguage :: Language
createRegularLanguage = Language {
    alphabet = Set.fromList "ab",
    productions = [
        Production "S" "aA",
        Production "A" "bA",
        Production "A" "Îµ"
    ],
    startSymbol = 'S',
    words = Set.fromList ["", "a", "ab", "abb", "abbb"]
}

createContextFreeLanguage :: Language
createContextFreeLanguage = Language {
    alphabet = Set.fromList "ab",
    productions = [
        Production "S" "aSb",
        Production "S" "Îµ"
    ],
    startSymbol = 'S',
    words = Set.fromList ["", "ab", "aabb", "aaabbb"]
}

createContextSensitiveLanguage :: Language
createContextSensitiveLanguage = Language {
    alphabet = Set.fromList "abc",
    productions = [
        Production "S" "aSb",
        Production "aSb" "aabb"
    ],
    startSymbol = 'S',
    words = Set.fromList ["", "aabb"]
}

createRecursivelyEnumerableLanguage :: Language
createRecursivelyEnumerableLanguage = Language {
    alphabet = Set.fromList "ab",
    productions = [
        Production "S" "aSb",
        Production "aSb" "ab",
        Production "ab" "ba"
    ],
    startSymbol = 'S',
    words = Set.fromList ["", "ab", "ba"]
}

-- è¯­è¨€å¤æ‚åº¦åˆ†æå™¨
analyzeComplexity :: Language -> Double
analyzeComplexity lang = 
  fromIntegral (length (productions lang)) * 0.1 +
  sum [fromIntegral (length (left p) + length (right p)) * 0.05 | p <- productions lang] +
  fromIntegral (Set.size (alphabet lang)) * 0.2

-- æ¯”è¾ƒè¯­è¨€å¤æ‚åº¦
compareComplexity :: [Language] -> [(String, Double)]
compareComplexity langs = sortBy (\a b -> compare (snd b) (snd a)) results
  where
    languageNames = map (\i -> "Language_" ++ show i) [0..length langs - 1]
    complexities = map analyzeComplexity langs
    results = zip languageNames complexities

-- æµ‹è¯•å‡½æ•°
testLanguageClassification :: IO ()
testLanguageClassification = do
    putStrLn "è¯­è¨€åˆ†ç±»æµ‹è¯•:"
    print $ classifyLanguage createRegularLanguage
    print $ classifyLanguage createContextFreeLanguage
    
    putStrLn "å±‚æ¬¡åŒ…å«å…³ç³»éªŒè¯:"
    print verifyHierarchyInclusion
    
    putStrLn "å¤æ‚åº¦åˆ†æ:"
    let langs = [createRegularLanguage, createContextFreeLanguage]
    print $ compareComplexity langs
```

## 5. åº”ç”¨ç¤ºä¾‹

### 5.1 ç¼–è¯‘å™¨è®¾è®¡ä¸­çš„åº”ç”¨

```rust
/// ç¼–è¯‘å™¨è¯­è¨€åˆ†ç±»å™¨
pub struct CompilerLanguageClassifier;

impl CompilerLanguageClassifier {
    /// æ ¹æ®è¯­è¨€ç±»å‹é€‰æ‹©è§£æç­–ç•¥
    pub fn select_parsing_strategy(language_type: &LanguageType) -> ParsingStrategy {
        match language_type {
            LanguageType::Regular => ParsingStrategy::FiniteAutomaton,
            LanguageType::ContextFree => ParsingStrategy::LLParser,
            LanguageType::ContextSensitive => ParsingStrategy::LRParser,
            LanguageType::RecursivelyEnumerable => ParsingStrategy::TuringMachine,
        }
    }
    
    /// åˆ†æç¼–ç¨‹è¯­è¨€å¤æ‚åº¦
    pub fn analyze_programming_language(language: &Language) -> ProgrammingLanguageComplexity {
        let language_type = LanguageClassifier::classify_language(language);
        let complexity_score = LanguageComplexityAnalyzer::analyze_complexity(language);
        
        ProgrammingLanguageComplexity {
            language_type,
            complexity_score,
            parsing_difficulty: Self::calculate_parsing_difficulty(&language_type),
            compilation_time: Self::estimate_compilation_time(complexity_score),
        }
    }
    
    fn calculate_parsing_difficulty(language_type: &LanguageType) -> f64 {
        match language_type {
            LanguageType::Regular => 1.0,
            LanguageType::ContextFree => 2.0,
            LanguageType::ContextSensitive => 3.0,
            LanguageType::RecursivelyEnumerable => 4.0,
        }
    }
    
    fn estimate_compilation_time(complexity_score: f64) -> f64 {
        complexity_score * 0.1 // æ¯«ç§’
    }
}

#[derive(Debug)]
pub enum ParsingStrategy {
    FiniteAutomaton,
    LLParser,
    LRParser,
    TuringMachine,
}

#[derive(Debug)]
pub struct ProgrammingLanguageComplexity {
    pub language_type: LanguageType,
    pub complexity_score: f64,
    pub parsing_difficulty: f64,
    pub compilation_time: f64,
}
```

### 5.2 è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åº”ç”¨

```rust
/// è‡ªç„¶è¯­è¨€åˆ†ç±»å™¨
pub struct NaturalLanguageClassifier;

impl NaturalLanguageClassifier {
    /// åˆ†æè‡ªç„¶è¯­è¨€ç»“æ„
    pub fn analyze_natural_language_structure(text: &str) -> NaturalLanguageStructure {
        let words: Vec<&str> = text.split_whitespace().collect();
        let sentences: Vec<&str> = text.split('.').collect();
        
        NaturalLanguageStructure {
            word_count: words.len(),
            sentence_count: sentences.len(),
            average_sentence_length: words.len() as f64 / sentences.len() as f64,
            vocabulary_complexity: Self::calculate_vocabulary_complexity(&words),
            syntactic_complexity: Self::calculate_syntactic_complexity(text),
        }
    }
    
    fn calculate_vocabulary_complexity(words: &[&str]) -> f64 {
        let unique_words: HashSet<&str> = words.iter().cloned().collect();
        unique_words.len() as f64 / words.len() as f64
    }
    
    fn calculate_syntactic_complexity(text: &str) -> f64 {
        let mut complexity = 0.0;
        
        // åŸºäºæ ‡ç‚¹ç¬¦å·
        complexity += text.chars().filter(|&c| ",;:!?".contains(c)).count() as f64 * 0.1;
        
        // åŸºäºä»å¥
        complexity += text.matches("that").count() as f64 * 0.2;
        complexity += text.matches("which").count() as f64 * 0.2;
        complexity += text.matches("who").count() as f64 * 0.2;
        
        complexity
    }
}

#[derive(Debug)]
pub struct NaturalLanguageStructure {
    pub word_count: usize,
    pub sentence_count: usize,
    pub average_sentence_length: f64,
    pub vocabulary_complexity: f64,
    pub syntactic_complexity: f64,
}
```

## 6. ç›¸å…³ç†è®º

### 6.1 ä¸è‡ªåŠ¨æœºç†è®ºçš„å…³ç³»

è¯­è¨€åˆ†ç±»ä¸è‡ªåŠ¨æœºç†è®ºç´§å¯†ç›¸å…³ï¼Œæ¯ç§è¯­è¨€ç±»å‹éƒ½æœ‰å¯¹åº”çš„è‡ªåŠ¨æœºæ¨¡å‹ã€‚

### 6.2 ä¸è®¡ç®—å¤æ‚æ€§ç†è®ºçš„å…³ç³»

**å®šç† 6.2.1** (è¯­è¨€å¤æ‚åº¦ä¸è®¡ç®—å¤æ‚åº¦)
è¯­è¨€çš„ä¹”å§†æ–¯åŸºå±‚æ¬¡è¶Šé«˜ï¼Œå…¶è¯†åˆ«ç®—æ³•çš„è®¡ç®—å¤æ‚åº¦è¶Šä½ã€‚

### 6.3 ä¸å½¢å¼è¯­ä¹‰å­¦çš„å…³ç³»

è¯­è¨€åˆ†ç±»ä¸ºå½¢å¼è¯­ä¹‰å­¦æä¾›è¯­æ³•åŸºç¡€ï¼Œä¸åŒç±»å‹çš„è¯­è¨€éœ€è¦ä¸åŒçš„è¯­ä¹‰è§£é‡Šæ–¹æ³•ã€‚

## 7. å‚è€ƒæ–‡çŒ®

1. **Hopcroft, J. E., Motwani, R., & Ullman, J. D.** (2006). *Introduction to Automata Theory, Languages, and Computation*. Pearson.
2. **Sipser, M.** (2012). *Introduction to the Theory of Computation*. Cengage Learning.
3. **Chomsky, N.** (1956). *Three models for the description of language*. IRE Transactions on Information Theory.
4. **Chomsky, N.** (1959). *On certain formal properties of grammars*. Information and Control.
5. **Kleene, S. C.** (1956). *Representation of events in nerve nets and finite automata*. Automata Studies.

---

**ç›¸å…³æ–‡æ¡£**:

- [03.3.1 ä¹”å§†æ–¯åŸºè°±ç³»](../03.3.1_ä¹”å§†æ–¯åŸºè°±ç³».md)
- [03.3.3 è¯­è¨€æ€§è´¨](../03.3.3_è¯­è¨€æ€§è´¨.md)
- [03.3.4 è¯­è¨€å…³ç³»](../03.3.4_è¯­è¨€å…³ç³».md)
- [03.1.1 æœ‰é™è‡ªåŠ¨æœº](../03.1.1_æœ‰é™è‡ªåŠ¨æœº.md)
- [03.1.2 ä¸‹æ¨è‡ªåŠ¨æœº](../03.1.2_ä¸‹æ¨è‡ªåŠ¨æœº.md)
