# 03.3.4 è¯­è¨€å…³ç³»

## ğŸ“‹ æ¦‚è¿°

è¯­è¨€å…³ç³»ç†è®ºç ”ç©¶å½¢å¼è¯­è¨€ä¹‹é—´çš„å„ç§å…³ç³»ï¼ŒåŒ…æ‹¬åŒ…å«å…³ç³»ã€ç­‰ä»·å…³ç³»ã€åŒæ€å…³ç³»ç­‰ã€‚è¿™äº›å…³ç³»ä¸ºè¯­è¨€åˆ†ç±»ã€è¯­è¨€æ¯”è¾ƒå’Œè¯­è¨€å˜æ¢æä¾›äº†ç†è®ºåŸºç¡€ã€‚

## ğŸ¯ æ ¸å¿ƒç›®æ ‡

1. **å»ºç«‹è¯­è¨€å…³ç³»çš„åŸºç¡€ç†è®ºä½“ç³»**
2. **ç ”ç©¶è¯­è¨€ä¹‹é—´çš„åŒ…å«å’Œç­‰ä»·å…³ç³»**
3. **å‘å±•è¯­è¨€åŒæ€å’Œå˜æ¢ç†è®º**
4. **æ¢ç´¢è¯­è¨€å…³ç³»çš„è®¡ç®—æ€§è´¨**

## ğŸ“š ç›®å½•

1. [åŸºæœ¬æ¦‚å¿µ](#1-åŸºæœ¬æ¦‚å¿µ)
2. [å½¢å¼åŒ–å®šä¹‰](#2-å½¢å¼åŒ–å®šä¹‰)
3. [å®šç†ä¸è¯æ˜](#3-å®šç†ä¸è¯æ˜)
4. [ä»£ç å®ç°](#4-ä»£ç å®ç°)
5. [åº”ç”¨ç¤ºä¾‹](#5-åº”ç”¨ç¤ºä¾‹)
6. [ç›¸å…³ç†è®º](#6-ç›¸å…³ç†è®º)
7. [å‚è€ƒæ–‡çŒ®](#7-å‚è€ƒæ–‡çŒ®)

## 1. åŸºæœ¬æ¦‚å¿µ

### 1.1 è¯­è¨€åŒ…å«å…³ç³»

å¯¹äºè¯­è¨€ $L_1$ å’Œ $L_2$ï¼Œå¦‚æœ $L_1 \subseteq L_2$ï¼Œåˆ™ç§° $L_1$ åŒ…å«äº $L_2$ï¼Œæˆ– $L_2$ åŒ…å« $L_1$ã€‚

### 1.2 è¯­è¨€ç­‰ä»·å…³ç³»

å¯¹äºè¯­è¨€ $L_1$ å’Œ $L_2$ï¼Œå¦‚æœ $L_1 = L_2$ï¼Œåˆ™ç§° $L_1$ å’Œ $L_2$ ç­‰ä»·ã€‚

### 1.3 è¯­è¨€åŒæ€å…³ç³»

è®¾ $h: \Sigma^* \to \Delta^*$ æ˜¯ä¸€ä¸ªåŒæ€æ˜ å°„ï¼Œå¯¹äºè¯­è¨€ $L \subseteq \Sigma^*$ï¼Œå®šä¹‰ï¼š

$$h(L) = \{h(w) \mid w \in L\}$$

### 1.4 è¯­è¨€é€†åŒæ€å…³ç³»

å¯¹äºåŒæ€æ˜ å°„ $h: \Sigma^* \to \Delta^*$ å’Œè¯­è¨€ $L \subseteq \Delta^*$ï¼Œå®šä¹‰ï¼š

$$h^{-1}(L) = \{w \in \Sigma^* \mid h(w) \in L\}$$

## 2. å½¢å¼åŒ–å®šä¹‰

### 2.1 è¯­è¨€åŒ…å«å…³ç³»

å¯¹äºè¯­è¨€ $L_1, L_2 \subseteq \Sigma^*$ï¼Œå®šä¹‰åŒ…å«å…³ç³»ï¼š

$$L_1 \subseteq L_2 \iff \forall w \in L_1, w \in L_2$$

### 2.2 è¯­è¨€ç­‰ä»·å…³ç³»

å¯¹äºè¯­è¨€ $L_1, L_2 \subseteq \Sigma^*$ï¼Œå®šä¹‰ç­‰ä»·å…³ç³»ï¼š

$$L_1 = L_2 \iff L_1 \subseteq L_2 \land L_2 \subseteq L_1$$

### 2.3 è¯­è¨€åŒæ€æ˜ å°„

åŒæ€æ˜ å°„ $h: \Sigma^* \to \Delta^*$ æ»¡è¶³ï¼š

1. $h(\varepsilon) = \varepsilon$
2. $h(uv) = h(u)h(v)$ å¯¹äºæ‰€æœ‰ $u, v \in \Sigma^*$

### 2.4 è¯­è¨€å˜æ¢å…³ç³»

å¯¹äºè¯­è¨€ $L \subseteq \Sigma^*$ å’Œå˜æ¢ $T: \Sigma^* \to \Delta^*$ï¼Œå®šä¹‰ï¼š

$$T(L) = \{T(w) \mid w \in L\}$$

## 3. å®šç†ä¸è¯æ˜

### 3.1 è¯­è¨€åŒ…å«å…³ç³»çš„ä¼ é€’æ€§

**å®šç† 3.1.1**ï¼šè¯­è¨€åŒ…å«å…³ç³»å…·æœ‰ä¼ é€’æ€§ï¼Œå³å¯¹äºè¯­è¨€ $L_1, L_2, L_3$ï¼š

å¦‚æœ $L_1 \subseteq L_2$ ä¸” $L_2 \subseteq L_3$ï¼Œåˆ™ $L_1 \subseteq L_3$ã€‚

**è¯æ˜**ï¼š
è®¾ $w \in L_1$ï¼Œç”± $L_1 \subseteq L_2$ çŸ¥ $w \in L_2$ï¼Œå†ç”± $L_2 \subseteq L_3$ çŸ¥ $w \in L_3$ã€‚
å› æ­¤ $L_1 \subseteq L_3$ã€‚

### 3.2 è¯­è¨€åŒæ€çš„ä¿æŒæ€§

**å®šç† 3.2.1**ï¼šæ­£åˆ™è¯­è¨€åœ¨åŒæ€æ˜ å°„ä¸‹ä¿æŒæ­£åˆ™æ€§ã€‚

**è¯æ˜**ï¼š
è®¾ $L$ æ˜¯æ­£åˆ™è¯­è¨€ï¼Œ$h$ æ˜¯åŒæ€æ˜ å°„ã€‚ç”±äº $L$ æ˜¯æ­£åˆ™çš„ï¼Œå­˜åœ¨æœ‰é™è‡ªåŠ¨æœº $M$ è¯†åˆ« $L$ã€‚

æ„é€ æ–°çš„æœ‰é™è‡ªåŠ¨æœº $M'$ï¼š
- çŠ¶æ€é›†ä¸ $M$ ç›¸åŒ
- å¯¹äº $M$ ä¸­çš„è½¬ç§» $\delta(q, a) = p$ï¼Œåœ¨ $M'$ ä¸­æ·»åŠ è½¬ç§» $\delta'(q, h(a)) = p$
- åˆå§‹çŠ¶æ€å’Œæ¥å—çŠ¶æ€ä¸ $M$ ç›¸åŒ

åˆ™ $M'$ è¯†åˆ« $h(L)$ï¼Œå› æ­¤ $h(L)$ æ˜¯æ­£åˆ™çš„ã€‚

### 3.3 è¯­è¨€é€†åŒæ€çš„ä¿æŒæ€§

**å®šç† 3.3.1**ï¼šæ­£åˆ™è¯­è¨€åœ¨é€†åŒæ€æ˜ å°„ä¸‹ä¿æŒæ­£åˆ™æ€§ã€‚

**è¯æ˜**ï¼š
è®¾ $L$ æ˜¯æ­£åˆ™è¯­è¨€ï¼Œ$h$ æ˜¯åŒæ€æ˜ å°„ã€‚å­˜åœ¨æœ‰é™è‡ªåŠ¨æœº $M$ è¯†åˆ« $L$ã€‚

æ„é€ æ–°çš„æœ‰é™è‡ªåŠ¨æœº $M'$ï¼š
- çŠ¶æ€é›†ä¸ $M$ ç›¸åŒ
- å¯¹äº $M$ ä¸­çš„è½¬ç§» $\delta(q, b) = p$ï¼Œåœ¨ $M'$ ä¸­æ·»åŠ æ‰€æœ‰è½¬ç§» $\delta'(q, a) = p$ï¼Œå…¶ä¸­ $h(a) = b$
- åˆå§‹çŠ¶æ€å’Œæ¥å—çŠ¶æ€ä¸ $M$ ç›¸åŒ

åˆ™ $M'$ è¯†åˆ« $h^{-1}(L)$ï¼Œå› æ­¤ $h^{-1}(L)$ æ˜¯æ­£åˆ™çš„ã€‚

### 3.4 è¯­è¨€ç­‰ä»·çš„å¯åˆ¤å®šæ€§

**å®šç† 3.4.1**ï¼šå¯¹äºæ­£åˆ™è¯­è¨€ $L_1$ å’Œ $L_2$ï¼Œ$L_1 = L_2$ æ˜¯å¯åˆ¤å®šçš„ã€‚

**è¯æ˜**ï¼š
ç”±äº $L_1 = L_2$ å½“ä¸”ä»…å½“ $L_1 \subseteq L_2$ ä¸” $L_2 \subseteq L_1$ï¼Œ
è€Œ $L_1 \subseteq L_2$ å½“ä¸”ä»…å½“ $L_1 \cap \overline{L_2} = \emptyset$ã€‚

ç”±äºæ­£åˆ™è¯­è¨€åœ¨è¡¥è¿ç®—å’Œäº¤è¿ç®—ä¸‹å°é—­ï¼Œä¸”ç©ºè¯­è¨€é—®é¢˜å¯¹äºæ­£åˆ™è¯­è¨€æ˜¯å¯åˆ¤å®šçš„ï¼Œ
å› æ­¤è¯­è¨€ç­‰ä»·é—®é¢˜æ˜¯å¯åˆ¤å®šçš„ã€‚

### 3.5 è¯­è¨€åŒ…å«çš„å¯åˆ¤å®šæ€§

**å®šç† 3.5.1**ï¼šå¯¹äºæ­£åˆ™è¯­è¨€ $L_1$ å’Œ $L_2$ï¼Œ$L_1 \subseteq L_2$ æ˜¯å¯åˆ¤å®šçš„ã€‚

**è¯æ˜**ï¼š
$L_1 \subseteq L_2$ å½“ä¸”ä»…å½“ $L_1 \cap \overline{L_2} = \emptyset$ã€‚

ç”±äºæ­£åˆ™è¯­è¨€åœ¨è¡¥è¿ç®—å’Œäº¤è¿ç®—ä¸‹å°é—­ï¼Œä¸”ç©ºè¯­è¨€é—®é¢˜å¯¹äºæ­£åˆ™è¯­è¨€æ˜¯å¯åˆ¤å®šçš„ï¼Œ
å› æ­¤è¯­è¨€åŒ…å«é—®é¢˜æ˜¯å¯åˆ¤å®šçš„ã€‚

## 4. ä»£ç å®ç°

### 4.1 Rustå®ç°

```rust
use std::collections::{HashMap, HashSet};
use std::collections::BTreeSet;

/// è¯­è¨€å…³ç³»ç†è®ºå®ç°
pub struct LanguageRelations;

impl LanguageRelations {
    /// æ£€æŸ¥è¯­è¨€åŒ…å«å…³ç³»
    pub fn is_subset(l1: &HashSet<String>, l2: &HashSet<String>) -> bool {
        l1.iter().all(|word| l2.contains(word))
    }
    
    /// æ£€æŸ¥è¯­è¨€ç­‰ä»·å…³ç³»
    pub fn is_equal(l1: &HashSet<String>, l2: &HashSet<String>) -> bool {
        Self::is_subset(l1, l2) && Self::is_subset(l2, l1)
    }
    
    /// è®¡ç®—è¯­è¨€äº¤é›†
    pub fn intersection(l1: &HashSet<String>, l2: &HashSet<String>) -> HashSet<String> {
        l1.intersection(l2).cloned().collect()
    }
    
    /// è®¡ç®—è¯­è¨€å¹¶é›†
    pub fn union(l1: &HashSet<String>, l2: &HashSet<String>) -> HashSet<String> {
        l1.union(l2).cloned().collect()
    }
    
    /// è®¡ç®—è¯­è¨€å·®é›†
    pub fn difference(l1: &HashSet<String>, l2: &HashSet<String>) -> HashSet<String> {
        l1.difference(l2).cloned().collect()
    }
    
    /// è®¡ç®—è¯­è¨€è¡¥é›†ï¼ˆç›¸å¯¹äºç»™å®šå­—æ¯è¡¨ï¼‰
    pub fn complement(l: &HashSet<String>, alphabet: &HashSet<char>, max_length: usize) -> HashSet<String> {
        let all_words = Self::generate_all_words(alphabet, max_length);
        all_words.difference(l).cloned().collect()
    }
    
    /// ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„å•è¯ï¼ˆç›´åˆ°æŒ‡å®šé•¿åº¦ï¼‰
    fn generate_all_words(alphabet: &HashSet<char>, max_length: usize) -> HashSet<String> {
        let mut words = HashSet::new();
        words.insert(String::new()); // ç©ºå­—ç¬¦ä¸²
        
        for length in 1..=max_length {
            let mut new_words = HashSet::new();
            for word in &words {
                if word.len() == length - 1 {
                    for &c in alphabet {
                        let mut new_word = word.clone();
                        new_word.push(c);
                        new_words.insert(new_word);
                    }
                }
            }
            words.extend(new_words);
        }
        
        words
    }
    
    /// åŒæ€æ˜ å°„
    pub fn homomorphism(l: &HashSet<String>, h: &HashMap<char, String>) -> HashSet<String> {
        let mut result = HashSet::new();
        
        for word in l {
            let mut image = String::new();
            for c in word.chars() {
                if let Some(image_c) = h.get(&c) {
                    image.push_str(image_c);
                } else {
                    image.push(c); // å¦‚æœå­—ç¬¦æ²¡æœ‰æ˜ å°„ï¼Œä¿æŒåŸæ ·
                }
            }
            result.insert(image);
        }
        
        result
    }
    
    /// é€†åŒæ€æ˜ å°„
    pub fn inverse_homomorphism(l: &HashSet<String>, h: &HashMap<char, String>) -> HashSet<String> {
        let mut result = HashSet::new();
        
        // ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„åŸåƒ
        let max_length = l.iter().map(|w| w.len()).max().unwrap_or(0);
        let alphabet: HashSet<char> = h.keys().cloned().collect();
        let all_possible_words = Self::generate_all_words(&alphabet, max_length);
        
        for word in all_possible_words {
            let image = Self::apply_homomorphism(&word, h);
            if l.contains(&image) {
                result.insert(word);
            }
        }
        
        result
    }
    
    /// åº”ç”¨åŒæ€æ˜ å°„åˆ°å•ä¸ªå•è¯
    fn apply_homomorphism(word: &str, h: &HashMap<char, String>) -> String {
        let mut result = String::new();
        for c in word.chars() {
            if let Some(image_c) = h.get(&c) {
                result.push_str(image_c);
            } else {
                result.push(c);
            }
        }
        result
    }
    
    /// è¯­è¨€å˜æ¢
    pub fn transform(l: &HashSet<String>, transform_fn: &dyn Fn(&str) -> String) -> HashSet<String> {
        l.iter().map(|word| transform_fn(word)).collect()
    }
    
    /// æ£€æŸ¥è¯­è¨€æ˜¯å¦ä¸ºç©º
    pub fn is_empty(l: &HashSet<String>) -> bool {
        l.is_empty() || (l.len() == 1 && l.contains(""))
    }
    
    /// æ£€æŸ¥è¯­è¨€æ˜¯å¦åŒ…å«ç©ºå­—ç¬¦ä¸²
    pub fn contains_empty(l: &HashSet<String>) -> bool {
        l.contains("")
    }
    
    /// è®¡ç®—è¯­è¨€çš„æœ€å°DFAçŠ¶æ€æ•°ï¼ˆè¿‘ä¼¼ï¼‰
    pub fn estimate_dfa_states(l: &HashSet<String>) -> usize {
        if l.is_empty() {
            return 1;
        }
        
        let max_length = l.iter().map(|w| w.len()).max().unwrap_or(0);
        let alphabet_size = Self::get_alphabet_size(l);
        
        // ç®€å•çš„ä¼°è®¡ï¼šåŸºäºè¯­è¨€å¤§å°å’Œå­—æ¯è¡¨å¤§å°
        (l.len() + alphabet_size * max_length).min(1000) // é™åˆ¶æœ€å¤§çŠ¶æ€æ•°
    }
    
    /// è·å–è¯­è¨€çš„å­—æ¯è¡¨å¤§å°
    fn get_alphabet_size(l: &HashSet<String>) -> usize {
        let mut alphabet = HashSet::new();
        for word in l {
            for c in word.chars() {
                alphabet.insert(c);
            }
        }
        alphabet.len()
    }
    
    /// è¯­è¨€ä¹˜ç§¯
    pub fn product(l1: &HashSet<String>, l2: &HashSet<String>) -> HashSet<String> {
        let mut result = HashSet::new();
        
        for word1 in l1 {
            for word2 in l2 {
                let mut product_word = word1.clone();
                product_word.push_str(word2);
                result.insert(product_word);
            }
        }
        
        result
    }
    
    /// è¯­è¨€å¹‚è¿ç®—
    pub fn power(l: &HashSet<String>, n: usize) -> HashSet<String> {
        if n == 0 {
            let mut result = HashSet::new();
            result.insert(String::new());
            return result;
        }
        
        if n == 1 {
            return l.clone();
        }
        
        let mut result = l.clone();
        for _ in 1..n {
            result = Self::product(&result, l);
        }
        
        result
    }
    
    /// è¯­è¨€æ˜Ÿé—­åŒ…
    pub fn kleene_star(l: &HashSet<String>, max_iterations: usize) -> HashSet<String> {
        let mut result = HashSet::new();
        result.insert(String::new()); // ç©ºå­—ç¬¦ä¸²
        
        let mut current = l.clone();
        for _ in 0..max_iterations {
            result.extend(current.clone());
            current = Self::product(&current, l);
        }
        
        result
    }
    
    /// è¯­è¨€æ­£é—­åŒ…
    pub fn kleene_plus(l: &HashSet<String>, max_iterations: usize) -> HashSet<String> {
        let mut result = HashSet::new();
        
        let mut current = l.clone();
        for _ in 0..max_iterations {
            result.extend(current.clone());
            current = Self::product(&current, l);
        }
        
        result
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::collections::HashMap;
    
    #[test]
    fn test_is_subset() {
        let l1: HashSet<String> = ["a", "b"].iter().map(|s| s.to_string()).collect();
        let l2: HashSet<String> = ["a", "b", "c"].iter().map(|s| s.to_string()).collect();
        
        assert!(LanguageRelations::is_subset(&l1, &l2));
        assert!(!LanguageRelations::is_subset(&l2, &l1));
    }
    
    #[test]
    fn test_is_equal() {
        let l1: HashSet<String> = ["a", "b"].iter().map(|s| s.to_string()).collect();
        let l2: HashSet<String> = ["b", "a"].iter().map(|s| s.to_string()).collect();
        
        assert!(LanguageRelations::is_equal(&l1, &l2));
    }
    
    #[test]
    fn test_intersection() {
        let l1: HashSet<String> = ["a", "b", "c"].iter().map(|s| s.to_string()).collect();
        let l2: HashSet<String> = ["b", "c", "d"].iter().map(|s| s.to_string()).collect();
        
        let intersection = LanguageRelations::intersection(&l1, &l2);
        let expected: HashSet<String> = ["b", "c"].iter().map(|s| s.to_string()).collect();
        
        assert_eq!(intersection, expected);
    }
    
    #[test]
    fn test_union() {
        let l1: HashSet<String> = ["a", "b"].iter().map(|s| s.to_string()).collect();
        let l2: HashSet<String> = ["b", "c"].iter().map(|s| s.to_string()).collect();
        
        let union = LanguageRelations::union(&l1, &l2);
        let expected: HashSet<String> = ["a", "b", "c"].iter().map(|s| s.to_string()).collect();
        
        assert_eq!(union, expected);
    }
    
    #[test]
    fn test_homomorphism() {
        let l: HashSet<String> = ["a", "ab"].iter().map(|s| s.to_string()).collect();
        let mut h = HashMap::new();
        h.insert('a', "0".to_string());
        h.insert('b', "1".to_string());
        
        let result = LanguageRelations::homomorphism(&l, &h);
        let expected: HashSet<String> = ["0", "01"].iter().map(|s| s.to_string()).collect();
        
        assert_eq!(result, expected);
    }
    
    #[test]
    fn test_product() {
        let l1: HashSet<String> = ["a", "b"].iter().map(|s| s.to_string()).collect();
        let l2: HashSet<String> = ["x", "y"].iter().map(|s| s.to_string()).collect();
        
        let product = LanguageRelations::product(&l1, &l2);
        let expected: HashSet<String> = ["ax", "ay", "bx", "by"].iter().map(|s| s.to_string()).collect();
        
        assert_eq!(product, expected);
    }
    
    #[test]
    fn test_power() {
        let l: HashSet<String> = ["a", "b"].iter().map(|s| s.to_string()).collect();
        
        let power_0 = LanguageRelations::power(&l, 0);
        let expected_0: HashSet<String> = [""].iter().map(|s| s.to_string()).collect();
        assert_eq!(power_0, expected_0);
        
        let power_2 = LanguageRelations::power(&l, 2);
        let expected_2: HashSet<String> = ["aa", "ab", "ba", "bb"].iter().map(|s| s.to_string()).collect();
        assert_eq!(power_2, expected_2);
    }
}
```

### 4.2 Haskellå®ç°

```haskell
module LanguageRelations where

import Data.Set (Set, fromList, toList, intersection, union, difference, empty, singleton, member, size)
import qualified Data.Set as Set
import Data.Map (Map, fromList, lookup, keys)
import qualified Data.Map as Map

-- è¯­è¨€å…³ç³»ç†è®ºå®ç°
class LanguageRelations a where
    isSubset :: Set a -> Set a -> Bool
    isEqual :: Set a -> Set a -> Bool
    intersection :: Set a -> Set a -> Set a
    union :: Set a -> Set a -> Set a
    difference :: Set a -> Set a -> Set a
    complement :: Set a -> Set Char -> Int -> Set a
    homomorphism :: Set a -> Map Char String -> Set String
    inverseHomomorphism :: Set a -> Map Char String -> Set String
    transform :: Set a -> (a -> String) -> Set String
    isEmpty :: Set a -> Bool
    containsEmpty :: Set a -> Bool
    product :: Set a -> Set a -> Set a
    power :: Set a -> Int -> Set a
    kleeneStar :: Set a -> Int -> Set a
    kleenePlus :: Set a -> Int -> Set a

instance LanguageRelations String where
    -- æ£€æŸ¥è¯­è¨€åŒ…å«å…³ç³»
    isSubset l1 l2 = all (`member` l2) l1
    
    -- æ£€æŸ¥è¯­è¨€ç­‰ä»·å…³ç³»
    isEqual l1 l2 = isSubset l1 l2 && isSubset l2 l1
    
    -- è®¡ç®—è¯­è¨€äº¤é›†
    intersection = Set.intersection
    
    -- è®¡ç®—è¯­è¨€å¹¶é›†
    union = Set.union
    
    -- è®¡ç®—è¯­è¨€å·®é›†
    difference = Set.difference
    
    -- è®¡ç®—è¯­è¨€è¡¥é›†
    complement l alphabet maxLength = 
        difference (generateAllWords alphabet maxLength) l
    
    -- ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„å•è¯
    generateAllWords alphabet maxLength = 
        fromList $ concatMap (generateWordsOfLength alphabet) [0..maxLength]
        where
            generateWordsOfLength _ 0 = [""]
            generateWordsOfLength chars n = 
                [c : word | c <- toList chars, word <- generateWordsOfLength chars (n-1)]
    
    -- åŒæ€æ˜ å°„
    homomorphism l h = fromList $ map (applyHomomorphism h) (toList l)
        where
            applyHomomorphism h word = concatMap (\c -> maybe [c] id (Map.lookup c h)) word
    
    -- é€†åŒæ€æ˜ å°„
    inverseHomomorphism l h = 
        fromList [word | word <- toList allWords, applyHomomorphism h word `member` l]
        where
            allWords = generateAllWords (fromList $ keys h) maxLength
            maxLength = maximum $ map length $ toList l
            applyHomomorphism h word = concatMap (\c -> maybe [c] id (Map.lookup c h)) word
    
    -- è¯­è¨€å˜æ¢
    transform l f = fromList $ map f (toList l)
    
    -- æ£€æŸ¥è¯­è¨€æ˜¯å¦ä¸ºç©º
    isEmpty l = Set.null l || (size l == 1 && member "" l)
    
    -- æ£€æŸ¥è¯­è¨€æ˜¯å¦åŒ…å«ç©ºå­—ç¬¦ä¸²
    containsEmpty l = member "" l
    
    -- è¯­è¨€ä¹˜ç§¯
    product l1 l2 = fromList [w1 ++ w2 | w1 <- toList l1, w2 <- toList l2]
    
    -- è¯­è¨€å¹‚è¿ç®—
    power l 0 = singleton ""
    power l 1 = l
    power l n = product (power l (n-1)) l
    
    -- è¯­è¨€æ˜Ÿé—­åŒ…
    kleeneStar l maxIterations = 
        union (singleton "") (kleenePlus l maxIterations)
    
    -- è¯­è¨€æ­£é—­åŒ…
    kleenePlus l maxIterations = 
        fromList $ concatMap (\n -> toList $ power l n) [1..maxIterations]

-- è¾…åŠ©å‡½æ•°
estimateDfaStates :: Set String -> Int
estimateDfaStates l
    | isEmpty l = 1
    | otherwise = min 1000 (size l + alphabetSize * maxLength)
    where
        maxLength = maximum $ map length $ toList l
        alphabetSize = size $ fromList $ concatMap (map (:[])) $ toList l

getAlphabetSize :: Set String -> Int
getAlphabetSize l = size $ fromList $ concatMap (map (:[])) $ toList l

-- æµ‹è¯•å‡½æ•°
testLanguageRelations :: IO ()
testLanguageRelations = do
    putStrLn "Testing Language Relations..."
    
    -- æµ‹è¯•åŒ…å«å…³ç³»
    let l1 = fromList ["a", "b"]
    let l2 = fromList ["a", "b", "c"]
    putStrLn $ "isSubset l1 l2: " ++ show (isSubset l1 l2)
    putStrLn $ "isSubset l2 l1: " ++ show (isSubset l2 l1)
    
    -- æµ‹è¯•ç­‰ä»·å…³ç³»
    let l3 = fromList ["b", "a"]
    putStrLn $ "isEqual l1 l3: " ++ show (isEqual l1 l3)
    
    -- æµ‹è¯•äº¤é›†
    let intersection_result = intersection l1 l2
    putStrLn $ "intersection l1 l2: " ++ show (toList intersection_result)
    
    -- æµ‹è¯•å¹¶é›†
    let union_result = union l1 l2
    putStrLn $ "union l1 l2: " ++ show (toList union_result)
    
    -- æµ‹è¯•åŒæ€æ˜ å°„
    let h = Map.fromList [('a', "0"), ('b', "1")]
    let hom_result = homomorphism l1 h
    putStrLn $ "homomorphism l1 h: " ++ show (toList hom_result)
    
    -- æµ‹è¯•ä¹˜ç§¯
    let l4 = fromList ["x", "y"]
    let product_result = product l1 l4
    putStrLn $ "product l1 l4: " ++ show (toList product_result)
    
    -- æµ‹è¯•å¹‚è¿ç®—
    let power_result = power l1 2
    putStrLn $ "power l1 2: " ++ show (toList power_result)
    
    -- æµ‹è¯•æ˜Ÿé—­åŒ…
    let star_result = kleeneStar l1 3
    putStrLn $ "kleeneStar l1 3: " ++ show (toList star_result)
```

## 5. åº”ç”¨ç¤ºä¾‹

### 5.1 ç¼–è¯‘å™¨è®¾è®¡åº”ç”¨

è¯­è¨€å…³ç³»åœ¨ç¼–è¯‘å™¨è®¾è®¡ä¸­çš„åº”ç”¨ï¼š

```rust
use std::collections::{HashMap, HashSet};

pub struct CompilerLanguageRelations;

impl CompilerLanguageRelations {
    /// æ£€æŸ¥è¯­æ³•è§„åˆ™çš„ä¸€è‡´æ€§
    pub fn check_grammar_consistency(
        terminals: &HashSet<String>,
        non_terminals: &HashSet<String>,
        productions: &HashMap<String, Vec<Vec<String>>>
    ) -> bool {
        // æ£€æŸ¥æ‰€æœ‰äº§ç”Ÿå¼å³éƒ¨çš„ç¬¦å·æ˜¯å¦éƒ½åœ¨å­—æ¯è¡¨ä¸­
        for (_, rhs_list) in productions {
            for rhs in rhs_list {
                for symbol in rhs {
                    if !terminals.contains(symbol) && !non_terminals.contains(symbol) {
                        return false;
                    }
                }
            }
        }
        true
    }
    
    /// è®¡ç®—è¯­è¨€çš„FIRSTé›†
    pub fn compute_first_set(
        symbol: &str,
        terminals: &HashSet<String>,
        non_terminals: &HashSet<String>,
        productions: &HashMap<String, Vec<Vec<String>>>,
        first_cache: &mut HashMap<String, HashSet<String>>
    ) -> HashSet<String> {
        if first_cache.contains_key(symbol) {
            return first_cache[symbol].clone();
        }
        
        let mut first = HashSet::new();
        
        if terminals.contains(symbol) {
            first.insert(symbol.to_string());
        } else if non_terminals.contains(symbol) {
            if let Some(rhs_list) = productions.get(symbol) {
                for rhs in rhs_list {
                    if rhs.is_empty() {
                        first.insert("Îµ".to_string());
                    } else {
                        let mut all_nullable = true;
                        for sym in rhs {
                            let sym_first = Self::compute_first_set(sym, terminals, non_terminals, productions, first_cache);
                            let non_nullable: HashSet<String> = sym_first.iter()
                                .filter(|&s| s != "Îµ")
                                .cloned()
                                .collect();
                            first.extend(non_nullable);
                            
                            if !sym_first.contains("Îµ") {
                                all_nullable = false;
                                break;
                            }
                        }
                        if all_nullable {
                            first.insert("Îµ".to_string());
                        }
                    }
                }
            }
        }
        
        first_cache.insert(symbol.to_string(), first.clone());
        first
    }
    
    /// è®¡ç®—è¯­è¨€çš„FOLLOWé›†
    pub fn compute_follow_set(
        symbol: &str,
        start_symbol: &str,
        terminals: &HashSet<String>,
        non_terminals: &HashSet<String>,
        productions: &HashMap<String, Vec<Vec<String>>>,
        first_cache: &HashMap<String, HashSet<String>>,
        follow_cache: &mut HashMap<String, HashSet<String>>
    ) -> HashSet<String> {
        if follow_cache.contains_key(symbol) {
            return follow_cache[symbol].clone();
        }
        
        let mut follow = HashSet::new();
        
        if symbol == start_symbol {
            follow.insert("$".to_string());
        }
        
        for (lhs, rhs_list) in productions {
            for rhs in rhs_list {
                for (i, sym) in rhs.iter().enumerate() {
                    if sym == symbol {
                        // æ£€æŸ¥åé¢çš„ç¬¦å·
                        if i + 1 < rhs.len() {
                            let next_sym = &rhs[i + 1];
                            let next_first = first_cache.get(next_sym).unwrap_or(&HashSet::new());
                            
                            let non_nullable: HashSet<String> = next_first.iter()
                                .filter(|&s| s != "Îµ")
                                .cloned()
                                .collect();
                            follow.extend(non_nullable);
                            
                            // å¦‚æœåé¢çš„ç¬¦å·å¯ä»¥æ¨å¯¼å‡ºç©ºä¸²
                            if next_first.contains("Îµ") {
                                let lhs_follow = Self::compute_follow_set(
                                    lhs, start_symbol, terminals, non_terminals, 
                                    productions, first_cache, follow_cache
                                );
                                follow.extend(lhs_follow);
                            }
                        } else {
                            // ç¬¦å·åœ¨äº§ç”Ÿå¼å³éƒ¨æœ«å°¾
                            let lhs_follow = Self::compute_follow_set(
                                lhs, start_symbol, terminals, non_terminals, 
                                productions, first_cache, follow_cache
                            );
                            follow.extend(lhs_follow);
                        }
                    }
                }
            }
        }
        
        follow_cache.insert(symbol.to_string(), follow.clone());
        follow
    }
    
    /// æ£€æŸ¥LL(1)æ–‡æ³•æ¡ä»¶
    pub fn is_ll1_grammar(
        start_symbol: &str,
        terminals: &HashSet<String>,
        non_terminals: &HashSet<String>,
        productions: &HashMap<String, Vec<Vec<String>>>
    ) -> bool {
        let mut first_cache = HashMap::new();
        let mut follow_cache = HashMap::new();
        
        // è®¡ç®—æ‰€æœ‰ç¬¦å·çš„FIRSTé›†
        for symbol in non_terminals {
            Self::compute_first_set(symbol, terminals, non_terminals, productions, &mut first_cache);
        }
        
        // è®¡ç®—æ‰€æœ‰ç¬¦å·çš„FOLLOWé›†
        for symbol in non_terminals {
            Self::compute_follow_set(symbol, start_symbol, terminals, non_terminals, productions, &first_cache, &mut follow_cache);
        }
        
        // æ£€æŸ¥æ¯ä¸ªéç»ˆç»“ç¬¦çš„äº§ç”Ÿå¼æ˜¯å¦æ»¡è¶³LL(1)æ¡ä»¶
        for (lhs, rhs_list) in productions {
            if rhs_list.len() > 1 {
                // æ£€æŸ¥æ‰€æœ‰äº§ç”Ÿå¼çš„FIRSTé›†æ˜¯å¦ä¸¤ä¸¤ä¸ç›¸äº¤
                for i in 0..rhs_list.len() {
                    for j in i + 1..rhs_list.len() {
                        let first_i = Self::compute_rhs_first(&rhs_list[i], &first_cache);
                        let first_j = Self::compute_rhs_first(&rhs_list[j], &first_cache);
                        
                        let intersection: HashSet<String> = first_i.intersection(&first_j).cloned().collect();
                        if !intersection.is_empty() {
                            return false;
                        }
                    }
                }
            }
        }
        
        true
    }
    
    /// è®¡ç®—äº§ç”Ÿå¼å³éƒ¨çš„FIRSTé›†
    fn compute_rhs_first(
        rhs: &[String],
        first_cache: &HashMap<String, HashSet<String>>
    ) -> HashSet<String> {
        let mut result = HashSet::new();
        let mut all_nullable = true;
        
        for symbol in rhs {
            let sym_first = first_cache.get(symbol).unwrap_or(&HashSet::new());
            let non_nullable: HashSet<String> = sym_first.iter()
                .filter(|&s| s != "Îµ")
                .cloned()
                .collect();
            result.extend(non_nullable);
            
            if !sym_first.contains("Îµ") {
                all_nullable = false;
                break;
            }
        }
        
        if all_nullable {
            result.insert("Îµ".to_string());
        }
        
        result
    }
}
```

### 5.2 è¯­è¨€å˜æ¢åº”ç”¨

```rust
pub struct LanguageTransformations;

impl LanguageTransformations {
    /// è¯­è¨€çš„æ­£åˆ™åŒ–å˜æ¢
    pub fn regularize_language(l: &HashSet<String>) -> HashSet<String> {
        let mut result = HashSet::new();
        
        for word in l {
            // å°†å•è¯è½¬æ¢ä¸ºæ­£åˆ™å½¢å¼ï¼ˆä¾‹å¦‚ï¼šæ·»åŠ è¾¹ç•Œæ ‡è®°ï¼‰
            let regularized = format!("^{}$", word);
            result.insert(regularized);
        }
        
        result
    }
    
    /// è¯­è¨€çš„æ ‡å‡†åŒ–å˜æ¢
    pub fn normalize_language(l: &HashSet<String>) -> HashSet<String> {
        let mut result = HashSet::new();
        
        for word in l {
            // æ ‡å‡†åŒ–ï¼šè½¬æ¢ä¸ºå°å†™ï¼Œå»é™¤å¤šä½™ç©ºæ ¼
            let normalized = word.to_lowercase().trim().to_string();
            if !normalized.is_empty() {
                result.insert(normalized);
            }
        }
        
        result
    }
    
    /// è¯­è¨€çš„ç¼–ç å˜æ¢
    pub fn encode_language(l: &HashSet<String>, encoding: &HashMap<char, String>) -> HashSet<String> {
        let mut result = HashSet::new();
        
        for word in l {
            let mut encoded = String::new();
            for c in word.chars() {
                if let Some(code) = encoding.get(&c) {
                    encoded.push_str(code);
                } else {
                    encoded.push(c);
                }
            }
            result.insert(encoded);
        }
        
        result
    }
    
    /// è¯­è¨€çš„è§£ç å˜æ¢
    pub fn decode_language(l: &HashSet<String>, decoding: &HashMap<String, char>) -> HashSet<String> {
        let mut result = HashSet::new();
        
        for word in l {
            let mut decoded = String::new();
            let mut current_code = String::new();
            
            for c in word.chars() {
                current_code.push(c);
                if let Some(&decoded_char) = decoding.get(&current_code) {
                    decoded.push(decoded_char);
                    current_code.clear();
                }
            }
            
            if current_code.is_empty() {
                result.insert(decoded);
            }
        }
        
        result
    }
}
```

## 6. ç›¸å…³ç†è®º

### 6.1 ä¸è¯­è¨€åˆ†ç±»çš„å…³ç³»

è¯­è¨€å…³ç³»ç†è®ºä¸ºä¹”å§†æ–¯åŸºè°±ç³»ä¸­çš„è¯­è¨€åˆ†ç±»æä¾›äº†ç†è®ºåŸºç¡€ã€‚

### 6.2 ä¸è‡ªåŠ¨æœºç†è®ºçš„å…³ç³»

è¯­è¨€å…³ç³»ä¸è‡ªåŠ¨æœºçš„ç­‰ä»·æ€§ã€åŒ…å«æ€§ç­‰æ€§è´¨å¯†åˆ‡ç›¸å…³ã€‚

### 6.3 ä¸å½¢å¼æ–‡æ³•ç†è®ºçš„å…³ç³»

è¯­è¨€å…³ç³»åœ¨å½¢å¼æ–‡æ³•çš„å˜æ¢å’Œç­‰ä»·æ€§åˆ¤å®šä¸­æœ‰é‡è¦åº”ç”¨ã€‚

### 6.4 ä¸è®¡ç®—å¤æ‚æ€§ç†è®ºçš„å…³ç³»

è¯­è¨€å…³ç³»çš„å¯åˆ¤å®šæ€§å’Œè®¡ç®—å¤æ‚æ€§æ˜¯é‡è¦çš„ç ”ç©¶è¯¾é¢˜ã€‚

## 7. å‚è€ƒæ–‡çŒ®

1. Hopcroft, J. E., Motwani, R., & Ullman, J. D. (2006). Introduction to Automata Theory, Languages, and Computation. Pearson.
2. Sipser, M. (2012). Introduction to the Theory of Computation. Cengage Learning.
3. Kozen, D. C. (2006). Automata and Computability. Springer.
4. Harrison, M. A. (1978). Introduction to Formal Language Theory. Addison-Wesley.
5. Salomaa, A. (1973). Formal Languages. Academic Press.

---

**ç›¸å…³æ–‡æ¡£**ï¼š
- [03.3.1 ä¹”å§†æ–¯åŸºè°±ç³»](../03.3.1_ä¹”å§†æ–¯åŸºè°±ç³».md)
- [03.3.2 è¯­è¨€åˆ†ç±»](../03.3.2_è¯­è¨€åˆ†ç±».md)
- [03.3.3 è¯­è¨€æ€§è´¨](../03.3.3_è¯­è¨€æ€§è´¨.md)
- [03.4.1 LLè§£æ](../03.4.1_LLè§£æ.md) 