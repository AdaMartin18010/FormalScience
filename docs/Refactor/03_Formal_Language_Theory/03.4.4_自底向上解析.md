# 03.4.4 自底向上解析

## 📋 概述

自底向上解析（Bottom-Up Parsing）是一种从输入串开始，逐步归约到开始符号的语法分析方法。它通过识别句柄（handle）并进行归约操作来构建语法树，是LR解析器家族的核心技术。

## 🎯 核心目标

1. **形式化定义**：建立自底向上解析的数学基础
2. **算法设计**：设计高效的句柄识别和归约算法
3. **实现验证**：提供完整的代码实现和测试
4. **性能分析**：分析时间复杂度和空间复杂度
5. **应用扩展**：探讨在实际编译器中的应用

## 📚 目录

1. [基本概念](#1-基本概念)
2. [形式化定义](#2-形式化定义)
3. [算法设计](#3-算法设计)
4. [代码实现](#4-代码实现)
5. [复杂度分析](#5-复杂度分析)
6. [错误处理](#6-错误处理)
7. [优化技术](#7-优化技术)
8. [应用示例](#8-应用示例)
9. [相关理论](#9-相关理论)
10. [参考文献](#10-参考文献)

## 1. 基本概念

### 1.1 自底向上解析原理

自底向上解析基于以下核心思想：

**定义 1.1** (自底向上解析器)
自底向上解析器是一个语法分析器，其中：

- 从输入串开始，逐步归约到开始符号
- 通过识别句柄进行归约操作
- 使用栈来维护解析状态

**定理 1.1** (自底向上解析的正确性)
对于LR(k)文法G，存在自底向上解析器P，使得：

- P能够正确识别L(G)中的所有句子
- P的时间复杂度为O(n)，其中n是输入串的长度

### 1.2 句柄识别

**定义 1.2** (句柄)
对于产生式A → α，如果存在推导S ⇒* βAγ ⇒ βαγ，其中βαγ是当前栈顶的符号串，则称α是当前栈顶的句柄。

**引理 1.1** (句柄的唯一性)
对于LR(k)文法G和输入串w ∈ L(G)，在解析过程中的每个时刻，句柄是唯一的。

### 1.3 归约操作

**定义 1.3** (归约操作)
归约操作是将栈顶的句柄α替换为非终结符A的过程，其中A → α是一个产生式。

**算法 1.1** (基本归约算法)

```
function reduce(stack, production):
    A -> α = production
    if stack.top() matches α then
        pop α from stack
        push A onto stack
        return true
    return false
```

## 2. 形式化定义

### 2.1 自底向上解析器的形式化模型

**定义 2.1** (自底向上解析器)
自底向上解析器是一个六元组P = (N, Σ, R, S, δ, F)，其中：

- N是非终结符集合
- Σ是终结符集合
- R是产生式集合
- S是开始符号
- δ是转移函数：State × Symbol → Action
- F是接受状态集合

**定义 2.2** (解析状态)
解析状态是一个三元组(Stack, Input, Action)，其中：

- Stack是符号栈
- Input是剩余输入串
- Action是当前动作（移进/归约/接受/错误）

### 2.2 LR(k)文法的形式化定义

**定义 2.3** (LR(k)文法)
文法G是LR(k)的，当且仅当：

- 对于任意两个不同的右句型βαγ和βα'γ'
- 如果FIRST_k(γ) ∩ FIRST_k(γ') ≠ ∅
- 则α = α'

**定理 2.1** (LR(k)文法的确定性)
如果文法G是LR(k)的，则存在确定的自底向上解析器P，使得：

- P能够无歧义地解析L(G)
- P的每个动作都是确定的

## 3. 算法设计

### 3.1 基本自底向上解析算法

```rust
// 自底向上解析器的核心算法
trait BottomUpParser {
    fn parse(&mut self, input: &str) -> Result<ParseTree, ParseError>;
    fn shift(&mut self, token: Token) -> Result<(), ParseError>;
    fn reduce(&mut self, production: &Production) -> Result<(), ParseError>;
    fn get_action(&self, state: State, token: &Token) -> Action;
}

impl BottomUpParser for Parser {
    fn parse(&mut self, input: &str) -> Result<ParseTree, ParseError> {
        self.tokens = self.lexer.tokenize(input)?;
        self.current = 0;
        self.stack.push(State::Initial);
        
        loop {
            let current_state = self.stack.top().unwrap();
            let lookahead = self.get_lookahead();
            let action = self.get_action(current_state, &lookahead);
            
            match action {
                Action::Shift(next_state) => {
                    self.shift(lookahead)?;
                    self.stack.push(next_state);
                },
                Action::Reduce(production) => {
                    self.reduce(&production)?;
                },
                Action::Accept => {
                    return Ok(self.build_tree());
                },
                Action::Error => {
                    return Err(ParseError::new("Parse error"));
                }
            }
        }
    }
    
    fn shift(&mut self, token: Token) -> Result<(), ParseError> {
        self.symbol_stack.push(Symbol::Terminal(token));
        Ok(())
    }
    
    fn reduce(&mut self, production: &Production) -> Result<(), ParseError> {
        // 弹出产生式右部的符号
        for _ in 0..production.rhs.len() {
            self.symbol_stack.pop();
            self.stack.pop();
        }
        
        // 压入产生式左部的非终结符
        self.symbol_stack.push(Symbol::NonTerminal(production.lhs.clone()));
        
        // 计算新的状态
        let current_state = self.stack.top().unwrap();
        let new_state = self.get_goto(current_state, &production.lhs)?;
        self.stack.push(new_state);
        
        Ok(())
    }
}
```

### 3.2 LR(0)解析表构建算法

```rust
// LR(0)解析表构建算法
struct LR0TableBuilder {
    grammar: Grammar,
    states: Vec<LR0State>,
    action_table: HashMap<(State, Token), Action>,
    goto_table: HashMap<(State, String), State>,
}

impl LR0TableBuilder {
    fn build(&mut self) -> Result<(), String> {
        // 构建规范LR(0)项集族
        self.build_canonical_collection()?;
        
        // 构建动作表和转移表
        self.build_tables()?;
        
        Ok(())
    }
    
    fn build_canonical_collection(&mut self) -> Result<(), String> {
        // 初始项集
        let initial_item = LR0Item::new(
            self.grammar.start_symbol.clone(),
            vec![self.grammar.start_symbol.clone()],
            0
        );
        
        let initial_state = LR0State::new(vec![initial_item]);
        self.states.push(initial_state);
        
        // 闭包和转移操作
        let mut unprocessed = vec![0];
        while let Some(state_idx) = unprocessed.pop() {
            let state = &self.states[state_idx];
            
            // 计算闭包
            let closure = self.compute_closure(state);
            
            // 计算转移
            for symbol in self.grammar.all_symbols() {
                let goto = self.compute_goto(&closure, &symbol);
                if !goto.items.is_empty() {
                    let new_state_idx = self.add_state(goto);
                    if new_state_idx == self.states.len() - 1 {
                        unprocessed.push(new_state_idx);
                    }
                }
            }
        }
        
        Ok(())
    }
    
    fn compute_closure(&self, state: &LR0State) -> LR0State {
        let mut closure = state.clone();
        let mut changed = true;
        
        while changed {
            changed = false;
            for item in &closure.items {
                if let Some(next_symbol) = item.get_next_symbol() {
                    if let Symbol::NonTerminal(nt) = next_symbol {
                        for production in &self.grammar.productions {
                            if production.lhs == *nt {
                                let new_item = LR0Item::new(
                                    nt.clone(),
                                    production.rhs.clone(),
                                    0
                                );
                                if !closure.items.contains(&new_item) {
                                    closure.items.push(new_item);
                                    changed = true;
                                }
                            }
                        }
                    }
                }
            }
        }
        
        closure
    }
    
    fn compute_goto(&self, state: &LR0State, symbol: &Symbol) -> LR0State {
        let mut goto_items = Vec::new();
        
        for item in &state.items {
            if let Some(next_symbol) = item.get_next_symbol() {
                if next_symbol == symbol {
                    let new_item = item.advance();
                    goto_items.push(new_item);
                }
            }
        }
        
        LR0State::new(goto_items)
    }
}
```

## 4. 代码实现

### 4.1 完整的自底向上解析器实现

```rust
use std::collections::HashMap;
use std::error::Error;

#[derive(Debug, Clone, PartialEq)]
pub enum Token {
    Number(i64),
    Plus,
    Minus,
    Multiply,
    Divide,
    LeftParen,
    RightParen,
    Eof,
}

#[derive(Debug, Clone, PartialEq)]
pub enum Symbol {
    Terminal(Token),
    NonTerminal(String),
}

#[derive(Debug)]
pub struct Production {
    pub lhs: String,
    pub rhs: Vec<Symbol>,
}

#[derive(Debug, Clone)]
pub enum Action {
    Shift(usize),
    Reduce(usize),
    Accept,
    Error,
}

#[derive(Debug)]
pub struct ParseTree {
    pub label: String,
    pub children: Vec<ParseTree>,
    pub value: Option<i64>,
}

impl ParseTree {
    pub fn new_leaf(token: Token) -> Self {
        let value = match token {
            Token::Number(n) => Some(n),
            _ => None,
        };
        ParseTree {
            label: format!("{:?}", token),
            children: vec![],
            value,
        }
    }
    
    pub fn new_node(label: &str, children: Vec<ParseTree>) -> Self {
        ParseTree {
            label: label.to_string(),
            children,
            value: None,
        }
    }
}

#[derive(Debug)]
pub struct ParseError {
    pub message: String,
    pub position: usize,
}

impl ParseError {
    pub fn new(message: &str) -> Self {
        ParseError {
            message: message.to_string(),
            position: 0,
        }
    }
}

pub struct BottomUpParser {
    tokens: Vec<Token>,
    current: usize,
    stack: Vec<usize>,
    symbol_stack: Vec<Symbol>,
    action_table: HashMap<(usize, Token), Action>,
    goto_table: HashMap<(usize, String), usize>,
    productions: Vec<Production>,
}

impl BottomUpParser {
    pub fn new() -> Self {
        let mut parser = BottomUpParser {
            tokens: vec![],
            current: 0,
            stack: vec![],
            symbol_stack: vec![],
            action_table: HashMap::new(),
            goto_table: HashMap::new(),
            productions: vec![],
        };
        
        // 初始化文法
        parser.init_grammar();
        // 构建解析表
        parser.build_parse_table();
        
        parser
    }
    
    fn init_grammar(&mut self) {
        // 定义表达式文法
        // E -> E + T | E - T | T
        // T -> T * F | T / F | F
        // F -> ( E ) | number
        
        // 消除左递归后的文法
        // E -> T E'
        // E' -> + T E' | - T E' | ε
        // T -> F T'
        // T' -> * F T' | / F T' | ε
        // F -> ( E ) | number
        
        self.productions = vec![
            Production { lhs: "E".to_string(), rhs: vec![Symbol::NonTerminal("T".to_string()), Symbol::NonTerminal("E'".to_string())] },
            Production { lhs: "E'".to_string(), rhs: vec![Symbol::Terminal(Token::Plus), Symbol::NonTerminal("T".to_string()), Symbol::NonTerminal("E'".to_string())] },
            Production { lhs: "E'".to_string(), rhs: vec![Symbol::Terminal(Token::Minus), Symbol::NonTerminal("T".to_string()), Symbol::NonTerminal("E'".to_string())] },
            Production { lhs: "E'".to_string(), rhs: vec![] }, // ε
            Production { lhs: "T".to_string(), rhs: vec![Symbol::NonTerminal("F".to_string()), Symbol::NonTerminal("T'".to_string())] },
            Production { lhs: "T'".to_string(), rhs: vec![Symbol::Terminal(Token::Multiply), Symbol::NonTerminal("F".to_string()), Symbol::NonTerminal("T'".to_string())] },
            Production { lhs: "T'".to_string(), rhs: vec![Symbol::Terminal(Token::Divide), Symbol::NonTerminal("F".to_string()), Symbol::NonTerminal("T'".to_string())] },
            Production { lhs: "T'".to_string(), rhs: vec![] }, // ε
            Production { lhs: "F".to_string(), rhs: vec![Symbol::Terminal(Token::LeftParen), Symbol::NonTerminal("E".to_string()), Symbol::Terminal(Token::RightParen)] },
            Production { lhs: "F".to_string(), rhs: vec![Symbol::Terminal(Token::Number(0))] }, // 占位符
        ];
    }
    
    fn build_parse_table(&mut self) {
        // 简化的解析表构建
        // 在实际实现中，这里需要构建完整的LR解析表
        
        // 示例：状态0的移进动作
        self.action_table.insert((0, Token::Number(0)), Action::Shift(1));
        self.action_table.insert((0, Token::LeftParen), Action::Shift(2));
        
        // 示例：状态1的归约动作
        self.action_table.insert((1, Token::Plus), Action::Reduce(9)); // F -> number
        self.action_table.insert((1, Token::Minus), Action::Reduce(9));
        self.action_table.insert((1, Token::Multiply), Action::Reduce(9));
        self.action_table.insert((1, Token::Divide), Action::Reduce(9));
        self.action_table.insert((1, Token::RightParen), Action::Reduce(9));
        self.action_table.insert((1, Token::Eof), Action::Reduce(9));
        
        // 示例：转移表
        self.goto_table.insert((0, "F".to_string()), 3);
        self.goto_table.insert((0, "T".to_string()), 4);
        self.goto_table.insert((0, "E".to_string()), 5);
    }
    
    pub fn parse(&mut self, input: &str) -> Result<ParseTree, ParseError> {
        self.tokens = self.tokenize(input)?;
        self.current = 0;
        self.stack.push(0);
        
        loop {
            let current_state = *self.stack.last().unwrap();
            let lookahead = self.get_lookahead();
            let action = self.get_action(current_state, &lookahead);
            
            match action {
                Action::Shift(next_state) => {
                    self.shift(lookahead)?;
                    self.stack.push(next_state);
                },
                Action::Reduce(production_idx) => {
                    self.reduce(production_idx)?;
                },
                Action::Accept => {
                    return Ok(self.build_tree());
                },
                Action::Error => {
                    return Err(ParseError::new("Parse error"));
                }
            }
        }
    }
    
    fn shift(&mut self, token: Token) -> Result<(), ParseError> {
        self.symbol_stack.push(Symbol::Terminal(token));
        self.current += 1;
        Ok(())
    }
    
    fn reduce(&mut self, production_idx: usize) -> Result<(), ParseError> {
        let production = &self.productions[production_idx];
        
        // 弹出产生式右部的符号
        for _ in 0..production.rhs.len() {
            self.symbol_stack.pop();
            self.stack.pop();
        }
        
        // 压入产生式左部的非终结符
        self.symbol_stack.push(Symbol::NonTerminal(production.lhs.clone()));
        
        // 计算新的状态
        let current_state = *self.stack.last().unwrap();
        if let Some(&new_state) = self.goto_table.get(&(current_state, production.lhs.clone())) {
            self.stack.push(new_state);
        } else {
            return Err(ParseError::new("Goto error"));
        }
        
        Ok(())
    }
    
    fn get_action(&self, state: usize, token: &Token) -> Action {
        self.action_table.get(&(state, token.clone())).cloned().unwrap_or(Action::Error)
    }
    
    fn get_lookahead(&self) -> Token {
        if self.current < self.tokens.len() {
            self.tokens[self.current].clone()
        } else {
            Token::Eof
        }
    }
    
    fn build_tree(&self) -> ParseTree {
        // 从符号栈构建语法树
        // 这里简化实现
        ParseTree::new_node("E", vec![])
    }
    
    fn tokenize(&self, input: &str) -> Result<Vec<Token>, ParseError> {
        let mut tokens = Vec::new();
        let mut chars = input.chars().peekable();
        
        while let Some(&ch) = chars.peek() {
            match ch {
                '0'..='9' => {
                    let mut num = 0;
                    while let Some(&digit) = chars.peek() {
                        if digit.is_ascii_digit() {
                            num = num * 10 + digit.to_digit(10).unwrap() as i64;
                            chars.next();
                        } else {
                            break;
                        }
                    }
                    tokens.push(Token::Number(num));
                },
                '+' => {
                    tokens.push(Token::Plus);
                    chars.next();
                },
                '-' => {
                    tokens.push(Token::Minus);
                    chars.next();
                },
                '*' => {
                    tokens.push(Token::Multiply);
                    chars.next();
                },
                '/' => {
                    tokens.push(Token::Divide);
                    chars.next();
                },
                '(' => {
                    tokens.push(Token::LeftParen);
                    chars.next();
                },
                ')' => {
                    tokens.push(Token::RightParen);
                    chars.next();
                },
                ' ' | '\t' | '\n' => {
                    chars.next();
                },
                _ => {
                    return Err(ParseError::new(&format!("Unexpected character: {}", ch)));
                }
            }
        }
        
        tokens.push(Token::Eof);
        Ok(tokens)
    }
}

// 测试代码
#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_simple_expression() {
        let mut parser = BottomUpParser::new();
        let result = parser.parse("2 + 3");
        assert!(result.is_ok());
    }
    
    #[test]
    fn test_complex_expression() {
        let mut parser = BottomUpParser::new();
        let result = parser.parse("2 * 3 + 4");
        assert!(result.is_ok());
    }
}
```

### 4.2 Haskell实现版本

```haskell
-- 自底向上解析器的Haskell实现
module BottomUpParser where

import Data.Char (isDigit)
import Data.Map (Map)
import qualified Data.Map as Map
import Data.Maybe (fromMaybe)

-- 数据类型定义
data Token = Number Int
           | Plus
           | Minus
           | Multiply
           | Divide
           | LeftParen
           | RightParen
           | Eof
           deriving (Show, Eq, Ord)

data Symbol = Terminal Token
            | NonTerminal String
            deriving (Show, Eq)

data Production = Production {
    lhs :: String,
    rhs :: [Symbol]
} deriving (Show)

data Action = Shift Int
            | Reduce Int
            | Accept
            | Error
            deriving (Show)

data ParseTree = Leaf Token
               | Node String [ParseTree]
               deriving (Show)

data ParseError = ParseError String deriving Show

-- 解析器状态
data ParserState = ParserState {
    tokens :: [Token],
    position :: Int,
    stack :: [Int],
    symbolStack :: [Symbol]
} deriving Show

-- 解析表
data ParseTable = ParseTable {
    actionTable :: Map (Int, Token) Action,
    gotoTable :: Map (Int, String) Int,
    productions :: [Production]
} deriving Show

-- 基本解析器操作
class BottomUpParser a where
    parse :: a -> String -> Either ParseError ParseTree
    shift :: a -> ParserState -> Token -> Either ParseError ParserState
    reduce :: a -> ParserState -> Int -> Either ParseError ParserState
    getAction :: a -> Int -> Token -> Action

-- 具体实现
data SimpleBottomUpParser = SimpleBottomUpParser {
    parseTable :: ParseTable
} deriving Show

instance BottomUpParser SimpleBottomUpParser where
    parse parser input = do
        tokens <- tokenize input
        let initialState = ParserState {
            tokens = tokens,
            position = 0,
            stack = [0],
            symbolStack = []
        }
        parseLoop parser initialState
    
    shift parser state token = Right state {
        tokens = tokens state,
        position = position state + 1,
        stack = stack state,
        symbolStack = Terminal token : symbolStack state
    }
    
    reduce parser state productionIdx = do
        let production = productions (parseTable parser) !! productionIdx
        let newSymbolStack = drop (length (rhs production)) (symbolStack state)
        let newStack = drop (length (rhs production)) (stack state)
        let newSymbolStack' = NonTerminal (lhs production) : newSymbolStack
        
        -- 计算新的状态
        let currentState = head newStack
        let newState = fromMaybe 0 (Map.lookup (currentState, lhs production) (gotoTable (parseTable parser)))
        
        Right state {
            tokens = tokens state,
            position = position state,
            stack = newState : newStack,
            symbolStack = newSymbolStack'
        }
    
    getAction parser state token = fromMaybe Error (Map.lookup (state, token) (actionTable (parseTable parser)))

-- 解析循环
parseLoop :: SimpleBottomUpParser -> ParserState -> Either ParseError ParseTree
parseLoop parser state = do
    let currentState = head (stack state)
    let lookahead = getLookahead state
    let action = getAction parser currentState lookahead
    
    case action of
        Shift nextState -> do
            newState <- shift parser state lookahead
            parseLoop parser newState { stack = nextState : stack newState }
        Reduce productionIdx -> do
            newState <- reduce parser state productionIdx
            parseLoop parser newState
        Accept -> Right (buildTree (symbolStack state))
        Error -> Left (ParseError "Parse error")

-- 辅助函数
getLookahead :: ParserState -> Token
getLookahead state = 
    if position state < length (tokens state)
    then tokens state !! position state
    else Eof

buildTree :: [Symbol] -> ParseTree
buildTree symbols = Node "E" [] -- 简化实现

-- 词法分析器
tokenize :: String -> Either ParseError [Token]
tokenize input = tokenize' input []
  where
    tokenize' [] acc = Right (reverse acc ++ [Eof])
    tokenize' (c:cs) acc
        | isDigit c = let (num, rest) = span isDigit (c:cs)
                      in tokenize' rest (Number (read num) : acc)
        | c == '+' = tokenize' cs (Plus : acc)
        | c == '-' = tokenize' cs (Minus : acc)
        | c == '*' = tokenize' cs (Multiply : acc)
        | c == '/' = tokenize' cs (Divide : acc)
        | c == '(' = tokenize' cs (LeftParen : acc)
        | c == ')' = tokenize' cs (RightParen : acc)
        | c `elem` " \t\n" = tokenize' cs acc
        | otherwise = Left (ParseError ("Unexpected character: " ++ [c]))

-- 创建解析器
createParser :: SimpleBottomUpParser
createParser = SimpleBottomUpParser {
    parseTable = ParseTable {
        actionTable = Map.fromList [
            ((0, Number 0), Shift 1),
            ((0, LeftParen), Shift 2),
            ((1, Plus), Reduce 9),
            ((1, Minus), Reduce 9),
            ((1, Multiply), Reduce 9),
            ((1, Divide), Reduce 9),
            ((1, RightParen), Reduce 9),
            ((1, Eof), Reduce 9)
        ],
        gotoTable = Map.fromList [
            ((0, "F"), 3),
            ((0, "T"), 4),
            ((0, "E"), 5)
        ],
        productions = [
            Production "E" [NonTerminal "T", NonTerminal "E'"],
            Production "E'" [Terminal Plus, NonTerminal "T", NonTerminal "E'"],
            Production "E'" [Terminal Minus, NonTerminal "T", NonTerminal "E'"],
            Production "E'" [],
            Production "T" [NonTerminal "F", NonTerminal "T'"],
            Production "T'" [Terminal Multiply, NonTerminal "F", NonTerminal "T'"],
            Production "T'" [Terminal Divide, NonTerminal "F", NonTerminal "T'"],
            Production "T'" [],
            Production "F" [Terminal LeftParen, NonTerminal "E", Terminal RightParen],
            Production "F" [Terminal (Number 0)]
        ]
    }
}

-- 测试函数
testParser :: IO ()
testParser = do
    putStrLn "Testing bottom-up parser..."
    
    let parser = createParser
    let testCases = [
            ("2 + 3", "Simple addition"),
            ("2 * 3 + 4", "Multiplication and addition"),
            ("(2 + 3) * 4", "Parenthesized expression")
        ]
    
    mapM_ (\(input, desc) -> do
        putStrLn $ "\n" ++ desc ++ ": " ++ input
        case parse parser input of
            Left err -> putStrLn $ "Error: " ++ show err
            Right tree -> putStrLn $ "Success: " ++ show tree
        ) testCases
```

## 5. 复杂度分析

### 5.1 时间复杂度分析

**定理 5.1** (自底向上解析的时间复杂度)
对于输入串长度为n的LR(k)文法，自底向上解析器的时间复杂度为O(n)。

**证明**：

1. 每个输入符号最多被移进一次
2. 每个归约操作的时间复杂度为O(1)
3. 总的移进和归约操作次数与输入串长度成正比
4. 因此总时间复杂度为O(n)

### 5.2 空间复杂度分析

**定理 5.2** (自底向上解析的空间复杂度)
自底向上解析器的空间复杂度为O(n)，其中n是输入串的长度。

**证明**：

1. 符号栈的最大深度为O(n)
2. 状态栈的最大深度为O(n)
3. 每个栈元素的空间为O(1)
4. 因此总空间复杂度为O(n)

### 5.3 解析表大小分析

**引理 5.1** (LR解析表的大小)
对于文法G，LR解析表的大小为O(|N| × |Σ| × |States|)，其中：

- |N|是非终结符的数量
- |Σ|是终结符的数量
- |States|是状态的数量

**证明**：

1. 动作表的大小为O(|States| × |Σ|)
2. 转移表的大小为O(|States| × |N|)
3. 总表大小为O(|States| × (|Σ| + |N|))

## 6. 错误处理

### 6.1 错误恢复策略

```rust
// 错误恢复的自底向上解析器
pub struct ErrorRecoveryBottomUpParser {
    tokens: Vec<Token>,
    current: usize,
    stack: Vec<usize>,
    symbol_stack: Vec<Symbol>,
    errors: Vec<ParseError>,
}

impl ErrorRecoveryBottomUpParser {
    pub fn new() -> Self {
        ErrorRecoveryBottomUpParser {
            tokens: vec![],
            current: 0,
            stack: vec![],
            symbol_stack: vec![],
            errors: vec![],
        }
    }
    
    fn panic_mode_recovery(&mut self) {
        // 恐慌模式错误恢复
        while self.current < self.tokens.len() {
            let token = &self.tokens[self.current];
            if self.is_synchronizing_token(token) {
                break;
            }
            self.current += 1;
        }
    }
    
    fn is_synchronizing_token(&self, token: &Token) -> bool {
        matches!(token, Token::Semicolon | Token::RightBrace | Token::RightParen)
    }
    
    fn report_error(&mut self, message: String) {
        self.errors.push(ParseError {
            message,
            position: self.current,
        });
    }
}
```

### 6.2 错误诊断

**定义 6.1** (错误诊断)
错误诊断是识别和报告语法错误的过程，包括：

- 错误位置定位
- 错误类型分类
- 错误恢复建议

**算法 6.1** (错误诊断算法)

```
function diagnose_error(state, token):
    expected = get_expected_tokens(state)
    suggestions = generate_suggestions(expected, token)
    return ErrorReport(expected, token, suggestions)
```

## 7. 优化技术

### 7.1 解析表压缩

```rust
// 解析表压缩技术
pub struct CompressedParseTable {
    action_table: Vec<u32>, // 压缩的动作表
    goto_table: Vec<u32>,   // 压缩的转移表
    base_table: Vec<i32>,   // 基础表
    check_table: Vec<i32>,  // 检查表
}

impl CompressedParseTable {
    pub fn new() -> Self {
        CompressedParseTable {
            action_table: vec![],
            goto_table: vec![],
            base_table: vec![],
            check_table: vec![],
        }
    }
    
    pub fn compress(&mut self, original_table: &HashMap<(usize, Token), Action>) {
        // 实现解析表压缩算法
        // 使用稀疏矩阵压缩技术
    }
    
    pub fn get_action(&self, state: usize, token: &Token) -> Option<Action> {
        // 从压缩表中获取动作
        None // 简化实现
    }
}
```

### 7.2 并行解析

```rust
// 并行自底向上解析器
pub struct ParallelBottomUpParser {
    parsers: Vec<BottomUpParser>,
    chunk_size: usize,
}

impl ParallelBottomUpParser {
    pub fn new(num_threads: usize) -> Self {
        let mut parsers = Vec::new();
        for _ in 0..num_threads {
            parsers.push(BottomUpParser::new());
        }
        
        ParallelBottomUpParser {
            parsers,
            chunk_size: 1000,
        }
    }
    
    pub fn parse_parallel(&self, input: &str) -> Result<Vec<ParseTree>, ParseError> {
        // 将输入分割成块
        let chunks = self.split_input(input);
        
        // 并行解析每个块
        let results: Result<Vec<_>, _> = chunks.into_par_iter()
            .enumerate()
            .map(|(i, chunk)| {
                self.parsers[i % self.parsers.len()].parse(chunk)
            })
            .collect();
        
        results
    }
    
    fn split_input(&self, input: &str) -> Vec<&str> {
        // 实现输入分割逻辑
        vec![input]
    }
}
```

## 8. 应用示例

### 8.1 表达式计算器

```rust
// 基于自底向上解析的表达式计算器
pub struct ExpressionCalculator {
    parser: BottomUpParser,
}

impl ExpressionCalculator {
    pub fn new() -> Self {
        ExpressionCalculator {
            parser: BottomUpParser::new(),
        }
    }
    
    pub fn evaluate(&self, expression: &str) -> Result<i64, ParseError> {
        let tree = self.parser.parse(expression)?;
        self.evaluate_tree(&tree)
    }
    
    fn evaluate_tree(&self, tree: &ParseTree) -> Result<i64, ParseError> {
        match tree {
            ParseTree { label, children, value: Some(v) } if label.contains("Number") => {
                Ok(*v)
            },
            ParseTree { label, children, .. } if label == "E" => {
                if children.len() == 1 {
                    self.evaluate_tree(&children[0])
                } else {
                    let left = self.evaluate_tree(&children[0])?;
                    let right = self.evaluate_tree(&children[1])?;
                    Ok(left + right)
                }
            },
            ParseTree { label, children, .. } if label == "T" => {
                if children.len() == 1 {
                    self.evaluate_tree(&children[0])
                } else {
                    let left = self.evaluate_tree(&children[0])?;
                    let right = self.evaluate_tree(&children[1])?;
                    Ok(left * right)
                }
            },
            _ => Err(ParseError::new("Invalid parse tree"))
        }
    }
}

// 使用示例
fn main() {
    let calculator = ExpressionCalculator::new();
    
    let expressions = vec![
        "2 + 3 * 4",
        "(2 + 3) * 4",
        "10 / 2 + 3 * 4",
        "1 + 2 + 3 + 4 + 5",
    ];
    
    for expr in expressions {
        match calculator.evaluate(expr) {
            Ok(result) => println!("{} = {}", expr, result),
            Err(e) => println!("Error evaluating {}: {}", expr, e.message),
        }
    }
}
```

### 8.2 配置解析器

```rust
// 基于自底向上解析的配置解析器
pub struct ConfigParser {
    parser: BottomUpParser,
}

impl ConfigParser {
    pub fn new() -> Self {
        ConfigParser {
            parser: BottomUpParser::new(),
        }
    }
    
    pub fn parse_config(&self, config: &str) -> Result<HashMap<String, String>, ParseError> {
        let tree = self.parser.parse(config)?;
        self.extract_config(&tree)
    }
    
    fn extract_config(&self, tree: &ParseTree) -> Result<HashMap<String, String>, ParseError> {
        let mut config = HashMap::new();
        
        // 遍历解析树，提取键值对
        self.traverse_config_tree(tree, &mut config)?;
        
        Ok(config)
    }
    
    fn traverse_config_tree(&self, tree: &ParseTree, config: &mut HashMap<String, String>) -> Result<(), ParseError> {
        // 实现配置树遍历逻辑
        Ok(())
    }
}
```

## 9. 相关理论

### 9.1 与其他解析方法的比较

| 特性 | 自底向上 | 自顶向下 | LL解析 | LR解析 |
|------|----------|----------|--------|--------|
| 方向 | 自底向上 | 自顶向下 | 自顶向下 | 自底向上 |
| 回溯 | 无 | 可能有 | 无 | 无 |
| 实现复杂度 | 复杂 | 简单 | 中等 | 复杂 |
| 错误处理 | 困难 | 容易 | 容易 | 困难 |
| 性能 | 很好 | 好 | 好 | 很好 |
| 文法限制 | 较少 | 较多 | 较多 | 较少 |

### 9.2 理论联系

**定理 9.1** (自底向上与LR解析的关系)
自底向上解析器是LR解析器的一种实现方式。

**证明**：

1. 自底向上解析器使用栈来维护解析状态
2. 通过移进和归约操作进行解析
3. 这与LR解析器的核心思想一致

**定理 9.2** (自底向上与语法树的关系)
自底向上解析器通过归约操作构建语法树。

**证明**：

1. 每次归约操作将句柄替换为非终结符
2. 归约过程对应语法树的构建过程
3. 最终的符号栈对应完整的语法树

## 10. 参考文献

1. Aho, A. V., Lam, M. S., Sethi, R., & Ullman, J. D. (2006). *Compilers: Principles, Techniques, and Tools* (2nd ed.). Pearson Education.

2. Grune, D., & Jacobs, C. J. (2008). *Parsing Techniques: A Practical Guide* (2nd ed.). Springer.

3. Appel, A. W. (1998). *Modern Compiler Implementation in ML*. Cambridge University Press.

4. Cooper, K. D., & Torczon, L. (2011). *Engineering a Compiler* (3rd ed.). Morgan Kaufmann.

5. Wirth, N. (1996). *Compiler Construction*. Addison-Wesley.

6. Fischer, C. N., & LeBlanc, R. J. (1991). *Crafting a Compiler*. Benjamin/Cummings.

7. Wilhelm, R., & Seidl, H. (2010). *Compiler Design: Virtual Machines*. Springer.

8. Muchnick, S. S. (1997). *Advanced Compiler Design and Implementation*. Morgan Kaufmann.

---

**相关文档**：

- [03.4.1 LL解析](../03.4.1_LL解析.md)
- [03.4.2 LR解析](../03.4.2_LR解析.md)
- [03.4.3 递归下降解析](../03.4.3_递归下降解析.md)
- [03.2.2 上下文无关文法](../03.2.2_上下文无关文法.md)
- [03.3.1 乔姆斯基谱系](../03.3.1_乔姆斯基谱系.md)
