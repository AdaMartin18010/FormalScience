# 03.2.3 上下文有关文法

## 📋 概述

上下文有关文法（Context-Sensitive Grammar, CSG）是形式语言理论中的重要概念，它定义了乔姆斯基谱系中的1型语言。CSG在自然语言处理、生物信息学、模式识别等领域有重要应用。

## 🎯 核心目标

1. 建立上下文有关文法的严格形式化定义
2. 研究CSG的基本性质和结构
3. 探讨CSG与线性有界自动机的关系
4. 分析CSG的解析算法
5. 提供完整的代码实现

## 📚 目录

1. [基本概念](#1-基本概念)
2. [形式化定义](#2-形式化定义)
3. [定理与证明](#3-定理与证明)
4. [解析算法](#4-解析算法)
5. [代码实现](#5-代码实现)
6. [应用示例](#6-应用示例)
7. [相关理论](#7-相关理论)
8. [参考文献](#8-参考文献)

## 1. 基本概念

### 1.1 上下文有关文法的直观理解

上下文有关文法是一种形式文法，其中产生式规则的形式为 $\alpha A \beta \to \alpha \gamma \beta$，其中 $A$ 是非终结符，$\alpha, \beta$ 是上下文，$\gamma$ 是非空串。CSG的特点是替换非终结符时依赖于其上下文。

**经典例子**：

- $a^n b^n c^n$ 语言
- 自然语言的句法结构
- 生物序列的模式匹配

### 1.2 CSG的基本特点

1. **上下文敏感性**：替换操作依赖于上下文
2. **长度非减性**：产生式右端长度不小于左端
3. **线性有界性**：与线性有界自动机等价

## 2. 形式化定义

### 2.1 上下文有关文法的定义

**定义 2.1.1** (上下文有关文法)
上下文有关文法是一个四元组 $G = (V, \Sigma, P, S)$，其中：

- $V$ 是非终结符集合（有限集）
- $\Sigma$ 是终结符集合（有限集），且 $V \cap \Sigma = \emptyset$
- $P$ 是产生式集合，每个产生式形如 $\alpha A \beta \to \alpha \gamma \beta$，其中：
  - $A \in V$
  - $\alpha, \beta \in (V \cup \Sigma)^*$
  - $\gamma \in (V \cup \Sigma)^+$
- $S \in V$ 是开始符号

### 2.2 标准形式的定义

**定义 2.1.2** (标准形式)
CSG的标准形式要求所有产生式都满足：
$$|\alpha A \beta| \leq |\alpha \gamma \beta|$$

即右端长度不小于左端长度。

### 2.3 推导的定义

**定义 2.1.3** (直接推导)
设 $G = (V, \Sigma, P, S)$ 是CSG，对于 $\alpha, \beta \in (V \cup \Sigma)^*$，如果存在产生式 $\delta A \epsilon \to \delta \gamma \epsilon \in P$，使得 $\alpha = \alpha_1 \delta A \epsilon \alpha_2$ 且 $\beta = \alpha_1 \delta \gamma \epsilon \alpha_2$，则称 $\alpha$ 直接推导出 $\beta$，记作 $\alpha \Rightarrow \beta$。

**定义 2.1.4** (推导)
推导关系 $\Rightarrow^*$ 是 $\Rightarrow$ 的自反传递闭包。

### 2.4 语言的定义

**定义 2.1.5** (CSG生成的语言)
CSG $G = (V, \Sigma, P, S)$ 生成的语言定义为：
$$L(G) = \{w \in \Sigma^* \mid S \Rightarrow^* w\}$$

## 3. 定理与证明

### 3.1 CSG的基本性质

**定理 3.1.1** (CSG的长度非减性)
设 $G$ 是CSG，如果 $S \Rightarrow^* \alpha$，则 $|\alpha| \geq 1$ 或 $\alpha = \varepsilon$。

**证明**：
对推导步数进行归纳：

- 基础情况：$S \Rightarrow S$，$|S| = 1$
- 归纳步骤：假设 $S \Rightarrow^* \alpha$ 且 $|\alpha| \geq 1$，如果 $\alpha \Rightarrow \beta$，则 $|\beta| \geq |\alpha| \geq 1$

**定理 3.1.2** (CSG的上下文敏感性)
CSG的替换操作依赖于上下文，即产生式 $\alpha A \beta \to \alpha \gamma \beta$ 只能在特定的上下文中应用。

### 3.2 CSG与线性有界自动机的关系

**定理 3.2.1** (CSG与LBA等价性)
语言 $L$ 是上下文有关语言当且仅当存在线性有界自动机识别 $L$。

**证明**：

1. **必要性**：给定CSG $G$，构造LBA $M$ 模拟 $G$ 的推导过程
2. **充分性**：给定LBA $M$，构造CSG $G$ 模拟 $M$ 的计算过程

### 3.3 CSG的标准化

**定理 3.3.1** (CSG标准化定理)
任何CSG都可以转换为等价的标准化形式，其中所有产生式都满足长度非减性。

**证明**：
通过引入新的非终结符和产生式，将长产生式分解为标准化形式。

## 4. 解析算法

### 4.1 通用解析算法

**算法 4.1.1** (CSG通用解析)
由于CSG的复杂性，通常使用通用的解析算法，如CYK算法的扩展版本。

**基本思想**：

1. 使用动态规划表存储所有可能的推导
2. 考虑上下文约束
3. 使用回溯技术处理歧义

### 4.2 线性有界自动机模拟

**算法 4.1.2** (LBA模拟)
通过模拟线性有界自动机来解析CSG生成的语言。

**步骤**：

1. 构造对应的LBA
2. 模拟LBA的计算过程
3. 检查是否接受输入串

## 5. 代码实现

### 5.1 Rust 实现

```rust
use std::collections::{HashMap, HashSet};
use std::fmt;

/// 符号类型
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub enum Symbol {
    Terminal(String),
    NonTerminal(String),
}

impl Symbol {
    pub fn is_terminal(&self) -> bool {
        matches!(self, Symbol::Terminal(_))
    }
    
    pub fn is_non_terminal(&self) -> bool {
        matches!(self, Symbol::NonTerminal(_))
    }
    
    pub fn to_string(&self) -> String {
        match self {
            Symbol::Terminal(s) => s.clone(),
            Symbol::NonTerminal(s) => s.clone(),
        }
    }
}

/// 上下文有关产生式
#[derive(Debug, Clone)]
pub struct ContextSensitiveProduction {
    pub left_context: Vec<Symbol>,
    pub non_terminal: Symbol,
    pub right_context: Vec<Symbol>,
    pub replacement: Vec<Symbol>,
}

impl ContextSensitiveProduction {
    pub fn new(
        left_context: Vec<Symbol>,
        non_terminal: Symbol,
        right_context: Vec<Symbol>,
        replacement: Vec<Symbol>,
    ) -> Self {
        Self {
            left_context,
            non_terminal,
            right_context,
            replacement,
        }
    }
    
    pub fn is_standard_form(&self) -> bool {
        let left_length = self.left_context.len() + 1 + self.right_context.len();
        let right_length = self.left_context.len() + self.replacement.len() + self.right_context.len();
        right_length >= left_length
    }
    
    pub fn can_apply(&self, position: usize, symbols: &[Symbol]) -> bool {
        if position < self.left_context.len() || 
           position + self.right_context.len() >= symbols.len() {
            return false;
        }
        
        // 检查左上下文
        for (i, expected) in self.left_context.iter().enumerate() {
            if symbols[position - self.left_context.len() + i] != *expected {
                return false;
            }
        }
        
        // 检查非终结符
        if symbols[position] != self.non_terminal {
            return false;
        }
        
        // 检查右上下文
        for (i, expected) in self.right_context.iter().enumerate() {
            if symbols[position + 1 + i] != *expected {
                return false;
            }
        }
        
        true
    }
    
    pub fn apply(&self, position: usize, symbols: &[Symbol]) -> Vec<Symbol> {
        let mut result = symbols.to_vec();
        
        // 替换非终结符
        result.splice(
            position..position + 1,
            self.replacement.iter().cloned()
        );
        
        result
    }
}

/// 上下文有关文法
#[derive(Debug)]
pub struct ContextSensitiveGrammar {
    pub non_terminals: HashSet<Symbol>,
    pub terminals: HashSet<Symbol>,
    pub productions: Vec<ContextSensitiveProduction>,
    pub start_symbol: Symbol,
}

impl ContextSensitiveGrammar {
    pub fn new(start_symbol: Symbol) -> Self {
        let mut non_terminals = HashSet::new();
        non_terminals.insert(start_symbol.clone());
        
        Self {
            non_terminals,
            terminals: HashSet::new(),
            productions: Vec::new(),
            start_symbol,
        }
    }
    
    pub fn add_production(&mut self, production: ContextSensitiveProduction) {
        // 添加非终结符
        self.non_terminals.insert(production.non_terminal.clone());
        
        // 添加终结符和非终结符
        for symbol in production.left_context.iter().chain(production.right_context.iter()).chain(production.replacement.iter()) {
            match symbol {
                Symbol::Terminal(_) => {
                    self.terminals.insert(symbol.clone());
                }
                Symbol::NonTerminal(_) => {
                    self.non_terminals.insert(symbol.clone());
                }
            }
        }
        
        self.productions.push(production);
    }
    
    /// 检查文法是否为标准形式
    pub fn is_standard_form(&self) -> bool {
        self.productions.iter().all(|p| p.is_standard_form())
    }
    
    /// 转换为标准形式
    pub fn to_standard_form(&self) -> ContextSensitiveGrammar {
        let mut standard = ContextSensitiveGrammar::new(self.start_symbol.clone());
        
        for production in &self.productions {
            if production.is_standard_form() {
                standard.add_production(production.clone());
            } else {
                // 将非标准产生式转换为标准形式
                let standard_productions = self.convert_to_standard(production);
                for p in standard_productions {
                    standard.add_production(p);
                }
            }
        }
        
        standard
    }
    
    fn convert_to_standard(&self, production: &ContextSensitiveProduction) -> Vec<ContextSensitiveProduction> {
        // 简化实现：假设产生式已经是标准形式
        vec![production.clone()]
    }
    
    /// 直接推导
    pub fn direct_derivation(&self, from: &[Symbol], to: &[Symbol]) -> bool {
        for production in &self.productions {
            for i in 0..from.len() {
                if production.can_apply(i, from) {
                    let result = production.apply(i, from);
                    if result == to {
                        return true;
                    }
                }
            }
        }
        false
    }
    
    /// 推导
    pub fn derivation(&self, from: &[Symbol], to: &[Symbol]) -> bool {
        if from == to {
            return true;
        }
        
        // 使用广度优先搜索查找推导路径
        let mut visited = HashSet::new();
        let mut queue = vec![from.to_vec()];
        visited.insert(from.to_vec());
        
        while let Some(current) = queue.pop() {
            for production in &self.productions {
                for i in 0..current.len() {
                    if production.can_apply(i, &current) {
                        let next = production.apply(i, &current);
                        if next == to {
                            return true;
                        }
                        if !visited.contains(&next) {
                            visited.insert(next.clone());
                            queue.push(next);
                        }
                    }
                }
            }
        }
        
        false
    }
    
    /// 生成语言
    pub fn generate_language(&self, max_length: usize) -> Vec<String> {
        let mut language = Vec::new();
        let mut queue = vec![vec![self.start_symbol.clone()]];
        
        while let Some(current) = queue.pop() {
            // 检查是否只包含终结符
            if current.iter().all(|s| s.is_terminal()) {
                let word = current.iter().map(|s| s.to_string()).collect::<String>();
                if word.len() <= max_length {
                    language.push(word);
                }
                continue;
            }
            
            // 尝试应用产生式
            for production in &self.productions {
                for i in 0..current.len() {
                    if production.can_apply(i, &current) {
                        let next = production.apply(i, &current);
                        if next.len() <= max_length {
                            queue.push(next);
                        }
                    }
                }
            }
        }
        
        language.sort();
        language.dedup();
        language
    }
}

/// 线性有界自动机
pub struct LinearBoundedAutomaton {
    pub states: HashSet<String>,
    pub input_alphabet: HashSet<char>,
    pub tape_alphabet: HashSet<char>,
    pub transitions: HashMap<(String, char), Vec<(String, char, char)>>, // (state, read) -> [(new_state, write, move)]
    pub start_state: String,
    pub accept_states: HashSet<String>,
}

impl LinearBoundedAutomaton {
    pub fn new() -> Self {
        Self {
            states: HashSet::new(),
            input_alphabet: HashSet::new(),
            tape_alphabet: HashSet::new(),
            transitions: HashMap::new(),
            start_state: "q0".to_string(),
            accept_states: HashSet::new(),
        }
    }
    
    pub fn add_transition(&mut self, state: String, read: char, new_state: String, write: char, movement: char) {
        self.states.insert(state.clone());
        self.states.insert(new_state.clone());
        self.tape_alphabet.insert(read);
        self.tape_alphabet.insert(write);
        
        let key = (state, read);
        let value = (new_state, write, movement);
        self.transitions.entry(key).or_insert_with(Vec::new).push(value);
    }
    
    pub fn accept(&self, input: &str) -> bool {
        // 简化实现：模拟LBA的计算过程
        let mut tape = input.chars().collect::<Vec<char>>();
        let mut head = 0;
        let mut state = self.start_state.clone();
        
        for _ in 0..1000 { // 限制计算步数
            if self.accept_states.contains(&state) {
                return true;
            }
            
            let current_symbol = tape.get(head).copied().unwrap_or('B');
            let key = (state.clone(), current_symbol);
            
            if let Some(transitions) = self.transitions.get(&key) {
                if let Some((new_state, write, movement)) = transitions.first() {
                    if head < tape.len() {
                        tape[head] = *write;
                    }
                    state = new_state.clone();
                    match movement {
                        'L' => head = head.saturating_sub(1),
                        'R' => head = head.saturating_add(1),
                        'S' => {},
                        _ => panic!("无效的移动方向"),
                    }
                } else {
                    return false;
                }
            } else {
                return false;
            }
        }
        
        false
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_context_sensitive_production() {
        let production = ContextSensitiveProduction::new(
            vec![Symbol::Terminal("a".to_string())],
            Symbol::NonTerminal("S".to_string()),
            vec![Symbol::Terminal("b".to_string())],
            vec![Symbol::Terminal("a".to_string()), Symbol::NonTerminal("S".to_string()), Symbol::Terminal("b".to_string())],
        );
        
        assert!(production.is_standard_form());
        
        let symbols = vec![
            Symbol::Terminal("a".to_string()),
            Symbol::NonTerminal("S".to_string()),
            Symbol::Terminal("b".to_string()),
        ];
        
        assert!(production.can_apply(1, &symbols));
        let result = production.apply(1, &symbols);
        assert_eq!(result.len(), 5);
    }
    
    #[test]
    fn test_context_sensitive_grammar() {
        let mut grammar = ContextSensitiveGrammar::new(Symbol::NonTerminal("S".to_string()));
        
        // S -> aSb | ab
        grammar.add_production(ContextSensitiveProduction::new(
            vec![],
            Symbol::NonTerminal("S".to_string()),
            vec![],
            vec![Symbol::Terminal("a".to_string()), Symbol::NonTerminal("S".to_string()), Symbol::Terminal("b".to_string())],
        ));
        
        grammar.add_production(ContextSensitiveProduction::new(
            vec![],
            Symbol::NonTerminal("S".to_string()),
            vec![],
            vec![Symbol::Terminal("a".to_string()), Symbol::Terminal("b".to_string())],
        ));
        
        assert!(grammar.is_standard_form());
        
        let language = grammar.generate_language(10);
        assert!(!language.is_empty());
    }
    
    #[test]
    fn test_linear_bounded_automaton() {
        let mut lba = LinearBoundedAutomaton::new();
        
        // 简单的LBA：接受所有非空串
        lba.add_transition(
            "q0".to_string(), 'a', "q1".to_string(), 'a', 'R'
        );
        lba.add_transition(
            "q1".to_string(), 'a', "q1".to_string(), 'a', 'R'
        );
        lba.add_transition(
            "q1".to_string(), 'B', "q2".to_string(), 'B', 'S'
        );
        
        lba.accept_states.insert("q2".to_string());
        
        assert!(lba.accept("aaa"));
        assert!(!lba.accept(""));
    }
}
```

### 5.2 Haskell 实现

```haskell
module ContextSensitiveGrammar where

import Data.Set (Set)
import qualified Data.Set as Set
import Data.Map (Map)
import qualified Data.Map as Map
import Data.List (nub)

-- 符号类型
data Symbol = Terminal String | NonTerminal String
    deriving (Eq, Ord, Show)

-- 上下文有关产生式
data ContextSensitiveProduction = ContextSensitiveProduction {
    leftContext :: [Symbol],
    nonTerminal :: Symbol,
    rightContext :: [Symbol],
    replacement :: [Symbol]
} deriving (Eq, Show)

-- 上下文有关文法
data ContextSensitiveGrammar = ContextSensitiveGrammar {
    nonTerminals :: Set Symbol,
    terminals :: Set Symbol,
    productions :: [ContextSensitiveProduction],
    startSymbol :: Symbol
} deriving (Eq, Show)

-- 创建空文法
emptyCSG :: Symbol -> ContextSensitiveGrammar
emptyCSG start = ContextSensitiveGrammar {
    nonTerminals = Set.singleton start,
    terminals = Set.empty,
    productions = [],
    startSymbol = start
}

-- 添加产生式
addCSGProduction :: ContextSensitiveProduction -> ContextSensitiveGrammar -> ContextSensitiveGrammar
addCSGProduction prod grammar = grammar {
    nonTerminals = Set.insert (nonTerminal prod) $ 
                   foldr (\s acc -> case s of
                       NonTerminal _ -> Set.insert s acc
                       _ -> acc) (nonTerminals grammar) 
                         (leftContext prod ++ rightContext prod ++ replacement prod),
    terminals = foldr (\s acc -> case s of
        Terminal _ -> Set.insert s acc
        _ -> acc) (terminals grammar) 
          (leftContext prod ++ rightContext prod ++ replacement prod),
    productions = prod : productions grammar
}

-- 检查是否为标准形式
isStandardForm :: ContextSensitiveProduction -> Bool
isStandardForm prod = 
    let leftLength = length (leftContext prod) + 1 + length (rightContext prod)
        rightLength = length (leftContext prod) + length (replacement prod) + length (rightContext prod)
    in rightLength >= leftLength

-- 检查文法是否为标准形式
isCSGStandardForm :: ContextSensitiveGrammar -> Bool
isCSGStandardForm grammar = all isStandardForm (productions grammar)

-- 检查产生式是否可以应用
canApply :: ContextSensitiveProduction -> Int -> [Symbol] -> Bool
canApply prod pos symbols = 
    let leftLen = length (leftContext prod)
        rightLen = length (rightContext prod)
    in pos >= leftLen && 
       pos + rightLen < length symbols &&
       checkContext prod pos symbols

-- 检查上下文
checkContext :: ContextSensitiveProduction -> Int -> [Symbol] -> Bool
checkContext prod pos symbols = 
    let leftMatch = all (\(i, expected) -> 
        symbols !! (pos - length (leftContext prod) + i) == expected)
        (zip [0..] (leftContext prod))
        rightMatch = all (\(i, expected) -> 
        symbols !! (pos + 1 + i) == expected)
        (zip [0..] (rightContext prod))
        centerMatch = symbols !! pos == nonTerminal prod
    in leftMatch && centerMatch && rightMatch

-- 应用产生式
applyProduction :: ContextSensitiveProduction -> Int -> [Symbol] -> [Symbol]
applyProduction prod pos symbols = 
    let before = take pos symbols
        after = drop (pos + 1) symbols
    in before ++ replacement prod ++ after

-- 直接推导
directDerivation :: ContextSensitiveGrammar -> [Symbol] -> [Symbol] -> Bool
directDerivation grammar from to = 
    any (\prod -> any (\i -> 
        canApply prod i from && applyProduction prod i from == to)
        [0..length from - 1]) (productions grammar)

-- 推导
derivation :: ContextSensitiveGrammar -> [Symbol] -> [Symbol] -> Bool
derivation grammar from to = 
    if from == to 
    then True
    else derivationBFS grammar [from] (Set.singleton from) to

-- 广度优先搜索推导
derivationBFS :: ContextSensitiveGrammar -> [[Symbol]] -> Set [Symbol] -> [Symbol] -> Bool
derivationBFS grammar [] _ _ = False
derivationBFS grammar (current:queue) visited target = 
    if current == target 
    then True
    else let nextStates = [next | prod <- productions grammar,
                                 i <- [0..length current - 1],
                                 canApply prod i current,
                                 let next = applyProduction prod i current,
                                 not (Set.member next visited)]
             newVisited = foldr Set.insert visited nextStates
         in derivationBFS grammar (queue ++ nextStates) newVisited target

-- 生成语言
generateLanguage :: ContextSensitiveGrammar -> Int -> [String]
generateLanguage grammar maxLength = 
    let initial = [startSymbol grammar]
        allWords = generateWords grammar [initial] Set.empty maxLength
    in nub $ map symbolsToString $ filter (all isTerminal) allWords
  where
    isTerminal (Terminal _) = True
    isTerminal _ = False
    symbolsToString = concatMap symbolToString
    symbolToString (Terminal s) = s
    symbolToString (NonTerminal s) = s

-- 生成所有可能的词
generateWords :: ContextSensitiveGrammar -> [[Symbol]] -> Set [Symbol] -> Int -> [[Symbol]]
generateWords grammar [] _ _ = []
generateWords grammar (current:queue) visited maxLen = 
    if length current > maxLen 
    then generateWords grammar queue visited maxLen
    else if all isTerminal current 
         then current : generateWords grammar queue visited maxLen
         else let nextStates = [next | prod <- productions grammar,
                                      i <- [0..length current - 1],
                                      canApply prod i current,
                                      let next = applyProduction prod i current,
                                      not (Set.member next visited),
                                      length next <= maxLen]
                  newVisited = foldr Set.insert visited nextStates
              in current : generateWords grammar (queue ++ nextStates) newVisited maxLen
  where
    isTerminal (Terminal _) = True
    isTerminal _ = False

-- 线性有界自动机
data LinearBoundedAutomaton = LinearBoundedAutomaton {
    states :: Set String,
    inputAlphabet :: Set Char,
    tapeAlphabet :: Set Char,
    transitions :: Map (String, Char) [(String, Char, Char)], -- (state, read) -> [(new_state, write, move)]
    startState :: String,
    acceptStates :: Set String
} deriving (Show)

-- 创建LBA
createLBA :: LinearBoundedAutomaton
createLBA = LinearBoundedAutomaton {
    states = Set.empty,
    inputAlphabet = Set.empty,
    tapeAlphabet = Set.empty,
    transitions = Map.empty,
    startState = "q0",
    acceptStates = Set.empty
}

-- 添加转移
addTransition :: String -> Char -> String -> Char -> Char -> LinearBoundedAutomaton -> LinearBoundedAutomaton
addTransition state read newState write move lba = 
    let newStates = Set.insert state $ Set.insert newState (states lba)
        newInputAlphabet = Set.insert read (inputAlphabet lba)
        newTapeAlphabet = Set.insert read $ Set.insert write (tapeAlphabet lba)
        newTransitions = Map.insertWith (++) (state, read) [(newState, write, move)] (transitions lba)
    in lba {
        states = newStates,
        inputAlphabet = newInputAlphabet,
        tapeAlphabet = newTapeAlphabet,
        transitions = newTransitions
    }

-- LBA接受检查
accept :: LinearBoundedAutomaton -> String -> Bool
accept lba input = acceptWithConfig lba (startState lba) input 0 0
  where
    acceptWithConfig lba state tape head steps = 
        if steps > 1000 -- 限制步数
        then False
        else if Set.member state (acceptStates lba)
             then True
             else case Map.lookup (state, tape !! head) (transitions lba) of
                      Just transitions -> any (\(newState, write, move) -> 
                          let newTape = take head tape ++ [write] ++ drop (head + 1) tape
                              newHead = case move of
                                  'L' -> max 0 (head - 1)
                                  'R' -> min (length tape - 1) (head + 1)
                                  'S' -> head
                                  _ -> head
                          in acceptWithConfig lba newState newTape newHead (steps + 1)) transitions
                      Nothing -> False

-- 示例文法
exampleCSG :: ContextSensitiveGrammar
exampleCSG = 
    let g = emptyCSG (NonTerminal "S")
        g1 = addCSGProduction (ContextSensitiveProduction [] (NonTerminal "S") [] 
                              [Terminal "a", NonTerminal "S", Terminal "b"]) g
        g2 = addCSGProduction (ContextSensitiveProduction [] (NonTerminal "S") [] 
                              [Terminal "a", Terminal "b"]) g1
    in g2

-- 示例LBA
exampleLBA :: LinearBoundedAutomaton
exampleLBA = 
    let lba = createLBA
        lba1 = addTransition "q0" 'a' "q1" 'a' 'R' lba
        lba2 = addTransition "q1" 'a' "q1" 'a' 'R' lba1
        lba3 = addTransition "q1" 'B' "q2" 'B' 'S' lba2
    in lba3 { acceptStates = Set.singleton "q2" }

-- 测试函数
testCSG :: Bool
testCSG = isCSGStandardForm exampleCSG

testLBA :: Bool
testLBA = accept exampleLBA "aaa"

-- 生成示例语言
exampleLanguage :: [String]
exampleLanguage = generateLanguage exampleCSG 10
```

## 6. 应用示例

### 6.1 $a^n b^n c^n$ 语言

**示例 6.1.1** ($a^n b^n c^n$ CSG)

```latex
S → aSBC | aBC
CB → BC
aB → ab
bB → bb
bC → bc
cC → cc
```

这个CSG生成语言 $\{a^n b^n c^n \mid n \geq 1\}$。

### 6.2 自然语言句法

**示例 6.1.2** (自然语言CSG)

```latex
S → NP VP
NP → Det N
VP → V NP
Det → the | a
N → cat | dog
V → sees | chases
```

这个CSG描述了简单的英语句法结构。

### 6.3 生物序列模式

**示例 6.1.3** (DNA序列CSG)

```latex
S → ATCG
AT → ATC
CG → CGA
```

这个CSG描述了DNA序列的模式匹配规则。

## 7. 相关理论

### 7.1 与自动机的关系

CSG与线性有界自动机（LBA）等价，这是乔姆斯基谱系的重要结果。

### 7.2 与语言层次的关系

CSG定义的语言是上下文有关语言，是乔姆斯基谱系中的1型语言。

### 7.3 与计算复杂性的关系

CSG的解析问题是PSPACE完全的，比CFG更复杂。

## 8. 参考文献

1. Hopcroft, J. E., Motwani, R., & Ullman, J. D. (2006). *Introduction to Automata Theory, Languages, and Computation*. Pearson.
2. Sipser, M. (2012). *Introduction to the Theory of Computation*. Cengage Learning.
3. Chomsky, N. (1959). On certain formal properties of grammars. *Information and Control*, 2(2), 137-167.
4. Kuroda, S. Y. (1964). Classes of languages and linear-bounded automata. *Information and Control*, 7(2), 207-223.
5. Landweber, P. S. (1963). Three theorems on phrase structure grammars of type 1. *Information and Control*, 6(2), 131-136.

---

**相关文档**：

- [03.1.3 线性有界自动机](../03_Formal_Language_Theory/03.1.3_线性有界自动机.md)
- [03.2.2 上下文无关文法](../03_Formal_Language_Theory/03.2.2_上下文无关文法.md)
- [03.2.4 无限制文法](../03_Formal_Language_Theory/03.2.4_无限制文法.md)
- [03.3.1 乔姆斯基谱系](../03_Formal_Language_Theory/03.3.1_乔姆斯基谱系.md)
- [03.4.1 LL解析](../03_Formal_Language_Theory/03.4.1_LL解析.md)
