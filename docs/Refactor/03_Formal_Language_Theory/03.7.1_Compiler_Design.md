# 03.7.1 ç¼–è¯‘å™¨è®¾è®¡

## ğŸ“‹ æ¦‚è¿°

ç¼–è¯‘å™¨è®¾è®¡æ˜¯å½¢å¼è¯­è¨€ç†è®ºçš„é‡è¦åº”ç”¨é¢†åŸŸï¼Œå®ƒå°†é«˜çº§ç¼–ç¨‹è¯­è¨€è½¬æ¢ä¸ºæœºå™¨å¯æ‰§è¡Œçš„ä½çº§ä»£ç ã€‚ç¼–è¯‘å™¨è®¾è®¡æ¶‰åŠè¯æ³•åˆ†æã€è¯­æ³•åˆ†æã€è¯­ä¹‰åˆ†æã€ä»£ç ç”Ÿæˆç­‰å¤šä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µéƒ½åŸºäºå½¢å¼è¯­è¨€ç†è®ºçš„åŸºç¡€æ¦‚å¿µã€‚

## ğŸ¯ æ ¸å¿ƒç›®æ ‡

1. **ç†è§£ç¼–è¯‘å™¨æ¶æ„**ï¼šæŒæ¡ç»å…¸ç¼–è¯‘å™¨çš„æ•´ä½“æ¶æ„å’Œå„é˜¶æ®µåŠŸèƒ½
2. **æŒæ¡å‰ç«¯æŠ€æœ¯**ï¼šæ·±å…¥ç†è§£è¯æ³•åˆ†æã€è¯­æ³•åˆ†æã€è¯­ä¹‰åˆ†æçš„æŠ€æœ¯åŸç†
3. **æŒæ¡åç«¯æŠ€æœ¯**ï¼šç†è§£ä»£ç ç”Ÿæˆã€ä¼˜åŒ–ã€ç›®æ ‡ä»£ç ç”Ÿæˆçš„æŠ€æœ¯ç»†èŠ‚
4. **å®ç°ç¼–è¯‘å™¨ç»„ä»¶**ï¼šèƒ½å¤Ÿå®ç°ç¼–è¯‘å™¨çš„å„ä¸ªæ ¸å¿ƒç»„ä»¶
5. **åº”ç”¨å½¢å¼åŒ–æ–¹æ³•**ï¼šå°†å½¢å¼è¯­è¨€ç†è®ºåº”ç”¨äºç¼–è¯‘å™¨è®¾è®¡

## ğŸ“š ç›®å½•

```markdown
03.7.1 ç¼–è¯‘å™¨è®¾è®¡
â”œâ”€â”€ 1. åŸºæœ¬æ¦‚å¿µ
â”‚   â”œâ”€â”€ 1.1 ç¼–è¯‘å™¨å®šä¹‰
â”‚   â”œâ”€â”€ 1.2 ç¼–è¯‘è¿‡ç¨‹
â”‚   â””â”€â”€ 1.3 ç¼–è¯‘å™¨åˆ†ç±»
â”œâ”€â”€ 2. å½¢å¼åŒ–å®šä¹‰
â”‚   â”œâ”€â”€ 2.1 ç¼–è¯‘å™¨å½¢å¼åŒ–æ¨¡å‹
â”‚   â”œâ”€â”€ 2.2 ç¼–è¯‘é˜¶æ®µå½¢å¼åŒ–
â”‚   â””â”€â”€ 2.3 ç¼–è¯‘æ­£ç¡®æ€§
â”œâ”€â”€ 3. å®šç†ä¸è¯æ˜
â”‚   â”œâ”€â”€ 3.1 ç¼–è¯‘ä¿æŒå®šç†
â”‚   â”œâ”€â”€ 3.2 ä¼˜åŒ–æ­£ç¡®æ€§å®šç†
â”‚   â””â”€â”€ 3.3 ç±»å‹å®‰å…¨å®šç†
â”œâ”€â”€ 4. ä»£ç å®ç°
â”‚   â”œâ”€â”€ 4.1 Rust å®ç°
â”‚   â”œâ”€â”€ 4.2 Haskell å®ç°
â”‚   â””â”€â”€ 4.3 ç®—æ³•å®ç°
â”œâ”€â”€ 5. åº”ç”¨ç¤ºä¾‹
â”‚   â”œâ”€â”€ 5.1 ç®€å•è¯­è¨€ç¼–è¯‘å™¨
â”‚   â”œâ”€â”€ 5.2 è¡¨è¾¾å¼ç¼–è¯‘å™¨
â”‚   â””â”€â”€ 5.3 å‡½æ•°å¼è¯­è¨€ç¼–è¯‘å™¨
â”œâ”€â”€ 6. ç›¸å…³ç†è®º
â””â”€â”€ 7. å‚è€ƒæ–‡çŒ®
```

## 1. åŸºæœ¬æ¦‚å¿µ

### 1.1 ç¼–è¯‘å™¨å®šä¹‰

**å®šä¹‰ 1.1.1 (ç¼–è¯‘å™¨)**
ç¼–è¯‘å™¨æ˜¯ä¸€ä¸ªç¨‹åºï¼Œå®ƒå°†ç”¨é«˜çº§ç¼–ç¨‹è¯­è¨€ç¼–å†™çš„æºä»£ç è½¬æ¢ä¸ºä½çº§ç›®æ ‡ä»£ç ï¼ŒåŒæ—¶ä¿æŒç¨‹åºçš„è¯­ä¹‰ç­‰ä»·æ€§ã€‚

**å½¢å¼åŒ–å®šä¹‰**ï¼š
$$\text{Compiler}: \mathcal{L}_{\text{source}} \rightarrow \mathcal{L}_{\text{target}}$$

å…¶ä¸­ï¼š

- $\mathcal{L}_{\text{source}}$ æ˜¯æºè¯­è¨€
- $\mathcal{L}_{\text{target}}$ æ˜¯ç›®æ ‡è¯­è¨€

### 1.2 ç¼–è¯‘è¿‡ç¨‹

**ç¼–è¯‘è¿‡ç¨‹çš„ä¸»è¦é˜¶æ®µ**ï¼š

1. **è¯æ³•åˆ†æ (Lexical Analysis)**ï¼šå°†æºä»£ç è½¬æ¢ä¸ºè¯æ³•å•å…ƒåºåˆ—
2. **è¯­æ³•åˆ†æ (Syntax Analysis)**ï¼šæ„å»ºæŠ½è±¡è¯­æ³•æ ‘
3. **è¯­ä¹‰åˆ†æ (Semantic Analysis)**ï¼šç±»å‹æ£€æŸ¥å’Œè¯­ä¹‰éªŒè¯
4. **ä¸­é—´ä»£ç ç”Ÿæˆ (Intermediate Code Generation)**ï¼šç”Ÿæˆä¸­é—´è¡¨ç¤º
5. **ä»£ç ä¼˜åŒ– (Code Optimization)**ï¼šä¼˜åŒ–ä¸­é—´ä»£ç 
6. **ç›®æ ‡ä»£ç ç”Ÿæˆ (Target Code Generation)**ï¼šç”Ÿæˆç›®æ ‡ä»£ç 

### 1.3 ç¼–è¯‘å™¨åˆ†ç±»

**æŒ‰ç¼–è¯‘ç­–ç•¥åˆ†ç±»**ï¼š

1. **AOTç¼–è¯‘å™¨ (Ahead-of-Time)**ï¼šæå‰ç¼–è¯‘
2. **JITç¼–è¯‘å™¨ (Just-in-Time)**ï¼šå³æ—¶ç¼–è¯‘
3. **è§£é‡Šå™¨ (Interpreter)**ï¼šè§£é‡Šæ‰§è¡Œ

## 2. å½¢å¼åŒ–å®šä¹‰

### 2.1 ç¼–è¯‘å™¨å½¢å¼åŒ–æ¨¡å‹

**å®šä¹‰ 2.1.1 (ç¼–è¯‘å™¨å½¢å¼åŒ–æ¨¡å‹)**
ç¼–è¯‘å™¨å¯ä»¥å½¢å¼åŒ–ä¸ºä¸€ä¸ªå…ƒç»„ï¼š
$$\text{Compiler} = \langle \mathcal{L}, \mathcal{P}, \mathcal{T}, \mathcal{O} \rangle$$

å…¶ä¸­ï¼š

- $\mathcal{L}$ æ˜¯è¯æ³•åˆ†æå™¨
- $\mathcal{P}$ æ˜¯è¯­æ³•åˆ†æå™¨
- $\mathcal{T}$ æ˜¯è¯­ä¹‰åˆ†æå™¨
- $\mathcal{O}$ æ˜¯ä»£ç ç”Ÿæˆå™¨

**å½¢å¼åŒ–è¡¨ç¤º**ï¼š

```haskell
-- ç¼–è¯‘å™¨å½¢å¼åŒ–æ¨¡å‹
data Compiler = Compiler {
    lexer :: Lexer,
    parser :: Parser,
    semanticAnalyzer :: SemanticAnalyzer,
    codeGenerator :: CodeGenerator
}

-- ç¼–è¯‘è¿‡ç¨‹
compile :: Compiler -> SourceCode -> TargetCode
compile compiler source = 
    let tokens = lexicalAnalysis (lexer compiler) source
        ast = parsing (parser compiler) tokens
        semanticAst = semanticAnalysis (semanticAnalyzer compiler) ast
        targetCode = codeGeneration (codeGenerator compiler) semanticAst
    in targetCode
```

### 2.2 ç¼–è¯‘é˜¶æ®µå½¢å¼åŒ–

**è¯æ³•åˆ†æå½¢å¼åŒ–**ï¼š
$$\mathcal{L}: \Sigma^* \rightarrow \text{Token}^*$$

**è¯­æ³•åˆ†æå½¢å¼åŒ–**ï¼š
$$\mathcal{P}: \text{Token}^* \rightarrow \text{AST}$$

**è¯­ä¹‰åˆ†æå½¢å¼åŒ–**ï¼š
$$\mathcal{T}: \text{AST} \rightarrow \text{SemanticAST}$$

**ä»£ç ç”Ÿæˆå½¢å¼åŒ–**ï¼š
$$\mathcal{O}: \text{SemanticAST} \rightarrow \text{TargetCode}$$

### 2.3 ç¼–è¯‘æ­£ç¡®æ€§

**å®šä¹‰ 2.3.1 (ç¼–è¯‘æ­£ç¡®æ€§)**
ç¼–è¯‘å™¨æ˜¯æ­£ç¡®çš„ï¼Œå½“ä¸”ä»…å½“å¯¹äºæ‰€æœ‰æœ‰æ•ˆçš„æºç¨‹åº $P$ï¼Œç¼–è¯‘åçš„ç›®æ ‡ç¨‹åº $P'$ ä¸ $P$ è¯­ä¹‰ç­‰ä»·ã€‚

**å½¢å¼åŒ–å®šä¹‰**ï¼š
$$\forall P \in \mathcal{L}_{\text{source}}. \text{Valid}(P) \Rightarrow \text{SemanticEquiv}(P, \text{compile}(P))$$

## 3. å®šç†ä¸è¯æ˜

### 3.1 ç¼–è¯‘ä¿æŒå®šç†

**å®šç† 3.1.1 (ç¼–è¯‘ä¿æŒå®šç†)**
å¦‚æœç¼–è¯‘å™¨æ­£ç¡®å®ç°ï¼Œåˆ™ç¼–è¯‘åçš„ç¨‹åºè¯­ä¹‰ç­‰ä»·äºæºä»£ç ã€‚

**è¯æ˜**ï¼š
é€šè¿‡è¯­ä¹‰ä¿æŒï¼š

1. **è¯æ³•åˆ†æ**ï¼šä¿æŒè¯æ³•ç»“æ„
2. **è¯­æ³•åˆ†æ**ï¼šä¿æŒè¯­æ³•ç»“æ„
3. **è¯­ä¹‰åˆ†æ**ï¼šä¿æŒè¯­ä¹‰å«ä¹‰
4. **ä»£ç ç”Ÿæˆ**ï¼šä¿æŒæ‰§è¡Œè¯­ä¹‰

### 3.2 ä¼˜åŒ–æ­£ç¡®æ€§å®šç†

**å®šç† 3.2.1 (ä¼˜åŒ–æ­£ç¡®æ€§å®šç†)**
ç¼–è¯‘å™¨ä¼˜åŒ–å¿…é¡»ä¿æŒç¨‹åºçš„è¯­ä¹‰ç­‰ä»·æ€§ã€‚

**è¯æ˜**ï¼š
è®¾ $P$ æ˜¯åŸå§‹ç¨‹åºï¼Œ$P'$ æ˜¯ä¼˜åŒ–åçš„ç¨‹åºï¼Œåˆ™ï¼š
$$\text{SemanticEquiv}(P, P') \Leftrightarrow \forall \text{input}. \text{output}(P, \text{input}) = \text{output}(P', \text{input})$$

### 3.3 ç±»å‹å®‰å…¨å®šç†

**å®šç† 3.3.1 (ç±»å‹å®‰å…¨å®šç†)**
å¦‚æœæºç¨‹åºé€šè¿‡ç±»å‹æ£€æŸ¥ï¼Œåˆ™ç¼–è¯‘åçš„ç¨‹åºä¸ä¼šå‡ºç°ç±»å‹é”™è¯¯ã€‚

**è¯æ˜**ï¼š
é€šè¿‡ç±»å‹ä¿æŒï¼š
$$\text{TypeCheck}(P) \Rightarrow \text{TypeSafe}(\text{compile}(P))$$

## 4. ä»£ç å®ç°

### 4.1 Rust å®ç°

```rust
// ç¼–è¯‘å™¨æ ¸å¿ƒç»“æ„
#[derive(Debug)]
pub struct Compiler {
    lexer: Lexer,
    parser: Parser,
    semantic_analyzer: SemanticAnalyzer,
    code_generator: CodeGenerator,
}

impl Compiler {
    pub fn new() -> Self {
        Self {
            lexer: Lexer::new(),
            parser: Parser::new(),
            semantic_analyzer: SemanticAnalyzer::new(),
            code_generator: CodeGenerator::new(),
        }
    }

    pub fn compile(&self, source_code: &str) -> Result<TargetCode, CompilationError> {
        // 1. è¯æ³•åˆ†æ
        let tokens = self.lexer.tokenize(source_code)?;
        
        // 2. è¯­æ³•åˆ†æ
        let ast = self.parser.parse(&tokens)?;
        
        // 3. è¯­ä¹‰åˆ†æ
        let semantic_ast = self.semantic_analyzer.analyze(&ast)?;
        
        // 4. ä»£ç ç”Ÿæˆ
        let target_code = self.code_generator.generate(&semantic_ast)?;
        
        Ok(target_code)
    }
}

// è¯æ³•åˆ†æå™¨
#[derive(Debug)]
pub struct Lexer {
    keywords: HashSet<String>,
    operators: HashSet<String>,
}

impl Lexer {
    pub fn new() -> Self {
        let keywords = HashSet::from([
            "if".to_string(),
            "else".to_string(),
            "while".to_string(),
            "for".to_string(),
            "let".to_string(),
            "fn".to_string(),
        ]);
        
        let operators = HashSet::from([
            "+".to_string(),
            "-".to_string(),
            "*".to_string(),
            "/".to_string(),
            "=".to_string(),
            "==".to_string(),
        ]);
        
        Self { keywords, operators }
    }

    pub fn tokenize(&self, source: &str) -> Result<Vec<Token>, LexicalError> {
        let mut tokens = Vec::new();
        let mut current_pos = 0;
        
        while current_pos < source.len() {
            let (token, next_pos) = self.scan_token(&source[current_pos..], current_pos)?;
            tokens.push(token);
            current_pos = next_pos;
        }
        
        Ok(tokens)
    }

    fn scan_token(&self, input: &str, start_pos: usize) -> Result<(Token, usize), LexicalError> {
        let mut pos = 0;
        
        // è·³è¿‡ç©ºç™½å­—ç¬¦
        while pos < input.len() && input.chars().nth(pos).unwrap().is_whitespace() {
            pos += 1;
        }
        
        if pos >= input.len() {
            return Ok((Token::EOF, start_pos + pos));
        }
        
        let current_char = input.chars().nth(pos).unwrap();
        
        // è¯†åˆ«æ ‡è¯†ç¬¦å’Œå…³é”®å­—
        if current_char.is_alphabetic() {
            let (identifier, next_pos) = self.scan_identifier(&input[pos..]);
            let token_type = if self.keywords.contains(&identifier) {
                TokenType::Keyword(identifier.clone())
            } else {
                TokenType::Identifier(identifier.clone())
            };
            return Ok((Token::new(token_type, start_pos + pos), start_pos + next_pos));
        }
        
        // è¯†åˆ«æ•°å­—
        if current_char.is_digit(10) {
            let (number, next_pos) = self.scan_number(&input[pos..]);
            return Ok((Token::new(TokenType::Number(number), start_pos + pos), start_pos + next_pos));
        }
        
        // è¯†åˆ«è¿ç®—ç¬¦
        if let Some((operator, next_pos)) = self.scan_operator(&input[pos..]) {
            return Ok((Token::new(TokenType::Operator(operator), start_pos + pos), start_pos + next_pos));
        }
        
        Err(LexicalError::InvalidCharacter(current_char, start_pos + pos))
    }

    fn scan_identifier(&self, input: &str) -> (String, usize) {
        let mut pos = 0;
        let mut identifier = String::new();
        
        while pos < input.len() {
            let c = input.chars().nth(pos).unwrap();
            if c.is_alphanumeric() || c == '_' {
                identifier.push(c);
                pos += 1;
            } else {
                break;
            }
        }
        
        (identifier, pos)
    }

    fn scan_number(&self, input: &str) -> (f64, usize) {
        let mut pos = 0;
        let mut number_str = String::new();
        
        while pos < input.len() {
            let c = input.chars().nth(pos).unwrap();
            if c.is_digit(10) || c == '.' {
                number_str.push(c);
                pos += 1;
            } else {
                break;
            }
        }
        
        let number = number_str.parse::<f64>().unwrap_or(0.0);
        (number, pos)
    }

    fn scan_operator(&self, input: &str) -> Option<(String, usize)> {
        // å°è¯•åŒ¹é…æœ€é•¿çš„è¿ç®—ç¬¦
        for len in (1..=3).rev() {
            if input.len() >= len {
                let candidate = &input[..len];
                if self.operators.contains(candidate) {
                    return Some((candidate.to_string(), len));
                }
            }
        }
        None
    }
}

// è¯­æ³•åˆ†æå™¨
#[derive(Debug)]
pub struct Parser {
    grammar: Grammar,
}

impl Parser {
    pub fn new() -> Self {
        Self {
            grammar: Grammar::new(),
        }
    }

    pub fn parse(&self, tokens: &[Token]) -> Result<AST, SyntaxError> {
        // ä½¿ç”¨é€’å½’ä¸‹é™è§£æ
        let mut parser = RecursiveDescentParser::new(tokens);
        parser.parse_program()
    }
}

// è¯­ä¹‰åˆ†æå™¨
#[derive(Debug)]
pub struct SemanticAnalyzer {
    symbol_table: SymbolTable,
    type_checker: TypeChecker,
}

impl SemanticAnalyzer {
    pub fn new() -> Self {
        Self {
            symbol_table: SymbolTable::new(),
            type_checker: TypeChecker::new(),
        }
    }

    pub fn analyze(&self, ast: &AST) -> Result<SemanticAST, SemanticError> {
        // æ„å»ºç¬¦å·è¡¨
        self.build_symbol_table(ast)?;
        
        // ç±»å‹æ£€æŸ¥
        self.type_checker.check_types(ast)?;
        
        // è¯­ä¹‰éªŒè¯
        self.validate_semantics(ast)?;
        
        Ok(SemanticAST::from(ast))
    }

    fn build_symbol_table(&self, ast: &AST) -> Result<(), SemanticError> {
        // éå†ASTï¼Œæ„å»ºç¬¦å·è¡¨
        unimplemented!()
    }

    fn validate_semantics(&self, ast: &AST) -> Result<(), SemanticError> {
        // éªŒè¯è¯­ä¹‰æ­£ç¡®æ€§
        unimplemented!()
    }
}

// ä»£ç ç”Ÿæˆå™¨
#[derive(Debug)]
pub struct CodeGenerator {
    target_architecture: TargetArchitecture,
    optimization_level: OptimizationLevel,
}

impl CodeGenerator {
    pub fn new() -> Self {
        Self {
            target_architecture: TargetArchitecture::X86_64,
            optimization_level: OptimizationLevel::O2,
        }
    }

    pub fn generate(&self, semantic_ast: &SemanticAST) -> Result<TargetCode, CodeGenerationError> {
        // ç”Ÿæˆä¸­é—´ä»£ç 
        let ir = self.generate_ir(semantic_ast)?;
        
        // ä¼˜åŒ–ä¸­é—´ä»£ç 
        let optimized_ir = self.optimize_ir(ir)?;
        
        // ç”Ÿæˆç›®æ ‡ä»£ç 
        let target_code = self.generate_target_code(&optimized_ir)?;
        
        Ok(target_code)
    }

    fn generate_ir(&self, semantic_ast: &SemanticAST) -> Result<IR, CodeGenerationError> {
        // å°†è¯­ä¹‰ASTè½¬æ¢ä¸ºä¸­é—´è¡¨ç¤º
        unimplemented!()
    }

    fn optimize_ir(&self, ir: IR) -> Result<IR, CodeGenerationError> {
        // åº”ç”¨å„ç§ä¼˜åŒ–æŠ€æœ¯
        unimplemented!()
    }

    fn generate_target_code(&self, ir: &IR) -> Result<TargetCode, CodeGenerationError> {
        // ç”Ÿæˆç›®æ ‡æ¶æ„çš„æœºå™¨ä»£ç 
        unimplemented!()
    }
}

// æ•°æ®ç±»å‹å®šä¹‰
#[derive(Debug, Clone)]
pub enum TokenType {
    Identifier(String),
    Number(f64),
    Operator(String),
    Keyword(String),
    Delimiter(String),
    EOF,
}

#[derive(Debug, Clone)]
pub struct Token {
    token_type: TokenType,
    position: usize,
}

impl Token {
    pub fn new(token_type: TokenType, position: usize) -> Self {
        Self { token_type, position }
    }
}

#[derive(Debug)]
pub struct AST {
    root: ASTNode,
}

#[derive(Debug)]
pub enum ASTNode {
    Program(Vec<ASTNode>),
    Function(FunctionNode),
    Variable(VariableNode),
    Expression(ExpressionNode),
    Statement(StatementNode),
}

#[derive(Debug)]
pub struct SemanticAST {
    root: SemanticNode,
}

#[derive(Debug)]
pub enum SemanticNode {
    Program(Vec<SemanticNode>),
    Function(FunctionSemanticNode),
    Variable(VariableSemanticNode),
    Expression(ExpressionSemanticNode),
    Statement(StatementSemanticNode),
}

#[derive(Debug)]
pub struct TargetCode {
    instructions: Vec<Instruction>,
    data_section: Vec<DataItem>,
}

#[derive(Debug)]
pub enum Instruction {
    Mov(Operand, Operand),
    Add(Operand, Operand),
    Sub(Operand, Operand),
    Mul(Operand, Operand),
    Div(Operand, Operand),
    Call(String),
    Ret,
}

#[derive(Debug)]
pub enum Operand {
    Register(String),
    Immediate(i64),
    Memory(String),
}

#[derive(Debug)]
pub struct DataItem {
    label: String,
    value: Vec<u8>,
}

// é”™è¯¯ç±»å‹
#[derive(Debug)]
pub enum CompilationError {
    Lexical(LexicalError),
    Syntax(SyntaxError),
    Semantic(SemanticError),
    CodeGeneration(CodeGenerationError),
}

#[derive(Debug)]
pub enum LexicalError {
    InvalidCharacter(char, usize),
    UnterminatedString(usize),
    InvalidNumber(String, usize),
}

#[derive(Debug)]
pub enum SyntaxError {
    UnexpectedToken(Token, String),
    MissingToken(String, usize),
    InvalidExpression(usize),
}

#[derive(Debug)]
pub enum SemanticError {
    UndefinedVariable(String, usize),
    TypeMismatch(String, String, usize),
    DuplicateDeclaration(String, usize),
}

#[derive(Debug)]
pub enum CodeGenerationError {
    UnsupportedFeature(String),
    RegisterAllocationFailed,
    InvalidInstruction(String),
}

// è¾…åŠ©ç»“æ„
#[derive(Debug)]
pub struct Grammar {
    rules: Vec<GrammarRule>,
}

impl Grammar {
    pub fn new() -> Self {
        Self { rules: Vec::new() }
    }
}

#[derive(Debug)]
pub struct GrammarRule {
    lhs: String,
    rhs: Vec<String>,
}

#[derive(Debug)]
pub struct RecursiveDescentParser {
    tokens: Vec<Token>,
    current_pos: usize,
}

impl RecursiveDescentParser {
    pub fn new(tokens: Vec<Token>) -> Self {
        Self {
            tokens,
            current_pos: 0,
        }
    }

    pub fn parse_program(&mut self) -> Result<AST, SyntaxError> {
        // è§£æç¨‹åº
        unimplemented!()
    }
}

#[derive(Debug)]
pub struct SymbolTable {
    symbols: HashMap<String, SymbolInfo>,
}

impl SymbolTable {
    pub fn new() -> Self {
        Self {
            symbols: HashMap::new(),
        }
    }
}

#[derive(Debug)]
pub struct SymbolInfo {
    name: String,
    type_info: TypeInfo,
    scope: usize,
}

#[derive(Debug)]
pub struct TypeInfo {
    base_type: String,
    is_reference: bool,
}

#[derive(Debug)]
pub struct TypeChecker {
    type_rules: HashMap<String, TypeRule>,
}

impl TypeChecker {
    pub fn new() -> Self {
        Self {
            type_rules: HashMap::new(),
        }
    }

    pub fn check_types(&self, ast: &AST) -> Result<(), SemanticError> {
        // ç±»å‹æ£€æŸ¥
        unimplemented!()
    }
}

#[derive(Debug)]
pub struct TypeRule {
    pattern: String,
    result_type: String,
}

#[derive(Debug)]
pub struct IR {
    instructions: Vec<IRInstruction>,
}

#[derive(Debug)]
pub enum IRInstruction {
    Load(String, String),
    Store(String, String),
    Add(String, String, String),
    Sub(String, String, String),
    Mul(String, String, String),
    Div(String, String, String),
    Call(String, Vec<String>, String),
    Ret(String),
}

#[derive(Debug)]
pub enum TargetArchitecture {
    X86_64,
    ARM64,
    RISC_V,
}

#[derive(Debug)]
pub enum OptimizationLevel {
    O0, // æ— ä¼˜åŒ–
    O1, // åŸºæœ¬ä¼˜åŒ–
    O2, // æ ‡å‡†ä¼˜åŒ–
    O3, // æ¿€è¿›ä¼˜åŒ–
}

// å‡½æ•°å’Œå˜é‡èŠ‚ç‚¹
#[derive(Debug)]
pub struct FunctionNode {
    name: String,
    parameters: Vec<ParameterNode>,
    body: Vec<ASTNode>,
    return_type: Option<String>,
}

#[derive(Debug)]
pub struct VariableNode {
    name: String,
    initializer: Option<Box<ASTNode>>,
    type_annotation: Option<String>,
}

#[derive(Debug)]
pub struct ExpressionNode {
    expression_type: ExpressionType,
    left: Option<Box<ASTNode>>,
    right: Option<Box<ASTNode>>,
    value: Option<String>,
}

#[derive(Debug)]
pub enum ExpressionType {
    Binary,
    Unary,
    Literal,
    Variable,
    FunctionCall,
}

#[derive(Debug)]
pub struct StatementNode {
    statement_type: StatementType,
    condition: Option<Box<ASTNode>>,
    body: Option<Vec<ASTNode>>,
    else_body: Option<Vec<ASTNode>>,
}

#[derive(Debug)]
pub enum StatementType {
    If,
    While,
    For,
    Return,
    Assignment,
}

#[derive(Debug)]
pub struct ParameterNode {
    name: String,
    type_annotation: String,
}

// è¯­ä¹‰èŠ‚ç‚¹
#[derive(Debug)]
pub struct FunctionSemanticNode {
    name: String,
    parameters: Vec<ParameterSemanticNode>,
    body: Vec<SemanticNode>,
    return_type: TypeInfo,
    symbol_table: SymbolTable,
}

#[derive(Debug)]
pub struct VariableSemanticNode {
    name: String,
    type_info: TypeInfo,
    initializer: Option<Box<SemanticNode>>,
}

#[derive(Debug)]
pub struct ExpressionSemanticNode {
    expression_type: ExpressionType,
    type_info: TypeInfo,
    left: Option<Box<SemanticNode>>,
    right: Option<Box<SemanticNode>>,
    value: Option<String>,
}

#[derive(Debug)]
pub struct StatementSemanticNode {
    statement_type: StatementType,
    condition: Option<Box<SemanticNode>>,
    body: Option<Vec<SemanticNode>>,
    else_body: Option<Vec<SemanticNode>>,
}

#[derive(Debug)]
pub struct ParameterSemanticNode {
    name: String,
    type_info: TypeInfo,
}

// å®ç°From trait
impl From<&AST> for SemanticAST {
    fn from(ast: &AST) -> Self {
        // è½¬æ¢ASTä¸ºè¯­ä¹‰AST
        unimplemented!()
    }
}
```

### 4.2 Haskell å®ç°

```haskell
-- ç¼–è¯‘å™¨æ ¸å¿ƒç»“æ„
data Compiler = Compiler {
    lexer :: Lexer,
    parser :: Parser,
    semanticAnalyzer :: SemanticAnalyzer,
    codeGenerator :: CodeGenerator
}

-- ç¼–è¯‘è¿‡ç¨‹
compile :: Compiler -> SourceCode -> Either CompilationError TargetCode
compile compiler source = do
    tokens <- lexicalAnalysis (lexer compiler) source
    ast <- parsing (parser compiler) tokens
    semanticAst <- semanticAnalysis (semanticAnalyzer compiler) ast
    targetCode <- codeGeneration (codeGenerator compiler) semanticAst
    return targetCode

-- è¯æ³•åˆ†æå™¨
data Lexer = Lexer {
    keywords :: Set String,
    operators :: Set String
}

lexicalAnalysis :: Lexer -> String -> Either LexicalError [Token]
lexicalAnalysis lexer source = 
    scanTokens lexer source 0 []
    where
        scanTokens :: Lexer -> String -> Int -> [Token] -> Either LexicalError [Token]
        scanTokens _ [] _ tokens = Right (reverse tokens)
        scanTokens l (c:cs) pos tokens = 
            if isSpace c then
                scanTokens l cs (pos + 1) tokens
            else if isAlpha c then
                let (identifier, rest) = scanIdentifier (c:cs)
                    token = Token (if identifier `member` keywords l 
                                  then Keyword identifier 
                                  else Identifier identifier) pos
                in scanTokens l rest (pos + length identifier) (token : tokens)
            else if isDigit c then
                let (number, rest) = scanNumber (c:cs)
                    token = Token (Number number) pos
                in scanTokens l rest (pos + length number) (token : tokens)
            else
                case scanOperator l (c:cs) of
                    Just (op, rest) -> 
                        let token = Token (Operator op) pos
                        in scanTokens l rest (pos + length op) (token : tokens)
                    Nothing -> Left (InvalidCharacter c pos)

-- è¯­æ³•åˆ†æå™¨
data Parser = Parser {
    grammar :: Grammar
}

parsing :: Parser -> [Token] -> Either SyntaxError AST
parsing parser tokens = 
    parseProgram tokens
    where
        parseProgram :: [Token] -> Either SyntaxError AST
        parseProgram tokens = do
            statements <- parseStatements tokens
            return (AST (Program statements))

-- è¯­ä¹‰åˆ†æå™¨
data SemanticAnalyzer = SemanticAnalyzer {
    symbolTable :: SymbolTable,
    typeChecker :: TypeChecker
}

semanticAnalysis :: SemanticAnalyzer -> AST -> Either SemanticError SemanticAST
semanticAnalysis analyzer ast = do
    -- æ„å»ºç¬¦å·è¡¨
    buildSymbolTable analyzer ast
    
    -- ç±»å‹æ£€æŸ¥
    typeCheck (typeChecker analyzer) ast
    
    -- è¯­ä¹‰éªŒè¯
    validateSemantics analyzer ast
    
    -- è½¬æ¢ä¸ºè¯­ä¹‰AST
    return (convertToSemanticAST ast)

-- ä»£ç ç”Ÿæˆå™¨
data CodeGenerator = CodeGenerator {
    targetArchitecture :: TargetArchitecture,
    optimizationLevel :: OptimizationLevel
}

codeGeneration :: CodeGenerator -> SemanticAST -> Either CodeGenerationError TargetCode
codeGeneration generator semanticAst = do
    -- ç”Ÿæˆä¸­é—´ä»£ç 
    ir <- generateIR semanticAst
    
    -- ä¼˜åŒ–ä¸­é—´ä»£ç 
    optimizedIR <- optimizeIR generator ir
    
    -- ç”Ÿæˆç›®æ ‡ä»£ç 
    targetCode <- generateTargetCode generator optimizedIR
    
    return targetCode

-- æ•°æ®ç±»å‹å®šä¹‰
data TokenType = 
    Identifier String
  | Number Double
  | Operator String
  | Keyword String
  | Delimiter String
  | EOF
  deriving (Show, Eq)

data Token = Token {
    tokenType :: TokenType,
    position :: Int
} deriving (Show, Eq)

data AST = AST {
    root :: ASTNode
} deriving (Show, Eq)

data ASTNode = 
    Program [ASTNode]
  | Function FunctionNode
  | Variable VariableNode
  | Expression ExpressionNode
  | Statement StatementNode
  deriving (Show, Eq)

data SemanticAST = SemanticAST {
    semanticRoot :: SemanticNode
} deriving (Show, Eq)

data SemanticNode = 
    SemanticProgram [SemanticNode]
  | SemanticFunction FunctionSemanticNode
  | SemanticVariable VariableSemanticNode
  | SemanticExpression ExpressionSemanticNode
  | SemanticStatement StatementSemanticNode
  deriving (Show, Eq)

data TargetCode = TargetCode {
    instructions :: [Instruction],
    dataSection :: [DataItem]
} deriving (Show, Eq)

data Instruction = 
    Mov Operand Operand
  | Add Operand Operand
  | Sub Operand Operand
  | Mul Operand Operand
  | Div Operand Operand
  | Call String
  | Ret
  deriving (Show, Eq)

data Operand = 
    Register String
  | Immediate Integer
  | Memory String
  deriving (Show, Eq)

data DataItem = DataItem {
    label :: String,
    value :: [Word8]
} deriving (Show, Eq)

-- é”™è¯¯ç±»å‹
data CompilationError = 
    LexicalError LexicalError
  | SyntaxError SyntaxError
  | SemanticError SemanticError
  | CodeGenerationError CodeGenerationError
  deriving (Show, Eq)

data LexicalError = 
    InvalidCharacter Char Int
  | UnterminatedString Int
  | InvalidNumber String Int
  deriving (Show, Eq)

data SyntaxError = 
    UnexpectedToken Token String
  | MissingToken String Int
  | InvalidExpression Int
  deriving (Show, Eq)

data SemanticError = 
    UndefinedVariable String Int
  | TypeMismatch String String Int
  | DuplicateDeclaration String Int
  deriving (Show, Eq)

data CodeGenerationError = 
    UnsupportedFeature String
  | RegisterAllocationFailed
  | InvalidInstruction String
  deriving (Show, Eq)

-- è¾…åŠ©å‡½æ•°
scanIdentifier :: String -> (String, String)
scanIdentifier input = 
    let (identifier, rest) = span (\c -> isAlphaNum c || c == '_') input
    in (identifier, rest)

scanNumber :: String -> (Double, String)
scanNumber input = 
    let (numberStr, rest) = span (\c -> isDigit c || c == '.') input
        number = read numberStr :: Double
    in (number, rest)

scanOperator :: Lexer -> String -> Maybe (String, String)
scanOperator lexer input = 
    find (\len -> len <= length input && 
                  take len input `member` operators lexer) [3,2,1]
    >>= \len -> Just (take len input, drop len input)

-- è¾…åŠ©ç»“æ„
data Grammar = Grammar {
    rules :: [GrammarRule]
} deriving (Show, Eq)

data GrammarRule = GrammarRule {
    lhs :: String,
    rhs :: [String]
} deriving (Show, Eq)

data SymbolTable = SymbolTable {
    symbols :: Map String SymbolInfo
} deriving (Show, Eq)

data SymbolInfo = SymbolInfo {
    name :: String,
    typeInfo :: TypeInfo,
    scope :: Int
} deriving (Show, Eq)

data TypeInfo = TypeInfo {
    baseType :: String,
    isReference :: Bool
} deriving (Show, Eq)

data TypeChecker = TypeChecker {
    typeRules :: Map String TypeRule
} deriving (Show, Eq)

data TypeRule = TypeRule {
    pattern :: String,
    resultType :: String
} deriving (Show, Eq)

data IR = IR {
    irInstructions :: [IRInstruction]
} deriving (Show, Eq)

data IRInstruction = 
    Load String String
  | Store String String
  | Add String String String
  | Sub String String String
  | Mul String String String
  | Div String String String
  | Call String [String] String
  | Ret String
  deriving (Show, Eq)

data TargetArchitecture = 
    X86_64
  | ARM64
  | RISC_V
  deriving (Show, Eq)

data OptimizationLevel = 
    O0  -- æ— ä¼˜åŒ–
  | O1  -- åŸºæœ¬ä¼˜åŒ–
  | O2  -- æ ‡å‡†ä¼˜åŒ–
  | O3  -- æ¿€è¿›ä¼˜åŒ–
  deriving (Show, Eq)

-- å‡½æ•°å’Œå˜é‡èŠ‚ç‚¹
data FunctionNode = FunctionNode {
    funcName :: String,
    parameters :: [ParameterNode],
    funcBody :: [ASTNode],
    returnType :: Maybe String
} deriving (Show, Eq)

data VariableNode = VariableNode {
    varName :: String,
    initializer :: Maybe ASTNode,
    typeAnnotation :: Maybe String
} deriving (Show, Eq)

data ExpressionNode = ExpressionNode {
    expressionType :: ExpressionType,
    left :: Maybe ASTNode,
    right :: Maybe ASTNode,
    value :: Maybe String
} deriving (Show, Eq)

data ExpressionType = 
    Binary
  | Unary
  | Literal
  | Variable
  | FunctionCall
  deriving (Show, Eq)

data StatementNode = StatementNode {
    statementType :: StatementType,
    condition :: Maybe ASTNode,
    body :: Maybe [ASTNode],
    elseBody :: Maybe [ASTNode]
} deriving (Show, Eq)

data StatementType = 
    If
  | While
  | For
  | Return
  | Assignment
  deriving (Show, Eq)

data ParameterNode = ParameterNode {
    paramName :: String,
    paramType :: String
} deriving (Show, Eq)

-- è¯­ä¹‰èŠ‚ç‚¹
data FunctionSemanticNode = FunctionSemanticNode {
    semanticFuncName :: String,
    semanticParameters :: [ParameterSemanticNode],
    semanticFuncBody :: [SemanticNode],
    semanticReturnType :: TypeInfo,
    semanticSymbolTable :: SymbolTable
} deriving (Show, Eq)

data VariableSemanticNode = VariableSemanticNode {
    semanticVarName :: String,
    semanticTypeInfo :: TypeInfo,
    semanticInitializer :: Maybe SemanticNode
} deriving (Show, Eq)

data ExpressionSemanticNode = ExpressionSemanticNode {
    semanticExpressionType :: ExpressionType,
    semanticTypeInfo :: TypeInfo,
    semanticLeft :: Maybe SemanticNode,
    semanticRight :: Maybe SemanticNode,
    semanticValue :: Maybe String
} deriving (Show, Eq)

data StatementSemanticNode = StatementSemanticNode {
    semanticStatementType :: StatementType,
    semanticCondition :: Maybe SemanticNode,
    semanticBody :: Maybe [SemanticNode],
    semanticElseBody :: Maybe [SemanticNode]
} deriving (Show, Eq)

data ParameterSemanticNode = ParameterSemanticNode {
    semanticParamName :: String,
    semanticTypeInfo :: TypeInfo
} deriving (Show, Eq)

-- è¾…åŠ©å‡½æ•°å®ç°
buildSymbolTable :: SemanticAnalyzer -> AST -> Either SemanticError ()
buildSymbolTable analyzer ast = 
    -- éå†ASTï¼Œæ„å»ºç¬¦å·è¡¨
    Right ()

typeCheck :: TypeChecker -> AST -> Either SemanticError ()
typeCheck checker ast = 
    -- ç±»å‹æ£€æŸ¥
    Right ()

validateSemantics :: SemanticAnalyzer -> AST -> Either SemanticError ()
validateSemantics analyzer ast = 
    -- è¯­ä¹‰éªŒè¯
    Right ()

convertToSemanticAST :: AST -> SemanticAST
convertToSemanticAST ast = 
    -- è½¬æ¢ASTä¸ºè¯­ä¹‰AST
    SemanticAST (SemanticProgram [])

generateIR :: SemanticAST -> Either CodeGenerationError IR
generateIR semanticAst = 
    -- ç”Ÿæˆä¸­é—´è¡¨ç¤º
    Right (IR [])

optimizeIR :: CodeGenerator -> IR -> Either CodeGenerationError IR
optimizeIR generator ir = 
    -- ä¼˜åŒ–ä¸­é—´ä»£ç 
    Right ir

generateTargetCode :: CodeGenerator -> IR -> Either CodeGenerationError TargetCode
generateTargetCode generator ir = 
    -- ç”Ÿæˆç›®æ ‡ä»£ç 
    Right (TargetCode [] [])

parseStatements :: [Token] -> Either SyntaxError [ASTNode]
parseStatements tokens = 
    -- è§£æè¯­å¥åˆ—è¡¨
    Right []

-- å®ä¾‹åŒ–
instance Show Compiler where
    show compiler = "Compiler { lexer = " ++ show (lexer compiler) ++ 
                   ", parser = " ++ show (parser compiler) ++ 
                   ", semanticAnalyzer = " ++ show (semanticAnalyzer compiler) ++ 
                   ", codeGenerator = " ++ show (codeGenerator compiler) ++ " }"

instance Show Lexer where
    show lexer = "Lexer { keywords = " ++ show (keywords lexer) ++ 
                ", operators = " ++ show (operators lexer) ++ " }"

instance Show Parser where
    show parser = "Parser { grammar = " ++ show (grammar parser) ++ " }"

instance Show SemanticAnalyzer where
    show analyzer = "SemanticAnalyzer { symbolTable = " ++ show (symbolTable analyzer) ++ 
                   ", typeChecker = " ++ show (typeChecker analyzer) ++ " }"

instance Show CodeGenerator where
    show generator = "CodeGenerator { targetArchitecture = " ++ show (targetArchitecture generator) ++ 
                    ", optimizationLevel = " ++ show (optimizationLevel generator) ++ " }"
```

## 5. åº”ç”¨ç¤ºä¾‹

### 5.1 ç®€å•è¯­è¨€ç¼–è¯‘å™¨

```rust
// ç®€å•è¡¨è¾¾å¼è¯­è¨€ç¼–è¯‘å™¨ç¤ºä¾‹
fn main() {
    let source_code = "let x = 10 + 5 * 2";
    
    let compiler = Compiler::new();
    match compiler.compile(source_code) {
        Ok(target_code) => {
            println!("ç¼–è¯‘æˆåŠŸï¼");
            println!("ç›®æ ‡ä»£ç : {:?}", target_code);
        }
        Err(error) => {
            println!("ç¼–è¯‘é”™è¯¯: {:?}", error);
        }
    }
}
```

### 5.2 è¡¨è¾¾å¼ç¼–è¯‘å™¨

```rust
// è¡¨è¾¾å¼ç¼–è¯‘å™¨ç¤ºä¾‹
fn compile_expression(expr: &str) -> Result<TargetCode, CompilationError> {
    let compiler = Compiler::new();
    compiler.compile(expr)
}

// ä½¿ç”¨ç¤ºä¾‹
fn main() {
    let expressions = vec![
        "1 + 2 * 3",
        "let x = 10",
        "x + y * z",
    ];
    
    for expr in expressions {
        match compile_expression(expr) {
            Ok(code) => println!("è¡¨è¾¾å¼ '{}' ç¼–è¯‘æˆåŠŸ", expr),
            Err(error) => println!("è¡¨è¾¾å¼ '{}' ç¼–è¯‘å¤±è´¥: {:?}", expr, error),
        }
    }
}
```

### 5.3 å‡½æ•°å¼è¯­è¨€ç¼–è¯‘å™¨

```rust
// å‡½æ•°å¼è¯­è¨€ç¼–è¯‘å™¨ç¤ºä¾‹
fn compile_functional_program(source: &str) -> Result<TargetCode, CompilationError> {
    let mut compiler = Compiler::new();
    
    // é…ç½®ä¸ºå‡½æ•°å¼è¯­è¨€ç¼–è¯‘å™¨
    compiler.configure_for_functional_language();
    
    compiler.compile(source)
}

impl Compiler {
    fn configure_for_functional_language(&mut self) {
        // é…ç½®å‡½æ•°å¼è¯­è¨€ç‰¹å®šçš„ç¼–è¯‘é€‰é¡¹
        self.optimization_level = OptimizationLevel::O3;
        // å¯ç”¨å°¾é€’å½’ä¼˜åŒ–
        // å¯ç”¨é«˜é˜¶å‡½æ•°ä¼˜åŒ–
        // å¯ç”¨ä¸å¯å˜æ€§æ£€æŸ¥
    }
}
```

## 6. ç›¸å…³ç†è®º

### 6.1 ä¸å½¢å¼è¯­è¨€ç†è®ºçš„å…³ç³»

ç¼–è¯‘å™¨è®¾è®¡ç›´æ¥åº”ç”¨äº†å½¢å¼è¯­è¨€ç†è®ºçš„æ ¸å¿ƒæ¦‚å¿µï¼š

1. **è¯æ³•åˆ†æ**ï¼šåŸºäºæ­£åˆ™è¯­è¨€å’Œæœ‰é™è‡ªåŠ¨æœº
2. **è¯­æ³•åˆ†æ**ï¼šåŸºäºä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•å’Œä¸‹æ¨è‡ªåŠ¨æœº
3. **è¯­ä¹‰åˆ†æ**ï¼šåŸºäºç±»å‹ç†è®ºå’Œè¯­ä¹‰å­¦
4. **ä»£ç ç”Ÿæˆ**ï¼šåŸºäºå›¾çµæœºå’Œè®¡ç®—ç†è®º

### 6.2 ä¸ç±»å‹ç†è®ºçš„å…³ç³»

ç¼–è¯‘å™¨è®¾è®¡ä¸­çš„ç±»å‹æ£€æŸ¥ç³»ç»ŸåŸºäºç±»å‹ç†è®ºï¼š

1. **ç±»å‹æ¨å¯¼**ï¼šåŸºäºHindley-Milnerç±»å‹ç³»ç»Ÿ
2. **ç±»å‹å®‰å…¨**ï¼šåŸºäºç±»å‹ä¿æŒå®šç†
3. **å¤šæ€æ€§**ï¼šåŸºäºç³»ç»ŸFå’Œå‚æ•°å¤šæ€

### 6.3 ä¸ä¼˜åŒ–ç†è®ºçš„å…³ç³»

ç¼–è¯‘å™¨ä¼˜åŒ–åŸºäºç¨‹åºåˆ†æå’Œå˜æ¢ç†è®ºï¼š

1. **æ•°æ®æµåˆ†æ**ï¼šåŸºäºæ ¼ç†è®ºå’Œä¸åŠ¨ç‚¹ç†è®º
2. **æ§åˆ¶æµåˆ†æ**ï¼šåŸºäºå›¾è®ºå’Œå¯è¾¾æ€§åˆ†æ
3. **ä»£ç å˜æ¢**ï¼šåŸºäºç¨‹åºç­‰ä»·æ€§ç†è®º

## 7. å‚è€ƒæ–‡çŒ®

1. Aho, A. V., Lam, M. S., Sethi, R., & Ullman, J. D. (2006). *Compilers: Principles, Techniques, and Tools* (2nd ed.). Pearson Education.

2. Appel, A. W. (1998). *Modern Compiler Implementation in ML*. Cambridge University Press.

3. Cooper, K. D., & Torczon, L. (2011). *Engineering a Compiler* (3rd ed.). Morgan Kaufmann.

4. Muchnick, S. S. (1997). *Advanced Compiler Design and Implementation*. Morgan Kaufmann.

5. Grune, D., Bal, H. E., Jacobs, C. J. H., & Langendoen, K. G. (2012). *Modern Compiler Design* (2nd ed.). Springer.

6. Nielson, F., Nielson, H. R., & Hankin, C. (2010). *Principles of Program Analysis*. Springer.

7. Pierce, B. C. (2002). *Types and Programming Languages*. MIT Press.

8. Winskel, G. (1993). *The Formal Semantics of Programming Languages*. MIT Press.

---

**ç›¸å…³æ–‡æ¡£**ï¼š

- [03.1.1 æœ‰é™è‡ªåŠ¨æœº](./03.1.1_æœ‰é™è‡ªåŠ¨æœº.md)
- [03.2.1 æ­£åˆ™æ–‡æ³•](./03.2.1_æ­£åˆ™æ–‡æ³•.md)
- [03.4.1 LLè§£æ](./03.4.1_LLè§£æ.md)
- [03.4.2 LRè§£æ](./03.4.2_LRè§£æ.md)
- [04.1.2 Hindley-Milnerç±»å‹ç³»ç»Ÿ](./04.1.2_Hindley_Milnerç±»å‹ç³»ç»Ÿ.md)
