# 06.2.4 åˆ†å¸ƒå¼å­˜å‚¨ç†è®º

## ğŸ“‹ æ¦‚è¿°

åˆ†å¸ƒå¼å­˜å‚¨ç†è®ºç ”ç©¶åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­å¦‚ä½•è®¾è®¡ã€å®ç°å’Œç®¡ç†å­˜å‚¨ç³»ç»Ÿï¼Œç¡®ä¿æ•°æ®çš„ä¸€è‡´æ€§ã€å¯ç”¨æ€§å’Œåˆ†åŒºå®¹é”™æ€§ã€‚æœ¬ç†è®ºä¸ºåˆ†å¸ƒå¼æ•°æ®åº“ã€æ–‡ä»¶ç³»ç»Ÿå’Œå¯¹è±¡å­˜å‚¨æä¾›ç†è®ºåŸºç¡€ã€‚

## ğŸ¯ æ ¸å¿ƒç›®æ ‡

1. **å½¢å¼åŒ–å®šä¹‰åˆ†å¸ƒå¼å­˜å‚¨æ¨¡å‹**
2. **å»ºç«‹CAPå®šç†çš„æ•°å­¦åŸºç¡€**
3. **è®¾è®¡åˆ†å¸ƒå¼å­˜å‚¨ç®—æ³•**
4. **åˆ†æå­˜å‚¨ä¸€è‡´æ€§é—®é¢˜**
5. **æä¾›å¯è¯æ˜æ­£ç¡®çš„å­˜å‚¨åè®®**

## ğŸ“š ç›®å½•

1. [åŸºæœ¬æ¦‚å¿µ](#1-åŸºæœ¬æ¦‚å¿µ)
2. [å½¢å¼åŒ–å®šä¹‰](#2-å½¢å¼åŒ–å®šä¹‰)
3. [å®šç†ä¸è¯æ˜](#3-å®šç†ä¸è¯æ˜)
4. [ä»£ç å®ç°](#4-ä»£ç å®ç°)
5. [åº”ç”¨ç¤ºä¾‹](#5-åº”ç”¨ç¤ºä¾‹)
6. [ç›¸å…³ç†è®º](#6-ç›¸å…³ç†è®º)
7. [å‚è€ƒæ–‡çŒ®](#7-å‚è€ƒæ–‡çŒ®)

## 1. åŸºæœ¬æ¦‚å¿µ

### 1.1 åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿ

**å®šä¹‰ 1.1.1** (åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿ)
åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿæ˜¯ä¸€ä¸ªäº”å…ƒç»„ $(N, D, R, S, C)$ï¼Œå…¶ä¸­ï¼š

- $N$: èŠ‚ç‚¹é›†åˆ
- $D$: æ•°æ®é›†åˆ
- $R$: å¤åˆ¶ç­–ç•¥
- $S$: å­˜å‚¨åè®®
- $C$: ä¸€è‡´æ€§çº¦æŸ

### 1.2 CAPå®šç†

**å®šä¹‰ 1.2.1** (CAPå±æ€§)
åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿå…·æœ‰ä¸‰ä¸ªåŸºæœ¬å±æ€§ï¼š

- **ä¸€è‡´æ€§ (Consistency)**: æ‰€æœ‰èŠ‚ç‚¹çœ‹åˆ°ç›¸åŒçš„æ•°æ®
- **å¯ç”¨æ€§ (Availability)**: æ¯ä¸ªè¯·æ±‚éƒ½èƒ½å¾—åˆ°å“åº”
- **åˆ†åŒºå®¹é”™æ€§ (Partition Tolerance)**: ç½‘ç»œåˆ†åŒºæ—¶ç³»ç»Ÿä»èƒ½å·¥ä½œ

**å®šç† 1.2.1** (CAPå®šç†)
åœ¨å¼‚æ­¥ç½‘ç»œæ¨¡å‹ä¸­ï¼Œåˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿæœ€å¤šåªèƒ½åŒæ—¶æ»¡è¶³CAPä¸­çš„ä¸¤ä¸ªå±æ€§ã€‚

### 1.3 å­˜å‚¨ä¸€è‡´æ€§æ¨¡å‹

**å®šä¹‰ 1.3.1** (å¼ºä¸€è‡´æ€§)
å¼ºä¸€è‡´æ€§è¦æ±‚æ‰€æœ‰æ“ä½œéƒ½æŒ‰ç…§å…¨å±€é¡ºåºæ‰§è¡Œï¼š
$$\forall op_1, op_2: op_1 \prec op_2 \Rightarrow op_1 \prec_{global} op_2$$

**å®šä¹‰ 1.3.2** (æœ€ç»ˆä¸€è‡´æ€§)
æœ€ç»ˆä¸€è‡´æ€§å…è®¸ä¸´æ—¶ä¸ä¸€è‡´ï¼Œä½†æœ€ç»ˆä¼šæ”¶æ•›ï¼š
$$\lim_{t \to \infty} \forall n_1, n_2: data(n_1, t) = data(n_2, t)$$

## 2. å½¢å¼åŒ–å®šä¹‰

### 2.1 åˆ†å¸ƒå¼å­˜å‚¨æ¨¡å‹

**å®šä¹‰ 2.1.1** (å­˜å‚¨èŠ‚ç‚¹)
å­˜å‚¨èŠ‚ç‚¹æ˜¯ä¸€ä¸ªå››å…ƒç»„ $(id, state, data, protocol)$ï¼Œå…¶ä¸­ï¼š

- $id$: èŠ‚ç‚¹æ ‡è¯†ç¬¦
- $state$: èŠ‚ç‚¹çŠ¶æ€
- $data$: æœ¬åœ°æ•°æ®
- $protocol$: å­˜å‚¨åè®®

**å®šä¹‰ 2.1.2** (æ•°æ®å¤åˆ¶)
æ•°æ®å¤åˆ¶æ˜¯ä¸€ä¸ªä¸‰å…ƒç»„ $(key, value, replicas)$ï¼Œå…¶ä¸­ï¼š

- $key$: æ•°æ®é”®
- $value$: æ•°æ®å€¼
- $replicas$: å‰¯æœ¬èŠ‚ç‚¹é›†åˆ

### 2.2 ä¸€è‡´æ€§åè®®

**å®šä¹‰ 2.2.1** (Paxosåè®®)
Paxosåè®®æ˜¯ä¸€ä¸ªçŠ¶æ€æœºï¼ŒåŒ…å«ä»¥ä¸‹è§’è‰²ï¼š

1. **Proposer**: æè®®è€…ï¼Œå‘èµ·æè®®
2. **Acceptor**: æ¥å—è€…ï¼Œæ¥å—æè®®
3. **Learner**: å­¦ä¹ è€…ï¼Œå­¦ä¹ æœ€ç»ˆå€¼

**å®šä¹‰ 2.2.2** (Raftåè®®)
Raftåè®®æ˜¯ä¸€ä¸ªé¢†å¯¼è€…é€‰ä¸¾å’Œæ—¥å¿—å¤åˆ¶åè®®ï¼š

1. **é¢†å¯¼è€…é€‰ä¸¾**: é€‰ä¸¾é¢†å¯¼è€…
2. **æ—¥å¿—å¤åˆ¶**: å¤åˆ¶æ—¥å¿—æ¡ç›®
3. **å®‰å…¨æ€§**: ä¿è¯å®‰å…¨æ€§

### 2.3 å­˜å‚¨æ“ä½œè¯­ä¹‰

**å®šä¹‰ 2.3.1** (å­˜å‚¨æ“ä½œ)
å­˜å‚¨æ“ä½œæ˜¯ä¸€ä¸ªå››å…ƒç»„ $(op, key, value, timestamp)$ï¼Œå…¶ä¸­ï¼š

- $op \in \{read, write, delete\}$
- $key$: æ“ä½œé”®
- $value$: æ“ä½œå€¼
- $timestamp$: æ—¶é—´æˆ³

**å®šä¹‰ 2.3.2** (æ“ä½œåºåˆ—)
æ“ä½œåºåˆ—æ˜¯ä¸€ä¸ªæœ‰åºçš„æ“ä½œåˆ—è¡¨ï¼š
$$\sigma = [op_1, op_2, ..., op_n]$$

## 3. å®šç†ä¸è¯æ˜

### 3.1 CAPå®šç†è¯æ˜

**å®šç† 3.1.1** (CAPå®šç†)
åœ¨å¼‚æ­¥ç½‘ç»œæ¨¡å‹ä¸­ï¼Œåˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿæœ€å¤šåªèƒ½åŒæ—¶æ»¡è¶³CAPä¸­çš„ä¸¤ä¸ªå±æ€§ã€‚

**è¯æ˜**:
å‡è®¾å­˜åœ¨ä¸€ä¸ªåŒæ—¶æ»¡è¶³CAPä¸‰ä¸ªå±æ€§çš„ç³»ç»Ÿã€‚

1. **ç½‘ç»œåˆ†åŒº**: è€ƒè™‘ç½‘ç»œåˆ†ä¸ºä¸¤ä¸ªåˆ†åŒº $P_1$ å’Œ $P_2$
2. **å†™æ“ä½œ**: å®¢æˆ·ç«¯å‘ $P_1$ å‘é€å†™æ“ä½œ
3. **è¯»æ“ä½œ**: å®¢æˆ·ç«¯å‘ $P_2$ å‘é€è¯»æ“ä½œ

æ ¹æ®ä¸€è‡´æ€§è¦æ±‚ï¼Œ$P_2$ å¿…é¡»è¿”å›æœ€æ–°å€¼ã€‚
æ ¹æ®å¯ç”¨æ€§è¦æ±‚ï¼Œ$P_2$ å¿…é¡»ç«‹å³å“åº”ã€‚
ä½†ç”±äºç½‘ç»œåˆ†åŒºï¼Œ$P_2$ æ— æ³•è·å¾— $P_1$ çš„æœ€æ–°å€¼ã€‚

è¿™å¯¼è‡´çŸ›ç›¾ï¼š$P_2$ æ—¢ä¸èƒ½è¿”å›æœ€æ–°å€¼ï¼ˆè¿åä¸€è‡´æ€§ï¼‰ï¼Œä¹Ÿä¸èƒ½æ‹’ç»è¯·æ±‚ï¼ˆè¿åå¯ç”¨æ€§ï¼‰ã€‚

å› æ­¤ï¼ŒCAPä¸‰ä¸ªå±æ€§ä¸èƒ½åŒæ—¶æ»¡è¶³ã€‚

### 3.2 Paxosæ­£ç¡®æ€§

**å®šç† 3.2.1** (Paxosæ­£ç¡®æ€§)
Paxosåè®®ä¿è¯åœ¨å¤§å¤šæ•°èŠ‚ç‚¹æ­£å¸¸æ—¶è¾¾æˆå…±è¯†ã€‚

**è¯æ˜**:
Paxosåè®®çš„æ­£ç¡®æ€§åŸºäºä»¥ä¸‹æ€§è´¨ï¼š

1. **å®‰å…¨æ€§**: å¦‚æœæŸä¸ªå€¼è¢«é€‰æ‹©ï¼Œé‚£ä¹ˆæ‰€æœ‰è¢«é€‰æ‹©çš„å€¼éƒ½æ˜¯ç›¸åŒçš„
2. **æ´»æ€§**: å¦‚æœæŸä¸ªå€¼è¢«æè®®ï¼Œé‚£ä¹ˆæœ€ç»ˆæŸä¸ªå€¼ä¼šè¢«é€‰æ‹©

**å®‰å…¨æ€§è¯æ˜**:

- å‡è®¾å€¼ $v_1$ å’Œ $v_2$ éƒ½è¢«é€‰æ‹©
- æ ¹æ®å¤šæ•°æ´¾æ€§è´¨ï¼Œå­˜åœ¨èŠ‚ç‚¹åŒæ—¶æ¥å— $v_1$ å’Œ $v_2$
- è¿™ä¸Paxosçš„æ¥å—æ¡ä»¶çŸ›ç›¾

**æ´»æ€§è¯æ˜**:

- é€šè¿‡é¢†å¯¼è€…é€‰ä¸¾ç¡®ä¿æœ‰æ´»è·ƒçš„æè®®è€…
- é€šè¿‡å¤šæ•°æ´¾æ¥å—ç¡®ä¿æè®®è¢«æ¥å—

### 3.3 æœ€ç»ˆä¸€è‡´æ€§æ”¶æ•›

**å®šç† 3.3.1** (æœ€ç»ˆä¸€è‡´æ€§æ”¶æ•›)
åœ¨æ— æ•…éšœç½‘ç»œä¸­ï¼Œæœ€ç»ˆä¸€è‡´æ€§ç³»ç»Ÿä¼šæ”¶æ•›åˆ°ä¸€è‡´çŠ¶æ€ã€‚

**è¯æ˜**:
è®¾ $S(t)$ æ˜¯æ—¶é—´ $t$ æ—¶ç³»ç»Ÿçš„çŠ¶æ€å·®å¼‚ã€‚

1. **ä¼ æ’­å»¶è¿Ÿ**: æ•°æ®ä¼ æ’­æœ‰æœ€å¤§å»¶è¿Ÿ $D$
2. **æ”¶æ•›è¿‡ç¨‹**: $S(t) \leq S(t-D) \cdot \alpha$ï¼Œå…¶ä¸­ $\alpha < 1$
3. **æé™**: $\lim_{t \to \infty} S(t) = 0$

å› æ­¤ç³»ç»Ÿæœ€ç»ˆæ”¶æ•›åˆ°ä¸€è‡´çŠ¶æ€ã€‚

## 4. ä»£ç å®ç°

### 4.1 åˆ†å¸ƒå¼é”®å€¼å­˜å‚¨å®ç°

```rust
use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use tokio::sync::RwLock;
use serde::{Serialize, Deserialize};
use uuid::Uuid;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DataEntry {
    key: String,
    value: String,
    version: u64,
    timestamp: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum StorageOperation {
    Read { key: String },
    Write { key: String, value: String },
    Delete { key: String },
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum StorageResponse {
    Success { value: Option<String> },
    Error { message: String },
}

#[derive(Debug)]
pub struct StorageNode {
    id: String,
    data: Arc<RwLock<HashMap<String, DataEntry>>>,
    replicas: Vec<String>,
    consistency_level: ConsistencyLevel,
}

#[derive(Debug, Clone)]
pub enum ConsistencyLevel {
    Strong,
    Eventual,
    ReadYourWrites,
}

impl StorageNode {
    pub fn new(id: String, consistency_level: ConsistencyLevel) -> Self {
        Self {
            id,
            data: Arc::new(RwLock::new(HashMap::new())),
            replicas: Vec::new(),
            consistency_level,
        }
    }

    pub async fn read(&self, key: &str) -> Result<Option<String>, Box<dyn std::error::Error>> {
        let data = self.data.read().await;
        
        match data.get(key) {
            Some(entry) => {
                println!("Node {} read key {}: {}", self.id, key, entry.value);
                Ok(Some(entry.value.clone()))
            }
            None => {
                println!("Node {} read key {}: not found", self.id, key);
                Ok(None)
            }
        }
    }

    pub async fn write(&self, key: &str, value: &str) -> Result<(), Box<dyn std::error::Error>> {
        let mut data = self.data.write().await;
        
        let entry = DataEntry {
            key: key.to_string(),
            value: value.to_string(),
            version: data.get(key).map(|e| e.version + 1).unwrap_or(1),
            timestamp: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_millis() as u64,
        };
        
        data.insert(key.to_string(), entry);
        println!("Node {} wrote key {}: {}", self.id, key, value);
        
        Ok(())
    }

    pub async fn delete(&self, key: &str) -> Result<(), Box<dyn std::error::Error>> {
        let mut data = self.data.write().await;
        
        data.remove(key);
        println!("Node {} deleted key {}", self.id, key);
        
        Ok(())
    }

    pub async fn replicate(&self, entry: DataEntry) -> Result<(), Box<dyn std::error::Error>> {
        let mut data = self.data.write().await;
        
        // æ£€æŸ¥ç‰ˆæœ¬å†²çª
        if let Some(existing) = data.get(&entry.key) {
            if existing.version >= entry.version {
                return Ok(());
            }
        }
        
        data.insert(entry.key.clone(), entry);
        Ok(())
    }
}

#[derive(Debug)]
pub struct DistributedStorage {
    nodes: HashMap<String, Arc<StorageNode>>,
    replication_factor: usize,
}

impl DistributedStorage {
    pub fn new(replication_factor: usize) -> Self {
        Self {
            nodes: HashMap::new(),
            replication_factor,
        }
    }

    pub fn add_node(&mut self, node: StorageNode) {
        let node_id = node.id.clone();
        self.nodes.insert(node_id, Arc::new(node));
    }

    pub async fn read(&self, key: &str, consistency: ConsistencyLevel) -> Result<Option<String>, Box<dyn std::error::Error>> {
        match consistency {
            ConsistencyLevel::Strong => {
                // å¼ºä¸€è‡´æ€§ï¼šä»æ‰€æœ‰å‰¯æœ¬è¯»å–ï¼Œç¡®ä¿ä¸€è‡´æ€§
                self.read_strong(key).await
            }
            ConsistencyLevel::Eventual => {
                // æœ€ç»ˆä¸€è‡´æ€§ï¼šä»ä»»æ„å‰¯æœ¬è¯»å–
                self.read_eventual(key).await
            }
            ConsistencyLevel::ReadYourWrites => {
                // è¯»å·±å†™ä¸€è‡´æ€§ï¼šä»ä¸Šæ¬¡å†™å…¥çš„å‰¯æœ¬è¯»å–
                self.read_your_writes(key).await
            }
        }
    }

    pub async fn write(&self, key: &str, value: &str) -> Result<(), Box<dyn std::error::Error>> {
        // é€‰æ‹©å‰¯æœ¬èŠ‚ç‚¹
        let replica_nodes = self.select_replicas(key);
        
        // å†™å…¥æ‰€æœ‰å‰¯æœ¬
        let mut results = Vec::new();
        for node_id in replica_nodes {
            if let Some(node) = self.nodes.get(&node_id) {
                let result = node.write(key, value).await;
                results.push(result);
            }
        }
        
        // æ£€æŸ¥å†™å…¥ç»“æœ
        let success_count = results.iter().filter(|r| r.is_ok()).count();
        if success_count >= self.replication_factor {
            Ok(())
        } else {
            Err("Insufficient replicas written".into())
        }
    }

    async fn read_strong(&self, key: &str) -> Result<Option<String>, Box<dyn std::error::Error>> {
        let replica_nodes = self.select_replicas(key);
        let mut values = Vec::new();
        
        for node_id in replica_nodes {
            if let Some(node) = self.nodes.get(&node_id) {
                if let Ok(value) = node.read(key).await {
                    values.push(value);
                }
            }
        }
        
        // æ£€æŸ¥æ‰€æœ‰å€¼æ˜¯å¦ä¸€è‡´
        if values.is_empty() {
            return Ok(None);
        }
        
        let first_value = &values[0];
        if values.iter().all(|v| v == first_value) {
            Ok(first_value.clone())
        } else {
            Err("Inconsistent values across replicas".into())
        }
    }

    async fn read_eventual(&self, key: &str) -> Result<Option<String>, Box<dyn std::error::Error>> {
        let replica_nodes = self.select_replicas(key);
        
        // ä»ç¬¬ä¸€ä¸ªå¯ç”¨å‰¯æœ¬è¯»å–
        for node_id in replica_nodes {
            if let Some(node) = self.nodes.get(&node_id) {
                if let Ok(value) = node.read(key).await {
                    return Ok(value);
                }
            }
        }
        
        Ok(None)
    }

    async fn read_your_writes(&self, key: &str) -> Result<Option<String>, Box<dyn std::error::Error>> {
        // ç®€åŒ–å®ç°ï¼šä»ä¸»å‰¯æœ¬è¯»å–
        let replica_nodes = self.select_replicas(key);
        if let Some(node_id) = replica_nodes.first() {
            if let Some(node) = self.nodes.get(node_id) {
                return node.read(key).await;
            }
        }
        
        Ok(None)
    }

    fn select_replicas(&self, key: &str) -> Vec<String> {
        // ä½¿ç”¨ä¸€è‡´æ€§å“ˆå¸Œé€‰æ‹©å‰¯æœ¬
        let mut node_ids: Vec<String> = self.nodes.keys().cloned().collect();
        node_ids.sort();
        
        let hash = self.hash_key(key);
        let start_index = hash % node_ids.len();
        
        let mut replicas = Vec::new();
        for i in 0..self.replication_factor {
            let index = (start_index + i) % node_ids.len();
            replicas.push(node_ids[index].clone());
        }
        
        replicas
    }

    fn hash_key(&self, key: &str) -> usize {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};
        
        let mut hasher = DefaultHasher::new();
        key.hash(&mut hasher);
        hasher.finish() as usize
    }
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let mut storage = DistributedStorage::new(3);
    
    // åˆ›å»ºå­˜å‚¨èŠ‚ç‚¹
    let node1 = StorageNode::new("node1".to_string(), ConsistencyLevel::Strong);
    let node2 = StorageNode::new("node2".to_string(), ConsistencyLevel::Strong);
    let node3 = StorageNode::new("node3".to_string(), ConsistencyLevel::Strong);
    
    storage.add_node(node1);
    storage.add_node(node2);
    storage.add_node(node3);
    
    // å†™å…¥æ•°æ®
    storage.write("user:1", "Alice").await?;
    storage.write("user:2", "Bob").await?;
    
    // è¯»å–æ•°æ®
    let value1 = storage.read("user:1", ConsistencyLevel::Strong).await?;
    let value2 = storage.read("user:2", ConsistencyLevel::Eventual).await?;
    
    println!("Read user:1 = {:?}", value1);
    println!("Read user:2 = {:?}", value2);
    
    Ok(())
}
```

### 4.2 Paxosåè®®å®ç°

```rust
use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use tokio::sync::mpsc;
use serde::{Serialize, Deserialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Proposal {
    id: u64,
    value: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum PaxosMessage {
    Prepare { proposal_id: u64 },
    Promise { proposal_id: u64, accepted_proposal: Option<Proposal> },
    Accept { proposal: Proposal },
    Accepted { proposal: Proposal },
    Learn { value: String },
}

#[derive(Debug)]
pub struct PaxosNode {
    id: String,
    proposal_id: Arc<Mutex<u64>>,
    accepted_proposal: Arc<Mutex<Option<Proposal>>>,
    promised_id: Arc<Mutex<u64>>,
    learned_value: Arc<Mutex<Option<String>>>,
    tx: mpsc::Sender<PaxosMessage>,
}

impl PaxosNode {
    pub fn new(id: String, tx: mpsc::Sender<PaxosMessage>) -> Self {
        Self {
            id,
            proposal_id: Arc::new(Mutex::new(0)),
            accepted_proposal: Arc::new(Mutex::new(None)),
            promised_id: Arc::new(Mutex::new(0)),
            learned_value: Arc::new(Mutex::new(None)),
            tx,
        }
    }

    pub async fn propose(&self, value: String) -> Result<(), Box<dyn std::error::Error>> {
        let mut proposal_id = self.proposal_id.lock().unwrap();
        *proposal_id += 1;
        let current_proposal_id = *proposal_id;
        
        println!("Node {} proposing value {} with id {}", self.id, value, current_proposal_id);
        
        // é˜¶æ®µ1: å‡†å¤‡é˜¶æ®µ
        self.prepare_phase(current_proposal_id).await?;
        
        // é˜¶æ®µ2: æ¥å—é˜¶æ®µ
        self.accept_phase(current_proposal_id, value).await?;
        
        Ok(())
    }

    async fn prepare_phase(&self, proposal_id: u64) -> Result<(), Box<dyn std::error::Error>> {
        // å‘é€å‡†å¤‡æ¶ˆæ¯
        self.tx.send(PaxosMessage::Prepare { proposal_id }).await?;
        Ok(())
    }

    async fn accept_phase(&self, proposal_id: u64, value: String) -> Result<(), Box<dyn std::error::Error>> {
        let proposal = Proposal {
            id: proposal_id,
            value: Some(value),
        };
        
        // å‘é€æ¥å—æ¶ˆæ¯
        self.tx.send(PaxosMessage::Accept { proposal }).await?;
        Ok(())
    }

    pub async fn handle_prepare(&self, proposal_id: u64) -> Result<(), Box<dyn std::error::Error>> {
        let mut promised_id = self.promised_id.lock().unwrap();
        
        if proposal_id > *promised_id {
            *promised_id = proposal_id;
            
            let accepted_proposal = self.accepted_proposal.lock().unwrap().clone();
            self.tx.send(PaxosMessage::Promise { 
                proposal_id, 
                accepted_proposal 
            }).await?;
        }
        
        Ok(())
    }

    pub async fn handle_accept(&self, proposal: Proposal) -> Result<(), Box<dyn std::error::Error>> {
        let mut promised_id = self.promised_id.lock().unwrap();
        
        if proposal.id >= *promised_id {
            *promised_id = proposal.id;
            
            let mut accepted_proposal = self.accepted_proposal.lock().unwrap();
            *accepted_proposal = Some(proposal.clone());
            
            self.tx.send(PaxosMessage::Accepted { proposal }).await?;
        }
        
        Ok(())
    }

    pub async fn handle_learn(&self, value: String) -> Result<(), Box<dyn std::error::Error>> {
        let mut learned_value = self.learned_value.lock().unwrap();
        *learned_value = Some(value.clone());
        
        println!("Node {} learned value: {}", self.id, value);
        Ok(())
    }
}

#[derive(Debug)]
pub struct PaxosCluster {
    nodes: HashMap<String, Arc<PaxosNode>>,
    majority: usize,
}

impl PaxosCluster {
    pub fn new() -> Self {
        Self {
            nodes: HashMap::new(),
            majority: 0,
        }
    }

    pub fn add_node(&mut self, node: PaxosNode) {
        let node_id = node.id.clone();
        self.nodes.insert(node_id, Arc::new(node));
        self.majority = (self.nodes.len() / 2) + 1;
    }

    pub async fn propose_value(&self, value: String) -> Result<(), Box<dyn std::error::Error>> {
        // é€‰æ‹©æè®®è€…èŠ‚ç‚¹
        if let Some(node) = self.nodes.values().next() {
            node.propose(value).await?;
        }
        
        Ok(())
    }
}
```

## 5. åº”ç”¨ç¤ºä¾‹

### 5.1 åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ

```rust
use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use tokio::sync::RwLock;
use std::path::PathBuf;

#[derive(Debug, Clone)]
pub struct FileMetadata {
    path: PathBuf,
    size: u64,
    checksum: String,
    replicas: Vec<String>,
    created_at: u64,
    modified_at: u64,
}

#[derive(Debug)]
pub struct DistributedFileSystem {
    nodes: HashMap<String, Arc<StorageNode>>,
    metadata: Arc<RwLock<HashMap<PathBuf, FileMetadata>>>,
}

impl DistributedFileSystem {
    pub fn new() -> Self {
        Self {
            nodes: HashMap::new(),
            metadata: Arc::new(RwLock::new(HashMap::new())),
        }
    }

    pub async fn write_file(&self, path: &str, content: &[u8]) -> Result<(), Box<dyn std::error::Error>> {
        let path_buf = PathBuf::from(path);
        let checksum = self.calculate_checksum(content);
        
        // é€‰æ‹©å­˜å‚¨èŠ‚ç‚¹
        let replica_nodes = self.select_replicas(path);
        
        // å†™å…¥æ‰€æœ‰å‰¯æœ¬
        for node_id in replica_nodes {
            if let Some(node) = self.nodes.get(&node_id) {
                let key = format!("file:{}", path);
                let value = String::from_utf8_lossy(content).to_string();
                node.write(&key, &value).await?;
            }
        }
        
        // æ›´æ–°å…ƒæ•°æ®
        let mut metadata = self.metadata.write().await;
        let file_metadata = FileMetadata {
            path: path_buf.clone(),
            size: content.len() as u64,
            checksum,
            replicas: replica_nodes,
            created_at: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_secs(),
            modified_at: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_secs(),
        };
        
        metadata.insert(path_buf, file_metadata);
        
        Ok(())
    }

    pub async fn read_file(&self, path: &str) -> Result<Option<Vec<u8>>, Box<dyn std::error::Error>> {
        let path_buf = PathBuf::from(path);
        
        // è·å–å…ƒæ•°æ®
        let metadata = self.metadata.read().await;
        if let Some(file_metadata) = metadata.get(&path_buf) {
            // ä»å‰¯æœ¬è¯»å–
            for node_id in &file_metadata.replicas {
                if let Some(node) = self.nodes.get(node_id) {
                    let key = format!("file:{}", path);
                    if let Ok(Some(content)) = node.read(&key).await {
                        let bytes = content.as_bytes().to_vec();
                        
                        // éªŒè¯æ ¡éªŒå’Œ
                        if self.calculate_checksum(&bytes) == file_metadata.checksum {
                            return Ok(Some(bytes));
                        }
                    }
                }
            }
        }
        
        Ok(None)
    }

    fn select_replicas(&self, path: &str) -> Vec<String> {
        let mut node_ids: Vec<String> = self.nodes.keys().cloned().collect();
        node_ids.sort();
        
        let hash = self.hash_path(path);
        let start_index = hash % node_ids.len();
        
        let mut replicas = Vec::new();
        for i in 0..3 { // 3ä¸ªå‰¯æœ¬
            let index = (start_index + i) % node_ids.len();
            replicas.push(node_ids[index].clone());
        }
        
        replicas
    }

    fn hash_path(&self, path: &str) -> usize {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};
        
        let mut hasher = DefaultHasher::new();
        path.hash(&mut hasher);
        hasher.finish() as usize
    }

    fn calculate_checksum(&self, content: &[u8]) -> String {
        use sha2::{Sha256, Digest};
        
        let mut hasher = Sha256::new();
        hasher.update(content);
        format!("{:x}", hasher.finalize())
    }
}
```

## 6. ç›¸å…³ç†è®º

### 6.1 ä¸ä¸€è‡´æ€§ç†è®ºçš„å…³ç³»

åˆ†å¸ƒå¼å­˜å‚¨ç†è®ºæ˜¯ä¸€è‡´æ€§ç†è®ºåœ¨å­˜å‚¨ç³»ç»Ÿä¸­çš„åº”ç”¨ã€‚CAPå®šç†ä¸ºåˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿè®¾è®¡æä¾›äº†åŸºæœ¬çº¦æŸã€‚

### 6.2 ä¸å…±è¯†ç†è®ºçš„å…³ç³»

åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿä½¿ç”¨å…±è¯†åè®®ï¼ˆå¦‚Paxosã€Raftï¼‰æ¥ä¿è¯æ•°æ®ä¸€è‡´æ€§ï¼Œç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹å¯¹æ•°æ®çŠ¶æ€è¾¾æˆå…±è¯†ã€‚

### 6.3 ä¸åˆ†å¸ƒå¼ç®—æ³•ç†è®ºçš„å…³ç³»

åˆ†å¸ƒå¼å­˜å‚¨ç®—æ³•æ˜¯åˆ†å¸ƒå¼ç®—æ³•çš„é‡è¦å®ä¾‹ï¼Œæ¶‰åŠæ•°æ®åˆ†ç‰‡ã€å¤åˆ¶ã€ä¸€è‡´æ€§ç»´æŠ¤ç­‰æ ¸å¿ƒé—®é¢˜ã€‚

## 7. å‚è€ƒæ–‡çŒ®

1. Brewer, E. A. (2012). CAP twelve years later: How the "rules" have changed. Computer, 45(2), 23-29.

2. Lamport, L. (1998). The part-time parliament. ACM Transactions on Computer Systems, 16(2), 133-169.

3. Ongaro, D., & Ousterhout, J. (2014). In search of an understandable consensus algorithm. In 2014 USENIX Annual Technical Conference (USENIX ATC 14) (pp. 305-319).

4. Vogels, W. (2009). Eventually consistent. Communications of the ACM, 52(1), 40-44.

5. Gilbert, S., & Lynch, N. (2002). Brewer's conjecture and the feasibility of consistent, available, partition-tolerant web services. ACM SIGACT News, 33(2), 51-59.

---

**ç›¸å…³æ–‡æ¡£**:

- [06.2.1 å…±è¯†ç†è®º](../06_Distributed_Systems_Theory/06.2.1_å…±è¯†ç†è®º.md)
- [06.2.2 ä¸€è‡´æ€§ç†è®º](../06_Distributed_Systems_Theory/06.2.2_ä¸€è‡´æ€§ç†è®º.md)
- [06.2.3 åˆ†å¸ƒå¼äº‹åŠ¡ç†è®º](../06_Distributed_Systems_Theory/06.2.3_åˆ†å¸ƒå¼äº‹åŠ¡ç†è®º.md)
