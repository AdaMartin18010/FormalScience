# 06.1.1 åˆ†å¸ƒå¼ç³»ç»ŸåŸºç¡€

## ğŸ“‹ æ¦‚è¿°

åˆ†å¸ƒå¼ç³»ç»ŸåŸºç¡€æ˜¯åˆ†å¸ƒå¼è®¡ç®—ç†è®ºçš„æ ¸å¿ƒåˆ†æ”¯ï¼Œç ”ç©¶ç”±å¤šä¸ªç‹¬ç«‹è®¡ç®—æœºç»„æˆçš„ç³»ç»Ÿå¦‚ä½•ååŒå·¥ä½œä»¥å®Œæˆå…±åŒçš„ä»»åŠ¡ã€‚è¯¥ç†è®ºä¸ºç°ä»£åˆ†å¸ƒå¼åº”ç”¨ã€äº‘è®¡ç®—å’Œåˆ†å¸ƒå¼æ•°æ®åº“æä¾›äº†ç†è®ºåŸºç¡€ï¼Œæ˜¯æ„å»ºå¤§è§„æ¨¡ã€é«˜å¯ç”¨ç³»ç»Ÿçš„å…³é”®ã€‚

## ğŸ¯ æ ¸å¿ƒç›®æ ‡

1. **å»ºç«‹åˆ†å¸ƒå¼ç³»ç»Ÿçš„æ•°å­¦åŸºç¡€**
2. **å®šä¹‰åˆ†å¸ƒå¼ç³»ç»Ÿçš„åŸºæœ¬æ¦‚å¿µ**
3. **ç ”ç©¶åˆ†å¸ƒå¼ç³»ç»Ÿçš„ç‰¹æ€§**
4. **æä¾›åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡æ–¹æ³•**
5. **åˆ†æåˆ†å¸ƒå¼ç³»ç»Ÿåœ¨å·¥ç¨‹ä¸­çš„åº”ç”¨**

## ğŸ“š ç›®å½•

1. [åŸºæœ¬æ¦‚å¿µ](#1-åŸºæœ¬æ¦‚å¿µ)
2. [å½¢å¼åŒ–å®šä¹‰](#2-å½¢å¼åŒ–å®šä¹‰)
3. [å®šç†ä¸è¯æ˜](#3-å®šç†ä¸è¯æ˜)
4. [ä»£ç å®ç°](#4-ä»£ç å®ç°)
5. [åº”ç”¨ç¤ºä¾‹](#5-åº”ç”¨ç¤ºä¾‹)
6. [ç›¸å…³ç†è®º](#6-ç›¸å…³ç†è®º)
7. [å‚è€ƒæ–‡çŒ®](#7-å‚è€ƒæ–‡çŒ®)

## 1. åŸºæœ¬æ¦‚å¿µ

### 1.1 åˆ†å¸ƒå¼ç³»ç»Ÿå®šä¹‰

**å®šä¹‰ 1.1.1 (åˆ†å¸ƒå¼ç³»ç»Ÿ)**
åˆ†å¸ƒå¼ç³»ç»Ÿæ˜¯ç”±å¤šä¸ªç‹¬ç«‹è®¡ç®—æœºï¼ˆèŠ‚ç‚¹ï¼‰ç»„æˆçš„ç³»ç»Ÿï¼Œè¿™äº›èŠ‚ç‚¹é€šè¿‡ç½‘ç»œè¿æ¥ï¼ŒååŒå·¥ä½œä»¥å®Œæˆå…±åŒçš„ä»»åŠ¡ï¼Œä½†å¯¹ç”¨æˆ·è¡¨ç°ä¸ºå•ä¸€ç³»ç»Ÿã€‚

**å®šä¹‰ 1.1.2 (èŠ‚ç‚¹)**
èŠ‚ç‚¹æ˜¯åˆ†å¸ƒå¼ç³»ç»Ÿä¸­çš„ç‹¬ç«‹è®¡ç®—å•å…ƒï¼Œå…·æœ‰è‡ªå·±çš„å¤„ç†å™¨ã€å†…å­˜å’Œå­˜å‚¨è®¾å¤‡ã€‚

**å®šä¹‰ 1.1.3 (ç½‘ç»œ)**
ç½‘ç»œæ˜¯è¿æ¥åˆ†å¸ƒå¼ç³»ç»Ÿä¸­å„ä¸ªèŠ‚ç‚¹çš„é€šä¿¡åŸºç¡€è®¾æ–½ï¼Œå¯ä»¥æ˜¯å±€åŸŸç½‘ã€å¹¿åŸŸç½‘æˆ–äº’è”ç½‘ã€‚

### 1.2 åˆ†å¸ƒå¼ç³»ç»Ÿç‰¹æ€§

**å®šä¹‰ 1.2.1 (é€æ˜æ€§)**
é€æ˜æ€§æ˜¯åˆ†å¸ƒå¼ç³»ç»Ÿçš„ä¸€ä¸ªé‡è¦ç‰¹æ€§ï¼ŒåŒ…æ‹¬ï¼š

- **ä½ç½®é€æ˜æ€§**ï¼šç”¨æˆ·ä¸éœ€è¦çŸ¥é“èµ„æºçš„å…·ä½“ä½ç½®
- **è¿ç§»é€æ˜æ€§**ï¼šèµ„æºå¯ä»¥åœ¨èŠ‚ç‚¹é—´ç§»åŠ¨è€Œä¸å½±å“ç”¨æˆ·
- **å¤åˆ¶é€æ˜æ€§**ï¼šç”¨æˆ·ä¸éœ€è¦çŸ¥é“èµ„æºçš„å‰¯æœ¬æ•°é‡
- **å¹¶å‘é€æ˜æ€§**ï¼šå¤šä¸ªç”¨æˆ·å¯ä»¥åŒæ—¶è®¿é—®èµ„æº

**å®šä¹‰ 1.2.2 (å¼€æ”¾æ€§)**
å¼€æ”¾æ€§æ˜¯æŒ‡åˆ†å¸ƒå¼ç³»ç»Ÿèƒ½å¤Ÿä¸å¼‚æ„ç³»ç»Ÿäº’æ“ä½œï¼Œæ”¯æŒä¸åŒçš„ç¡¬ä»¶ã€æ“ä½œç³»ç»Ÿå’Œç½‘ç»œåè®®ã€‚

**å®šä¹‰ 1.2.3 (å¯æ‰©å±•æ€§)**
å¯æ‰©å±•æ€§æ˜¯æŒ‡åˆ†å¸ƒå¼ç³»ç»Ÿèƒ½å¤Ÿé€šè¿‡å¢åŠ èŠ‚ç‚¹æ¥æé«˜æ€§èƒ½å’Œå®¹é‡ã€‚

### 1.3 åˆ†å¸ƒå¼ç³»ç»ŸæŒ‘æˆ˜

**å®šä¹‰ 1.3.1 (éƒ¨åˆ†æ•…éšœ)**
éƒ¨åˆ†æ•…éšœæ˜¯æŒ‡åˆ†å¸ƒå¼ç³»ç»Ÿä¸­çš„æŸäº›èŠ‚ç‚¹æˆ–ç½‘ç»œé“¾è·¯å‘ç”Ÿæ•…éšœï¼Œè€Œå…¶ä»–éƒ¨åˆ†ä»ç„¶æ­£å¸¸å·¥ä½œã€‚

**å®šä¹‰ 1.3.2 (ç½‘ç»œåˆ†åŒº)**
ç½‘ç»œåˆ†åŒºæ˜¯æŒ‡ç½‘ç»œæ•…éšœå¯¼è‡´åˆ†å¸ƒå¼ç³»ç»Ÿè¢«åˆ†å‰²æˆå¤šä¸ªæ— æ³•é€šä¿¡çš„å­ç½‘ç»œã€‚

**å®šä¹‰ 1.3.3 (æ—¶é’ŸåŒæ­¥)**
æ—¶é’ŸåŒæ­¥æ˜¯æŒ‡åˆ†å¸ƒå¼ç³»ç»Ÿä¸­å„ä¸ªèŠ‚ç‚¹çš„æ—¶é’Ÿå¯èƒ½å­˜åœ¨åå·®ï¼Œéœ€è¦åè°ƒä¸€è‡´ã€‚

## 2. å½¢å¼åŒ–å®šä¹‰

### 2.1 åˆ†å¸ƒå¼ç³»ç»Ÿæ¨¡å‹

**å®šä¹‰ 2.1.1 (åˆ†å¸ƒå¼ç³»ç»Ÿæ¨¡å‹)**
åˆ†å¸ƒå¼ç³»ç»Ÿå¯ä»¥å½¢å¼åŒ–ä¸ºä¸€ä¸ªä¸‰å…ƒç»„ $DS = (N, E, P)$ï¼Œå…¶ä¸­ï¼š

- $N = \{n_1, n_2, \ldots, n_m\}$ æ˜¯èŠ‚ç‚¹é›†åˆ
- $E \subseteq N \times N$ æ˜¯è¾¹é›†åˆï¼Œè¡¨ç¤ºèŠ‚ç‚¹é—´çš„è¿æ¥
- $P = \{p_1, p_2, \ldots, p_k\}$ æ˜¯è¿›ç¨‹é›†åˆ

**å®šä¹‰ 2.1.2 (æ¶ˆæ¯ä¼ é€’æ¨¡å‹)**
æ¶ˆæ¯ä¼ é€’æ¨¡å‹æè¿°èŠ‚ç‚¹é—´çš„é€šä¿¡ï¼š
$$send(n_i, n_j, m) \rightarrow receive(n_j, n_i, m)$$

å…¶ä¸­ $m$ æ˜¯æ¶ˆæ¯å†…å®¹ã€‚

**å®šä¹‰ 2.1.3 (çŠ¶æ€è½¬æ¢)**
èŠ‚ç‚¹çš„çŠ¶æ€è½¬æ¢å¯ä»¥æè¿°ä¸ºï¼š
$$\delta: S \times M \rightarrow S \times M^*$$

å…¶ä¸­ $S$ æ˜¯çŠ¶æ€é›†åˆï¼Œ$M$ æ˜¯æ¶ˆæ¯é›†åˆã€‚

### 2.2 åˆ†å¸ƒå¼ç®—æ³•

**å®šä¹‰ 2.2.1 (åˆ†å¸ƒå¼ç®—æ³•)**
åˆ†å¸ƒå¼ç®—æ³•æ˜¯åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸Šæ‰§è¡Œçš„ç®—æ³•ï¼Œæ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œç®—æ³•çš„ä¸€éƒ¨åˆ†ã€‚

**å®šä¹‰ 2.2.2 (åŒæ­¥æ¨¡å‹)**
åœ¨åŒæ­¥æ¨¡å‹ä¸­ï¼Œæ‰€æœ‰èŠ‚ç‚¹æŒ‰ç…§å…¨å±€æ—¶é’ŸåŒæ­¥æ‰§è¡Œï¼Œæ¶ˆæ¯ä¼ é€’æœ‰å›ºå®šçš„å»¶è¿Ÿã€‚

**å®šä¹‰ 2.2.3 (å¼‚æ­¥æ¨¡å‹)**
åœ¨å¼‚æ­¥æ¨¡å‹ä¸­ï¼ŒèŠ‚ç‚¹æ‰§è¡Œé€Ÿåº¦ä¸åŒï¼Œæ¶ˆæ¯ä¼ é€’å»¶è¿Ÿä¸ç¡®å®šï¼Œä½†æ¶ˆæ¯æœ€ç»ˆä¼šè¢«ä¼ é€’ã€‚

### 2.3 ä¸€è‡´æ€§æ¨¡å‹

**å®šä¹‰ 2.3.1 (å¼ºä¸€è‡´æ€§)**
å¼ºä¸€è‡´æ€§è¦æ±‚æ‰€æœ‰èŠ‚ç‚¹çœ‹åˆ°ç›¸åŒçš„æ“ä½œé¡ºåºï¼Œä»»ä½•è¯»å–æ“ä½œéƒ½èƒ½çœ‹åˆ°æœ€è¿‘ä¸€æ¬¡å†™å…¥çš„å€¼ã€‚

**å®šä¹‰ 2.3.2 (æœ€ç»ˆä¸€è‡´æ€§)**
æœ€ç»ˆä¸€è‡´æ€§å…è®¸ç³»ç»Ÿæš‚æ—¶ä¸ä¸€è‡´ï¼Œä½†æœ€ç»ˆä¼šæ”¶æ•›åˆ°ä¸€è‡´çŠ¶æ€ã€‚

**å®šä¹‰ 2.3.3 (å› æœä¸€è‡´æ€§)**
å› æœä¸€è‡´æ€§è¦æ±‚å› æœç›¸å…³çš„æ“ä½œåœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šä»¥ç›¸åŒçš„é¡ºåºæ‰§è¡Œã€‚

## 3. å®šç†ä¸è¯æ˜

### 3.1 CAPå®šç†

**å®šç† 3.1.1 (CAPå®šç†)**
åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œä¸å¯èƒ½åŒæ—¶æ»¡è¶³ä¸€è‡´æ€§ï¼ˆConsistencyï¼‰ã€å¯ç”¨æ€§ï¼ˆAvailabilityï¼‰å’Œåˆ†åŒºå®¹é”™æ€§ï¼ˆPartition toleranceï¼‰ä¸‰ä¸ªå±æ€§ã€‚

**è¯æ˜**ï¼š
å‡è®¾å­˜åœ¨ä¸€ä¸ªåˆ†å¸ƒå¼ç³»ç»ŸåŒæ—¶æ»¡è¶³CAPä¸‰ä¸ªå±æ€§ã€‚å½“ç½‘ç»œåˆ†åŒºå‘ç”Ÿæ—¶ï¼š

1. ä¸ºäº†ä¿è¯å¯ç”¨æ€§ï¼Œç³»ç»Ÿå¿…é¡»ç»§ç»­å“åº”è¯·æ±‚
2. ä¸ºäº†ä¿è¯ä¸€è‡´æ€§ï¼Œæ‰€æœ‰èŠ‚ç‚¹å¿…é¡»çœ‹åˆ°ç›¸åŒçš„æ•°æ®
3. ç”±äºç½‘ç»œåˆ†åŒºï¼ŒèŠ‚ç‚¹é—´æ— æ³•é€šä¿¡ï¼Œæ— æ³•ä¿è¯ä¸€è‡´æ€§

è¿™å¯¼è‡´çŸ›ç›¾ï¼Œå› æ­¤CAPä¸‰ä¸ªå±æ€§ä¸å¯èƒ½åŒæ—¶æ»¡è¶³ã€‚$\square$

**æ¨è®º 3.1.1 (CAPå®šç†çš„åº”ç”¨)**
æ ¹æ®CAPå®šç†ï¼Œåˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡éœ€è¦åœ¨ä¸€è‡´æ€§ã€å¯ç”¨æ€§å’Œåˆ†åŒºå®¹é”™æ€§ä¹‹é—´åšå‡ºæƒè¡¡ã€‚

### 3.2 FLPä¸å¯èƒ½æ€§å®šç†

**å®šç† 3.2.1 (FLPä¸å¯èƒ½æ€§å®šç†)**
åœ¨å¼‚æ­¥åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œå³ä½¿åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹å¯èƒ½å‘ç”Ÿæ•…éšœï¼Œä¹Ÿä¸å¯èƒ½è®¾è®¡å‡ºä¸€ä¸ªç¡®å®šæ€§ç®—æ³•æ¥è§£å†³å…±è¯†é—®é¢˜ã€‚

**è¯æ˜**ï¼š

1. å‡è®¾å­˜åœ¨ä¸€ä¸ªç¡®å®šæ€§ç®—æ³•èƒ½å¤Ÿè§£å†³å…±è¯†é—®é¢˜
2. åœ¨å¼‚æ­¥ç³»ç»Ÿä¸­ï¼Œæ¶ˆæ¯ä¼ é€’å»¶è¿Ÿä¸ç¡®å®š
3. å½“æŸä¸ªèŠ‚ç‚¹æ•…éšœæ—¶ï¼Œå…¶ä»–èŠ‚ç‚¹æ— æ³•åŒºåˆ†è¯¥èŠ‚ç‚¹æ˜¯æ•…éšœè¿˜æ˜¯å»¶è¿Ÿ
4. è¿™å¯¼è‡´ç®—æ³•æ— æ³•ç¡®å®šæ˜¯å¦è¾¾æˆå…±è¯†

å› æ­¤ï¼Œåœ¨å¼‚æ­¥ç³»ç»Ÿä¸­æ— æ³•è®¾è®¡å‡ºç¡®å®šæ€§çš„å…±è¯†ç®—æ³•ã€‚$\square$

### 3.3 åˆ†å¸ƒå¼ç³»ç»Ÿçš„åŸºæœ¬é™åˆ¶

**å®šç† 3.3.1 (åˆ†å¸ƒå¼ç³»ç»Ÿçš„åŸºæœ¬é™åˆ¶)**
åˆ†å¸ƒå¼ç³»ç»Ÿå­˜åœ¨ä»¥ä¸‹åŸºæœ¬é™åˆ¶ï¼š

1. ç½‘ç»œå»¶è¿Ÿä¸å¯é¢„æµ‹
2. æ—¶é’Ÿä¸åŒæ­¥
3. éƒ¨åˆ†æ•…éšœä¸å¯é¿å…
4. æ¶ˆæ¯å¯èƒ½ä¸¢å¤±æˆ–é‡å¤

**è¯æ˜**ï¼š
è¿™äº›é™åˆ¶æ˜¯åˆ†å¸ƒå¼ç³»ç»Ÿçš„ç‰©ç†å’Œé€»è¾‘çº¦æŸï¼š

1. ç½‘ç»œå»¶è¿Ÿå—ç‰©ç†è·ç¦»å’Œç½‘ç»œæ‹¥å¡å½±å“
2. æ—¶é’ŸåŒæ­¥å—ç¡¬ä»¶ç²¾åº¦å’Œç¯å¢ƒå› ç´ å½±å“
3. éƒ¨åˆ†æ•…éšœæ˜¯ç¡¬ä»¶å’Œè½¯ä»¶çš„å›ºæœ‰ç‰¹æ€§
4. æ¶ˆæ¯ä¼ é€’å—ç½‘ç»œåè®®å’Œç¡¬ä»¶æ•…éšœå½±å“

å› æ­¤ï¼Œè¿™äº›é™åˆ¶æ˜¯åˆ†å¸ƒå¼ç³»ç»Ÿçš„åŸºæœ¬ç‰¹æ€§ã€‚$\square$

## 4. ä»£ç å®ç°

### 4.1 åˆ†å¸ƒå¼èŠ‚ç‚¹å®ç°

```rust
use std::collections::HashMap;
use std::net::{TcpListener, TcpStream};
use std::sync::{Arc, Mutex};
use std::thread;
use serde::{Deserialize, Serialize};
use uuid::Uuid;

/// èŠ‚ç‚¹ID
pub type NodeId = String;

/// æ¶ˆæ¯ç±»å‹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Message {
    Ping { from: NodeId, to: NodeId },
    Pong { from: NodeId, to: NodeId },
    Data { from: NodeId, to: NodeId, content: String },
    Heartbeat { from: NodeId },
}

/// èŠ‚ç‚¹çŠ¶æ€
#[derive(Debug, Clone)]
pub struct NodeState {
    pub id: NodeId,
    pub address: String,
    pub port: u16,
    pub neighbors: HashMap<NodeId, String>,
    pub data: HashMap<String, String>,
    pub timestamp: u64,
}

/// åˆ†å¸ƒå¼èŠ‚ç‚¹
pub struct DistributedNode {
    pub state: Arc<Mutex<NodeState>>,
    pub message_queue: Arc<Mutex<Vec<Message>>>,
    pub running: Arc<Mutex<bool>>,
}

impl DistributedNode {
    /// åˆ›å»ºæ–°èŠ‚ç‚¹
    pub fn new(id: NodeId, address: String, port: u16) -> Self {
        Self {
            state: Arc::new(Mutex::new(NodeState {
                id,
                address,
                port,
                neighbors: HashMap::new(),
                data: HashMap::new(),
                timestamp: 0,
            })),
            message_queue: Arc::new(Mutex::new(Vec::new())),
            running: Arc::new(Mutex::new(true)),
        }
    }

    /// å¯åŠ¨èŠ‚ç‚¹
    pub fn start(&self) -> Result<(), Box<dyn std::error::Error>> {
        let state = Arc::clone(&self.state);
        let message_queue = Arc::clone(&self.message_queue);
        let running = Arc::clone(&self.running);

        // å¯åŠ¨æ¶ˆæ¯å¤„ç†çº¿ç¨‹
        thread::spawn(move || {
            Self::message_processor(state, message_queue, running);
        });

        // å¯åŠ¨ç½‘ç»œç›‘å¬
        let listener = TcpListener::bind(format!("{}:{}", 
            state.lock().unwrap().address, 
            state.lock().unwrap().port))?;

        println!("èŠ‚ç‚¹å¯åŠ¨åœ¨ {}:{}", 
            state.lock().unwrap().address, 
            state.lock().unwrap().port);

        for stream in listener.incoming() {
            match stream {
                Ok(stream) => {
                    let message_queue = Arc::clone(&self.message_queue);
                    thread::spawn(move || {
                        Self::handle_connection(stream, message_queue);
                    });
                }
                Err(e) => eprintln!("è¿æ¥é”™è¯¯: {}", e),
            }
        }

        Ok(())
    }

    /// æ¶ˆæ¯å¤„ç†å™¨
    fn message_processor(
        state: Arc<Mutex<NodeState>>,
        message_queue: Arc<Mutex<Vec<Message>>>,
        running: Arc<Mutex<bool>>,
    ) {
        while *running.lock().unwrap() {
            let message = {
                let mut queue = message_queue.lock().unwrap();
                queue.pop()
            };

            if let Some(msg) = message {
                Self::process_message(&state, msg);
            }

            thread::sleep(std::time::Duration::from_millis(10));
        }
    }

    /// å¤„ç†æ¶ˆæ¯
    fn process_message(state: &Arc<Mutex<NodeState>>, message: Message) {
        match message {
            Message::Ping { from, to } => {
                let state_guard = state.lock().unwrap();
                if state_guard.id == to {
                    println!("æ”¶åˆ°Pingæ¥è‡ª: {}", from);
                    // å‘é€Pongå“åº”
                    let response = Message::Pong {
                        from: state_guard.id.clone(),
                        to: from,
                    };
                    // è¿™é‡Œåº”è¯¥å‘é€å“åº”
                }
            }
            Message::Pong { from, to } => {
                let state_guard = state.lock().unwrap();
                if state_guard.id == to {
                    println!("æ”¶åˆ°Pongæ¥è‡ª: {}", from);
                }
            }
            Message::Data { from, to, content } => {
                let mut state_guard = state.lock().unwrap();
                if state_guard.id == to {
                    println!("æ”¶åˆ°æ•°æ®æ¥è‡ª: {}: {}", from, content);
                    state_guard.data.insert(from, content);
                }
            }
            Message::Heartbeat { from } => {
                let state_guard = state.lock().unwrap();
                println!("æ”¶åˆ°å¿ƒè·³æ¥è‡ª: {}", from);
            }
        }
    }

    /// å¤„ç†è¿æ¥
    fn handle_connection(stream: TcpStream, message_queue: Arc<Mutex<Vec<Message>>>) {
        // ç®€åŒ–çš„æ¶ˆæ¯æ¥æ”¶å¤„ç†
        use std::io::{Read, Write};
        
        let mut buffer = [0; 1024];
        if let Ok(n) = stream.try_clone().unwrap().read(&mut buffer) {
            if n > 0 {
                if let Ok(message) = serde_json::from_slice::<Message>(&buffer[..n]) {
                    message_queue.lock().unwrap().push(message);
                }
            }
        }
    }

    /// å‘é€æ¶ˆæ¯
    pub fn send_message(&self, message: Message) -> Result<(), Box<dyn std::error::Error>> {
        let state_guard = self.state.lock().unwrap();
        
        match &message {
            Message::Ping { to, .. } | Message::Pong { to, .. } | Message::Data { to, .. } => {
                if let Some(address) = state_guard.neighbors.get(to) {
                    let mut stream = TcpStream::connect(address)?;
                    let message_json = serde_json::to_string(&message)?;
                    stream.write_all(message_json.as_bytes())?;
                }
            }
            Message::Heartbeat { .. } => {
                // å¹¿æ’­å¿ƒè·³åˆ°æ‰€æœ‰é‚»å±…
                for address in state_guard.neighbors.values() {
                    if let Ok(mut stream) = TcpStream::connect(address) {
                        let message_json = serde_json::to_string(&message)?;
                        let _ = stream.write_all(message_json.as_bytes());
                    }
                }
            }
        }
        
        Ok(())
    }

    /// æ·»åŠ é‚»å±…èŠ‚ç‚¹
    pub fn add_neighbor(&self, id: NodeId, address: String) {
        self.state.lock().unwrap().neighbors.insert(id, address);
    }

    /// å­˜å‚¨æ•°æ®
    pub fn store_data(&self, key: String, value: String) {
        self.state.lock().unwrap().data.insert(key, value);
    }

    /// è·å–æ•°æ®
    pub fn get_data(&self, key: &str) -> Option<String> {
        self.state.lock().unwrap().data.get(key).cloned()
    }
}

/// åˆ†å¸ƒå¼ç³»ç»Ÿç®¡ç†å™¨
pub struct DistributedSystem {
    pub nodes: HashMap<NodeId, DistributedNode>,
}

impl DistributedSystem {
    /// åˆ›å»ºæ–°çš„åˆ†å¸ƒå¼ç³»ç»Ÿ
    pub fn new() -> Self {
        Self {
            nodes: HashMap::new(),
        }
    }

    /// æ·»åŠ èŠ‚ç‚¹
    pub fn add_node(&mut self, id: NodeId, address: String, port: u16) -> Result<(), Box<dyn std::error::Error>> {
        let node = DistributedNode::new(id.clone(), address, port);
        self.nodes.insert(id, node);
        Ok(())
    }

    /// å¯åŠ¨æ‰€æœ‰èŠ‚ç‚¹
    pub fn start_all(&self) -> Result<(), Box<dyn std::error::Error>> {
        for (id, node) in &self.nodes {
            println!("å¯åŠ¨èŠ‚ç‚¹: {}", id);
            node.start()?;
        }
        Ok(())
    }

    /// è¿æ¥èŠ‚ç‚¹
    pub fn connect_nodes(&self, from: &NodeId, to: &NodeId) -> Result<(), Box<dyn std::error::Error>> {
        if let (Some(from_node), Some(to_node)) = (self.nodes.get(from), self.nodes.get(to)) {
            let to_address = format!("{}:{}", 
                to_node.state.lock().unwrap().address,
                to_node.state.lock().unwrap().port);
            from_node.add_neighbor(to.clone(), to_address);
        }
        Ok(())
    }
}

/// ä¸€è‡´æ€§åè®®å®ç°
pub struct ConsistencyProtocol;

impl ConsistencyProtocol {
    /// ä¸¤é˜¶æ®µæäº¤åè®®
    pub fn two_phase_commit(
        coordinator: &DistributedNode,
        participants: &[&DistributedNode],
        transaction: &str,
    ) -> bool {
        // é˜¶æ®µ1ï¼šå‡†å¤‡é˜¶æ®µ
        let mut all_prepared = true;
        for participant in participants {
            // å‘é€å‡†å¤‡æ¶ˆæ¯
            let prepare_msg = Message::Data {
                from: coordinator.state.lock().unwrap().id.clone(),
                to: participant.state.lock().unwrap().id.clone(),
                content: format!("PREPARE:{}", transaction),
            };
            if coordinator.send_message(prepare_msg).is_err() {
                all_prepared = false;
                break;
            }
        }

        if !all_prepared {
            // å‘é€ä¸­æ­¢æ¶ˆæ¯
            for participant in participants {
                let abort_msg = Message::Data {
                    from: coordinator.state.lock().unwrap().id.clone(),
                    to: participant.state.lock().unwrap().id.clone(),
                    content: format!("ABORT:{}", transaction),
                };
                let _ = coordinator.send_message(abort_msg);
            }
            return false;
        }

        // é˜¶æ®µ2ï¼šæäº¤é˜¶æ®µ
        for participant in participants {
            let commit_msg = Message::Data {
                from: coordinator.state.lock().unwrap().id.clone(),
                to: participant.state.lock().unwrap().id.clone(),
                content: format!("COMMIT:{}", transaction),
            };
            if coordinator.send_message(commit_msg).is_err() {
                return false;
            }
        }

        true
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_distributed_node() {
        let node = DistributedNode::new(
            "node1".to_string(),
            "127.0.0.1".to_string(),
            8080,
        );
        
        node.store_data("key1".to_string(), "value1".to_string());
        assert_eq!(node.get_data("key1"), Some("value1".to_string()));
    }

    #[test]
    fn test_distributed_system() {
        let mut system = DistributedSystem::new();
        
        system.add_node("node1".to_string(), "127.0.0.1".to_string(), 8081).unwrap();
        system.add_node("node2".to_string(), "127.0.0.1".to_string(), 8082).unwrap();
        
        assert_eq!(system.nodes.len(), 2);
    }
}
```

### 4.2 Haskellåˆ†å¸ƒå¼ç³»ç»Ÿå®ç°

```haskell
-- èŠ‚ç‚¹IDç±»å‹
type NodeId = String

-- æ¶ˆæ¯ç±»å‹
data Message = Ping NodeId NodeId
             | Pong NodeId NodeId
             | Data NodeId NodeId String
             | Heartbeat NodeId
             deriving (Show, Read)

-- èŠ‚ç‚¹çŠ¶æ€
data NodeState = NodeState
    { nodeId :: NodeId
    , address :: String
    , port :: Int
    , neighbors :: Map NodeId String
    , dataStore :: Map String String
    , timestamp :: Integer
    } deriving (Show)

-- åˆ†å¸ƒå¼èŠ‚ç‚¹
data DistributedNode = DistributedNode
    { state :: MVar NodeState
    , messageQueue :: MVar [Message]
    , running :: MVar Bool
    }

-- åˆ›å»ºæ–°èŠ‚ç‚¹
createNode :: NodeId -> String -> Int -> IO DistributedNode
createNode id addr port = do
    initialState <- newMVar $ NodeState id addr port empty empty 0
    queue <- newMVar []
    running <- newMVar True
    return $ DistributedNode initialState queue running

-- å¯åŠ¨èŠ‚ç‚¹
startNode :: DistributedNode -> IO ()
startNode node = do
    putStrLn $ "å¯åŠ¨èŠ‚ç‚¹: " ++ nodeId (readMVar (state node))
    
    -- å¯åŠ¨æ¶ˆæ¯å¤„ç†çº¿ç¨‹
    forkIO $ messageProcessor node
    
    -- å¯åŠ¨ç½‘ç»œç›‘å¬
    let addr = address (readMVar (state node))
    let port = port (readMVar (state node))
    listenSocket <- listenOn $ PortNumber $ fromIntegral port
    
    putStrLn $ "ç›‘å¬åœ¨ " ++ addr ++ ":" ++ show port
    
    -- æ¥å—è¿æ¥
    forever $ do
        (handle, host, port) <- accept listenSocket
        forkIO $ handleConnection handle node

-- æ¶ˆæ¯å¤„ç†å™¨
messageProcessor :: DistributedNode -> IO ()
messageProcessor node = do
    isRunning <- readMVar (running node)
    if isRunning
        then do
            message <- takeMVar (messageQueue node)
            processMessage node message
            messageProcessor node
        else return ()

-- å¤„ç†æ¶ˆæ¯
processMessage :: DistributedNode -> Message -> IO ()
processMessage node message = do
    currentState <- readMVar (state node)
    case message of
        Ping from to -> 
            when (nodeId currentState == to) $ do
                putStrLn $ "æ”¶åˆ°Pingæ¥è‡ª: " ++ from
                -- å‘é€Pongå“åº”
                let response = Pong (nodeId currentState) from
                sendMessage node response
        
        Pong from to ->
            when (nodeId currentState == to) $ do
                putStrLn $ "æ”¶åˆ°Pongæ¥è‡ª: " ++ from
        
        Data from to content ->
            when (nodeId currentState == to) $ do
                putStrLn $ "æ”¶åˆ°æ•°æ®æ¥è‡ª: " ++ from ++ ": " ++ content
                modifyMVar_ (state node) $ \s -> 
                    return s { dataStore = insert from content (dataStore s) }
        
        Heartbeat from ->
            putStrLn $ "æ”¶åˆ°å¿ƒè·³æ¥è‡ª: " ++ from

-- å¤„ç†è¿æ¥
handleConnection :: Handle -> DistributedNode -> IO ()
handleConnection handle node = do
    content <- hGetContents handle
    case reads content of
        [(message, _)] -> do
            modifyMVar_ (messageQueue node) $ \queue -> 
                return (message : queue)
        _ -> putStrLn "æ— æ•ˆæ¶ˆæ¯æ ¼å¼"
    hClose handle

-- å‘é€æ¶ˆæ¯
sendMessage :: DistributedNode -> Message -> IO ()
sendMessage node message = do
    currentState <- readMVar (state node)
    case message of
        Ping _ to | Just addr <- lookup to (neighbors currentState) -> do
            handle <- connectTo "localhost" (PortNumber $ fromIntegral (read addr))
            hPutStrLn handle (show message)
            hClose handle
        
        Pong _ to | Just addr <- lookup to (neighbors currentState) -> do
            handle <- connectTo "localhost" (PortNumber $ fromIntegral (read addr))
            hPutStrLn handle (show message)
            hClose handle
        
        Data _ to content | Just addr <- lookup to (neighbors currentState) -> do
            handle <- connectTo "localhost" (PortNumber $ fromIntegral (read addr))
            hPutStrLn handle (show message)
            hClose handle
        
        Heartbeat _ -> do
            -- å¹¿æ’­å¿ƒè·³åˆ°æ‰€æœ‰é‚»å±…
            mapM_ (\addr -> do
                handle <- connectTo "localhost" (PortNumber $ fromIntegral (read addr))
                hPutStrLn handle (show message)
                hClose handle) (elems (neighbors currentState))
        
        _ -> return ()

-- æ·»åŠ é‚»å±…èŠ‚ç‚¹
addNeighbor :: DistributedNode -> NodeId -> String -> IO ()
addNeighbor node id addr = do
    modifyMVar_ (state node) $ \s -> 
        return s { neighbors = insert id addr (neighbors s) }

-- å­˜å‚¨æ•°æ®
storeData :: DistributedNode -> String -> String -> IO ()
storeData node key value = do
    modifyMVar_ (state node) $ \s -> 
        return s { dataStore = insert key value (dataStore s) }

-- è·å–æ•°æ®
getData :: DistributedNode -> String -> IO (Maybe String)
getData node key = do
    currentState <- readMVar (state node)
    return $ lookup key (dataStore currentState)

-- åˆ†å¸ƒå¼ç³»ç»Ÿç®¡ç†å™¨
data DistributedSystem = DistributedSystem
    { nodes :: MVar (Map NodeId DistributedNode)
    }

-- åˆ›å»ºåˆ†å¸ƒå¼ç³»ç»Ÿ
createDistributedSystem :: IO DistributedSystem
createDistributedSystem = do
    nodesMap <- newMVar empty
    return $ DistributedSystem nodesMap

-- æ·»åŠ èŠ‚ç‚¹
addNode :: DistributedSystem -> NodeId -> String -> Int -> IO ()
addNode system id addr port = do
    node <- createNode id addr port
    modifyMVar_ (nodes system) $ \nodesMap -> 
        return $ insert id node nodesMap

-- è¿æ¥èŠ‚ç‚¹
connectNodes :: DistributedSystem -> NodeId -> NodeId -> IO ()
connectNodes system from to = do
    nodesMap <- readMVar (nodes system)
    case (lookup from nodesMap, lookup to nodesMap) of
        (Just fromNode, Just toNode) -> do
            currentState <- readMVar (state toNode)
            let addr = address currentState ++ ":" ++ show (port currentState)
            addNeighbor fromNode to addr
        _ -> putStrLn "èŠ‚ç‚¹ä¸å­˜åœ¨"

-- ä¸€è‡´æ€§åè®®
-- ä¸¤é˜¶æ®µæäº¤
twoPhaseCommit :: DistributedNode -> [DistributedNode] -> String -> IO Bool
twoPhaseCommit coordinator participants transaction = do
    -- é˜¶æ®µ1ï¼šå‡†å¤‡é˜¶æ®µ
    prepareResults <- mapM (\participant -> do
        let prepareMsg = Data (nodeId (readMVar (state coordinator))) 
                              (nodeId (readMVar (state participant))) 
                              ("PREPARE:" ++ transaction)
        sendMessage coordinator prepareMsg
        return True) participants
    
    let allPrepared = and prepareResults
    
    if not allPrepared
        then do
            -- å‘é€ä¸­æ­¢æ¶ˆæ¯
            mapM_ (\participant -> do
                let abortMsg = Data (nodeId (readMVar (state coordinator))) 
                                   (nodeId (readMVar (state participant))) 
                                   ("ABORT:" ++ transaction)
                sendMessage coordinator abortMsg) participants
            return False
        else do
            -- é˜¶æ®µ2ï¼šæäº¤é˜¶æ®µ
            commitResults <- mapM (\participant -> do
                let commitMsg = Data (nodeId (readMVar (state coordinator))) 
                                    (nodeId (readMVar (state participant))) 
                                    ("COMMIT:" ++ transaction)
                sendMessage coordinator commitMsg
                return True) participants
            return $ and commitResults

-- æµ‹è¯•å‡½æ•°
testDistributedSystem :: IO ()
testDistributedSystem = do
    putStrLn "æµ‹è¯•åˆ†å¸ƒå¼ç³»ç»Ÿ:"
    
    -- åˆ›å»ºåˆ†å¸ƒå¼ç³»ç»Ÿ
    system <- createDistributedSystem
    
    -- æ·»åŠ èŠ‚ç‚¹
    addNode system "node1" "127.0.0.1" 8081
    addNode system "node2" "127.0.0.1" 8082
    
    -- è¿æ¥èŠ‚ç‚¹
    connectNodes system "node1" "node2"
    
    putStrLn "åˆ†å¸ƒå¼ç³»ç»Ÿåˆ›å»ºå®Œæˆ"
```

## 5. åº”ç”¨ç¤ºä¾‹

### 5.1 åˆ†å¸ƒå¼é”®å€¼å­˜å‚¨

```rust
/// åˆ†å¸ƒå¼é”®å€¼å­˜å‚¨
pub struct DistributedKeyValueStore {
    pub nodes: HashMap<NodeId, DistributedNode>,
    pub replication_factor: usize,
}

impl DistributedKeyValueStore {
    /// åˆ›å»ºæ–°çš„åˆ†å¸ƒå¼é”®å€¼å­˜å‚¨
    pub fn new(replication_factor: usize) -> Self {
        Self {
            nodes: HashMap::new(),
            replication_factor,
        }
    }

    /// æ·»åŠ èŠ‚ç‚¹
    pub fn add_node(&mut self, id: NodeId, address: String, port: u16) -> Result<(), Box<dyn std::error::Error>> {
        let node = DistributedNode::new(id.clone(), address, port);
        self.nodes.insert(id, node);
        Ok(())
    }

    /// å­˜å‚¨é”®å€¼å¯¹
    pub fn put(&self, key: String, value: String) -> Result<(), Box<dyn std::error::Error>> {
        let node_ids: Vec<NodeId> = self.nodes.keys().cloned().collect();
        let hash = self.hash_key(&key);
        let primary_node_id = &node_ids[hash % node_ids.len()];
        
        if let Some(primary_node) = self.nodes.get(primary_node_id) {
            // å­˜å‚¨åˆ°ä¸»èŠ‚ç‚¹
            primary_node.store_data(key.clone(), value.clone());
            
            // å¤åˆ¶åˆ°å…¶ä»–èŠ‚ç‚¹
            let replica_nodes: Vec<&NodeId> = node_ids
                .iter()
                .filter(|&id| id != primary_node_id)
                .take(self.replication_factor - 1)
                .collect();
            
            for replica_id in replica_nodes {
                if let Some(replica_node) = self.nodes.get(replica_id) {
                    replica_node.store_data(key.clone(), value.clone());
                }
            }
        }
        
        Ok(())
    }

    /// è·å–å€¼
    pub fn get(&self, key: &str) -> Option<String> {
        let node_ids: Vec<NodeId> = self.nodes.keys().cloned().collect();
        let hash = self.hash_key(key);
        let primary_node_id = &node_ids[hash % node_ids.len()];
        
        if let Some(primary_node) = self.nodes.get(primary_node_id) {
            if let Some(value) = primary_node.get_data(key) {
                return Some(value);
            }
        }
        
        // å¦‚æœä¸»èŠ‚ç‚¹æ²¡æœ‰æ•°æ®ï¼Œå°è¯•ä»å‰¯æœ¬èŠ‚ç‚¹è·å–
        for (node_id, node) in &self.nodes {
            if node_id != primary_node_id {
                if let Some(value) = node.get_data(key) {
                    return Some(value);
                }
            }
        }
        
        None
    }

    /// ç®€å•çš„å“ˆå¸Œå‡½æ•°
    fn hash_key(&self, key: &str) -> usize {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};
        
        let mut hasher = DefaultHasher::new();
        key.hash(&mut hasher);
        hasher.finish() as usize
    }
}

#[test]
fn test_distributed_kv_store() {
    let mut store = DistributedKeyValueStore::new(3);
    
    store.add_node("node1".to_string(), "127.0.0.1".to_string(), 8081).unwrap();
    store.add_node("node2".to_string(), "127.0.0.1".to_string(), 8082).unwrap();
    store.add_node("node3".to_string(), "127.0.0.1".to_string(), 8083).unwrap();
    
    store.put("key1".to_string(), "value1".to_string()).unwrap();
    assert_eq!(store.get("key1"), Some("value1".to_string()));
}
```

### 5.2 åˆ†å¸ƒå¼é”

```rust
/// åˆ†å¸ƒå¼é”
pub struct DistributedLock {
    pub nodes: Vec<DistributedNode>,
    pub lock_key: String,
    pub timeout: std::time::Duration,
}

impl DistributedLock {
    /// åˆ›å»ºæ–°çš„åˆ†å¸ƒå¼é”
    pub fn new(nodes: Vec<DistributedNode>, lock_key: String, timeout: std::time::Duration) -> Self {
        Self {
            nodes,
            lock_key,
            timeout,
        }
    }

    /// å°è¯•è·å–é”
    pub fn try_lock(&self, node_id: &NodeId) -> bool {
        let lock_value = format!("{}:{}", node_id, chrono::Utc::now().timestamp());
        
        // å°è¯•åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šåˆ›å»ºé”
        let mut acquired_count = 0;
        let required_count = (self.nodes.len() / 2) + 1; // å¤šæ•°æ´¾
        
        for node in &self.nodes {
            if let Ok(()) = node.store_data(self.lock_key.clone(), lock_value.clone()) {
                acquired_count += 1;
            }
        }
        
        acquired_count >= required_count
    }

    /// é‡Šæ”¾é”
    pub fn unlock(&self, node_id: &NodeId) -> bool {
        let mut released_count = 0;
        
        for node in &self.nodes {
            if let Some(lock_value) = node.get_data(&self.lock_key) {
                if lock_value.starts_with(&format!("{}:", node_id)) {
                    // åˆ é™¤é”
                    node.store_data(self.lock_key.clone(), "".to_string());
                    released_count += 1;
                }
            }
        }
        
        released_count > 0
    }
}

#[test]
fn test_distributed_lock() {
    let nodes = vec![
        DistributedNode::new("node1".to_string(), "127.0.0.1".to_string(), 8081),
        DistributedNode::new("node2".to_string(), "127.0.0.1".to_string(), 8082),
        DistributedNode::new("node3".to_string(), "127.0.0.1".to_string(), 8083),
    ];
    
    let lock = DistributedLock::new(
        nodes,
        "test_lock".to_string(),
        std::time::Duration::from_secs(10),
    );
    
    assert!(lock.try_lock(&"node1".to_string()));
    assert!(lock.unlock(&"node1".to_string()));
}
```

## 6. ç›¸å…³ç†è®º

### 6.1 ä¸ç½‘ç»œç†è®ºçš„å…³ç³»

**å®šç† 6.1.1 (åˆ†å¸ƒå¼ç³»ç»Ÿä¸ç½‘ç»œç†è®º)**
åˆ†å¸ƒå¼ç³»ç»Ÿçš„æ€§èƒ½å—ç½‘ç»œæ‹“æ‰‘å’Œé€šä¿¡åè®®çš„å½±å“ã€‚

**è¯æ˜**ï¼š

1. ç½‘ç»œæ‹“æ‰‘å†³å®šäº†èŠ‚ç‚¹é—´çš„è¿æ¥å…³ç³»
2. é€šä¿¡åè®®å†³å®šäº†æ¶ˆæ¯ä¼ é€’çš„å¯é æ€§å’Œæ•ˆç‡
3. ç½‘ç»œå»¶è¿Ÿå’Œå¸¦å®½å½±å“ç³»ç»Ÿæ€§èƒ½
4. ç½‘ç»œåˆ†åŒºå½±å“ç³»ç»Ÿå¯ç”¨æ€§

å› æ­¤ï¼Œç½‘ç»œç†è®ºæ˜¯åˆ†å¸ƒå¼ç³»ç»Ÿç†è®ºçš„åŸºç¡€ã€‚$\square$

### 6.2 ä¸å¹¶å‘ç†è®ºçš„å…³ç³»

**å®šç† 6.2.1 (åˆ†å¸ƒå¼ç³»ç»Ÿä¸å¹¶å‘ç†è®º)**
åˆ†å¸ƒå¼ç³»ç»Ÿæ˜¯å¹¶å‘ç³»ç»Ÿçš„ç‰¹ä¾‹ï¼Œå…·æœ‰ç½‘ç»œå»¶è¿Ÿå’Œéƒ¨åˆ†æ•…éšœçš„ç‰¹æ€§ã€‚

**è¯æ˜**ï¼š

1. åˆ†å¸ƒå¼ç³»ç»Ÿä¸­çš„èŠ‚ç‚¹å¹¶å‘æ‰§è¡Œ
2. èŠ‚ç‚¹é—´é€šè¿‡æ¶ˆæ¯ä¼ é€’é€šä¿¡
3. éœ€è¦è€ƒè™‘ç½‘ç»œå»¶è¿Ÿå’Œæ•…éšœ
4. å¹¶å‘æ§åˆ¶ç®—æ³•éœ€è¦é€‚åº”åˆ†å¸ƒå¼ç¯å¢ƒ

å› æ­¤ï¼Œå¹¶å‘ç†è®ºä¸ºåˆ†å¸ƒå¼ç³»ç»Ÿæä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€ã€‚$\square$

### 6.3 ä¸æ•°æ®åº“ç†è®ºçš„å…³ç³»

**å®šç† 6.3.1 (åˆ†å¸ƒå¼ç³»ç»Ÿä¸æ•°æ®åº“ç†è®º)**
åˆ†å¸ƒå¼æ•°æ®åº“æ˜¯åˆ†å¸ƒå¼ç³»ç»Ÿçš„é‡è¦åº”ç”¨ï¼Œéœ€è¦è§£å†³ä¸€è‡´æ€§å’Œå¯ç”¨æ€§é—®é¢˜ã€‚

**è¯æ˜**ï¼š

1. åˆ†å¸ƒå¼æ•°æ®åº“éœ€è¦åœ¨å¤šä¸ªèŠ‚ç‚¹ä¸Šå­˜å‚¨æ•°æ®
2. éœ€è¦ä¿è¯æ•°æ®çš„ä¸€è‡´æ€§å’Œå¯ç”¨æ€§
3. éœ€è¦å¤„ç†ç½‘ç»œåˆ†åŒºå’ŒèŠ‚ç‚¹æ•…éšœ
4. éœ€è¦å®ç°åˆ†å¸ƒå¼äº‹åŠ¡å’Œå…±è¯†ç®—æ³•

å› æ­¤ï¼Œæ•°æ®åº“ç†è®ºä¸ºåˆ†å¸ƒå¼ç³»ç»Ÿæä¾›äº†é‡è¦çš„åº”ç”¨åœºæ™¯ã€‚$\square$

## 7. å‚è€ƒæ–‡çŒ®

1. Tanenbaum, A. S., & Van Steen, M. (2017). *Distributed systems: Principles and paradigms* (3rd ed.). Pearson.

2. Coulouris, G., Dollimore, J., Kindberg, T., & Blair, G. (2011). *Distributed systems: Concepts and design* (5th ed.). Addison-Wesley.

3. Lamport, L. (1978). Time, clocks, and the ordering of events in a distributed system. *Communications of the ACM*, 21(7), 558-565.

4. Fischer, M. J., Lynch, N. A., & Paterson, M. S. (1985). Impossibility of distributed consensus with one faulty process. *Journal of the ACM*, 32(2), 374-382.

5. Brewer, E. A. (2012). CAP twelve years later: How the "rules" have changed. *Computer*, 45(2), 23-29.

6. Lamport, L. (1998). The part-time parliament. *ACM Transactions on Computer Systems*, 16(2), 133-169.

7. Chandra, T. D., Griesemer, R., & Redstone, J. (2007). Paxos made live: An engineering perspective. *Proceedings of the Twenty-Sixth Annual ACM Symposium on Principles of Distributed Computing*, 398-407.

8. Ongaro, D., & Ousterhout, J. (2014). In search of an understandable consensus algorithm. *Proceedings of the 2014 USENIX Conference on USENIX Annual Technical Conference*, 305-319.

---

**ç›¸å…³æ–‡æ¡£**ï¼š

- [06.1.2 å…±è¯†ç†è®º](06.1.2_å…±è¯†ç†è®º.md)
- [06.1.3 ä¸€è‡´æ€§ç†è®º](06.1.3_ä¸€è‡´æ€§ç†è®º.md)
- [06.1.4 åˆ†å¸ƒå¼ç®—æ³•](06.1.4_åˆ†å¸ƒå¼ç®—æ³•.md)
- [02.4.1 å‡½æ•°æ¦‚å¿µ](../02_Mathematical_Foundation/02.4.1_å‡½æ•°æ¦‚å¿µ.md)
- [02.5.1 å…³ç³»æ¦‚å¿µ](../02_Mathematical_Foundation/02.5.1_å…³ç³»æ¦‚å¿µ.md)
