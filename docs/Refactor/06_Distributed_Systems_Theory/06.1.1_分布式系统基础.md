# 06.1.1 分布式系统基础

## 📋 概述

分布式系统基础理论是计算机科学的重要分支，研究由多个独立计算机组成的系统如何协同工作。它包括系统模型、通信协议、一致性算法等核心概念，为现代分布式应用提供理论基础。

## 🎯 核心目标

1. 建立分布式系统的基本数学模型
2. 研究分布式系统的通信机制
3. 探讨系统故障和容错理论
4. 分析分布式算法的正确性
5. 提供完整的代码实现

## 📚 目录

1. [基本概念](#1-基本概念)
2. [形式化定义](#2-形式化定义)
3. [定理与证明](#3-定理与证明)
4. [系统模型](#4-系统模型)
5. [代码实现](#5-代码实现)
6. [应用示例](#6-应用示例)
7. [相关理论](#7-相关理论)
8. [参考文献](#8-参考文献)

## 1. 基本概念

### 1.1 分布式系统的直观理解

分布式系统是由多个独立节点组成的系统，这些节点通过网络进行通信和协作，共同完成系统功能。

**基本特征**：

- **并发性**：多个节点同时执行
- **缺乏全局时钟**：节点间时钟不同步
- **故障独立性**：节点故障相互独立
- **消息传递**：通过消息进行通信

### 1.2 分布式系统的基本类型

1. **客户端-服务器系统**：集中式控制
2. **对等网络系统**：去中心化架构
3. **集群系统**：同构节点集合
4. **网格系统**：异构资源整合

## 2. 形式化定义

### 2.1 分布式系统模型

**定义 2.1.1** (分布式系统)
分布式系统是一个三元组 $DS = (N, C, P)$，其中：

- $N = \{n_1, n_2, ..., n_k\}$ 是节点集合
- $C \subseteq N \times N$ 是通信关系
- $P = \{p_1, p_2, ..., p_m\}$ 是进程集合

### 2.2 消息传递模型

**定义 2.1.2** (消息)
消息是一个四元组 $m = (s, d, t, c)$，其中：

- $s \in N$ 是发送节点
- $d \in N$ 是接收节点
- $t \in \mathbb{R}$ 是发送时间
- $c$ 是消息内容

### 2.3 事件模型

**定义 2.1.3** (事件)
事件是一个五元组 $e = (n, t, type, data, state)$，其中：

- $n \in N$ 是事件发生的节点
- $t \in \mathbb{R}$ 是事件时间戳
- $type \in \{send, receive, internal\}$ 是事件类型
- $data$ 是事件数据
- $state$ 是节点状态

## 3. 定理与证明

### 3.1 CAP定理

**定理 3.1.1** (CAP定理)
在异步网络模型中，分布式系统无法同时满足以下三个性质：

1. **一致性(Consistency)**：所有节点看到相同的数据
2. **可用性(Availability)**：每个请求都能得到响应
3. **分区容错性(Partition Tolerance)**：网络分区时系统仍能工作

**证明**：
假设系统满足CA，在网络分区时，节点无法通信，无法保证一致性，矛盾。

### 3.2 FLP不可能性定理

**定理 3.2.1** (FLP不可能性定理)
在异步分布式系统中，即使只有一个节点可能崩溃，也不存在确定性算法能够解决共识问题。

**证明**：
通过构造反例证明，任何确定性算法都存在执行序列导致无法达成共识。

### 3.3 两将军问题

**定理 3.3.1** (两将军问题)
在不可靠通信网络中，两个将军无法通过消息传递达成一致的攻击计划。

**证明**：
通过归纳法证明，无论发送多少消息，都无法保证两个将军同时知道对方收到了消息。

## 4. 系统模型

### 4.1 同步模型

**定义 4.1.1** (同步分布式系统)
同步分布式系统满足：

1. **消息延迟有界**：存在常数 $\Delta$ 使得消息延迟 $\leq \Delta$
2. **处理时间有界**：存在常数 $\tau$ 使得处理时间 $\leq \tau$
3. **时钟同步**：节点间时钟偏差有界

### 4.2 异步模型

**定义 4.1.2** (异步分布式系统)
异步分布式系统满足：

1. **消息延迟无界**：消息可能无限延迟
2. **处理时间无界**：处理时间可能无限长
3. **时钟不同步**：节点间时钟可能完全不同步

### 4.3 部分同步模型

**定义 4.1.3** (部分同步分布式系统)
部分同步分布式系统满足：

1. **消息延迟有界但未知**：存在有界延迟但不知道具体值
2. **处理时间有界但未知**：存在有界处理时间但不知道具体值
3. **时钟偏差有界但未知**：存在有界时钟偏差但不知道具体值

## 5. 代码实现

### 5.1 Rust 实现

```rust
use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use std::thread;
use std::time::{Duration, Instant};
use tokio::sync::mpsc;
use uuid::Uuid;

/// 节点ID
pub type NodeId = String;

/// 消息类型
#[derive(Debug, Clone)]
pub enum MessageType {
    Request,
    Response,
    Heartbeat,
    Consensus,
}

/// 消息
#[derive(Debug, Clone)]
pub struct Message {
    pub id: String,
    pub from: NodeId,
    pub to: NodeId,
    pub msg_type: MessageType,
    pub content: String,
    pub timestamp: Instant,
}

impl Message {
    pub fn new(from: NodeId, to: NodeId, msg_type: MessageType, content: String) -> Self {
        Self {
            id: Uuid::new_v4().to_string(),
            from,
            to,
            msg_type,
            content,
            timestamp: Instant::now(),
        }
    }
}

/// 节点状态
#[derive(Debug, Clone, PartialEq)]
pub enum NodeState {
    Active,
    Inactive,
    Failed,
    Recovering,
}

/// 分布式节点
pub struct DistributedNode {
    pub id: NodeId,
    pub state: Arc<Mutex<NodeState>>,
    pub neighbors: Arc<Mutex<Vec<NodeId>>>,
    pub message_queue: Arc<Mutex<Vec<Message>>>,
    pub local_clock: Arc<Mutex<Instant>>,
    pub tx: mpsc::Sender<Message>,
    pub rx: mpsc::Receiver<Message>,
}

impl DistributedNode {
    pub fn new(id: NodeId) -> Self {
        let (tx, rx) = mpsc::channel(100);
        Self {
            id,
            state: Arc::new(Mutex::new(NodeState::Active)),
            neighbors: Arc::new(Mutex::new(Vec::new())),
            message_queue: Arc::new(Mutex::new(Vec::new())),
            local_clock: Arc::new(Mutex::new(Instant::now())),
            tx,
            rx,
        }
    }
    
    pub fn add_neighbor(&self, neighbor_id: NodeId) {
        let mut neighbors = self.neighbors.lock().unwrap();
        if !neighbors.contains(&neighbor_id) {
            neighbors.push(neighbor_id);
        }
    }
    
    pub fn remove_neighbor(&self, neighbor_id: &NodeId) {
        let mut neighbors = self.neighbors.lock().unwrap();
        neighbors.retain(|id| id != neighbor_id);
    }
    
    pub async fn send_message(&self, to: NodeId, msg_type: MessageType, content: String) {
        let message = Message::new(self.id.clone(), to, msg_type, content);
        if let Err(e) = self.tx.send(message).await {
            eprintln!("Failed to send message: {}", e);
        }
    }
    
    pub async fn broadcast(&self, msg_type: MessageType, content: String) {
        let neighbors = self.neighbors.lock().unwrap().clone();
        for neighbor in neighbors {
            self.send_message(neighbor, msg_type.clone(), content.clone()).await;
        }
    }
    
    pub async fn process_messages(&mut self) {
        while let Some(message) = self.rx.recv().await {
            self.handle_message(message).await;
        }
    }
    
    async fn handle_message(&self, message: Message) {
        let mut queue = self.message_queue.lock().unwrap();
        queue.push(message.clone());
        
        match message.msg_type {
            MessageType::Request => {
                println!("Node {} received request: {}", self.id, message.content);
                // 处理请求
            }
            MessageType::Response => {
                println!("Node {} received response: {}", self.id, message.content);
                // 处理响应
            }
            MessageType::Heartbeat => {
                println!("Node {} received heartbeat from {}", self.id, message.from);
                // 更新邻居状态
            }
            MessageType::Consensus => {
                println!("Node {} received consensus message: {}", self.id, message.content);
                // 处理共识消息
            }
        }
    }
    
    pub fn get_state(&self) -> NodeState {
        self.state.lock().unwrap().clone()
    }
    
    pub fn set_state(&self, state: NodeState) {
        *self.state.lock().unwrap() = state;
    }
    
    pub fn get_clock(&self) -> Instant {
        *self.local_clock.lock().unwrap()
    }
    
    pub fn update_clock(&self) {
        *self.local_clock.lock().unwrap() = Instant::now();
    }
}

/// 分布式系统
pub struct DistributedSystem {
    pub nodes: HashMap<NodeId, Arc<DistributedNode>>,
    pub network_delay: Duration,
    pub failure_probability: f64,
}

impl DistributedSystem {
    pub fn new() -> Self {
        Self {
            nodes: HashMap::new(),
            network_delay: Duration::from_millis(10),
            failure_probability: 0.01,
        }
    }
    
    pub fn add_node(&mut self, node: DistributedNode) {
        let node_id = node.id.clone();
        self.nodes.insert(node_id, Arc::new(node));
    }
    
    pub fn remove_node(&mut self, node_id: &NodeId) {
        self.nodes.remove(node_id);
        // 从其他节点的邻居列表中移除
        for node in self.nodes.values() {
            node.remove_neighbor(node_id);
        }
    }
    
    pub fn connect_nodes(&self, node1_id: &NodeId, node2_id: &NodeId) {
        if let Some(node1) = self.nodes.get(node1_id) {
            node1.add_neighbor(node2_id.clone());
        }
        if let Some(node2) = self.nodes.get(node2_id) {
            node2.add_neighbor(node1_id.clone());
        }
    }
    
    pub async fn simulate_network(&self, duration: Duration) {
        let start = Instant::now();
        let mut handles = Vec::new();
        
        // 启动所有节点的消息处理
        for node in self.nodes.values() {
            let node_clone = Arc::clone(node);
            let handle = tokio::spawn(async move {
                let mut node_guard = node_clone;
                node_guard.process_messages().await;
            });
            handles.push(handle);
        }
        
        // 等待仿真完成
        tokio::time::sleep(duration).await;
        
        // 取消所有任务
        for handle in handles {
            handle.abort();
        }
        
        println!("Simulation completed in {:?}", start.elapsed());
    }
}

/// 共识算法
pub trait ConsensusAlgorithm {
    fn propose(&self, value: String) -> Result<(), String>;
    fn decide(&self) -> Option<String>;
    fn is_decided(&self) -> bool;
}

/// Paxos共识算法
pub struct PaxosNode {
    pub node: Arc<DistributedNode>,
    pub proposal_number: u64,
    pub accepted_value: Option<String>,
    pub decided_value: Option<String>,
}

impl PaxosNode {
    pub fn new(node: Arc<DistributedNode>) -> Self {
        Self {
            node,
            proposal_number: 0,
            accepted_value: None,
            decided_value: None,
        }
    }
    
    pub async fn propose(&mut self, value: String) -> Result<(), String> {
        self.proposal_number += 1;
        
        // Phase 1: Prepare
        let prepare_msg = format!("PREPARE:{}", self.proposal_number);
        self.node.broadcast(MessageType::Consensus, prepare_msg).await;
        
        // 等待多数派响应
        tokio::time::sleep(Duration::from_millis(100)).await;
        
        // Phase 2: Accept
        let accept_msg = format!("ACCEPT:{}:{}", self.proposal_number, value);
        self.node.broadcast(MessageType::Consensus, accept_msg).await;
        
        Ok(())
    }
    
    pub async fn handle_consensus_message(&mut self, message: Message) {
        let parts: Vec<&str> = message.content.split(':').collect();
        if parts.len() >= 2 {
            match parts[0] {
                "PREPARE" => {
                    // 处理Prepare消息
                    if let Ok(proposal_num) = parts[1].parse::<u64>() {
                        if proposal_num > self.proposal_number {
                            self.proposal_number = proposal_num;
                        }
                    }
                }
                "ACCEPT" => {
                    // 处理Accept消息
                    if parts.len() >= 3 {
                        if let Ok(proposal_num) = parts[1].parse::<u64>() {
                            if proposal_num >= self.proposal_number {
                                self.accepted_value = Some(parts[2].to_string());
                            }
                        }
                    }
                }
                "DECIDE" => {
                    // 处理Decide消息
                    if parts.len() >= 2 {
                        self.decided_value = Some(parts[1].to_string());
                    }
                }
                _ => {}
            }
        }
    }
}

impl ConsensusAlgorithm for PaxosNode {
    fn propose(&self, value: String) -> Result<(), String> {
        // 简化实现
        Ok(())
    }
    
    fn decide(&self) -> Option<String> {
        self.decided_value.clone()
    }
    
    fn is_decided(&self) -> bool {
        self.decided_value.is_some()
    }
}

/// 故障检测器
pub struct FailureDetector {
    pub nodes: HashMap<NodeId, Instant>,
    pub timeout: Duration,
}

impl FailureDetector {
    pub fn new(timeout: Duration) -> Self {
        Self {
            nodes: HashMap::new(),
            timeout,
        }
    }
    
    pub fn update_heartbeat(&mut self, node_id: NodeId) {
        self.nodes.insert(node_id, Instant::now());
    }
    
    pub fn get_suspected_nodes(&self) -> Vec<NodeId> {
        let now = Instant::now();
        self.nodes
            .iter()
            .filter(|(_, &last_heartbeat)| now.duration_since(last_heartbeat) > self.timeout)
            .map(|(node_id, _)| node_id.clone())
            .collect()
    }
    
    pub fn is_node_suspected(&self, node_id: &NodeId) -> bool {
        if let Some(&last_heartbeat) = self.nodes.get(node_id) {
            Instant::now().duration_since(last_heartbeat) > self.timeout
        } else {
            true
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tokio;
    
    #[tokio::test]
    async fn test_distributed_node() {
        let node = DistributedNode::new("node1".to_string());
        assert_eq!(node.get_state(), NodeState::Active);
        
        node.set_state(NodeState::Inactive);
        assert_eq!(node.get_state(), NodeState::Inactive);
    }
    
    #[tokio::test]
    async fn test_distributed_system() {
        let mut system = DistributedSystem::new();
        
        let node1 = DistributedNode::new("node1".to_string());
        let node2 = DistributedNode::new("node2".to_string());
        
        system.add_node(node1);
        system.add_node(node2);
        
        assert_eq!(system.nodes.len(), 2);
        
        system.connect_nodes(&"node1".to_string(), &"node2".to_string());
        
        // 测试网络仿真
        system.simulate_network(Duration::from_millis(100)).await;
    }
    
    #[tokio::test]
    async fn test_consensus() {
        let node = DistributedNode::new("node1".to_string());
        let mut paxos = PaxosNode::new(Arc::new(node));
        
        let result = paxos.propose("test_value".to_string()).await;
        assert!(result.is_ok());
    }
    
    #[test]
    fn test_failure_detector() {
        let mut detector = FailureDetector::new(Duration::from_millis(100));
        
        detector.update_heartbeat("node1".to_string());
        assert!(!detector.is_node_suspected(&"node1".to_string()));
        
        // 等待超时
        std::thread::sleep(Duration::from_millis(150));
        assert!(detector.is_node_suspected(&"node1".to_string()));
    }
}
```

### 5.2 Haskell 实现

```haskell
module DistributedSystems where

import Data.Map (Map)
import qualified Data.Map as Map
import Data.Set (Set)
import qualified Data.Set as Set
import Data.Time.Clock
import Data.Time.Clock.POSIX
import Control.Concurrent
import Control.Concurrent.STM
import Control.Monad
import System.Random

-- 节点ID
type NodeId = String

-- 消息类型
data MessageType = Request | Response | Heartbeat | Consensus
    deriving (Eq, Show)

-- 消息
data Message = Message {
    msgId :: String,
    msgFrom :: NodeId,
    msgTo :: NodeId,
    msgType :: MessageType,
    msgContent :: String,
    msgTimestamp :: POSIXTime
} deriving (Show)

-- 节点状态
data NodeState = Active | Inactive | Failed | Recovering
    deriving (Eq, Show)

-- 分布式节点
data DistributedNode = DistributedNode {
    nodeId :: NodeId,
    nodeState :: TVar NodeState,
    neighbors :: TVar (Set NodeId),
    messageQueue :: TVar [Message],
    localClock :: TVar POSIXTime
}

-- 创建节点
createNode :: NodeId -> IO DistributedNode
createNode id = do
    state <- newTVarIO Active
    neighs <- newTVarIO Set.empty
    queue <- newTVarIO []
    clock <- newTVarIO =<< getPOSIXTime
    return $ DistributedNode id state neighs queue clock

-- 添加邻居
addNeighbor :: DistributedNode -> NodeId -> IO ()
addNeighbor node neighborId = 
    atomically $ modifyTVar (neighbors node) (Set.insert neighborId)

-- 移除邻居
removeNeighbor :: DistributedNode -> NodeId -> IO ()
removeNeighbor node neighborId = 
    atomically $ modifyTVar (neighbors node) (Set.delete neighborId)

-- 获取邻居列表
getNeighbors :: DistributedNode -> IO (Set NodeId)
getNeighbors node = readTVarIO (neighbors node)

-- 发送消息
sendMessage :: DistributedNode -> NodeId -> MessageType -> String -> IO Message
sendMessage node to msgType content = do
    timestamp <- getPOSIXTime
    let message = Message {
        msgId = show timestamp,
        msgFrom = nodeId node,
        msgTo = to,
        msgType = msgType,
        msgContent = content,
        msgTimestamp = timestamp
    }
    return message

-- 广播消息
broadcast :: DistributedNode -> MessageType -> String -> IO [Message]
broadcast node msgType content = do
    neighs <- getNeighbors node
    mapM (\neighbor -> sendMessage node neighbor msgType content) (Set.toList neighs)

-- 接收消息
receiveMessage :: DistributedNode -> Message -> IO ()
receiveMessage node message = 
    atomically $ modifyTVar (messageQueue node) (message :)

-- 处理消息
handleMessage :: DistributedNode -> Message -> IO ()
handleMessage node message = do
    receiveMessage node message
    case msgType message of
        Request -> putStrLn $ "Node " ++ nodeId node ++ " received request: " ++ msgContent message
        Response -> putStrLn $ "Node " ++ nodeId node ++ " received response: " ++ msgContent message
        Heartbeat -> putStrLn $ "Node " ++ nodeId node ++ " received heartbeat from " ++ msgFrom message
        Consensus -> putStrLn $ "Node " ++ nodeId node ++ " received consensus: " ++ msgContent message

-- 获取节点状态
getNodeState :: DistributedNode -> IO NodeState
getNodeState node = readTVarIO (nodeState node)

-- 设置节点状态
setNodeState :: DistributedNode -> NodeState -> IO ()
setNodeState node state = writeTVarIO (nodeState node) state

-- 分布式系统
data DistributedSystem = DistributedSystem {
    nodes :: TVar (Map NodeId DistributedNode),
    networkDelay :: Int, -- milliseconds
    failureProbability :: Double
}

-- 创建分布式系统
createDistributedSystem :: Int -> Double -> IO DistributedSystem
createDistributedSystem delay prob = do
    nodesMap <- newTVarIO Map.empty
    return $ DistributedSystem nodesMap delay prob

-- 添加节点
addNodeToSystem :: DistributedSystem -> DistributedNode -> IO ()
addNodeToSystem system node = 
    atomically $ modifyTVar (nodes system) (Map.insert (nodeId node) node)

-- 移除节点
removeNodeFromSystem :: DistributedSystem -> NodeId -> IO ()
removeNodeFromSystem system nodeId = do
    atomically $ modifyTVar (nodes system) (Map.delete nodeId)
    -- 从其他节点的邻居列表中移除
    nodesMap <- readTVarIO (nodes system)
    mapM_ (\node -> removeNeighbor node nodeId) (Map.elems nodesMap)

-- 连接节点
connectNodes :: DistributedSystem -> NodeId -> NodeId -> IO ()
connectNodes system node1Id node2Id = do
    nodesMap <- readTVarIO (nodes system)
    case (Map.lookup node1Id nodesMap, Map.lookup node2Id nodesMap) of
        (Just node1, Just node2) -> do
            addNeighbor node1 node2Id
            addNeighbor node2 node1Id
        _ -> return ()

-- 共识算法类型类
class ConsensusAlgorithm a where
    propose :: a -> String -> IO (Either String ())
    decide :: a -> IO (Maybe String)
    isDecided :: a -> IO Bool

-- Paxos节点
data PaxosNode = PaxosNode {
    paxosNode :: DistributedNode,
    proposalNumber :: TVar Integer,
    acceptedValue :: TVar (Maybe String),
    decidedValue :: TVar (Maybe String)
}

-- 创建Paxos节点
createPaxosNode :: DistributedNode -> IO PaxosNode
createPaxosNode node = do
    propNum <- newTVarIO 0
    accVal <- newTVarIO Nothing
    decVal <- newTVarIO Nothing
    return $ PaxosNode node propNum accVal decVal

-- Paxos共识实现
instance ConsensusAlgorithm PaxosNode where
    propose paxos value = do
        atomically $ modifyTVar (proposalNumber paxos) (+1)
        
        -- Phase 1: Prepare
        propNum <- readTVarIO (proposalNumber paxos)
        let prepareMsg = "PREPARE:" ++ show propNum
        broadcast (paxosNode paxos) Consensus prepareMsg
        
        -- 等待一段时间
        threadDelay 100000 -- 100ms
        
        -- Phase 2: Accept
        let acceptMsg = "ACCEPT:" ++ show propNum ++ ":" ++ value
        broadcast (paxosNode paxos) Consensus acceptMsg
        
        return $ Right ()
    
    decide paxos = readTVarIO (decidedValue paxos)
    
    isDecided paxos = do
        val <- readTVarIO (decidedValue paxos)
        return $ isJust val

-- 处理Paxos消息
handlePaxosMessage :: PaxosNode -> Message -> IO ()
handlePaxosMessage paxos message = do
    let parts = words $ map (\c -> if c == ':' then ' ' else c) (msgContent message)
    case parts of
        ["PREPARE", numStr] -> do
            let num = read numStr :: Integer
            currentNum <- readTVarIO (proposalNumber paxos)
            when (num > currentNum) $ 
                writeTVarIO (proposalNumber paxos) num
        
        ["ACCEPT", numStr, value] -> do
            let num = read numStr :: Integer
            currentNum <- readTVarIO (proposalNumber paxos)
            when (num >= currentNum) $ 
                writeTVarIO (acceptedValue paxos) (Just value)
        
        ["DECIDE", value] -> 
            writeTVarIO (decidedValue paxos) (Just value)
        
        _ -> return ()

-- 故障检测器
data FailureDetector = FailureDetector {
    nodeHeartbeats :: TVar (Map NodeId POSIXTime),
    timeout :: Int -- milliseconds
}

-- 创建故障检测器
createFailureDetector :: Int -> IO FailureDetector
createFailureDetector timeoutMs = do
    heartbeats <- newTVarIO Map.empty
    return $ FailureDetector heartbeats timeoutMs

-- 更新心跳
updateHeartbeat :: FailureDetector -> NodeId -> IO ()
updateFailureDetector detector nodeId = do
    timestamp <- getPOSIXTime
    atomically $ modifyTVar (nodeHeartbeats detector) (Map.insert nodeId timestamp)

-- 获取可疑节点
getSuspectedNodes :: FailureDetector -> IO [NodeId]
getSuspectedNodes detector = do
    now <- getPOSIXTime
    heartbeats <- readTVarIO (nodeHeartbeats detector)
    let timeoutSeconds = fromIntegral (timeout detector) / 1000.0
    return [nodeId | (nodeId, lastHeartbeat) <- Map.toList heartbeats,
                    now - lastHeartbeat > timeoutSeconds]

-- 检查节点是否可疑
isNodeSuspected :: FailureDetector -> NodeId -> IO Bool
isNodeSuspected detector nodeId = do
    now <- getPOSIXTime
    heartbeats <- readTVarIO (nodeHeartbeats detector)
    case Map.lookup nodeId heartbeats of
        Just lastHeartbeat -> do
            let timeoutSeconds = fromIntegral (timeout detector) / 1000.0
            return $ now - lastHeartbeat > timeoutSeconds
        Nothing -> return True

-- 网络仿真
simulateNetwork :: DistributedSystem -> Int -> IO ()
simulateNetwork system durationMs = do
    putStrLn "Starting network simulation..."
    
    -- 启动所有节点的消息处理
    nodesMap <- readTVarIO (nodes system)
    let nodeIds = Map.keys nodesMap
    
    -- 模拟消息传递
    replicateM_ (durationMs `div` 100) $ do
        -- 随机选择节点发送消息
        randomNode <- randomRIO (0, length nodeIds - 1)
        let senderId = nodeIds !! randomNode
        case Map.lookup senderId nodesMap of
            Just sender -> do
                -- 发送心跳消息
                messages <- broadcast sender Heartbeat "ping"
                -- 模拟网络延迟
                threadDelay (networkDelay system * 1000)
            Nothing -> return ()
        
        threadDelay 100000 -- 100ms
    
    putStrLn "Network simulation completed."

-- 示例函数
exampleDistributedSystem :: IO ()
exampleDistributedSystem = do
    -- 创建分布式系统
    system <- createDistributedSystem 10 0.01
    
    -- 创建节点
    node1 <- createNode "node1"
    node2 <- createNode "node2"
    node3 <- createNode "node3"
    
    -- 添加节点到系统
    addNodeToSystem system node1
    addNodeToSystem system node2
    addNodeToSystem system node3
    
    -- 连接节点
    connectNodes system "node1" "node2"
    connectNodes system "node2" "node3"
    connectNodes system "node1" "node3"
    
    -- 创建Paxos节点
    paxos1 <- createPaxosNode node1
    
    -- 运行共识
    result <- propose paxos1 "test_value"
    case result of
        Right () -> putStrLn "Proposal sent successfully"
        Left err -> putStrLn $ "Proposal failed: " ++ err
    
    -- 创建故障检测器
    detector <- createFailureDetector 100
    
    -- 更新心跳
    updateHeartbeat detector "node1"
    updateHeartbeat detector "node2"
    
    -- 检查可疑节点
    suspected <- getSuspectedNodes detector
    putStrLn $ "Suspected nodes: " ++ show suspected
    
    -- 运行网络仿真
    simulateNetwork system 1000

-- 测试函数
testDistributedNode :: IO Bool
testDistributedNode = do
    node <- createNode "test_node"
    state <- getNodeState node
    return $ state == Active

testConsensus :: IO Bool
testConsensus = do
    node <- createNode "consensus_node"
    paxos <- createPaxosNode node
    result <- propose paxos "test"
    case result of
        Right () -> return True
        Left _ -> return False

testFailureDetector :: IO Bool
testFailureDetector = do
    detector <- createFailureDetector 50
    updateHeartbeat detector "test_node"
    suspected <- isNodeSuspected detector "test_node"
    return $ not suspected
```

## 6. 应用示例

### 6.1 分布式数据库

**示例 6.1.1** (分布式数据库)
分布式数据库使用共识算法确保数据一致性，如Raft、Paxos等。

### 6.2 分布式缓存

**示例 6.1.2** (分布式缓存)
Redis Cluster使用一致性哈希和故障检测实现高可用缓存。

### 6.3 微服务架构

**示例 6.1.3** (微服务)
微服务架构中的服务发现、负载均衡、熔断器等都是分布式系统的应用。

## 7. 相关理论

### 7.1 与网络理论的关系

分布式系统建立在网络通信基础之上，网络理论为其提供通信模型。

### 7.2 与并发理论的关系

分布式系统的并发控制与并发理论密切相关。

### 7.3 与算法理论的关系

分布式算法是算法理论在分布式环境下的扩展。

## 8. 参考文献

1. Tanenbaum, A. S., & Van Steen, M. (2007). *Distributed Systems: Principles and Paradigms*. Prentice Hall.
2. Coulouris, G., Dollimore, J., Kindberg, T., & Blair, G. (2011). *Distributed Systems: Concepts and Design*. Pearson.
3. Lamport, L. (1998). *The Part-Time Parliament*. ACM Transactions on Computer Systems.
4. Fischer, M. J., Lynch, N. A., & Paterson, M. S. (1985). *Impossibility of Distributed Consensus with One Faulty Process*. Journal of the ACM.
5. Chandra, T. D., & Toueg, S. (1996). *Unreliable Failure Detectors for Reliable Distributed Systems*. Journal of the ACM.

---

**相关文档**：

- [06.1.2 共识理论](../06_Distributed_Systems_Theory/06.1.2_共识理论.md)
- [06.1.3 一致性理论](../06_Distributed_Systems_Theory/06.1.3_一致性理论.md)
- [06.1.4 分布式算法](../06_Distributed_Systems_Theory/06.1.4_分布式算法.md)
- [02.6.1 群论基础](../02_Mathematical_Foundation/02.6.1_Group_Theory_Foundation.md)
- [03.2.2 上下文无关文法](../03_Formal_Language_Theory/03.2.2_上下文无关文法.md)
</rewritten_file>
