# 内存层次理论

## 1. 形式化定义

### 1.1 内存层次基础

**定义 9.1.04.1 (内存层次)**
内存层次 $\mathcal{M}$ 是一个偏序集：
$$\mathcal{M} = (L, \prec, \text{size}, \text{latency}, \text{bandwidth})$$
其中：

- $L$ 是内存级别集合
- $\prec$ 表示访问延迟关系：$L_i \prec L_j$ 表示 $L_i$ 比 $L_j$ 更快
- $\text{size}: L \rightarrow \mathbb{N}$ 是容量函数
- $\text{latency}: L \rightarrow \mathbb{R}^+$ 是延迟函数
- $\text{bandwidth}: L \rightarrow \mathbb{R}^+$ 是带宽函数

**定义 9.1.04.2 (缓存)**
缓存 $C$ 是一个四元组：
$$C = (\text{size}, \text{associativity}, \text{line\_size}, \text{policy})$$
其中：

- $\text{size}$ 是缓存总容量
- $\text{associativity}$ 是组相联度
- $\text{line\_size}$ 是缓存行大小
- $\text{policy}$ 是替换策略

**定义 9.1.04.3 (局部性)**
程序访问模式具有局部性，定义为：

- 时间局部性：$\text{Pr}[A(t) = A(t+\Delta t)] > \text{Pr}[A(t) = A(t+\Delta t')]$ 对于 $\Delta t < \Delta t'$
- 空间局部性：$\text{Pr}[A(t) = a] > \text{Pr}[A(t) = b]$ 对于 $|a - A(t-1)| < |b - A(t-1)|$

### 1.2 性能模型

**定义 9.1.04.4 (平均访问时间)**
平均访问时间：
$$T_{\text{avg}} = T_h + (1 - h) \times T_m$$
其中 $h$ 是命中率，$T_h$ 是命中时间，$T_m$ 是未命中时间。

**定义 9.1.04.5 (内存带宽)**
内存带宽：
$$B = \frac{\text{data\_size}}{\text{access\_time}}$$

## 2. 核心定理

### 2.1 缓存性能定理

**定理 9.1.04.1 (缓存命中率与容量)**
缓存命中率 $h$ 与容量 $S$ 的关系：
$$h(S) = 1 - \frac{1}{1 + \alpha \times S}$$
其中 $\alpha$ 是程序局部性参数。

**证明：**

1. 基于程序访问模式建模
2. 使用概率论分析
3. 容量增加导致命中率提升

### 2.2 内存墙定理

**定理 9.1.04.2 (内存墙)**
处理器性能与内存性能差距随时间增长：
$$\frac{\text{CPU\_performance}}{\text{Memory\_performance}} \propto t^2$$

**证明：**

1. CPU性能按指数增长
2. 内存性能增长缓慢
3. 差距不断扩大

## 3. 算法实现

### 3.1 多级缓存实现

```rust
use std::collections::HashMap;

// 缓存行
#[derive(Debug, Clone)]
struct CacheLine {
    tag: usize,
    data: Vec<u8>,
    valid: bool,
    dirty: bool,
    lru_counter: usize,
    access_count: usize,
}

// 替换策略
#[derive(Debug, Clone)]
enum ReplacementPolicy {
    LRU,    // 最近最少使用
    FIFO,   // 先进先出
    Random, // 随机替换
    LFU,    // 最少使用
}

// 写策略
#[derive(Debug, Clone)]
enum WritePolicy {
    WriteThrough,  // 写直达
    WriteBack,     // 写回
    WriteAllocate, // 写分配
    NoWriteAllocate, // 不写分配
}

// 缓存级别
#[derive(Debug)]
struct CacheLevel {
    lines: Vec<CacheLine>,
    line_size: usize,
    num_sets: usize,
    associativity: usize,
    replacement_policy: ReplacementPolicy,
    write_policy: WritePolicy,
    hits: usize,
    misses: usize,
    clock: usize,
    total_accesses: usize,
}

impl CacheLevel {
    fn new(
        line_size: usize,
        num_sets: usize,
        associativity: usize,
        replacement_policy: ReplacementPolicy,
        write_policy: WritePolicy,
    ) -> Self {
        let num_lines = num_sets * associativity;
        let mut lines = Vec::with_capacity(num_lines);
        
        for _ in 0..num_lines {
            lines.push(CacheLine {
                tag: 0,
                data: vec![0; line_size],
                valid: false,
                dirty: false,
                lru_counter: 0,
                access_count: 0,
            });
        }
        
        Self {
            lines,
            line_size,
            num_sets,
            associativity,
            replacement_policy,
            write_policy,
            hits: 0,
            misses: 0,
            clock: 0,
            total_accesses: 0,
        }
    }

    // 访问缓存
    fn access(&mut self, address: usize, is_write: bool) -> (bool, Option<Vec<u8>>) {
        let (set_index, tag) = self.address_to_index_tag(address);
        self.clock += 1;
        self.total_accesses += 1;
        
        if let Some(line_index) = self.find_line(set_index, tag) {
            // 缓存命中
            self.hits += 1;
            self.update_line_stats(line_index, is_write);
            
            let data = self.lines[line_index].data.clone();
            (true, Some(data))
        } else {
            // 缓存未命中
            self.misses += 1;
            let victim_index = self.select_victim(set_index);
            let evicted_data = self.evict_line(victim_index);
            
            // 加载新数据
            self.load_line(victim_index, tag, address, is_write);
            
            (false, evicted_data)
        }
    }

    fn address_to_index_tag(&self, address: usize) -> (usize, usize) {
        let set_index = (address / self.line_size) % self.num_sets;
        let tag = address / (self.line_size * self.num_sets);
        (set_index, tag)
    }

    fn find_line(&self, set_index: usize, tag: usize) -> Option<usize> {
        let start = set_index * self.associativity;
        let end = start + self.associativity;
        
        for i in start..end {
            if self.lines[i].valid && self.lines[i].tag == tag {
                return Some(i);
            }
        }
        None
    }

    fn select_victim(&self, set_index: usize) -> usize {
        let start = set_index * self.associativity;
        let end = start + self.associativity;
        
        match self.replacement_policy {
            ReplacementPolicy::LRU => {
                let mut victim = start;
                let mut oldest = self.lines[start].lru_counter;
                
                for i in start..end {
                    if !self.lines[i].valid {
                        return i;
                    }
                    if self.lines[i].lru_counter < oldest {
                        oldest = self.lines[i].lru_counter;
                        victim = i;
                    }
                }
                victim
            }
            ReplacementPolicy::FIFO => {
                let mut victim = start;
                let mut oldest = self.lines[start].lru_counter;
                
                for i in start..end {
                    if !self.lines[i].valid {
                        return i;
                    }
                    if self.lines[i].lru_counter < oldest {
                        oldest = self.lines[i].lru_counter;
                        victim = i;
                    }
                }
                victim
            }
            ReplacementPolicy::Random => {
                use std::collections::hash_map::DefaultHasher;
                use std::hash::{Hash, Hasher};
                
                let mut hasher = DefaultHasher::new();
                self.clock.hash(&mut hasher);
                set_index.hash(&mut hasher);
                
                let hash = hasher.finish() as usize;
                start + (hash % self.associativity)
            }
            ReplacementPolicy::LFU => {
                let mut victim = start;
                let mut min_count = self.lines[start].access_count;
                
                for i in start..end {
                    if !self.lines[i].valid {
                        return i;
                    }
                    if self.lines[i].access_count < min_count {
                        min_count = self.lines[i].access_count;
                        victim = i;
                    }
                }
                victim
            }
        }
    }

    fn update_line_stats(&mut self, line_index: usize, is_write: bool) {
        self.lines[line_index].lru_counter = self.clock;
        self.lines[line_index].access_count += 1;
        
        if is_write {
            match self.write_policy {
                WritePolicy::WriteThrough => {
                    // 写直达：立即写回下一级
                    self.lines[line_index].dirty = false;
                }
                WritePolicy::WriteBack => {
                    // 写回：标记为脏
                    self.lines[line_index].dirty = true;
                }
                _ => {}
            }
        }
    }

    fn evict_line(&mut self, line_index: usize) -> Option<Vec<u8>> {
        if self.lines[line_index].valid && self.lines[line_index].dirty {
            Some(self.lines[line_index].data.clone())
        } else {
            None
        }
    }

    fn load_line(&mut self, line_index: usize, tag: usize, address: usize, is_write: bool) {
        self.lines[line_index].tag = tag;
        self.lines[line_index].valid = true;
        self.lines[line_index].lru_counter = self.clock;
        self.lines[line_index].access_count = 1;
        
        // 根据写策略决定是否标记为脏
        match self.write_policy {
            WritePolicy::WriteAllocate => {
                self.lines[line_index].dirty = is_write;
            }
            WritePolicy::NoWriteAllocate => {
                self.lines[line_index].dirty = false;
            }
            _ => {
                self.lines[line_index].dirty = false;
            }
        }
        
        // 这里应该从下一级加载数据，简化实现中省略
    }

    fn get_hit_rate(&self) -> f64 {
        if self.total_accesses > 0 {
            self.hits as f64 / self.total_accesses as f64
        } else {
            0.0
        }
    }

    fn get_miss_rate(&self) -> f64 {
        if self.total_accesses > 0 {
            self.misses as f64 / self.total_accesses as f64
        } else {
            0.0
        }
    }
}

// 内存层次
#[derive(Debug)]
struct MemoryHierarchy {
    levels: Vec<CacheLevel>,
    main_memory: HashMap<usize, u8>,
    memory_accesses: usize,
    total_latency: usize,
}

impl MemoryHierarchy {
    fn new() -> Self {
        let mut levels = Vec::new();
        
        // L1数据缓存：32KB，8路组相联，64字节行，写回策略
        levels.push(CacheLevel::new(
            64,
            64,
            8,
            ReplacementPolicy::LRU,
            WritePolicy::WriteBack,
        ));
        
        // L2缓存：256KB，8路组相联，64字节行，写回策略
        levels.push(CacheLevel::new(
            64,
            512,
            8,
            ReplacementPolicy::LRU,
            WritePolicy::WriteBack,
        ));
        
        // L3缓存：8MB，16路组相联，64字节行，写回策略
        levels.push(CacheLevel::new(
            64,
            8192,
            16,
            ReplacementPolicy::LRU,
            WritePolicy::WriteBack,
        ));
        
        Self {
            levels,
            main_memory: HashMap::new(),
            memory_accesses: 0,
            total_latency: 0,
        }
    }

    // 访问内存层次
    fn access(&mut self, address: usize, is_write: bool) -> (usize, Vec<u8>) {
        let mut current_latency = 0;
        let mut data = Vec::new();
        
        // 尝试在各级缓存中查找
        for (level, cache) in self.levels.iter_mut().enumerate() {
            current_latency += self.get_level_latency(level);
            
            let (hit, cache_data) = cache.access(address, is_write);
            if hit {
                if let Some(cached_data) = cache_data {
                    data = cached_data;
                }
                self.total_latency += current_latency;
                return (level, data);
            }
        }
        
        // 所有缓存都未命中，访问主内存
        current_latency += 100; // 主内存延迟
        self.memory_accesses += 1;
        self.total_latency += current_latency;
        
        // 从主内存读取数据（简化实现）
        data = vec![0; 64]; // 假设缓存行大小为64字节
        
        (self.levels.len(), data)
    }

    fn get_level_latency(&self, level: usize) -> usize {
        match level {
            0 => 1,   // L1缓存：1个周期
            1 => 10,  // L2缓存：10个周期
            2 => 50,  // L3缓存：50个周期
            _ => 100, // 主内存：100个周期
        }
    }

    // 获取整体命中率
    fn get_overall_hit_rate(&self) -> f64 {
        let mut total_hits = 0;
        let mut total_accesses = 0;
        
        for cache in &self.levels {
            total_hits += cache.hits;
            total_accesses += cache.total_accesses;
        }
        
        if total_accesses > 0 {
            total_hits as f64 / total_accesses as f64
        } else {
            0.0
        }
    }

    // 获取平均访问延迟
    fn get_average_latency(&self) -> f64 {
        let total_accesses = self.memory_accesses;
        for cache in &self.levels {
            total_accesses += cache.total_accesses;
        }
        
        if total_accesses > 0 {
            self.total_latency as f64 / total_accesses as f64
        } else {
            0.0
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_memory_hierarchy() {
        let mut hierarchy = MemoryHierarchy::new();
        
        // 测试局部性访问
        for i in 0..1000 {
            hierarchy.access(i * 64, false); // 读取
        }
        
        // 重复访问相同地址
        for _ in 0..100 {
            hierarchy.access(0, false);
        }
        
        let hit_rate = hierarchy.get_overall_hit_rate();
        let avg_latency = hierarchy.get_average_latency();
        
        assert!(hit_rate > 0.0);
        assert!(avg_latency > 0.0);
    }
}
```

### 3.2 预取器实现

```rust
use std::collections::HashMap;

// 预取策略
#[derive(Debug, Clone)]
enum PrefetchPolicy {
    None,
    Sequential,      // 顺序预取
    Stride,          // 步长预取
    Pattern,         // 模式预取
}

// 预取器
#[derive(Debug)]
struct Prefetcher {
    policy: PrefetchPolicy,
    stride_table: HashMap<usize, (usize, usize)>, // PC -> (stride, confidence)
    pattern_table: HashMap<usize, Vec<usize>>,    // PC -> 访问模式
    prefetch_queue: Vec<usize>,                   // 预取队列
    prefetch_hits: usize,
    prefetch_misses: usize,
}

impl Prefetcher {
    fn new(policy: PrefetchPolicy) -> Self {
        Self {
            policy,
            stride_table: HashMap::new(),
            pattern_table: HashMap::new(),
            prefetch_queue: Vec::new(),
            prefetch_hits: 0,
            prefetch_misses: 0,
        }
    }

    // 处理访问请求
    fn process_access(&mut self, pc: usize, address: usize) -> Vec<usize> {
        let mut prefetch_addresses = Vec::new();
        
        match self.policy {
            PrefetchPolicy::None => {}
            PrefetchPolicy::Sequential => {
                // 顺序预取：预取下一个缓存行
                let next_address = (address / 64 + 1) * 64;
                prefetch_addresses.push(next_address);
            }
            PrefetchPolicy::Stride => {
                // 步长预取
                if let Some((stride, confidence)) = self.stride_table.get_mut(&pc) {
                    if *confidence > 2 {
                        let next_address = address + *stride;
                        prefetch_addresses.push(next_address);
                    }
                }
                
                // 更新步长表
                self.update_stride_table(pc, address);
            }
            PrefetchPolicy::Pattern => {
                // 模式预取
                if let Some(pattern) = self.pattern_table.get_mut(&pc) {
                    if pattern.len() >= 2 {
                        // 基于历史模式预测下一个地址
                        let last_diff = pattern[pattern.len() - 1] - pattern[pattern.len() - 2];
                        let next_address = address + last_diff;
                        prefetch_addresses.push(next_address);
                    }
                }
                
                // 更新模式表
                self.update_pattern_table(pc, address);
            }
        }
        
        // 将预取地址加入队列
        self.prefetch_queue.extend(prefetch_addresses.clone());
        
        prefetch_addresses
    }

    fn update_stride_table(&mut self, pc: usize, address: usize) {
        if let Some((stride, confidence)) = self.stride_table.get_mut(&pc) {
            let new_stride = address - *stride;
            if new_stride == *stride {
                *confidence += 1;
            } else {
                *confidence = 0;
                *stride = new_stride;
            }
        } else {
            self.stride_table.insert(pc, (0, 0));
        }
    }

    fn update_pattern_table(&mut self, pc: usize, address: usize) {
        let pattern = self.pattern_table.entry(pc).or_insert_with(Vec::new);
        pattern.push(address);
        
        // 保持模式历史在合理范围内
        if pattern.len() > 10 {
            pattern.remove(0);
        }
    }

    // 检查预取命中
    fn check_prefetch_hit(&mut self, address: usize) -> bool {
        if let Some(index) = self.prefetch_queue.iter().position(|&x| x == address) {
            self.prefetch_queue.remove(index);
            self.prefetch_hits += 1;
            true
        } else {
            self.prefetch_misses += 1;
            false
        }
    }

    // 获取预取准确率
    fn get_prefetch_accuracy(&self) -> f64 {
        let total_prefetches = self.prefetch_hits + self.prefetch_misses;
        if total_prefetches > 0 {
            self.prefetch_hits as f64 / total_prefetches as f64
        } else {
            0.0
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_prefetcher() {
        let mut prefetcher = Prefetcher::new(PrefetchPolicy::Stride);
        
        // 测试步长访问模式
        for i in 0..100 {
            let address = i * 64;
            let pc = 0x1000;
            prefetcher.process_access(pc, address);
        }
        
        let accuracy = prefetcher.get_prefetch_accuracy();
        assert!(accuracy >= 0.0);
    }
}
```

### 3.3 内存控制器实现

```rust
use std::collections::VecDeque;

// 内存请求类型
#[derive(Debug, Clone)]
enum MemoryRequest {
    Read { address: usize, size: usize },
    Write { address: usize, data: Vec<u8> },
}

// 内存控制器
#[derive(Debug)]
struct MemoryController {
    request_queue: VecDeque<MemoryRequest>,
    current_request: Option<MemoryRequest>,
    busy_cycles: usize,
    total_cycles: usize,
    total_requests: usize,
    memory_banks: usize,
    bank_busy: Vec<usize>,
}

impl MemoryController {
    fn new(memory_banks: usize) -> Self {
        Self {
            request_queue: VecDeque::new(),
            current_request: None,
            busy_cycles: 0,
            total_cycles: 0,
            total_requests: 0,
            memory_banks,
            bank_busy: vec![0; memory_banks],
        }
    }

    // 提交内存请求
    fn submit_request(&mut self, request: MemoryRequest) {
        self.request_queue.push_back(request);
        self.total_requests += 1;
    }

    // 执行一个周期
    fn cycle(&mut self) -> Option<MemoryRequest> {
        self.total_cycles += 1;
        
        // 更新银行忙状态
        for bank in &mut self.bank_busy {
            if *bank > 0 {
                *bank -= 1;
            }
        }
        
        // 处理当前请求
        if let Some(ref request) = self.current_request {
            self.busy_cycles += 1;
            
            // 检查请求是否完成
            if self.is_request_complete(request) {
                let completed_request = self.current_request.take();
                return completed_request;
            }
        }
        
        // 开始处理新请求
        if self.current_request.is_none() {
            if let Some(request) = self.select_next_request() {
                self.current_request = Some(request.clone());
                self.start_request(&request);
            }
        }
        
        None
    }

    fn is_request_complete(&self, request: &MemoryRequest) -> bool {
        // 简化的完成条件：固定延迟
        match request {
            MemoryRequest::Read { .. } => self.busy_cycles >= 10,
            MemoryRequest::Write { .. } => self.busy_cycles >= 5,
        }
    }

    fn select_next_request(&mut self) -> Option<MemoryRequest> {
        // 简单的FIFO调度
        self.request_queue.pop_front()
    }

    fn start_request(&mut self, request: &MemoryRequest) {
        self.busy_cycles = 0;
        
        // 计算银行冲突
        let bank = match request {
            MemoryRequest::Read { address, .. } |
            MemoryRequest::Write { address, .. } => {
                address / 64 % self.memory_banks
            }
        };
        
        if self.bank_busy[bank] > 0 {
            // 银行冲突，增加延迟
            self.busy_cycles += self.bank_busy[bank];
        }
        
        // 设置银行忙状态
        self.bank_busy[bank] = match request {
            MemoryRequest::Read { .. } => 10,
            MemoryRequest::Write { .. } => 5,
        };
    }

    // 获取内存利用率
    fn get_memory_utilization(&self) -> f64 {
        if self.total_cycles > 0 {
            self.busy_cycles as f64 / self.total_cycles as f64
        } else {
            0.0
        }
    }

    // 获取平均延迟
    fn get_average_latency(&self) -> f64 {
        if self.total_requests > 0 {
            self.total_cycles as f64 / self.total_requests as f64
        } else {
            0.0
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_memory_controller() {
        let mut controller = MemoryController::new(4);
        
        // 提交一些内存请求
        for i in 0..10 {
            let request = MemoryRequest::Read {
                address: i * 64,
                size: 64,
            };
            controller.submit_request(request);
        }
        
        // 执行几个周期
        for _ in 0..50 {
            controller.cycle();
        }
        
        let utilization = controller.get_memory_utilization();
        let avg_latency = controller.get_average_latency();
        
        assert!(utilization >= 0.0 && utilization <= 1.0);
        assert!(avg_latency > 0.0);
    }
}
```

## 4. 应用场景

### 4.1 处理器设计

- 缓存层次设计
- 内存控制器设计
- 预取器设计

### 4.2 性能优化

- 缓存优化
- 内存带宽优化
- 延迟优化

### 4.3 系统设计

- 内存子系统设计
- 存储层次设计
- I/O系统设计

## 5. 相关理论

### 5.1 计算机组织

- 存储系统设计
- 内存管理
- 缓存设计

### 5.2 性能分析

- 内存性能建模
- 瓶颈分析
- 可扩展性分析

### 5.3 并行计算

- 内存一致性
- 缓存一致性
- 分布式存储

## 6. 参考文献

1. Hennessy, J. L., & Patterson, D. A. (2017). Computer Architecture: A Quantitative Approach.
2. Smith, A. J. (1982). Cache memories.
3. Jouppi, N. P. (1990). Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers.
4. Baer, J. L., & Chen, W. H. (1991). An effective on-chip preloading scheme for data caches.
5. Chen, T. F., & Baer, J. L. (1994). A performance study of software and hardware data prefetching schemes.


## 批判性分析

- 本节内容待补充：请从多元理论视角、局限性、争议点、应用前景等方面进行批判性分析。
