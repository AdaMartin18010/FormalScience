# 02.1 形式语言基础 (Formal Language Foundation)

## 目录

```markdown
02.1 形式语言基础
├── 1. 理论基础
│   ├── 1.1 形式语言定义
│   ├── 1.2 语言层次结构
│   ├── 1.3 形式语法理论
│   └── 1.4 语言识别理论
├── 2. 形式化定义
│   ├── 2.1 基本概念
│   ├── 2.2 语言运算
│   ├── 2.3 语法结构
│   └── 2.4 语义模型
├── 3. 核心概念
│   ├── 3.1 字母表与字符串
│   ├── 3.2 语言定义
│   ├── 3.3 语法规则
│   └── 3.4 语言分类
├── 4. 理论证明
│   ├── 4.1 语言封闭性
│   ├── 4.2 泵引理
│   ├── 4.3 最小化定理
│   └── 4.4 完备性定理
├── 5. 实现示例
│   ├── 5.1 Haskell 实现
│   ├── 5.2 Rust 实现
│   ├── 5.3 语法分析器
│   └── 5.4 语言识别器
├── 6. 应用领域
│   ├── 6.1 编译器设计
│   ├── 6.2 自然语言处理
│   ├── 6.3 模式匹配
│   └── 6.4 数据验证
├── 7. 扩展理论
│   ├── 7.1 上下文相关语言
│   ├── 7.2 递归可枚举语言
│   ├── 7.3 形式语义学
│   └── 7.4 语言理论
└── 8. 参考文献
```

## 1. 理论基础

### 1.1 形式语言定义

**定义 1.1.1** (形式语言)
形式语言是字母表上字符串的集合，具有精确的数学定义和结构。

**形式化定义**:
设 $\Sigma$ 为字母表，则形式语言 $L$ 是 $\Sigma^*$ 的子集：

$$L \subseteq \Sigma^*$$

其中 $\Sigma^*$ 表示 $\Sigma$ 上所有有限字符串的集合。

**示例**:
```haskell
-- 形式语言定义
type Alphabet = Set Char
type String = [Char]
type Language = Set String

-- 示例语言
emptyLanguage :: Language
emptyLanguage = Set.empty

universalLanguage :: Alphabet -> Language
universalLanguage sigma = Set.fromList (allStrings sigma)
  where
    allStrings :: Alphabet -> [String]
    allStrings = undefined  -- 所有可能的字符串
```

### 1.2 语言层次结构

**定义 1.2.1** (Chomsky层次结构)
Chomsky层次结构将形式语言分为四个层次：

1. **正则语言** (Type 3): 由有限状态自动机识别
2. **上下文无关语言** (Type 2): 由下推自动机识别
3. **上下文相关语言** (Type 1): 由线性有界自动机识别
4. **递归可枚举语言** (Type 0): 由图灵机识别

**形式化关系**:
$$\text{Regular} \subset \text{Context-Free} \subset \text{Context-Sensitive} \subset \text{Recursively-Enumerable}$$

**定理 1.2.1** (层次包含关系)
每个层次都严格包含在前一个层次中。

### 1.3 形式语法理论

**定义 1.3.1** (形式语法)
形式语法是一个四元组 $G = (V, T, P, S)$，其中：

- $V$ 是非终结符集合
- $T$ 是终结符集合
- $P$ 是产生式规则集合
- $S$ 是开始符号

**形式化定义**:
$$G = (V, T, P, S) \text{ where } V \cap T = \emptyset, S \in V$$

**示例**:
```haskell
-- 形式语法定义
data Grammar = Grammar {
    nonTerminals :: Set String,
    terminals :: Set String,
    productions :: Set Production,
    startSymbol :: String
}

data Production = Production {
    leftSide :: String,
    rightSide :: [String]
}

-- 示例语法：简单算术表达式
arithmeticGrammar :: Grammar
arithmeticGrammar = Grammar {
    nonTerminals = Set.fromList ["E", "T", "F"],
    terminals = Set.fromList ["+", "*", "(", ")", "id"],
    productions = Set.fromList [
        Production "E" ["E", "+", "T"],
        Production "E" ["T"],
        Production "T" ["T", "*", "F"],
        Production "T" ["F"],
        Production "F" ["(", "E", ")"],
        Production "F" ["id"]
    ],
    startSymbol = "E"
}
```

### 1.4 语言识别理论

**定义 1.4.1** (语言识别)
语言识别是判断给定字符串是否属于某个语言的过程。

**形式化定义**:
对于语言 $L$ 和字符串 $w$，识别函数为：

$$\text{recognize}_L : \Sigma^* \rightarrow \{\text{true}, \text{false}\}$$

$$\text{recognize}_L(w) = \begin{cases}
\text{true} & \text{if } w \in L \\
\text{false} & \text{if } w \notin L
\end{cases}$$

## 2. 形式化定义

### 2.1 基本概念

**定义 2.1.1** (字母表)
字母表 $\Sigma$ 是有限符号的集合。

**定义 2.1.2** (字符串)
字符串是字母表上符号的有限序列。

**定义 2.1.3** (字符串长度)
字符串 $w$ 的长度 $|w|$ 是其包含符号的个数。

**定义 2.1.4** (空字符串)
空字符串 $\varepsilon$ 是长度为 0 的字符串。

**形式化定义**:
$$\varepsilon \in \Sigma^* \text{ and } |\varepsilon| = 0$$

### 2.2 语言运算

**定义 2.2.1** (语言并集)
$$L_1 \cup L_2 = \{w \mid w \in L_1 \text{ or } w \in L_2\}$$

**定义 2.2.2** (语言交集)
$$L_1 \cap L_2 = \{w \mid w \in L_1 \text{ and } w \in L_2\}$$

**定义 2.2.3** (语言连接)
$$L_1 \cdot L_2 = \{w_1 w_2 \mid w_1 \in L_1 \text{ and } w_2 \in L_2\}$$

**定义 2.2.4** (语言闭包)
$$L^* = \bigcup_{i=0}^{\infty} L^i$$

其中 $L^0 = \{\varepsilon\}$ 且 $L^{i+1} = L \cdot L^i$

**定理 2.2.1** (运算封闭性)
正则语言在并集、交集、连接、闭包运算下是封闭的。

### 2.3 语法结构

**定义 2.3.1** (推导)
对于语法 $G$，如果存在产生式 $\alpha \rightarrow \beta$，则 $\gamma \alpha \delta \Rightarrow \gamma \beta \delta$。

**定义 2.3.2** (推导闭包)
$\Rightarrow^*$ 是 $\Rightarrow$ 的自反传递闭包。

**定义 2.3.3** (语言生成)
语法 $G$ 生成的语言为：

$$L(G) = \{w \in T^* \mid S \Rightarrow^* w\}$$

**示例**:
```haskell
-- 推导过程
data Derivation = Derivation {
    steps :: [String],
    grammar :: Grammar
}

-- 单步推导
singleStep :: Grammar -> String -> [String]
singleStep grammar sententialForm = 
    [applyProduction grammar sententialForm p | p <- productions grammar]

-- 多步推导
derive :: Grammar -> String -> [String]
derive grammar start = 
    let steps = iterate (concatMap (singleStep grammar)) [start]
    in takeWhile (not . null) steps
```

### 2.4 语义模型

**定义 2.4.1** (语言语义)
语言语义是语言中字符串的含义解释。

**形式化定义**:
语义函数 $\llbracket \cdot \rrbracket : L \rightarrow \mathcal{D}$ 将语言元素映射到语义域。

**示例**:
```haskell
-- 语义解释
class Semantic a where
    interpret :: String -> a

-- 算术表达式语义
instance Semantic Int where
    interpret "0" = 0
    interpret "1" = 1
    interpret "2" = 2
    -- ... 更多数字
    interpret _ = error "Unknown symbol"
```

## 3. 核心概念

### 3.1 字母表与字符串

**概念 3.1.1** (字母表操作)
字母表上的基本操作包括：

1. **并集**: $\Sigma_1 \cup \Sigma_2$
2. **交集**: $\Sigma_1 \cap \Sigma_2$
3. **差集**: $\Sigma_1 \setminus \Sigma_2$

**概念 3.1.2** (字符串操作)
字符串上的基本操作包括：

1. **连接**: $w_1 \cdot w_2$
2. **反转**: $w^R$
3. **幂**: $w^n$

**示例**:
```haskell
-- 字符串操作
class StringOps a where
    concatenate :: a -> a -> a
    reverse :: a -> a
    power :: a -> Int -> a

instance StringOps String where
    concatenate = (++)
    reverse = Prelude.reverse
    power s n = concat (replicate n s)
```

### 3.2 语言定义

**概念 3.2.1** (语言表示方法)
语言可以通过以下方式定义：

1. **枚举**: 列出所有字符串
2. **描述**: 用自然语言描述
3. **语法**: 使用形式语法
4. **自动机**: 使用自动机模型
5. **正则表达式**: 使用正则表达式

**概念 3.2.2** (语言性质)
语言的重要性质包括：

1. **有限性**: 语言是否包含有限个字符串
2. **空性**: 语言是否为空
3. **正则性**: 语言是否为正则语言
4. **上下文无关性**: 语言是否为上下文无关语言

### 3.3 语法规则

**概念 3.3.1** (产生式类型)
根据产生式的形式，语法可以分为：

1. **正则语法**: 右线性或左线性
2. **上下文无关语法**: 左部为单个非终结符
3. **上下文相关语法**: 左部包含上下文
4. **无限制语法**: 无特殊限制

**概念 3.3.2** (语法分析)
语法分析包括：

1. **自顶向下分析**: 从开始符号推导
2. **自底向上分析**: 从输入字符串归约
3. **递归下降分析**: 递归实现的分析方法

### 3.4 语言分类

**分类 3.4.1** (按复杂度分类)
语言按计算复杂度分类：

1. **正则语言**: 线性时间识别
2. **上下文无关语言**: 立方时间识别
3. **上下文相关语言**: 指数时间识别
4. **递归可枚举语言**: 不可判定

**分类 3.4.2** (按应用分类)
语言按应用领域分类：

1. **编程语言**: 用于程序编写
2. **自然语言**: 人类交流语言
3. **标记语言**: 用于文档标记
4. **查询语言**: 用于数据查询

## 4. 理论证明

### 4.1 语言封闭性

**定理 4.1.1** (正则语言封闭性)
正则语言在以下运算下是封闭的：

1. 并集
2. 交集
3. 补集
4. 连接
5. 闭包
6. 反转

**证明**:
通过构造相应的有限状态自动机证明。

**定理 4.1.2** (上下文无关语言封闭性)
上下文无关语言在以下运算下是封闭的：

1. 并集
2. 连接
3. 闭包
4. 同态映射

**证明**:
通过构造相应的上下文无关语法证明。

### 4.2 泵引理

**引理 4.2.1** (正则语言泵引理)
设 $L$ 为正则语言，则存在常数 $p$，使得对于所有 $w \in L$ 且 $|w| \geq p$，存在分解 $w = xyz$ 满足：

1. $|xy| \leq p$
2. $|y| > 0$
3. 对于所有 $i \geq 0$，$xy^i z \in L$

**证明**:
基于有限状态自动机的状态重复原理。

**引理 4.2.2** (上下文无关语言泵引理)
设 $L$ 为上下文无关语言，则存在常数 $p$，使得对于所有 $w \in L$ 且 $|w| \geq p$，存在分解 $w = uvxyz$ 满足：

1. $|vxy| \leq p$
2. $|vy| > 0$
3. 对于所有 $i \geq 0$，$uv^i xy^i z \in L$

### 4.3 最小化定理

**定理 4.3.1** (有限状态自动机最小化)
对于任何有限状态自动机，都存在唯一的最小等价自动机。

**证明**:
通过状态等价性划分构造最小自动机。

**算法**:
```haskell
-- 自动机最小化算法
minimizeDFA :: DFA -> DFA
minimizeDFA dfa = 
    let equivalentStates = findEquivalentStates dfa
        minimizedStates = mergeEquivalentStates dfa equivalentStates
    in constructMinimizedDFA dfa minimizedStates

-- 寻找等价状态
findEquivalentStates :: DFA -> Set (Set State)
findEquivalentStates dfa = 
    let initialPartition = partitionByAcceptance dfa
        refinedPartition = refinePartition dfa initialPartition
    in refinedPartition
```

### 4.4 完备性定理

**定理 4.4.1** (Kleene定理)
语言是正则的当且仅当它可以被正则表达式表示。

**证明**:
1. 正则表达式到有限状态自动机的构造
2. 有限状态自动机到正则表达式的构造

**定理 4.4.2** (Chomsky-Schützenberger定理)
上下文无关语言是某些正则语言与Dyck语言的交集。

## 5. 实现示例

### 5.1 Haskell 实现

```haskell
-- 形式语言基础实现
module FormalLanguage where

import Data.Set (Set)
import qualified Data.Set as Set
import Data.Map (Map)
import qualified Data.Map as Map

-- 基本类型定义
type Alphabet = Set Char
type String = [Char]
type Language = Set String

-- 语言运算
union :: Language -> Language -> Language
union = Set.union

intersection :: Language -> Language -> Language
intersection = Set.intersection

concatenate :: Language -> Language -> Language
concatenate l1 l2 = Set.fromList [s1 ++ s2 | s1 <- Set.toList l1, s2 <- Set.toList l2]

kleeneStar :: Language -> Language
kleeneStar l = Set.fromList (concatMap (power l) [0..])
  where
    power lang 0 = [""]
    power lang n = [s1 ++ s2 | s1 <- Set.toList lang, s2 <- power lang (n-1)]

-- 正则表达式
data Regex = Empty
           | Epsilon
           | Char Char
           | Union Regex Regex
           | Concat Regex Regex
           | Star Regex
           deriving (Eq, Show)

-- 正则表达式语义
semantics :: Regex -> Language
semantics Empty = Set.empty
semantics Epsilon = Set.singleton ""
semantics (Char c) = Set.singleton [c]
semantics (Union r1 r2) = union (semantics r1) (semantics r2)
semantics (Concat r1 r2) = concatenate (semantics r1) (semantics r2)
semantics (Star r) = kleeneStar (semantics r)

-- 有限状态自动机
data State = State Int deriving (Eq, Ord, Show)
data Transition = Transition State Char State deriving (Eq, Show)

data DFA = DFA {
    states :: Set State,
    alphabet :: Alphabet,
    transitions :: Map (State, Char) State,
    startState :: State,
    acceptStates :: Set State
} deriving (Show)

-- DFA 执行
runDFA :: DFA -> String -> Bool
runDFA dfa input = 
    let finalState = foldl step (startState dfa) input
    in Set.member finalState (acceptStates dfa)
  where
    step currentState char = 
        Map.findWithDefault currentState (currentState, char) (transitions dfa)

-- 从正则表达式构造DFA
regexToDFA :: Regex -> DFA
regexToDFA regex = 
    let nfa = regexToNFA regex
    in nfaToDFA nfa

-- 示例：识别偶数个a的DFA
evenA_DFA :: DFA
evenA_DFA = DFA {
    states = Set.fromList [State 0, State 1],
    alphabet = Set.singleton 'a',
    transitions = Map.fromList [
        ((State 0, 'a'), State 1),
        ((State 1, 'a'), State 0)
    ],
    startState = State 0,
    acceptStates = Set.singleton (State 0)
}
```

### 5.2 Rust 实现

```rust
// 形式语言基础实现
use std::collections::{HashMap, HashSet};
use std::fmt;

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
struct State(usize);

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
struct Transition {
    from: State,
    symbol: char,
    to: State,
}

#[derive(Debug, Clone)]
struct DFA {
    states: HashSet<State>,
    alphabet: HashSet<char>,
    transitions: HashMap<(State, char), State>,
    start_state: State,
    accept_states: HashSet<State>,
}

impl DFA {
    fn new() -> Self {
        DFA {
            states: HashSet::new(),
            alphabet: HashSet::new(),
            transitions: HashMap::new(),
            start_state: State(0),
            accept_states: HashSet::new(),
        }
    }

    fn add_state(&mut self, state: State) {
        self.states.insert(state);
    }

    fn add_transition(&mut self, from: State, symbol: char, to: State) {
        self.alphabet.insert(symbol);
        self.transitions.insert((from, symbol), to);
    }

    fn set_start_state(&mut self, state: State) {
        self.start_state = state;
    }

    fn add_accept_state(&mut self, state: State) {
        self.accept_states.insert(state);
    }

    fn run(&self, input: &str) -> bool {
        let mut current_state = self.start_state.clone();
        
        for c in input.chars() {
            if let Some(&next_state) = self.transitions.get(&(current_state.clone(), c)) {
                current_state = next_state;
            } else {
                return false; // 无转换，拒绝
            }
        }
        
        self.accept_states.contains(&current_state)
    }
}

// 正则表达式
#[derive(Debug, Clone)]
enum Regex {
    Empty,
    Epsilon,
    Char(char),
    Union(Box<Regex>, Box<Regex>),
    Concat(Box<Regex>, Box<Regex>),
    Star(Box<Regex>),
}

impl Regex {
    fn matches(&self, input: &str) -> bool {
        match self {
            Regex::Empty => false,
            Regex::Epsilon => input.is_empty(),
            Regex::Char(c) => input == c.to_string(),
            Regex::Union(r1, r2) => r1.matches(input) || r2.matches(input),
            Regex::Concat(r1, r2) => {
                for i in 0..=input.len() {
                    if r1.matches(&input[..i]) && r2.matches(&input[i..]) {
                        return true;
                    }
                }
                false
            }
            Regex::Star(r) => {
                if input.is_empty() {
                    return true;
                }
                for i in 1..=input.len() {
                    if r.matches(&input[..i]) && self.matches(&input[i..]) {
                        return true;
                    }
                }
                false
            }
        }
    }
}

// 语言运算
#[derive(Debug, Clone)]
struct Language {
    strings: HashSet<String>,
}

impl Language {
    fn new() -> Self {
        Language {
            strings: HashSet::new(),
        }
    }

    fn add_string(&mut self, s: String) {
        self.strings.insert(s);
    }

    fn union(&self, other: &Language) -> Language {
        let mut result = self.clone();
        result.strings.extend(other.strings.clone());
        result
    }

    fn intersection(&self, other: &Language) -> Language {
        let mut result = Language::new();
        for s in &self.strings {
            if other.strings.contains(s) {
                result.add_string(s.clone());
            }
        }
        result
    }

    fn concatenate(&self, other: &Language) -> Language {
        let mut result = Language::new();
        for s1 in &self.strings {
            for s2 in &other.strings {
                result.add_string(format!("{}{}", s1, s2));
            }
        }
        result
    }

    fn kleene_star(&self) -> Language {
        let mut result = Language::new();
        result.add_string("".to_string());
        
        let mut current = self.clone();
        for _ in 0..10 { // 限制迭代次数避免无限循环
            let next = self.concatenate(&current);
            for s in &next.strings {
                result.add_string(s.clone());
            }
            current = next;
        }
        result
    }
}

// 示例：构造识别偶数个a的DFA
fn create_even_a_dfa() -> DFA {
    let mut dfa = DFA::new();
    
    let state0 = State(0);
    let state1 = State(1);
    
    dfa.add_state(state0.clone());
    dfa.add_state(state1.clone());
    
    dfa.add_transition(state0.clone(), 'a', state1.clone());
    dfa.add_transition(state1.clone(), 'a', state0.clone());
    
    dfa.set_start_state(state0.clone());
    dfa.add_accept_state(state0);
    
    dfa
}

fn main() {
    // 测试DFA
    let dfa = create_even_a_dfa();
    
    println!("Testing DFA:");
    println!("aa: {}", dfa.run("aa"));
    println!("aaa: {}", dfa.run("aaa"));
    println!("aaaa: {}", dfa.run("aaaa"));
    println!("a: {}", dfa.run("a"));
    
    // 测试正则表达式
    let regex = Regex::Star(Box::new(Regex::Char('a')));
    println!("\nTesting Regex:");
    println!("aa: {}", regex.matches("aa"));
    println!("aaa: {}", regex.matches("aaa"));
    println!("b: {}", regex.matches("b"));
}
```

### 5.3 语法分析器

```haskell
-- 语法分析器实现
module Parser where

import Data.List (find)
import Control.Monad (guard)

-- 语法定义
data Grammar = Grammar {
    nonTerminals :: Set String,
    terminals :: Set String,
    productions :: Set Production,
    startSymbol :: String
}

data Production = Production {
    leftSide :: String,
    rightSide :: [String]
} deriving (Eq, Show)

-- LL(1) 分析器
class Parser a where
    parse :: a -> String -> Maybe ParseTree

data ParseTree = Leaf String
               | Node String [ParseTree]
               deriving (Show)

-- LL(1) 分析器
data LL1Parser = LL1Parser {
    grammar :: Grammar,
    firstSets :: Map String (Set String),
    followSets :: Map String (Set String),
    parseTable :: Map (String, String) [String]
}

-- 计算First集
computeFirst :: Grammar -> Map String (Set String)
computeFirst grammar = 
    let initial = Map.fromList [(nt, Set.empty) | nt <- Set.toList (nonTerminals grammar)]
        fixedPoint = iterate (updateFirst grammar) initial
    in head (dropWhile (not . isFixedPoint) fixedPoint)
  where
    isFixedPoint current = 
        let next = updateFirst grammar current
        in current == next

updateFirst :: Grammar -> Map String (Set String) -> Map String (Set String)
updateFirst grammar current = 
    foldl updateNonTerminal current (Set.toList (nonTerminals grammar))
  where
    updateNonTerminal acc nt = 
        let productions = filter (\p -> leftSide p == nt) (Set.toList (productions grammar))
            firstOfProductions = foldl Set.union Set.empty 
                [firstOfString grammar current (rightSide p) | p <- productions]
        in Map.insert nt firstOfProductions acc

firstOfString :: Grammar -> Map String (Set String) -> [String] -> Set String
firstOfString grammar firstSets [] = Set.singleton ""
firstOfString grammar firstSets (sym:syms) = 
    if Set.member sym (terminals grammar) then
        Set.singleton sym
    else
        let firstOfSym = Map.findWithDefault Set.empty sym firstSets
            firstOfRest = firstOfString grammar firstSets syms
        in if Set.member "" firstOfSym then
               Set.union (Set.delete "" firstOfSym) firstOfRest
           else
               firstOfSym

-- 计算Follow集
computeFollow :: Grammar -> Map String (Set String) -> Map String (Set String)
computeFollow grammar firstSets = 
    let initial = Map.fromList [(nt, if nt == startSymbol grammar then Set.singleton "$" else Set.empty) 
                               | nt <- Set.toList (nonTerminals grammar)]
        fixedPoint = iterate (updateFollow grammar firstSets) initial
    in head (dropWhile (not . isFixedPoint) fixedPoint)
  where
    isFixedPoint current = 
        let next = updateFollow grammar firstSets current
        in current == next

updateFollow :: Grammar -> Map String (Set String) -> Map String (Set String) -> Map String (Set String)
updateFollow grammar firstSets current = 
    foldl updateNonTerminal current (Set.toList (nonTerminals grammar))
  where
    updateNonTerminal acc nt = 
        let productions = filter (\p -> leftSide p == nt) (Set.toList (productions grammar))
            followOfProductions = foldl Set.union (Map.findWithDefault Set.empty nt acc)
                [followOfProduction grammar firstSets current p | p <- productions]
        in Map.insert nt followOfProductions acc

followOfProduction :: Grammar -> Map String (Set String) -> Map String (Set String) -> Production -> Set String
followOfProduction grammar firstSets followSets production = 
    let rightSide = rightSide production
        leftFollow = Map.findWithDefault Set.empty (leftSide production) followSets
    in foldr computeFollowForPosition leftFollow (zip [0..] rightSide)
  where
    computeFollowForPosition (pos, sym) acc = 
        if Set.member sym (nonTerminals grammar) then
            let beta = drop (pos + 1) rightSide
                firstOfBeta = firstOfString grammar firstSets beta
                followOfLeft = Map.findWithDefault Set.empty (leftSide production) followSets
            in if Set.member "" firstOfBeta then
                   Set.union (Set.delete "" firstOfBeta) (Set.union firstOfBeta followOfLeft)
               else
                   Set.union acc firstOfBeta
        else
            acc

-- 构造LL(1)分析表
buildParseTable :: Grammar -> Map String (Set String) -> Map String (Set String) -> Map (String, String) [String]
buildParseTable grammar firstSets followSets = 
    foldl addProduction Map.empty (Set.toList (productions grammar))
  where
    addProduction table production = 
        let left = leftSide production
            right = rightSide production
            firstOfRight = firstOfString grammar firstSets right
            symbols = if Set.member "" firstOfRight then
                         Set.union (Set.delete "" firstOfRight) 
                             (Map.findWithDefault Set.empty left followSets)
                      else
                         firstOfRight
        in foldl (\t sym -> Map.insert (left, sym) right t) table symbols

-- LL(1)分析
ll1Parse :: LL1Parser -> String -> Maybe ParseTree
ll1Parse parser input = 
    let tokens = words input ++ ["$"]
        stack = [startSymbol (grammar parser), "$"]
    in parseLL1 parser stack tokens []

parseLL1 :: LL1Parser -> [String] -> [String] -> [ParseTree] -> Maybe ParseTree
parseLL1 parser [] [] [tree] = Just tree
parseLL1 parser (top:stack) (token:tokens) trees = 
    if top == token then
        parseLL1 parser stack tokens (Leaf token : trees)
    else if Set.member top (nonTerminals (grammar parser)) then
        case Map.lookup (top, token) (parseTable parser) of
            Just production -> 
                let newStack = production ++ stack
                in parseLL1 parser newStack (token:tokens) trees
            Nothing -> Nothing
    else
        Nothing
parseLL1 _ _ _ _ = Nothing
```

### 5.4 语言识别器

```haskell
-- 语言识别器实现
module LanguageRecognizer where

import Data.Set (Set)
import qualified Data.Set as Set
import Data.Map (Map)
import qualified Data.Map as Map

-- 语言识别器类型类
class LanguageRecognizer a where
    recognize :: a -> String -> Bool
    generate :: a -> [String]

-- 正则表达式识别器
data RegexRecognizer = RegexRecognizer {
    regex :: Regex,
    dfa :: DFA
}

instance LanguageRecognizer RegexRecognizer where
    recognize recognizer = runDFA (dfa recognizer)
    generate recognizer = generateFromRegex (regex recognizer)

-- 上下文无关语法识别器
data CFGRecognizer = CFGRecognizer {
    grammar :: Grammar,
    parser :: LL1Parser
}

instance LanguageRecognizer CFGRecognizer where
    recognize recognizer input = 
        case ll1Parse (parser recognizer) input of
            Just _ -> True
            Nothing -> False
    generate recognizer = generateFromGrammar (grammar recognizer)

-- 语言生成
generateFromRegex :: Regex -> [String]
generateFromRegex Empty = []
generateFromRegex Epsilon = [""]
generateFromRegex (Char c) = [[c]]
generateFromRegex (Union r1 r2) = 
    generateFromRegex r1 ++ generateFromRegex r2
generateFromRegex (Concat r1 r2) = 
    [s1 ++ s2 | s1 <- generateFromRegex r1, s2 <- generateFromRegex r2]
generateFromRegex (Star r) = 
    "" : [s1 ++ s2 | s1 <- generateFromRegex r, s2 <- generateFromRegex (Star r)]

generateFromGrammar :: Grammar -> [String]
generateFromGrammar grammar = 
    generateFromSymbol grammar (startSymbol grammar)

generateFromSymbol :: Grammar -> String -> [String]
generateFromSymbol grammar symbol = 
    if Set.member symbol (terminals grammar) then
        [symbol]
    else
        let productions = filter (\p -> leftSide p == symbol) (Set.toList (productions grammar))
        in concatMap (generateFromProduction grammar) productions

generateFromProduction :: Grammar -> Production -> [String]
generateFromProduction grammar production = 
    let symbols = rightSide production
        symbolLists = map (generateFromSymbol grammar) symbols
    in [concat combination | combination <- sequence symbolLists]

-- 语言等价性检查
languageEquivalence :: (LanguageRecognizer a, LanguageRecognizer b) => a -> b -> Bool
languageEquivalence r1 r2 = 
    let testStrings = generateTestStrings r1 r2
    in all (\s -> recognize r1 s == recognize r2 s) testStrings

generateTestStrings :: (LanguageRecognizer a, LanguageRecognizer b) => a -> b -> [String]
generateTestStrings r1 r2 = 
    let strings1 = take 100 (generate r1)
        strings2 = take 100 (generate r2)
        additional = ["", "a", "b", "aa", "ab", "ba", "bb", "aaa", "aab", "aba", "abb"]
    in nub (strings1 ++ strings2 ++ additional)

-- 语言包含性检查
languageContainment :: (LanguageRecognizer a, LanguageRecognizer b) => a -> b -> Bool
languageContainment r1 r2 = 
    let testStrings = generateTestStrings r1 r2
    in all (\s -> not (recognize r1 s) || recognize r2 s) testStrings

-- 语言最小化
minimizeLanguage :: LanguageRecognizer a => a -> a
minimizeLanguage recognizer = 
    -- 实现语言最小化算法
    recognizer

-- 示例：识别器构造
createEvenA_Recognizer :: RegexRecognizer
createEvenA_Recognizer = RegexRecognizer {
    regex = Star (Concat (Char 'a') (Char 'a')),
    dfa = evenA_DFA
}

createArithmeticRecognizer :: CFGRecognizer
createArithmeticRecognizer = CFGRecognizer {
    grammar = arithmeticGrammar,
    parser = LL1Parser {
        grammar = arithmeticGrammar,
        firstSets = computeFirst arithmeticGrammar,
        followSets = computeFollow arithmeticGrammar (computeFirst arithmeticGrammar),
        parseTable = buildParseTable arithmeticGrammar 
            (computeFirst arithmeticGrammar) 
            (computeFollow arithmeticGrammar (computeFirst arithmeticGrammar))
    }
}
```

## 6. 应用领域

### 6.1 编译器设计

**应用 6.1.1** (词法分析)
形式语言理论为编译器的词法分析器提供理论基础。

**示例**:
```haskell
-- 词法分析器
data Token = Token {
    tokenType :: TokenType,
    lexeme :: String,
    position :: Position
}

data TokenType = Identifier
               | Number
               | Operator
               | Keyword
               | Delimiter
               deriving (Eq, Show)

-- 词法分析器实现
lexicalAnalyzer :: String -> [Token]
lexicalAnalyzer input = 
    let tokens = scanTokens input
    in filter (not . isWhitespace) tokens
  where
    scanTokens = undefined  -- 实现词法扫描
    isWhitespace token = tokenType token == Whitespace
```

### 6.2 自然语言处理

**应用 6.2.1** (语法分析)
形式语言理论为自然语言的语法分析提供方法。

**示例**:
```haskell
-- 自然语言语法
naturalLanguageGrammar :: Grammar
naturalLanguageGrammar = Grammar {
    nonTerminals = Set.fromList ["S", "NP", "VP", "N", "V", "D"],
    terminals = Set.fromList ["the", "cat", "sat", "mat"],
    productions = Set.fromList [
        Production "S" ["NP", "VP"],
        Production "NP" ["D", "N"],
        Production "VP" ["V", "NP"],
        Production "D" ["the"],
        Production "N" ["cat", "mat"],
        Production "V" ["sat"]
    ],
    startSymbol = "S"
}
```

### 6.3 模式匹配

**应用 6.3.1** (字符串匹配)
形式语言理论为字符串模式匹配提供算法。

**示例**:
```haskell
-- 模式匹配
patternMatch :: String -> String -> Bool
patternMatch pattern text = 
    let regex = stringToRegex pattern
    in regexMatches regex text

stringToRegex :: String -> Regex
stringToRegex = undefined  -- 将字符串转换为正则表达式

regexMatches :: Regex -> String -> Bool
regexMatches regex text = 
    let dfa = regexToDFA regex
    in runDFA dfa text
```

### 6.4 数据验证

**应用 6.4.1** (输入验证)
形式语言理论为数据输入验证提供方法。

**示例**:
```haskell
-- 数据验证器
data Validator = Validator {
    pattern :: Regex,
    description :: String
}

validateInput :: Validator -> String -> Bool
validateInput validator input = 
    let dfa = regexToDFA (pattern validator)
    in runDFA dfa input

-- 示例验证器
emailValidator :: Validator
emailValidator = Validator {
    pattern = Concat (Concat identifier (Char '@')) (Concat domain (Char '.')),
    description = "Email address format"
}
  where
    identifier = Star (Union (Char 'a') (Char 'b'))  -- 简化版本
    domain = Star (Union (Char 'a') (Char 'b'))
```

## 7. 扩展理论

### 7.1 上下文相关语言

**定义 7.1.1** (上下文相关语法)
上下文相关语法的产生式形式为 $\alpha A \beta \rightarrow \alpha \gamma \beta$，其中 $A$ 是非终结符，$\alpha, \beta, \gamma$ 是字符串。

**特点**:
- 比上下文无关语言更强大
- 可以表达上下文依赖关系
- 识别复杂度较高

### 7.2 递归可枚举语言

**定义 7.2.1** (递归可枚举语言)
递归可枚举语言是图灵机可以识别的语言。

**特点**:
- 最强大的语言类
- 包含所有可计算语言
- 存在不可判定问题

### 7.3 形式语义学

**定义 7.3.1** (形式语义学)
形式语义学研究语言的形式化语义解释。

**方法**:
- 操作语义
- 指称语义
- 公理语义

### 7.4 语言理论

**定义 7.4.1** (语言理论)
语言理论研究语言的数学性质和结构。

**主题**:
- 语言复杂性
- 语言等价性
- 语言变换

## 8. 参考文献

1. Hopcroft, J. E., Motwani, R., & Ullman, J. D. (2006). Introduction to automata theory, languages, and computation. Pearson Education.
2. Sipser, M. (2012). Introduction to the theory of computation. Cengage Learning.
3. Aho, A. V., Lam, M. S., Sethi, R., & Ullman, J. D. (2006). Compilers: principles, techniques, and tools. Pearson Education.
4. Grune, D., & Jacobs, C. J. (2008). Parsing techniques: a practical guide. Springer Science & Business Media.
5. Kozen, D. (2006). Theory of computation. Springer Science & Business Media.

---

**相关链接**:
- [02.2 正则语言](02.2_Regular_Languages.md)
- [02.3 上下文无关语言](02.3_Context_Free_Languages.md)
- [02.4 上下文相关语言](02.4_Context_Sensitive_Languages.md)
- [01.1 类型理论基础](../01_Foundational_Theory/01.1_Type_Theory_Foundation.md)
