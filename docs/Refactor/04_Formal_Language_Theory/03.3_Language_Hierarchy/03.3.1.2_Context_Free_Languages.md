# 03.3.1.2 上下文无关语言 (Context-Free Languages)

## 📚 概述与定义

上下文无关语言是乔姆斯基层次结构中的第二类语言（2型语言），在形式语言理论和计算机科学中具有重要意义。

### 定义与特征

**定义 1.1** (上下文无关语言)
语言 $L$ 是上下文无关的，当且仅当存在上下文无关文法 $G$，使得 $L = L(G)$。

**特征**:

- 具有递归结构
- 能够表示嵌套匹配关系（如括号匹配）
- 支持上下文无关文法和下推自动机建模
- 具有泵引理

### 与其他语言类的关系

上下文无关语言在乔姆斯基谱系中处于中间层次：

- $\mathcal{L}_\text{Regular} \subset \mathcal{L}_\text{Context-Free} \subset \mathcal{L}_\text{Context-Sensitive}$
- 比正则语言表达能力更强，能处理嵌套结构
- 比上下文相关语言表达能力更弱，不能处理交叉依赖

### 基本性质

- **递归性**: 可以通过递归结构表示
- **嵌套性**: 能处理嵌套依赖关系
- **闭包性**: 在并、连接、星闭包等操作下保持封闭
- **可判定性**: 成员资格、空性问题可判定，等价性问题不可判定

## 🔍 表示方法

### 上下文无关文法

**定义 2.1** (上下文无关文法)
上下文无关文法是四元组 $G = (V, \Sigma, P, S)$，其中：

- $V$ 是非终结符集
- $\Sigma$ 是终结符集
- $P$ 是产生式规则集，每个规则形式为 $A \to \alpha$，其中 $A \in V$ 且 $\alpha \in (V \cup \Sigma)^*$
- $S \in V$ 是开始符号

**例子**:
文法 $G = (\{S\}, \{a, b\}, P, S)$，其中 $P = \{S \to aSb \mid \varepsilon\}$，生成语言 $L(G) = \{a^n b^n \mid n \geq 0\}$。

### 下推自动机

**定义 2.2** (下推自动机，PDA)
下推自动机是七元组 $M = (Q, \Sigma, \Gamma, \delta, q_0, Z_0, F)$，其中：

- $Q$ 是状态集
- $\Sigma$ 是输入字母表
- $\Gamma$ 是栈字母表
- $\delta: Q \times (\Sigma \cup \{\varepsilon\}) \times \Gamma \to 2^{Q \times \Gamma^*}$ 是转移函数
- $q_0 \in Q$ 是初始状态
- $Z_0 \in \Gamma$ 是初始栈符号
- $F \subseteq Q$ 是接受状态集

**定理 2.3** (PDA等价性)
语言 $L$ 是上下文无关的，当且仅当存在PDA $M$，使得 $L = L(M)$。

### 派生树与句型

**定义 2.4** (派生树)
派生树是表示句子推导过程的树形结构：

- 根节点是开始符号
- 内部节点是非终结符
- 叶节点是终结符或 $\varepsilon$
- 每个内部节点及其直接子节点对应一个产生式应用

**定义 2.5** (句型)
在推导过程中出现的字符串称为句型。如果句型中只包含终结符，则称为句子。

## 🧠 理论基础

### 文法转换和规范形式

**定理 3.1** (Chomsky范式)
每个上下文无关文法都可以转换为Chomsky范式，其中每个产生式形式为：

- $A \to BC$ (其中 $A, B, C \in V$)
- $A \to a$ (其中 $A \in V, a \in \Sigma$)

**定理 3.2** (Greibach范式)
每个上下文无关文法都可以转换为Greibach范式，其中每个产生式形式为：

- $A \to a\alpha$ (其中 $A \in V, a \in \Sigma, \alpha \in V^*$)

**算法 3.3** (消除ε-产生式)

```rust
fn eliminate_epsilon_productions(grammar: &CFG) -> CFG {
    // 1. 找出所有可以推导出ε的非终结符
    let mut nullable = HashSet::new();
    let mut changed = true;
    
    while changed {
        changed = false;
        for (A, productions) in &grammar.productions {
            if !nullable.contains(A) {
                for rhs in productions {
                    if rhs.is_empty() || rhs.iter().all(|symbol| nullable.contains(symbol)) {
                        nullable.insert(A.clone());
                        changed = true;
                        break;
                    }
                }
            }
        }
    }
    
    // 2. 构造新的产生式规则
    let mut new_productions = HashMap::new();
    
    for (A, productions) in &grammar.productions {
        let mut new_prods = Vec::new();
        
        for rhs in productions {
            // 原始产生式（如果不是ε产生式）
            if !rhs.is_empty() {
                new_prods.push(rhs.clone());
            }
            
            // 生成所有可能的组合
            if !rhs.is_empty() {
                let nullable_positions: Vec<_> = rhs.iter()
                    .enumerate()
                    .filter(|(_, symbol)| nullable.contains(*symbol))
                    .map(|(i, _)| i)
                    .collect();
                
                // 生成所有可能的子集
                for mask in 1..(1 << nullable_positions.len()) {
                    let mut new_rhs = rhs.clone();
                    for (bit_pos, &symbol_pos) in nullable_positions.iter().enumerate().rev() {
                        if (mask >> bit_pos) & 1 == 1 {
                            new_rhs.remove(symbol_pos);
                        }
                    }
                    if !new_rhs.is_empty() && !new_prods.contains(&new_rhs) {
                        new_prods.push(new_rhs);
                    }
                }
            }
        }
        
        new_productions.insert(A.clone(), new_prods);
    }
    
    // 3. 构造新的文法
    CFG {
        non_terminals: grammar.non_terminals.clone(),
        terminals: grammar.terminals.clone(),
        productions: new_productions,
        start_symbol: grammar.start_symbol.clone()
    }
}
```

### 闭包性质

**定理 3.4** (闭包性质)
上下文无关语言类在以下操作下封闭：

1. **并运算**: 如果 $L_1, L_2$ 是上下文无关语言，则 $L_1 \cup L_2$ 也是上下文无关语言
2. **连接运算**: 如果 $L_1, L_2$ 是上下文无关语言，则 $L_1 \cdot L_2$ 也是上下文无关语言
3. **星闭包**: 如果 $L$ 是上下文无关语言，则 $L^*$ 也是上下文无关语言
4. **同态映射**: 如果 $L$ 是上下文无关语言，$h$ 是同态，则 $h(L)$ 也是上下文无关语言
5. **逆同态映射**: 如果 $L$ 是上下文无关语言，$h$ 是同态，则 $h^{-1}(L)$ 也是上下文无关语言

**上下文无关语言类在以下操作下不封闭**：

1. **交运算**: 存在上下文无关语言 $L_1, L_2$，使得 $L_1 \cap L_2$ 不是上下文无关语言
2. **补运算**: 存在上下文无关语言 $L$，使得 $\Sigma^* - L$ 不是上下文无关语言
3. **差运算**: 存在上下文无关语言 $L_1, L_2$，使得 $L_1 - L_2$ 不是上下文无关语言

### 泵引理及应用

**定理 3.5** (上下文无关语言泵引理)
对于任意上下文无关语言 $L$，存在常数 $p > 0$，使得对于任意 $w \in L$，若 $|w| \geq p$，则 $w$ 可以分解为 $w = uvxyz$，满足：

1. $|vxy| \leq p$
2. $|vy| > 0$
3. 对于任意 $i \geq 0$，都有 $uv^ixy^iz \in L$

**应用**:
泵引理用于证明某个语言不是上下文无关语言。

**例子**:
证明 $L = \{a^n b^n c^n \mid n \geq 1\}$ 不是上下文无关语言。

**证明**:
假设 $L$ 是上下文无关语言，则存在泵引理常数 $p$。考虑字符串 $w = a^p b^p c^p \in L$。

根据泵引理，$w$ 可以分解为 $w = uvxyz$，其中 $|vxy| \leq p$ 且 $|vy| > 0$。由于 $|vxy| \leq p$，$vxy$ 不可能同时包含三种字符。

分情况讨论：

1. 如果 $vy$ 只包含 $a$，则 $uv^2xy^2z$ 包含过多的 $a$
2. 如果 $vy$ 只包含 $b$，则 $uv^2xy^2z$ 包含过多的 $b$
3. 如果 $vy$ 只包含 $c$，则 $uv^2xy^2z$ 包含过多的 $c$
4. 如果 $vy$ 包含 $a$ 和 $b$，则 $uv^2xy^2z$ 中 $a$ 和 $b$ 的顺序会混乱
5. 如果 $vy$ 包含 $b$ 和 $c$，则 $uv^2xy^2z$ 中 $b$ 和 $c$ 的顺序会混乱

所有情况都导致 $uv^2xy^2z \notin L$，矛盾。因此，$L$ 不是上下文无关语言。

### 判定性问题

**定理 3.6** (判定问题)
对于上下文无关语言，有以下判定性结果：

1. **成员资格问题**: 可判定（CYK算法，时间复杂度 $O(n^3)$）
2. **空性问题**: 可判定
3. **有限性问题**: 可判定
4. **等价性问题**: 不可判定
5. **包含性问题**: 不可判定
6. **歧义性问题**: 不可判定

## 🔄 语法分析方法

### 自顶向下分析

**定义 4.1** (自顶向下分析)
自顶向下分析从开始符号出发，通过应用产生式规则逐步推导出输入字符串。

**递归下降分析**:

```rust
fn recursive_descent_parse(input: &str, grammar: &CFG) -> bool {
    fn parse_nonterminal(nt: &NonTerminal, pos: usize, input: &[Token]) -> Option<usize> {
        for production in &grammar.productions[nt] {
            let mut current_pos = pos;
            let mut success = true;
            
            for symbol in production {
                match symbol {
                    Symbol::Terminal(term) => {
                        if current_pos < input.len() && &input[current_pos] == term {
                            current_pos += 1;
                        } else {
                            success = false;
                            break;
                        }
                    },
                    Symbol::NonTerminal(nt) => {
                        if let Some(new_pos) = parse_nonterminal(nt, current_pos, input) {
                            current_pos = new_pos;
                        } else {
                            success = false;
                            break;
                        }
                    }
                }
            }
            
            if success {
                return Some(current_pos);
            }
        }
        
        None
    }
    
    let tokens = tokenize(input);
    parse_nonterminal(&grammar.start_symbol, 0, &tokens) == Some(tokens.len())
}
```

### 自底向上分析

**定义 4.2** (自底向上分析)
自底向上分析从输入字符串开始，通过归约操作逐步归约到开始符号。

**移进-归约分析**:

```rust
fn shift_reduce_parse(input: &str, grammar: &CFG) -> bool {
    let tokens = tokenize(input);
    let mut stack = Vec::new();
    let mut pos = 0;
    
    while pos < tokens.len() || !stack.is_empty() {
        // 尝试归约
        let mut reduced = false;
        
        for (nt, productions) in &grammar.productions {
            for production in productions {
                if stack.len() >= production.len() {
                    let stack_suffix = &stack[stack.len() - production.len()..];
                    
                    if symbols_match(stack_suffix, production) {
                        // 执行归约
                        stack.truncate(stack.len() - production.len());
                        stack.push(Symbol::NonTerminal(nt.clone()));
                        reduced = true;
                        break;
                    }
                }
            }
            
            if reduced {
                break;
            }
        }
        
        // 如果无法归约且还有输入，则移进
        if !reduced {
            if pos < tokens.len() {
                stack.push(Symbol::Terminal(tokens[pos].clone()));
                pos += 1;
            } else {
                return false; // 无法继续分析
            }
        }
        
        // 检查是否已完成解析
        if stack.len() == 1 && stack[0] == Symbol::NonTerminal(grammar.start_symbol.clone()) {
            return pos == tokens.len();
        }
    }
    
    false
}
```

### LL与LR分析

**定义 4.3** (LL分析)
LL(k)分析是自顶向下的预测分析方法，通过查看输入的前k个符号决定使用哪条产生式。

**LL(1)分析表构建**:

```rust
fn build_ll1_table(grammar: &CFG) -> LL1Table {
    let mut table = HashMap::new();
    
    // 计算FIRST和FOLLOW集合
    let first_sets = compute_first_sets(grammar);
    let follow_sets = compute_follow_sets(grammar, &first_sets);
    
    for (nt, productions) in &grammar.productions {
        for production in productions {
            let first_of_rhs = compute_first_of_sequence(production, &first_sets);
            
            for terminal in &first_of_rhs {
                if terminal != &EPSILON {
                    table.insert((nt.clone(), terminal.clone()), production.clone());
                } else {
                    // 对于ε产生式，在FOLLOW(A)中的每个终结符上应用该产生式
                    for follow_term in &follow_sets[nt] {
                        table.insert((nt.clone(), follow_term.clone()), production.clone());
                    }
                }
            }
        }
    }
    
    table
}
```

**定义 4.4** (LR分析)
LR(k)分析是自底向上的分析方法，通过查看已处理的输入和未处理输入的前k个符号决定移进或归约操作。

**LR(0)项集构建**:

```rust
fn build_lr0_items(grammar: &CFG) -> Vec<LR0ItemSet> {
    let mut item_sets = Vec::new();
    let mut unmarked_sets = Vec::new();
    
    // 创建初始项集
    let initial_item = LR0Item { 
        production: &grammar.productions[&grammar.start_symbol][0], 
        dot_position: 0 
    };
    let initial_set = closure(&HashSet::from([initial_item]), grammar);
    
    item_sets.push(initial_set.clone());
    unmarked_sets.push(initial_set);
    
    // 不断处理未标记的项集
    while let Some(item_set) = unmarked_sets.pop() {
        // 获取所有可能的下一个符号
        let mut next_symbols = HashSet::new();
        for item in &item_set {
            if item.dot_position < item.production.len() {
                next_symbols.insert(&item.production[item.dot_position]);
            }
        }
        
        // 对每个符号构建goto集合
        for symbol in next_symbols {
            let goto_set = goto(&item_set, symbol, grammar);
            
            if !goto_set.is_empty() {
                // 检查是否已有相同的项集
                if let Some(index) = item_sets.iter().position(|set| set == &goto_set) {
                    // 添加转换
                    transitions.insert((item_sets.len() - 1, symbol.clone()), index);
                } else {
                    // 添加新的项集
                    transitions.insert((item_sets.len() - 1, symbol.clone()), item_sets.len());
                    item_sets.push(goto_set.clone());
                    unmarked_sets.push(goto_set);
                }
            }
        }
    }
    
    item_sets
}
```

## 💼 应用场景

### 程序语言语法

上下文无关语言是定义和解析编程语言语法的基础，通过BNF或EBNF表示语法规则。

```rust
// 表达式语法的实现
fn parse_expression(tokens: &[Token], pos: &mut usize) -> Result<Expr, ParseError> {
    parse_binary_expr(tokens, pos, 0)
}

fn parse_binary_expr(tokens: &[Token], pos: &mut usize, precedence: u8) -> Result<Expr, ParseError> {
    let mut left = parse_primary(tokens, pos)?;
    
    while *pos < tokens.len() {
        let op = match &tokens[*pos] {
            Token::Plus => BinaryOp::Add,
            Token::Minus => BinaryOp::Sub,
            Token::Star => BinaryOp::Mul,
            Token::Slash => BinaryOp::Div,
            _ => break
        };
        
        let op_precedence = get_precedence(&op);
        if op_precedence < precedence {
            break;
        }
        
        *pos += 1; // 消耗操作符
        
        let right = parse_binary_expr(tokens, pos, op_precedence + 1)?;
        left = Expr::Binary(Box::new(left), op, Box::new(right));
    }
    
    Ok(left)
}
```

### 自然语言结构

上下文无关文法被用于模拟自然语言的句法结构，是计算语言学的基础。

```rust
// 简单句法分析器
fn parse_sentence(tokens: &[Word]) -> Option<SyntaxTree> {
    // S -> NP VP
    let np = parse_noun_phrase(tokens, 0)?;
    let vp = parse_verb_phrase(tokens, np.end_pos)?;
    
    if vp.end_pos == tokens.len() {
        Some(SyntaxTree {
            label: "S",
            children: vec![np.tree, vp.tree],
            start_pos: 0,
            end_pos: tokens.len()
        })
    } else {
        None
    }
}

fn parse_noun_phrase(tokens: &[Word], start_pos: usize) -> Option<ParseResult> {
    // NP -> Det N | N
    if start_pos >= tokens.len() {
        return None;
    }
    
    if tokens[start_pos].pos == POS::Determiner {
        if start_pos + 1 < tokens.len() && tokens[start_pos + 1].pos == POS::Noun {
            let det_tree = SyntaxTree {
                label: "Det",
                children: vec![],
                start_pos,
                end_pos: start_pos + 1
            };
            
            let n_tree = SyntaxTree {
                label: "N",
                children: vec![],
                start_pos: start_pos + 1,
                end_pos: start_pos + 2
            };
            
            let np_tree = SyntaxTree {
                label: "NP",
                children: vec![det_tree, n_tree],
                start_pos,
                end_pos: start_pos + 2
            };
            
            return Some(ParseResult {
                tree: np_tree,
                end_pos: start_pos + 2
            });
        }
    } else if tokens[start_pos].pos == POS::Noun {
        let n_tree = SyntaxTree {
            label: "N",
            children: vec![],
            start_pos,
            end_pos: start_pos + 1
        };
        
        let np_tree = SyntaxTree {
            label: "NP",
            children: vec![n_tree],
            start_pos,
            end_pos: start_pos + 1
        };
        
        return Some(ParseResult {
            tree: np_tree,
            end_pos: start_pos + 1
        });
    }
    
    None
}
```

### 表达式求值

上下文无关语言用于定义和解析算术、逻辑或其他表达式。

```rust
// 算术表达式求值器
fn evaluate_expression(expr: &str) -> Result<f64, EvalError> {
    let tokens = tokenize(expr)?;
    let mut pos = 0;
    let ast = parse_expression(&tokens, &mut pos)?;
    
    if pos < tokens.len() {
        return Err(EvalError::UnexpectedToken);
    }
    
    evaluate_ast(&ast)
}

fn evaluate_ast(ast: &Expr) -> Result<f64, EvalError> {
    match ast {
        Expr::Number(n) => Ok(*n),
        Expr::Binary(left, op, right) => {
            let left_val = evaluate_ast(left)?;
            let right_val = evaluate_ast(right)?;
            
            match op {
                BinaryOp::Add => Ok(left_val + right_val),
                BinaryOp::Sub => Ok(left_val - right_val),
                BinaryOp::Mul => Ok(left_val * right_val),
                BinaryOp::Div => {
                    if right_val == 0.0 {
                        Err(EvalError::DivisionByZero)
                    } else {
                        Ok(left_val / right_val)
                    }
                }
            }
        }
    }
}
```

## 🔗 相关内容

- [03.3.1 乔姆斯基谱系](./03.3.1_Chomsky_Hierarchy.md) - 形式语言层次概述
- [03.3.1.1 正则语言](./03.3.1.1_Regular_Languages.md) - 上下文无关语言的子集
- [03.3.1.3 上下文相关语言](./03.3.1.3_Context_Sensitive_Languages.md) - 上下文无关语言的超集
- [03.2.2 上下文无关文法](../03.2_Formal_Grammars/03.2.2_Context_Free_Grammar.md) - 生成上下文无关语言的文法
- [03.4.2 下推自动机](../03.4_Automata_Theory/03.4.2_Pushdown_Automata.md) - 识别上下文无关语言的计算模型

---

**更新时间**: 2024-12-30  
**版本**: 1.0  
**状态**: 完成初稿
