# 02.1 形式语言基础 (Formal Language Foundation)

## 目录

```markdown
02.1 形式语言基础
├── 1. 概述
│   ├── 1.1 基本概念
│   ├── 1.2 历史发展
│   ├── 1.3 应用领域
│   └── 1.4 与其他理论的关系
├── 2. 形式化定义
│   ├── 2.1 字母表与字符串
│   ├── 2.2 语言定义
│   ├── 2.3 语言运算
│   └── 2.4 语言层次
├── 3. 语法理论
│   ├── 3.1 文法定义
│   ├── 3.2 推导过程
│   ├── 3.3 语法树
│   └── 3.4 歧义性
├── 4. 自动机理论
│   ├── 4.1 有限自动机
│   ├── 4.2 下推自动机
│   ├── 4.3 图灵机
│   └── 4.4 自动机等价性
├── 5. 实现示例
│   ├── 5.1 Rust 实现
│   ├── 5.2 Haskell 实现
│   └── 5.3 语法分析器
├── 6. 应用实例
│   ├── 6.1 编译器设计
│   ├── 6.2 自然语言处理
│   └── 6.3 协议验证
└── 7. 参考文献
```

## 1. 概述

### 1.1 基本概念

形式语言理论是计算机科学的基础理论之一，研究语言的数学性质和计算模型。

**核心概念**:

- **字母表 (Alphabet)**: 符号的有限集合
- **字符串 (String)**: 字母表中符号的有限序列
- **语言 (Language)**: 字符串的集合
- **文法 (Grammar)**: 语言的形式化描述
- **自动机 (Automaton)**: 语言的识别器

### 1.2 历史发展

形式语言理论的发展历程：

1. **Chomsky 层次结构** (1956) - 语言分类体系
2. **有限自动机理论** (1950s) - 正则语言识别
3. **上下文无关文法** (1960s) - 编程语言语法
4. **图灵机理论** (1936) - 计算模型基础
5. **编译理论** (1970s) - 实际应用发展

### 1.3 应用领域

形式语言理论的主要应用：

- **编译器设计**: 语法分析、词法分析
- **自然语言处理**: 语法分析、语义分析
- **协议验证**: 通信协议形式化
- **数据库查询**: 查询语言设计
- **人工智能**: 知识表示、推理

### 1.4 与其他理论的关系

形式语言理论与相关理论的关系：

- **自动机理论**: 语言的识别模型
- **计算理论**: 可计算性基础
- **复杂性理论**: 计算复杂度分析
- **类型理论**: 形式化语言设计

## 2. 形式化定义

### 2.1 字母表与字符串

**字母表定义**:
字母表 $\Sigma$ 是一个有限的符号集合。

**字符串定义**:

- 空字符串 $\varepsilon$ 是长度为 0 的字符串
- 如果 $a \in \Sigma$ 且 $w$ 是字符串，则 $aw$ 是字符串
- 字符串的长度 $|w|$ 递归定义：
  - $|\varepsilon| = 0$
  - $|aw| = 1 + |w|$

**字符串运算**:

- **连接**: $w \cdot v$ 或 $wv$
- **幂**: $w^0 = \varepsilon$, $w^{n+1} = w \cdot w^n$
- **反转**: $w^R$ 递归定义：
  - $\varepsilon^R = \varepsilon$
  - $(aw)^R = w^R \cdot a$

### 2.2 语言定义

**语言定义**:
语言 $L$ 是字母表 $\Sigma$ 上字符串的任意子集，即 $L \subseteq \Sigma^*$。

**语言运算**:

- **并**: $L_1 \cup L_2 = \{w \mid w \in L_1 \text{ or } w \in L_2\}$
- **交**: $L_1 \cap L_2 = \{w \mid w \in L_1 \text{ and } w \in L_2\}$
- **补**: $\overline{L} = \Sigma^* \setminus L$
- **连接**: $L_1 \cdot L_2 = \{w_1 w_2 \mid w_1 \in L_1, w_2 \in L_2\}$
- **幂**: $L^0 = \{\varepsilon\}$, $L^{n+1} = L \cdot L^n$
- **克林闭包**: $L^* = \bigcup_{n \geq 0} L^n$
- **正闭包**: $L^+ = \bigcup_{n \geq 1} L^n$

### 2.3 语言运算

**语言运算的性质**:

**交换律**:

- $L_1 \cup L_2 = L_2 \cup L_1$
- $L_1 \cap L_2 = L_2 \cap L_1$

**结合律**:

- $(L_1 \cup L_2) \cup L_3 = L_1 \cup (L_2 \cup L_3)$
- $(L_1 \cap L_2) \cap L_3 = L_1 \cap (L_2 \cap L_3)$
- $(L_1 \cdot L_2) \cdot L_3 = L_1 \cdot (L_2 \cdot L_3)$

**分配律**:

- $L_1 \cdot (L_2 \cup L_3) = (L_1 \cdot L_2) \cup (L_1 \cdot L_3)$
- $(L_1 \cup L_2) \cdot L_3 = (L_1 \cdot L_3) \cup (L_2 \cdot L_3)$

**德摩根律**:

- $\overline{L_1 \cup L_2} = \overline{L_1} \cap \overline{L_2}$
- $\overline{L_1 \cap L_2} = \overline{L_1} \cup \overline{L_2}$

### 2.4 语言层次

**Chomsky 层次结构**:

1. **类型 0 (递归可枚举语言)**:
   - 无限制文法
   - 图灵机识别

2. **类型 1 (上下文相关语言)**:
   - 上下文相关文法
   - 线性有界自动机识别

3. **类型 2 (上下文无关语言)**:
   - 上下文无关文法
   - 下推自动机识别

4. **类型 3 (正则语言)**:
   - 正则文法
   - 有限自动机识别

## 3. 语法理论

### 3.1 文法定义

**文法定义**:
文法 $G = (V, T, P, S)$ 其中：

- $V$ 是非终结符集合
- $T$ 是终结符集合
- $P$ 是产生式集合
- $S \in V$ 是开始符号

**产生式形式**:

- **无限制文法**: $\alpha \to \beta$，其中 $\alpha, \beta \in (V \cup T)^*$
- **上下文相关文法**: $\alpha A \beta \to \alpha \gamma \beta$，其中 $A \in V$, $\alpha, \beta, \gamma \in (V \cup T)^*$, $\gamma \neq \varepsilon$
- **上下文无关文法**: $A \to \alpha$，其中 $A \in V$, $\alpha \in (V \cup T)^*$
- **正则文法**: $A \to aB$ 或 $A \to a$，其中 $A, B \in V$, $a \in T$

### 3.2 推导过程

**直接推导**:
如果 $\alpha \to \beta \in P$，则 $\gamma \alpha \delta \Rightarrow \gamma \beta \delta$

**推导**:
$\alpha \Rightarrow^* \beta$ 表示通过零次或多次直接推导从 $\alpha$ 得到 $\beta$

**最左推导**:
每次替换最左边的非终结符

**最右推导**:
每次替换最右边的非终结符

### 3.3 语法树

**语法树定义**:
语法树是推导过程的树形表示，其中：

- 根节点是开始符号
- 内部节点是非终结符
- 叶节点是终结符
- 每个节点的子节点对应一个产生式的右部

**语法树构造**:

```rust
#[derive(Debug, Clone)]
enum Node {
    Terminal(String),
    NonTerminal(String, Vec<Node>),
}

impl Node {
    fn new_terminal(value: String) -> Self {
        Node::Terminal(value)
    }
    
    fn new_non_terminal(name: String, children: Vec<Node>) -> Self {
        Node::NonTerminal(name, children)
    }
    
    fn is_terminal(&self) -> bool {
        matches!(self, Node::Terminal(_))
    }
    
    fn is_non_terminal(&self) -> bool {
        matches!(self, Node::NonTerminal(_, _))
    }
}
```

### 3.4 歧义性

**歧义性定义**:
如果语言中存在字符串有多个不同的语法树，则文法是歧义的。

**歧义性检测**:

```rust
struct Grammar {
    productions: Vec<Production>,
    start_symbol: String,
}

impl Grammar {
    fn is_ambiguous(&self, input: &str) -> bool {
        let parse_trees = self.parse_all(input);
        parse_trees.len() > 1
    }
    
    fn parse_all(&self, input: &str) -> Vec<Node> {
        // 实现所有可能的解析树
        vec![]
    }
}
```

## 4. 自动机理论

### 4.1 有限自动机

**确定性有限自动机 (DFA)**:
$M = (Q, \Sigma, \delta, q_0, F)$ 其中：

- $Q$ 是状态集合
- $\Sigma$ 是输入字母表
- $\delta: Q \times \Sigma \to Q$ 是转移函数
- $q_0 \in Q$ 是初始状态
- $F \subseteq Q$ 是接受状态集合

**非确定性有限自动机 (NFA)**:
$M = (Q, \Sigma, \delta, q_0, F)$ 其中：

- $\delta: Q \times \Sigma \to 2^Q$ 是转移函数

**Rust 实现**:

```rust
use std::collections::{HashMap, HashSet};

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
struct State(String);

#[derive(Debug, Clone)]
struct DFA {
    states: HashSet<State>,
    alphabet: HashSet<char>,
    transitions: HashMap<(State, char), State>,
    initial_state: State,
    accepting_states: HashSet<State>,
}

impl DFA {
    fn new(initial: State) -> Self {
        Self {
            states: HashSet::new(),
            alphabet: HashSet::new(),
            transitions: HashMap::new(),
            initial_state: initial,
            accepting_states: HashSet::new(),
        }
    }
    
    fn add_state(&mut self, state: State) {
        self.states.insert(state);
    }
    
    fn add_transition(&mut self, from: State, symbol: char, to: State) {
        self.alphabet.insert(symbol);
        self.transitions.insert((from, symbol), to);
    }
    
    fn add_accepting_state(&mut self, state: State) {
        self.accepting_states.insert(state);
    }
    
    fn accepts(&self, input: &str) -> bool {
        let mut current_state = self.initial_state.clone();
        
        for symbol in input.chars() {
            if let Some(next_state) = self.transitions.get(&(current_state.clone(), symbol)) {
                current_state = next_state.clone();
            } else {
                return false;
            }
        }
        
        self.accepting_states.contains(&current_state)
    }
}
```

### 4.2 下推自动机

**下推自动机 (PDA)**:
$M = (Q, \Sigma, \Gamma, \delta, q_0, Z_0, F)$ 其中：

- $Q$ 是状态集合
- $\Sigma$ 是输入字母表
- $\Gamma$ 是栈字母表
- $\delta: Q \times (\Sigma \cup \{\varepsilon\}) \times \Gamma \to 2^{Q \times \Gamma^*}$ 是转移函数
- $q_0 \in Q$ 是初始状态
- $Z_0 \in \Gamma$ 是初始栈符号
- $F \subseteq Q$ 是接受状态集合

**Haskell 实现**:

```haskell
import Data.Map (Map)
import qualified Data.Map as Map
import Data.Set (Set)
import qualified Data.Set as Set

type State = String
type Symbol = Char
type StackSymbol = Char
type Stack = [StackSymbol]

data PDA = PDA {
    states :: Set State,
    alphabet :: Set Symbol,
    stackAlphabet :: Set StackSymbol,
    transitions :: Map (State, Maybe Symbol, StackSymbol) (Set (State, [StackSymbol])),
    initialState :: State,
    initialStackSymbol :: StackSymbol,
    acceptingStates :: Set State
}

pdaStep :: PDA -> State -> Maybe Symbol -> Stack -> [(State, Stack)]
pdaStep pda state symbol stack = 
    case stack of
        [] -> []
        (top:rest) -> 
            let key = (state, symbol, top)
                transitions = Map.findWithDefault Set.empty key (transitions pda)
            in [(nextState, rest ++ newStack) | (nextState, newStack) <- Set.toList transitions]

pdaAccepts :: PDA -> String -> Bool
pdaAccepts pda input = 
    let initialConfig = (initialState pda, [initialStackSymbol pda])
        finalConfigs = pdaRun pda initialConfig input
    in any (\(state, _) -> state `Set.member` acceptingStates pda) finalConfigs

pdaRun :: PDA -> (State, Stack) -> String -> [(State, Stack)]
pdaRun pda (state, stack) input =
    case input of
        [] -> [(state, stack)]
        (c:cs) -> 
            let epsilonSteps = pdaStep pda state Nothing stack
                symbolSteps = pdaStep pda state (Just c) stack
                allSteps = epsilonSteps ++ symbolSteps
            in concat [pdaRun pda config cs | config <- allSteps]
```

### 4.3 图灵机

**图灵机 (TM)**:
$M = (Q, \Sigma, \Gamma, \delta, q_0, B, F)$ 其中：

- $Q$ 是状态集合
- $\Sigma$ 是输入字母表
- $\Gamma$ 是带字母表
- $\delta: Q \times \Gamma \to Q \times \Gamma \times \{L, R\}$ 是转移函数
- $q_0 \in Q$ 是初始状态
- $B \in \Gamma$ 是空白符号
- $F \subseteq Q$ 是接受状态集合

**Rust 实现**:

```rust
use std::collections::HashMap;

#[derive(Debug, Clone, PartialEq)]
enum Direction {
    Left,
    Right,
}

#[derive(Debug, Clone)]
struct TuringMachine {
    states: Vec<String>,
    alphabet: Vec<char>,
    tape_alphabet: Vec<char>,
    transitions: HashMap<(String, char), (String, char, Direction)>,
    initial_state: String,
    blank_symbol: char,
    accepting_states: Vec<String>,
}

impl TuringMachine {
    fn new(initial: String, blank: char) -> Self {
        Self {
            states: Vec::new(),
            alphabet: Vec::new(),
            tape_alphabet: Vec::new(),
            transitions: HashMap::new(),
            initial_state: initial,
            blank_symbol: blank,
            accepting_states: Vec::new(),
        }
    }
    
    fn add_transition(&mut self, state: String, symbol: char, 
                     next_state: String, write_symbol: char, direction: Direction) {
        self.transitions.insert((state, symbol), (next_state, write_symbol, direction));
    }
    
    fn run(&self, input: &str) -> bool {
        let mut tape: Vec<char> = input.chars().collect();
        let mut head = 0;
        let mut current_state = self.initial_state.clone();
        
        // 扩展磁带
        while head >= tape.len() {
            tape.push(self.blank_symbol);
        }
        
        loop {
            let current_symbol = tape[head];
            
            if let Some((next_state, write_symbol, direction)) = 
                self.transitions.get(&(current_state.clone(), current_symbol)) {
                
                // 写入符号
                tape[head] = *write_symbol;
                
                // 移动头
                match direction {
                    Direction::Left => {
                        if head == 0 {
                            tape.insert(0, self.blank_symbol);
                        } else {
                            head -= 1;
                        }
                    }
                    Direction::Right => {
                        head += 1;
                        if head >= tape.len() {
                            tape.push(self.blank_symbol);
                        }
                    }
                }
                
                current_state = next_state.clone();
            } else {
                break;
            }
        }
        
        self.accepting_states.contains(&current_state)
    }
}
```

### 4.4 自动机等价性

**DFA 与 NFA 等价性**:
对于每个 NFA，存在等价的 DFA。

**构造方法**:

```rust
impl DFA {
    fn from_nfa(nfa: &NFA) -> Self {
        let mut dfa = DFA::new(State("q0".to_string()));
        
        // 子集构造法
        let initial_closure = nfa.epsilon_closure(&[nfa.initial_state.clone()]);
        let mut unprocessed = vec![initial_closure.clone()];
        let mut processed = HashSet::new();
        
        while let Some(current_states) = unprocessed.pop() {
            if processed.contains(&current_states) {
                continue;
            }
            
            processed.insert(current_states.clone());
            
            for symbol in &nfa.alphabet {
                let next_states = nfa.transition(&current_states, *symbol);
                let closure = nfa.epsilon_closure(&next_states);
                
                if !processed.contains(&closure) {
                    unprocessed.push(closure.clone());
                }
                
                // 添加转移
                dfa.add_transition(
                    State(format!("{:?}", current_states)),
                    *symbol,
                    State(format!("{:?}", closure))
                );
            }
        }
        
        dfa
    }
}
```

## 5. 实现示例

### 5.1 Rust 实现

```rust
use std::collections::{HashMap, HashSet};

// 文法定义
#[derive(Debug, Clone)]
struct Grammar {
    non_terminals: HashSet<String>,
    terminals: HashSet<String>,
    productions: Vec<Production>,
    start_symbol: String,
}

#[derive(Debug, Clone)]
struct Production {
    left: String,
    right: Vec<String>,
}

impl Grammar {
    fn new(start: String) -> Self {
        Self {
            non_terminals: HashSet::new(),
            terminals: HashSet::new(),
            productions: Vec::new(),
            start_symbol: start,
        }
    }
    
    fn add_production(&mut self, left: String, right: Vec<String>) {
        self.non_terminals.insert(left.clone());
        for symbol in &right {
            if symbol.chars().next().unwrap().is_uppercase() {
                self.non_terminals.insert(symbol.clone());
            } else {
                self.terminals.insert(symbol.clone());
            }
        }
        self.productions.push(Production { left, right });
    }
    
    fn derive(&self, input: &str) -> bool {
        let mut current = vec![self.start_symbol.clone()];
        let target: Vec<String> = input.chars().map(|c| c.to_string()).collect();
        
        self.derive_recursive(&mut current, &target, 0)
    }
    
    fn derive_recursive(&self, current: &mut Vec<String>, target: &[String], depth: usize) -> bool {
        if depth > 1000 { // 防止无限递归
            return false;
        }
        
        if current == target {
            return true;
        }
        
        for i in 0..current.len() {
            if let Some(production) = self.find_production(&current[i]) {
                let mut new_current = current.clone();
                new_current.splice(i..i+1, production.right.clone());
                
                if self.derive_recursive(&mut new_current, target, depth + 1) {
                    *current = new_current;
                    return true;
                }
            }
        }
        
        false
    }
    
    fn find_production(&self, non_terminal: &str) -> Option<&Vec<String>> {
        self.productions.iter()
            .find(|p| p.left == non_terminal)
            .map(|p| &p.right)
    }
}

// 使用示例
fn main() {
    let mut grammar = Grammar::new("S".to_string());
    
    // 添加产生式: S -> aSb | ab
    grammar.add_production("S".to_string(), vec!["a".to_string(), "S".to_string(), "b".to_string()]);
    grammar.add_production("S".to_string(), vec!["a".to_string(), "b".to_string()]);
    
    // 测试推导
    println!("Derives 'aabb': {}", grammar.derive("aabb"));
    println!("Derives 'ab': {}", grammar.derive("ab"));
    println!("Derives 'abb': {}", grammar.derive("abb"));
}
```

### 5.2 Haskell 实现

```haskell
import Data.Map (Map)
import qualified Data.Map as Map
import Data.Set (Set)
import qualified Data.Set as Set

-- 文法定义
data Grammar = Grammar {
    nonTerminals :: Set String,
    terminals :: Set String,
    productions :: Map String [[String]],
    startSymbol :: String
}

-- 产生式
type Production = (String, [String])

-- 创建文法
emptyGrammar :: String -> Grammar
emptyGrammar start = Grammar {
    nonTerminals = Set.singleton start,
    terminals = Set.empty,
    productions = Map.empty,
    startSymbol = start
}

-- 添加产生式
addProduction :: Grammar -> String -> [String] -> Grammar
addProduction grammar left right = grammar {
    nonTerminals = Set.insert left (nonTerminals grammar),
    terminals = Set.union (terminals grammar) (Set.fromList [s | s <- right, isTerminal s]),
    productions = Map.insertWith (++) left [right] (productions grammar)
}
  where
    isTerminal s = not (null s) && isUpper (head s)

-- 推导
derive :: Grammar -> String -> Bool
derive grammar input = deriveRecursive grammar [startSymbol grammar] (words input) 0
  where
    deriveRecursive :: Grammar -> [String] -> [String] -> Int -> Bool
    deriveRecursive _ current target depth
        | depth > 1000 = False  -- 防止无限递归
        | current == target = True
        | otherwise = any tryDerivation [0..length current - 1]
      where
        tryDerivation i = 
            case current !! i of
                nt | nt `Set.member` nonTerminals grammar ->
                    let productions = Map.findWithDefault [] nt (productions grammar)
                    in any (\prod -> 
                        let newCurrent = take i current ++ prod ++ drop (i+1) current
                        in deriveRecursive grammar newCurrent target (depth + 1)
                    ) productions
                _ -> False

-- 使用示例
main :: IO ()
main = do
    let grammar = addProduction 
                    (addProduction 
                        (emptyGrammar "S") 
                        "S" ["a", "S", "b"]) 
                    "S" ["a", "b"]
    
    putStrLn $ "Derives 'aabb': " ++ show (derive grammar "a a b b")
    putStrLn $ "Derives 'ab': " ++ show (derive grammar "a b")
    putStrLn $ "Derives 'abb': " ++ show (derive grammar "a b b")
```

### 5.3 语法分析器

```rust
use std::collections::HashMap;

#[derive(Debug, Clone)]
enum Token {
    Identifier(String),
    Number(i64),
    Plus,
    Minus,
    Times,
    Divide,
    LeftParen,
    RightParen,
    End,
}

#[derive(Debug, Clone)]
enum AST {
    Number(i64),
    BinaryOp(Box<AST>, String, Box<AST>),
    Identifier(String),
}

struct Parser {
    tokens: Vec<Token>,
    current: usize,
}

impl Parser {
    fn new(tokens: Vec<Token>) -> Self {
        Self { tokens, current: 0 }
    }
    
    fn peek(&self) -> Option<&Token> {
        self.tokens.get(self.current)
    }
    
    fn advance(&mut self) -> Option<&Token> {
        let token = self.tokens.get(self.current);
        self.current += 1;
        token
    }
    
    fn parse(&mut self) -> Result<AST, String> {
        self.parse_expression()
    }
    
    fn parse_expression(&mut self) -> Result<AST, String> {
        let mut left = self.parse_term()?;
        
        while let Some(token) = self.peek() {
            match token {
                Token::Plus | Token::Minus => {
                    let op = match self.advance().unwrap() {
                        Token::Plus => "+".to_string(),
                        Token::Minus => "-".to_string(),
                        _ => unreachable!(),
                    };
                    let right = self.parse_term()?;
                    left = AST::BinaryOp(Box::new(left), op, Box::new(right));
                }
                _ => break,
            }
        }
        
        Ok(left)
    }
    
    fn parse_term(&mut self) -> Result<AST, String> {
        let mut left = self.parse_factor()?;
        
        while let Some(token) = self.peek() {
            match token {
                Token::Times | Token::Divide => {
                    let op = match self.advance().unwrap() {
                        Token::Times => "*".to_string(),
                        Token::Divide => "/".to_string(),
                        _ => unreachable!(),
                    };
                    let right = self.parse_factor()?;
                    left = AST::BinaryOp(Box::new(left), op, Box::new(right));
                }
                _ => break,
            }
        }
        
        Ok(left)
    }
    
    fn parse_factor(&mut self) -> Result<AST, String> {
        match self.advance() {
            Some(Token::Number(n)) => Ok(AST::Number(*n)),
            Some(Token::Identifier(name)) => Ok(AST::Identifier(name.clone())),
            Some(Token::LeftParen) => {
                let expr = self.parse_expression()?;
                match self.advance() {
                    Some(Token::RightParen) => Ok(expr),
                    _ => Err("Expected ')'".to_string()),
                }
            }
            _ => Err("Expected factor".to_string()),
        }
    }
}

// 使用示例
fn main() {
    let tokens = vec![
        Token::Number(1),
        Token::Plus,
        Token::Number(2),
        Token::Times,
        Token::Number(3),
        Token::End,
    ];
    
    let mut parser = Parser::new(tokens);
    match parser.parse() {
        Ok(ast) => println!("AST: {:?}", ast),
        Err(e) => println!("Error: {}", e),
    }
}
```

## 6. 应用实例

### 6.1 编译器设计

**词法分析器**:

```rust
use std::collections::HashMap;

#[derive(Debug, Clone)]
enum TokenType {
    Identifier,
    Number,
    String,
    Operator,
    Delimiter,
    Keyword,
}

#[derive(Debug, Clone)]
struct Token {
    token_type: TokenType,
    value: String,
    line: usize,
    column: usize,
}

struct Lexer {
    source: String,
    position: usize,
    line: usize,
    column: usize,
    keywords: HashMap<String, TokenType>,
}

impl Lexer {
    fn new(source: String) -> Self {
        let mut keywords = HashMap::new();
        keywords.insert("if".to_string(), TokenType::Keyword);
        keywords.insert("else".to_string(), TokenType::Keyword);
        keywords.insert("while".to_string(), TokenType::Keyword);
        keywords.insert("for".to_string(), TokenType::Keyword);
        keywords.insert("return".to_string(), TokenType::Keyword);
        
        Self {
            source,
            position: 0,
            line: 1,
            column: 1,
            keywords,
        }
    }
    
    fn next_token(&mut self) -> Option<Token> {
        self.skip_whitespace();
        
        if self.position >= self.source.len() {
            return None;
        }
        
        let start_pos = self.position;
        let start_line = self.line;
        let start_column = self.column;
        
        let current_char = self.source.chars().nth(self.position)?;
        
        match current_char {
            c if c.is_alphabetic() => self.tokenize_identifier(start_line, start_column),
            c if c.is_digit(10) => self.tokenize_number(start_line, start_column),
            '"' => self.tokenize_string(start_line, start_column),
            c if self.is_operator(c) => self.tokenize_operator(start_line, start_column),
            c if self.is_delimiter(c) => self.tokenize_delimiter(start_line, start_column),
            _ => {
                self.position += 1;
                self.column += 1;
                Some(Token {
                    token_type: TokenType::Delimiter,
                    value: current_char.to_string(),
                    line: start_line,
                    column: start_column,
                })
            }
        }
    }
    
    fn tokenize_identifier(&mut self, line: usize, column: usize) -> Option<Token> {
        let mut value = String::new();
        
        while let Some(c) = self.source.chars().nth(self.position) {
            if c.is_alphanumeric() || c == '_' {
                value.push(c);
                self.position += 1;
                self.column += 1;
            } else {
                break;
            }
        }
        
        let token_type = self.keywords.get(&value)
            .cloned()
            .unwrap_or(TokenType::Identifier);
        
        Some(Token {
            token_type,
            value,
            line,
            column,
        })
    }
    
    fn tokenize_number(&mut self, line: usize, column: usize) -> Option<Token> {
        let mut value = String::new();
        
        while let Some(c) = self.source.chars().nth(self.position) {
            if c.is_digit(10) || c == '.' {
                value.push(c);
                self.position += 1;
                self.column += 1;
            } else {
                break;
            }
        }
        
        Some(Token {
            token_type: TokenType::Number,
            value,
            line,
            column,
        })
    }
    
    fn tokenize_string(&mut self, line: usize, column: usize) -> Option<Token> {
        let mut value = String::new();
        self.position += 1; // 跳过开始的引号
        self.column += 1;
        
        while let Some(c) = self.source.chars().nth(self.position) {
            if c == '"' {
                self.position += 1;
                self.column += 1;
                break;
            } else {
                value.push(c);
                self.position += 1;
                self.column += 1;
            }
        }
        
        Some(Token {
            token_type: TokenType::String,
            value,
            line,
            column,
        })
    }
    
    fn tokenize_operator(&mut self, line: usize, column: usize) -> Option<Token> {
        let mut value = String::new();
        
        while let Some(c) = self.source.chars().nth(self.position) {
            if self.is_operator(c) {
                value.push(c);
                self.position += 1;
                self.column += 1;
            } else {
                break;
            }
        }
        
        Some(Token {
            token_type: TokenType::Operator,
            value,
            line,
            column,
        })
    }
    
    fn tokenize_delimiter(&mut self, line: usize, column: usize) -> Option<Token> {
        let c = self.source.chars().nth(self.position)?;
        self.position += 1;
        self.column += 1;
        
        Some(Token {
            token_type: TokenType::Delimiter,
            value: c.to_string(),
            line,
            column,
        })
    }
    
    fn skip_whitespace(&mut self) {
        while let Some(c) = self.source.chars().nth(self.position) {
            match c {
                ' ' | '\t' => {
                    self.position += 1;
                    self.column += 1;
                }
                '\n' => {
                    self.position += 1;
                    self.line += 1;
                    self.column = 1;
                }
                _ => break,
            }
        }
    }
    
    fn is_operator(&self, c: char) -> bool {
        matches!(c, '+' | '-' | '*' | '/' | '=' | '<' | '>' | '!' | '&' | '|')
    }
    
    fn is_delimiter(&self, c: char) -> bool {
        matches!(c, '(' | ')' | '{' | '}' | '[' | ']' | ';' | ',')
    }
}
```

### 6.2 自然语言处理

**语法分析器**:

```rust
use std::collections::HashMap;

#[derive(Debug, Clone)]
enum POS {
    Noun,
    Verb,
    Adjective,
    Adverb,
    Preposition,
    Conjunction,
    Determiner,
}

#[derive(Debug, Clone)]
struct Word {
    text: String,
    pos: POS,
    lemma: String,
}

#[derive(Debug, Clone)]
enum Phrase {
    NounPhrase(Vec<Word>),
    VerbPhrase(Vec<Word>),
    PrepositionalPhrase(Vec<Word>),
}

#[derive(Debug, Clone)]
struct Sentence {
    subject: Option<Phrase>,
    predicate: Option<Phrase>,
    objects: Vec<Phrase>,
}

struct NLParser {
    grammar: HashMap<String, Vec<Vec<String>>>,
}

impl NLParser {
    fn new() -> Self {
        let mut grammar = HashMap::new();
        
        // 名词短语规则
        grammar.insert("NP".to_string(), vec![
            vec!["DET".to_string(), "N".to_string()],
            vec!["N".to_string()],
            vec!["ADJ".to_string(), "N".to_string()],
        ]);
        
        // 动词短语规则
        grammar.insert("VP".to_string(), vec![
            vec!["V".to_string()],
            vec!["V".to_string(), "NP".to_string()],
            vec!["V".to_string(), "PP".to_string()],
        ]);
        
        // 介词短语规则
        grammar.insert("PP".to_string(), vec![
            vec!["P".to_string(), "NP".to_string()],
        ]);
        
        // 句子规则
        grammar.insert("S".to_string(), vec![
            vec!["NP".to_string(), "VP".to_string()],
        ]);
        
        Self { grammar }
    }
    
    fn parse(&self, words: &[Word]) -> Option<Sentence> {
        // 简化的语法分析
        let mut sentence = Sentence {
            subject: None,
            predicate: None,
            objects: Vec::new(),
        };
        
        // 找到主语（第一个名词短语）
        if let Some(subject_end) = self.find_noun_phrase(words, 0) {
            sentence.subject = Some(Phrase::NounPhrase(words[0..subject_end].to_vec()));
            
            // 找到谓语（动词短语）
            if let Some(verb_end) = self.find_verb_phrase(words, subject_end) {
                sentence.predicate = Some(Phrase::VerbPhrase(words[subject_end..verb_end].to_vec()));
                
                // 找到宾语
                if verb_end < words.len() {
                    sentence.objects.push(Phrase::NounPhrase(words[verb_end..].to_vec()));
                }
            }
        }
        
        Some(sentence)
    }
    
    fn find_noun_phrase(&self, words: &[Word], start: usize) -> Option<usize> {
        for i in start..words.len() {
            if matches!(words[i].pos, POS::Noun) {
                return Some(i + 1);
            }
        }
        None
    }
    
    fn find_verb_phrase(&self, words: &[Word], start: usize) -> Option<usize> {
        for i in start..words.len() {
            if matches!(words[i].pos, POS::Verb) {
                return Some(i + 1);
            }
        }
        None
    }
}
```

### 6.3 协议验证

**协议状态机**:

```rust
use std::collections::HashMap;

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
enum ProtocolState {
    Idle,
    Connecting,
    Connected,
    Sending,
    Receiving,
    Disconnecting,
    Error,
}

#[derive(Debug, Clone)]
enum ProtocolEvent {
    Connect,
    Disconnect,
    Send,
    Receive,
    Timeout,
    Error,
}

#[derive(Debug, Clone)]
struct ProtocolTransition {
    from: ProtocolState,
    event: ProtocolEvent,
    to: ProtocolState,
    action: Option<fn()>,
}

struct ProtocolMachine {
    current_state: ProtocolState,
    transitions: Vec<ProtocolTransition>,
}

impl ProtocolMachine {
    fn new() -> Self {
        let mut machine = Self {
            current_state: ProtocolState::Idle,
            transitions: Vec::new(),
        };
        
        // 定义状态转换
        machine.add_transition(ProtocolState::Idle, ProtocolEvent::Connect, ProtocolState::Connecting);
        machine.add_transition(ProtocolState::Connecting, ProtocolEvent::Connect, ProtocolState::Connected);
        machine.add_transition(ProtocolState::Connecting, ProtocolEvent::Error, ProtocolState::Error);
        machine.add_transition(ProtocolState::Connected, ProtocolEvent::Send, ProtocolState::Sending);
        machine.add_transition(ProtocolState::Connected, ProtocolEvent::Receive, ProtocolState::Receiving);
        machine.add_transition(ProtocolState::Connected, ProtocolEvent::Disconnect, ProtocolState::Disconnecting);
        machine.add_transition(ProtocolState::Sending, ProtocolEvent::Send, ProtocolState::Connected);
        machine.add_transition(ProtocolState::Receiving, ProtocolEvent::Receive, ProtocolState::Connected);
        machine.add_transition(ProtocolState::Disconnecting, ProtocolEvent::Disconnect, ProtocolState::Idle);
        machine.add_transition(ProtocolState::Error, ProtocolEvent::Connect, ProtocolState::Connecting);
        
        machine
    }
    
    fn add_transition(&mut self, from: ProtocolState, event: ProtocolEvent, to: ProtocolState) {
        self.transitions.push(ProtocolTransition {
            from,
            event,
            to,
            action: None,
        });
    }
    
    fn process_event(&mut self, event: ProtocolEvent) -> bool {
        for transition in &self.transitions {
            if transition.from == self.current_state && transition.event == event {
                self.current_state = transition.to.clone();
                if let Some(action) = transition.action {
                    action();
                }
                return true;
            }
        }
        false
    }
    
    fn current_state(&self) -> &ProtocolState {
        &self.current_state
    }
    
    fn is_valid_state(&self) -> bool {
        matches!(self.current_state, 
            ProtocolState::Idle | 
            ProtocolState::Connected | 
            ProtocolState::Sending | 
            ProtocolState::Receiving
        )
    }
}
```

## 7. 参考文献

1. Hopcroft, J. E., Motwani, R., & Ullman, J. D. (2006). *Introduction to Automata Theory, Languages, and Computation*. Pearson Education.
2. Sipser, M. (2012). *Introduction to the Theory of Computation*. Cengage Learning.
3. Chomsky, N. (1956). *Three Models for the Description of Language*. IRE Transactions on Information Theory, 2(3), 113-124.
4. Aho, A. V., Lam, M. S., Sethi, R., & Ullman, J. D. (2006). *Compilers: Principles, Techniques, and Tools*. Pearson Education.
5. Jurafsky, D., & Martin, J. H. (2009). *Speech and Language Processing*. Pearson Education.
6. Lynch, N. A. (1996). *Distributed Algorithms*. Morgan Kaufmann.
7. Clarke, E. M., Grumberg, O., & Peled, D. A. (1999). *Model Checking*. MIT Press.
8. Kozen, D. (2006). *Theory of Computation*. Springer.

---

**相关文档**:

- [02.2 正则语言](02.2_Regular_Languages.md)
- [02.3 上下文无关语言](02.3_Context_Free_Languages.md)
- [02.4 上下文相关语言](02.4_Context_Sensitive_Languages.md)
- [02.5 递归可枚举语言](02.5_Recursively_Enumerable_Languages.md)
- [02.6 自动机理论](../02.6_Automata_Theory.md)
- [02.7 可计算性理论](02.7_Computability_Theory.md)
- [02.8 复杂性理论](02.8_Complexity_Theory.md)


## 批判性分析

- 本节内容待补充：请从多元理论视角、局限性、争议点、应用前景等方面进行批判性分析。
