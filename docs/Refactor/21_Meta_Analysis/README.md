# 21. å…ƒåˆ†æç†è®º (Meta Analysis Theory)

## ç†è®ºæ¦‚è¿°

å…ƒåˆ†æç†è®ºæ˜¯å½¢å¼ç§‘å­¦çŸ¥è¯†ä½“ç³»ä¸­çš„é«˜çº§åˆ†ææ–¹æ³•è®ºï¼Œæ—¨åœ¨å¯¹ç§‘å­¦ç†è®ºã€æ–¹æ³•å’Œç»“æœè¿›è¡Œç³»ç»Ÿæ€§åˆ†æå’Œç»¼åˆã€‚è¯¥ç†è®ºæ¶µç›–äº†ç†è®ºè¯„ä¼°ã€æ–¹æ³•æ¯”è¾ƒã€ç»“æœæ•´åˆä»¥åŠçŸ¥è¯†ç»¼åˆç­‰æ ¸å¿ƒå†…å®¹ã€‚

### æ ¸å¿ƒæ¦‚å¿µ

**å®šä¹‰ 21.1 (å…ƒåˆ†æ)** å…ƒåˆ†ææ˜¯å¯¹å¤šä¸ªç ”ç©¶ç»“æœè¿›è¡Œç³»ç»Ÿæ€§ç»Ÿè®¡åˆ†æå’Œç»¼åˆçš„æ–¹æ³•ã€‚

**å®šä¹‰ 21.2 (ç†è®ºè¯„ä¼°)** ç†è®ºè¯„ä¼°æ˜¯å¯¹ç§‘å­¦ç†è®ºçš„æœ‰æ•ˆæ€§ã€ä¸€è‡´æ€§å’Œé€‚ç”¨æ€§è¿›è¡Œç³»ç»Ÿæ€§è¯„ä»·çš„è¿‡ç¨‹ã€‚

**å®šä¹‰ 21.3 (çŸ¥è¯†ç»¼åˆ)** çŸ¥è¯†ç»¼åˆæ˜¯å°†åˆ†æ•£çš„çŸ¥è¯†ç‰‡æ®µæ•´åˆæˆç³»ç»Ÿæ€§çŸ¥è¯†ä½“ç³»çš„è¿‡ç¨‹ã€‚

### ç†è®ºåŸºç¡€

**å®šç† 21.1 (å…ƒåˆ†ææœ‰æ•ˆæ€§å®šç†)** å…ƒåˆ†æçš„æœ‰æ•ˆæ€§å–å†³äºåŸå§‹ç ”ç©¶çš„è´¨é‡å’Œåˆ†ææ–¹æ³•çš„é€‚å½“æ€§ã€‚

**è¯æ˜:** è®¾ $M$ ä¸ºå…ƒåˆ†æç»“æœï¼Œ$Q_i$ ä¸ºç¬¬ $i$ ä¸ªç ”ç©¶çš„è´¨é‡ï¼Œ$A$ ä¸ºåˆ†ææ–¹æ³•ã€‚å…ƒåˆ†ææœ‰æ•ˆæ€§ $E = f(\prod_{i} Q_i, A)$ã€‚å½“ç ”ç©¶è´¨é‡é«˜ä¸”æ–¹æ³•é€‚å½“æ—¶ï¼Œ$E$ è¾¾åˆ°æœ€å¤§å€¼ã€‚$\square$

**å®šç† 21.2 (çŸ¥è¯†ç»¼åˆå®šç†)** çŸ¥è¯†ç»¼åˆçš„æ•ˆæœä¸çŸ¥è¯†ç‰‡æ®µé—´çš„ç›¸å…³æ€§å’Œç»¼åˆæ–¹æ³•çš„ç³»ç»Ÿæ€§æˆæ­£æ¯”ã€‚

**è¯æ˜:** è®¾ $K_1, K_2, ..., K_n$ ä¸ºçŸ¥è¯†ç‰‡æ®µï¼Œ$C(K_i, K_j)$ ä¸ºç›¸å…³æ€§ï¼Œ$S$ ä¸ºç»¼åˆæ–¹æ³•ã€‚ç»¼åˆæ•ˆæœ $F = f(\sum_{i,j} C(K_i, K_j), S)$ã€‚å½“ç›¸å…³æ€§é«˜ä¸”æ–¹æ³•ç³»ç»Ÿæ—¶ï¼Œ$F$ æœ€å¤§åŒ–ã€‚$\square$

## ç›®å½•ç»“æ„

```text
21_Meta_Analysis/
â”œâ”€â”€ README.md                           # æœ¬æ–‡ä»¶
â”œâ”€â”€ 21.1_Fundamentals/                 # åŸºç¡€ç†è®º
â”‚   â”œâ”€â”€ 21.1_Fundamentals.md          # å…ƒåˆ†æåŸºç¡€ç†è®º
â”‚   â”œâ”€â”€ 21.1.1_Statistical_Analysis.md # ç»Ÿè®¡åˆ†æç†è®º
â”‚   â”œâ”€â”€ 21.1.2_Theory_Evaluation.md   # ç†è®ºè¯„ä¼°ç†è®º
â”‚   â””â”€â”€ 21.1.3_Knowledge_Synthesis.md # çŸ¥è¯†ç»¼åˆç†è®º
â”œâ”€â”€ 21.2_Meta_Study_Methods/           # å…ƒç ”ç©¶æ–¹æ³•
â”‚   â”œâ”€â”€ 21.2.1_Systematic_Review.md   # ç³»ç»Ÿç»¼è¿°
â”‚   â”œâ”€â”€ 21.2.2_Meta_Regression.md     # å…ƒå›å½’åˆ†æ
â”‚   â””â”€â”€ 21.2.3_Bayesian_Meta.md       # è´å¶æ–¯å…ƒåˆ†æ
â”œâ”€â”€ 21.3_Quality_Assessment/           # è´¨é‡è¯„ä¼°
â”‚   â”œâ”€â”€ 21.3.1_Study_Quality.md       # ç ”ç©¶è´¨é‡è¯„ä¼°
â”‚   â”œâ”€â”€ 21.3.2_Bias_Assessment.md     # åå€šè¯„ä¼°
â”‚   â””â”€â”€ 21.3.3_Heterogeneity.md       # å¼‚è´¨æ€§åˆ†æ
â””â”€â”€ 21.4_Reporting_Standards/          # æŠ¥å‘Šæ ‡å‡†
    â”œâ”€â”€ 21.4.1_PRISMA_Standards.md    # PRISMAæ ‡å‡†
    â”œâ”€â”€ 21.4.2_Reporting_Guidelines.md # æŠ¥å‘ŠæŒ‡å—
    â””â”€â”€ 21.4.3_Quality_Checklist.md   # è´¨é‡æ£€æŸ¥æ¸…å•
```

## Rust å®ç°

### å…ƒåˆ†ææ¡†æ¶

```rust
use std::collections::HashMap;
use serde::{Deserialize, Serialize};

/// ç ”ç©¶ç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StudyResult {
    pub study_id: String,
    pub title: String,
    pub authors: Vec<String>,
    pub year: i32,
    pub sample_size: i32,
    pub effect_size: f64,
    pub standard_error: f64,
    pub confidence_interval: (f64, f64),
    pub quality_score: f64,
    pub publication_bias: PublicationBias,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum PublicationBias {
    Low,
    Medium,
    High,
}

/// å…ƒåˆ†æ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MetaAnalysis {
    pub analysis_id: String,
    pub title: String,
    pub studies: Vec<StudyResult>,
    pub analysis_method: AnalysisMethod,
    pub results: MetaAnalysisResults,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AnalysisMethod {
    FixedEffects,
    RandomEffects,
    Bayesian,
    Network,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MetaAnalysisResults {
    pub overall_effect: f64,
    pub standard_error: f64,
    pub confidence_interval: (f64, f64),
    pub heterogeneity: HeterogeneityStats,
    pub publication_bias: PublicationBiasStats,
}
```

### ç»Ÿè®¡åˆ†æå®ç°

```rust
/// å…ƒåˆ†æç»Ÿè®¡è®¡ç®—å™¨
pub struct MetaAnalysisCalculator {
    studies: Vec<StudyResult>,
    method: AnalysisMethod,
}

impl MetaAnalysisCalculator {
    pub fn new(studies: Vec<StudyResult>, method: AnalysisMethod) -> Self {
        Self { studies, method }
    }

    /// æ‰§è¡Œå…ƒåˆ†æ
    pub fn perform_analysis(&self) -> MetaAnalysisResults {
        match self.method {
            AnalysisMethod::FixedEffects => self.fixed_effects_analysis(),
            AnalysisMethod::RandomEffects => self.random_effects_analysis(),
            AnalysisMethod::Bayesian => self.bayesian_analysis(),
            AnalysisMethod::Network => self.network_analysis(),
        }
    }

    /// å›ºå®šæ•ˆåº”åˆ†æ
    fn fixed_effects_analysis(&self) -> MetaAnalysisResults {
        let mut weighted_sum = 0.0;
        let mut weight_sum = 0.0;
        
        for study in &self.studies {
            let weight = 1.0 / (study.standard_error.powi(2));
            weighted_sum += study.effect_size * weight;
            weight_sum += weight;
        }
        
        let overall_effect = weighted_sum / weight_sum;
        let standard_error = (1.0 / weight_sum).sqrt();
        let confidence_interval = (
            overall_effect - 1.96 * standard_error,
            overall_effect + 1.96 * standard_error,
        );
        
        MetaAnalysisResults {
            overall_effect,
            standard_error,
            confidence_interval,
            heterogeneity: self.calculate_heterogeneity(),
            publication_bias: self.assess_publication_bias(),
        }
    }

    /// éšæœºæ•ˆåº”åˆ†æ
    fn random_effects_analysis(&self) -> MetaAnalysisResults {
        // è®¡ç®—ç»„é—´æ–¹å·®
        let tau_squared = self.calculate_tau_squared();
        
        let mut weighted_sum = 0.0;
        let mut weight_sum = 0.0;
        
        for study in &self.studies {
            let total_variance = study.standard_error.powi(2) + tau_squared;
            let weight = 1.0 / total_variance;
            weighted_sum += study.effect_size * weight;
            weight_sum += weight;
        }
        
        let overall_effect = weighted_sum / weight_sum;
        let standard_error = (1.0 / weight_sum).sqrt();
        let confidence_interval = (
            overall_effect - 1.96 * standard_error,
            overall_effect + 1.96 * standard_error,
        );
        
        MetaAnalysisResults {
            overall_effect,
            standard_error,
            confidence_interval,
            heterogeneity: self.calculate_heterogeneity(),
            publication_bias: self.assess_publication_bias(),
        }
    }

    fn calculate_tau_squared(&self) -> f64 {
        // Qç»Ÿè®¡é‡è®¡ç®—
        let q_statistic = self.calculate_q_statistic();
        let df = self.studies.len() as f64 - 1.0;
        
        if q_statistic > df {
            (q_statistic - df) / self.calculate_c_statistic()
        } else {
            0.0
        }
    }

    fn calculate_q_statistic(&self) -> f64 {
        let fixed_effects_result = self.fixed_effects_analysis();
        let mut q = 0.0;
        
        for study in &self.studies {
            let weight = 1.0 / study.standard_error.powi(2);
            q += weight * (study.effect_size - fixed_effects_result.overall_effect).powi(2);
        }
        
        q
    }

    fn calculate_c_statistic(&self) -> f64 {
        let mut sum_weights = 0.0;
        let mut sum_squared_weights = 0.0;
        
        for study in &self.studies {
            let weight = 1.0 / study.standard_error.powi(2);
            sum_weights += weight;
            sum_squared_weights += weight.powi(2);
        }
        
        sum_weights - sum_squared_weights / sum_weights
    }

    fn calculate_heterogeneity(&self) -> HeterogeneityStats {
        let q_statistic = self.calculate_q_statistic();
        let df = self.studies.len() as f64 - 1.0;
        let i_squared = if q_statistic > df {
            ((q_statistic - df) / q_statistic) * 100.0
        } else {
            0.0
        };
        
        HeterogeneityStats {
            q_statistic,
            i_squared,
            tau_squared: self.calculate_tau_squared(),
            p_value: self.calculate_heterogeneity_p_value(q_statistic, df),
        }
    }

    fn calculate_heterogeneity_p_value(&self, q: f64, df: f64) -> f64 {
        // ç®€åŒ–çš„å¡æ–¹åˆ†å¸ƒpå€¼è®¡ç®—
        1.0 - (q / df).exp() / 2.0
    }

    fn assess_publication_bias(&self) -> PublicationBiasStats {
        // æ¼æ–—å›¾åˆ†æ
        let mut small_studies = Vec::new();
        let mut large_studies = Vec::new();
        
        for study in &self.studies {
            if study.sample_size < 100 {
                small_studies.push(study.effect_size);
            } else {
                large_studies.push(study.effect_size);
            }
        }
        
        let small_mean = small_studies.iter().sum::<f64>() / small_studies.len() as f64;
        let large_mean = large_studies.iter().sum::<f64>() / large_studies.len() as f64;
        let bias_estimate = small_mean - large_mean;
        
        PublicationBiasStats {
            bias_estimate,
            funnel_plot_asymmetry: self.calculate_funnel_asymmetry(),
            egger_test: self.perform_egger_test(),
        }
    }

    fn calculate_funnel_asymmetry(&self) -> f64 {
        // ç®€åŒ–çš„æ¼æ–—å›¾ä¸å¯¹ç§°æ€§è®¡ç®—
        let mut precision_sum = 0.0;
        let mut effect_sum = 0.0;
        
        for study in &self.studies {
            let precision = 1.0 / study.standard_error;
            precision_sum += precision;
            effect_sum += study.effect_size * precision;
        }
        
        let mean_effect = effect_sum / precision_sum;
        let mut asymmetry = 0.0;
        
        for study in &self.studies {
            let precision = 1.0 / study.standard_error;
            asymmetry += (study.effect_size - mean_effect) * precision;
        }
        
        asymmetry
    }

    fn perform_egger_test(&self) -> EggerTestResult {
        // ç®€åŒ–çš„Eggeræ£€éªŒ
        let n = self.studies.len() as f64;
        let mut x_sum = 0.0;
        let mut y_sum = 0.0;
        let mut xy_sum = 0.0;
        let mut x_squared_sum = 0.0;
        
        for study in &self.studies {
            let x = 1.0 / study.standard_error;
            let y = study.effect_size / study.standard_error;
            
            x_sum += x;
            y_sum += y;
            xy_sum += x * y;
            x_squared_sum += x.powi(2);
        }
        
        let slope = (n * xy_sum - x_sum * y_sum) / (n * x_squared_sum - x_sum.powi(2));
        let intercept = (y_sum - slope * x_sum) / n;
        
        EggerTestResult {
            intercept,
            slope,
            p_value: 0.05, // ç®€åŒ–å€¼
        }
    }

    fn bayesian_analysis(&self) -> MetaAnalysisResults {
        // ç®€åŒ–çš„è´å¶æ–¯åˆ†æ
        self.random_effects_analysis()
    }

    fn network_analysis(&self) -> MetaAnalysisResults {
        // ç®€åŒ–çš„ç½‘ç»œå…ƒåˆ†æ
        self.random_effects_analysis()
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HeterogeneityStats {
    pub q_statistic: f64,
    pub i_squared: f64,
    pub tau_squared: f64,
    pub p_value: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PublicationBiasStats {
    pub bias_estimate: f64,
    pub funnel_plot_asymmetry: f64,
    pub egger_test: EggerTestResult,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EggerTestResult {
    pub intercept: f64,
    pub slope: f64,
    pub p_value: f64,
}
```

### è´¨é‡è¯„ä¼°ç³»ç»Ÿ

```rust
/// ç ”ç©¶è´¨é‡è¯„ä¼°å™¨
pub struct QualityAssessor {
    criteria: Vec<QualityCriterion>,
    weights: HashMap<String, f64>,
}

impl QualityAssessor {
    pub fn new() -> Self {
        let mut weights = HashMap::new();
        weights.insert("randomization".to_string(), 0.3);
        weights.insert("blinding".to_string(), 0.2);
        weights.insert("allocation".to_string(), 0.2);
        weights.insert("reporting".to_string(), 0.15);
        weights.insert("follow_up".to_string(), 0.15);
        
        Self {
            criteria: vec![
                QualityCriterion {
                    name: "randomization".to_string(),
                    description: "éšæœºåŒ–æ–¹æ³•".to_string(),
                    max_score: 2.0,
                },
                QualityCriterion {
                    name: "blinding".to_string(),
                    description: "ç›²æ³•ä½¿ç”¨".to_string(),
                    max_score: 2.0,
                },
                QualityCriterion {
                    name: "allocation".to_string(),
                    description: "åˆ†é…éšè—".to_string(),
                    max_score: 2.0,
                },
                QualityCriterion {
                    name: "reporting".to_string(),
                    description: "æŠ¥å‘Šå®Œæ•´æ€§".to_string(),
                    max_score: 1.0,
                },
                QualityCriterion {
                    name: "follow_up".to_string(),
                    description: "éšè®¿å®Œæ•´æ€§".to_string(),
                    max_score: 1.0,
                },
            ],
            weights,
        }
    }

    /// è¯„ä¼°ç ”ç©¶è´¨é‡
    pub fn assess_study_quality(&self, study: &StudyResult) -> QualityAssessment {
        let mut scores = HashMap::new();
        let mut total_score = 0.0;
        let mut max_possible_score = 0.0;
        
        for criterion in &self.criteria {
            let score = self.evaluate_criterion(criterion, study);
            scores.insert(criterion.name.clone(), score);
            
            let weight = self.weights.get(&criterion.name).unwrap_or(&1.0);
            total_score += score * weight;
            max_possible_score += criterion.max_score * weight;
        }
        
        let quality_score = total_score / max_possible_score;
        
        QualityAssessment {
            study_id: study.study_id.clone(),
            scores,
            total_score,
            quality_score,
            risk_level: self.determine_risk_level(quality_score),
        }
    }

    fn evaluate_criterion(&self, criterion: &QualityCriterion, study: &StudyResult) -> f64 {
        // ç®€åŒ–çš„æ ‡å‡†è¯„ä¼°
        match criterion.name.as_str() {
            "randomization" => {
                if study.sample_size > 100 { 2.0 } else { 1.0 }
            },
            "blinding" => {
                if study.quality_score > 0.7 { 2.0 } else { 1.0 }
            },
            "allocation" => {
                if study.standard_error < 0.5 { 2.0 } else { 1.0 }
            },
            "reporting" => {
                if study.confidence_interval.1 - study.confidence_interval.0 < 1.0 { 1.0 } else { 0.5 }
            },
            "follow_up" => {
                if study.year > 2010 { 1.0 } else { 0.5 }
            },
            _ => 0.0,
        }
    }

    fn determine_risk_level(&self, quality_score: f64) -> RiskLevel {
        match quality_score {
            s if s >= 0.8 => RiskLevel::Low,
            s if s >= 0.6 => RiskLevel::Medium,
            s if s >= 0.4 => RiskLevel::High,
            _ => RiskLevel::VeryHigh,
        }
    }
}

#[derive(Debug, Clone)]
pub struct QualityCriterion {
    pub name: String,
    pub description: String,
    pub max_score: f64,
}

#[derive(Debug, Clone)]
pub struct QualityAssessment {
    pub study_id: String,
    pub scores: HashMap<String, f64>,
    pub total_score: f64,
    pub quality_score: f64,
    pub risk_level: RiskLevel,
}

#[derive(Debug, Clone)]
pub enum RiskLevel {
    Low,
    Medium,
    High,
    VeryHigh,
}
```

## åº”ç”¨åœºæ™¯

### 1. ç³»ç»Ÿç»¼è¿°ç”Ÿæˆ

```rust
/// ç³»ç»Ÿç»¼è¿°ç”Ÿæˆå™¨
pub struct SystematicReviewGenerator {
    search_strategy: SearchStrategy,
    inclusion_criteria: Vec<InclusionCriterion>,
    quality_assessor: QualityAssessor,
    meta_analyzer: MetaAnalysisCalculator,
}

impl SystematicReviewGenerator {
    pub fn new() -> Self {
        Self {
            search_strategy: SearchStrategy::new(),
            inclusion_criteria: vec![
                InclusionCriterion {
                    name: "sample_size".to_string(),
                    condition: ">= 30".to_string(),
                },
                InclusionCriterion {
                    name: "year".to_string(),
                    condition: ">= 2010".to_string(),
                },
            ],
            quality_assessor: QualityAssessor::new(),
            meta_analyzer: MetaAnalysisCalculator::new(Vec::new(), AnalysisMethod::RandomEffects),
        }
    }

    /// ç”Ÿæˆç³»ç»Ÿç»¼è¿°
    pub fn generate_review(&self, research_question: &str) -> SystematicReview {
        let studies = self.search_strategy.search(research_question);
        let filtered_studies = self.apply_inclusion_criteria(&studies);
        let quality_assessments = self.assess_study_quality(&filtered_studies);
        let meta_analysis = self.perform_meta_analysis(&filtered_studies);
        
        SystematicReview {
            research_question: research_question.to_string(),
            included_studies: filtered_studies,
            quality_assessments,
            meta_analysis,
            conclusions: self.generate_conclusions(&meta_analysis),
        }
    }

    fn apply_inclusion_criteria(&self, studies: &[StudyResult]) -> Vec<StudyResult> {
        studies.iter()
            .filter(|study| {
                self.inclusion_criteria.iter().all(|criterion| {
                    self.evaluate_criterion(study, criterion)
                })
            })
            .cloned()
            .collect()
    }

    fn evaluate_criterion(&self, study: &StudyResult, criterion: &InclusionCriterion) -> bool {
        match criterion.name.as_str() {
            "sample_size" => study.sample_size >= 30,
            "year" => study.year >= 2010,
            _ => true,
        }
    }

    fn assess_study_quality(&self, studies: &[StudyResult]) -> Vec<QualityAssessment> {
        studies.iter()
            .map(|study| self.quality_assessor.assess_study_quality(study))
            .collect()
    }

    fn perform_meta_analysis(&self, studies: &[StudyResult]) -> MetaAnalysisResults {
        let calculator = MetaAnalysisCalculator::new(studies.to_vec(), AnalysisMethod::RandomEffects);
        calculator.perform_analysis()
    }

    fn generate_conclusions(&self, results: &MetaAnalysisResults) -> Vec<String> {
        let mut conclusions = Vec::new();
        
        if results.overall_effect > 0.0 {
            conclusions.push("å¹²é¢„æªæ–½å…·æœ‰ç§¯ææ•ˆæœ".to_string());
        } else {
            conclusions.push("å¹²é¢„æªæ–½æ•ˆæœä¸æ˜¾è‘—".to_string());
        }
        
        if results.heterogeneity.i_squared > 50.0 {
            conclusions.push("ç ”ç©¶é—´å­˜åœ¨æ˜¾è‘—å¼‚è´¨æ€§".to_string());
        }
        
        if results.publication_bias.bias_estimate.abs() > 0.5 {
            conclusions.push("å¯èƒ½å­˜åœ¨å‘è¡¨åå€š".to_string());
        }
        
        conclusions
    }
}

#[derive(Debug)]
pub struct SearchStrategy {
    pub databases: Vec<String>,
    pub keywords: Vec<String>,
}

impl SearchStrategy {
    pub fn new() -> Self {
        Self {
            databases: vec!["PubMed".to_string(), "Embase".to_string(), "Cochrane".to_string()],
            keywords: Vec::new(),
        }
    }

    pub fn search(&self, query: &str) -> Vec<StudyResult> {
        // ç®€åŒ–çš„æœç´¢å®ç°
        vec![
            StudyResult {
                study_id: "STUDY001".to_string(),
                title: "Randomized controlled trial".to_string(),
                authors: vec!["Author A".to_string(), "Author B".to_string()],
                year: 2020,
                sample_size: 100,
                effect_size: 0.5,
                standard_error: 0.1,
                confidence_interval: (0.3, 0.7),
                quality_score: 0.8,
                publication_bias: PublicationBias::Low,
            },
        ]
    }
}

#[derive(Debug)]
pub struct InclusionCriterion {
    pub name: String,
    pub condition: String,
}

#[derive(Debug)]
pub struct SystematicReview {
    pub research_question: String,
    pub included_studies: Vec<StudyResult>,
    pub quality_assessments: Vec<QualityAssessment>,
    pub meta_analysis: MetaAnalysisResults,
    pub conclusions: Vec<String>,
}
```

## ç†è®ºæ‰©å±•

### 1. è´å¶æ–¯å…ƒåˆ†æç†è®º

**å®šç† 21.3 (è´å¶æ–¯å…ƒåˆ†æå®šç†)** è´å¶æ–¯å…ƒåˆ†æé€šè¿‡å…ˆéªŒåˆ†å¸ƒå’ŒåéªŒåˆ†å¸ƒæä¾›æ›´ä¸°å¯Œçš„ä¸ç¡®å®šæ€§é‡åŒ–ã€‚

**è¯æ˜:** è®¾ $\theta$ ä¸ºçœŸå®æ•ˆåº”ï¼Œ$D$ ä¸ºæ•°æ®ï¼Œ$\pi(\theta)$ ä¸ºå…ˆéªŒåˆ†å¸ƒã€‚åéªŒåˆ†å¸ƒ $p(\theta|D) \propto p(D|\theta)\pi(\theta)$ã€‚è´å¶æ–¯æ–¹æ³•æä¾›å®Œæ•´çš„åéªŒåˆ†å¸ƒï¼Œè€Œä¸ä»…ä»…æ˜¯ç‚¹ä¼°è®¡ã€‚$\square$

### 2. ç½‘ç»œå…ƒåˆ†æç†è®º

**å®šä¹‰ 21.4 (ç½‘ç»œå…ƒåˆ†æ)** ç½‘ç»œå…ƒåˆ†ææ˜¯åŒæ—¶æ¯”è¾ƒå¤šä¸ªå¹²é¢„æªæ–½çš„å…ƒåˆ†ææ–¹æ³•ã€‚

**å®šç† 21.4 (ç½‘ç»œä¸€è‡´æ€§å®šç†)** ç½‘ç»œå…ƒåˆ†æçš„ä¸€è‡´æ€§å–å†³äºç›´æ¥è¯æ®å’Œé—´æ¥è¯æ®çš„ä¸€è‡´æ€§ã€‚

**è¯æ˜:** è®¾ $E_{direct}$ ä¸ºç›´æ¥è¯æ®ï¼Œ$E_{indirect}$ ä¸ºé—´æ¥è¯æ®ã€‚ç½‘ç»œä¸€è‡´æ€§ $C = f(E_{direct}, E_{indirect})$ã€‚å½“ç›´æ¥å’Œé—´æ¥è¯æ®ä¸€è‡´æ—¶ï¼Œç½‘ç»œåˆ†æç»“æœå¯é ã€‚$\square$

## ğŸ¯ æ‰¹åˆ¤æ€§åˆ†æ

### å¤šå…ƒç†è®ºè§†è§’

- ç»Ÿè®¡è§†è§’ï¼šå…ƒåˆ†æç†è®ºåŸºäºç»Ÿè®¡å­¦åŸç†ï¼Œæä¾›ç³»ç»ŸåŒ–çš„è¯æ®ç»¼åˆæ–¹æ³•ã€‚
- è´¨é‡è§†è§’ï¼šå…ƒåˆ†æç†è®ºå…³æ³¨ç ”ç©¶è´¨é‡è¯„ä¼°å’Œåå€šæ§åˆ¶ã€‚
- ç»¼åˆè§†è§’ï¼šå…ƒåˆ†æç†è®ºæ•´åˆå¤šä¸ªç ”ç©¶ç»“æœï¼Œæä¾›æ›´å¯é çš„è¯æ®ã€‚
- åº”ç”¨è§†è§’ï¼šå…ƒåˆ†æç†è®ºä¸ºç§‘å­¦å†³ç­–å’Œä¸´åºŠå®è·µæä¾›è¯æ®æ”¯æŒã€‚

### å±€é™æ€§åˆ†æ

- å‘è¡¨åå€šï¼šé˜³æ€§ç»“æœæ›´å®¹æ˜“å‘è¡¨ï¼Œå¯¼è‡´ç³»ç»Ÿæ€§åå€šã€‚
- å¼‚è´¨æ€§ï¼šç ”ç©¶é—´å·®å¼‚å¯èƒ½å½±å“ç»“æœçš„å¯è§£é‡Šæ€§å’Œå¯é æ€§ã€‚
- è´¨é‡å·®å¼‚ï¼šçº³å…¥ç ”ç©¶çš„è´¨é‡å‚å·®ä¸é½ï¼Œå½±å“ç»¼åˆç»“æœçš„å¯é æ€§ã€‚
- ç»Ÿè®¡æ–¹æ³•ï¼šä¸åŒç»Ÿè®¡æ–¹æ³•å¯èƒ½äº§ç”Ÿä¸åŒçš„ç»“æœå’Œè§£é‡Šã€‚

### äº‰è®®ä¸åˆ†æ­§

- çº³å…¥æ ‡å‡†ï¼šä¸åŒçº³å…¥æ ‡å‡†å¯¹ç»“æœçš„å½±å“å’Œé€‰æ‹©ã€‚
- ç»Ÿè®¡æ¨¡å‹ï¼šå›ºå®šæ•ˆåº”vséšæœºæ•ˆåº”æ¨¡å‹çš„é€‰æ‹©ã€‚
- è´¨é‡è¯„ä¼°ï¼šä¸åŒè´¨é‡è¯„ä¼°å·¥å…·çš„æœ‰æ•ˆæ€§å’Œé€‚ç”¨æ€§ã€‚
- ç»“æœè§£é‡Šï¼šå…ƒåˆ†æç»“æœçš„è§£é‡Šå’Œä¸´åºŠåº”ç”¨ã€‚

### åº”ç”¨å‰æ™¯

- åŒ»å­¦ç ”ç©¶ï¼šå¾ªè¯åŒ»å­¦å’Œä¸´åºŠå†³ç­–æ”¯æŒã€‚
- ç¤¾ä¼šç§‘å­¦ï¼šç¤¾ä¼šç§‘å­¦ç ”ç©¶çš„è¯æ®ç»¼åˆã€‚
- æ”¿ç­–åˆ¶å®šï¼šåŸºäºè¯æ®çš„æ”¿ç­–åˆ¶å®šå’Œè¯„ä¼°ã€‚
- æ•™è‚²ç ”ç©¶ï¼šæ•™è‚²å¹²é¢„æªæ–½çš„æ•ˆæœè¯„ä¼°ã€‚

### æ”¹è¿›å»ºè®®

- å‘å±•æ›´å¼ºå¤§çš„åå€šæ£€æµ‹å’Œæ§åˆ¶æ–¹æ³•ã€‚
- å»ºç«‹æ›´å®Œå–„çš„è´¨é‡è¯„ä¼°å’ŒæŠ¥å‘Šæ ‡å‡†ã€‚
- åŠ å¼ºå…ƒåˆ†æç»“æœçš„é€æ˜åº¦å’Œå¯é‡ç°æ€§ã€‚
- ä¿ƒè¿›å…ƒåˆ†æç†è®ºçš„æ•™è‚²å’Œæ ‡å‡†åŒ–åº”ç”¨ã€‚

## æ€»ç»“

å…ƒåˆ†æç†è®ºä¸ºå½¢å¼ç§‘å­¦çŸ¥è¯†ä½“ç³»æä¾›äº†é‡è¦çš„ç»¼åˆåˆ†ææ–¹æ³•ã€‚é€šè¿‡ç³»ç»ŸåŒ–çš„ç»Ÿè®¡åˆ†æå’Œè´¨é‡è¯„ä¼°ï¼Œæˆ‘ä»¬å¯ä»¥ä»å¤šä¸ªç ”ç©¶ä¸­å¾—å‡ºæ›´å¯é çš„ç»“è®ºã€‚Rustå®ç°æä¾›äº†å…ƒåˆ†æçš„è®¡ç®—æ”¯æŒï¼Œä¸ºç§‘å­¦ç ”ç©¶æä¾›äº†å¼ºå¤§çš„åˆ†æå·¥å…·ã€‚

---

**å‚è€ƒæ–‡çŒ®:**

1. Borenstein, M., Hedges, L. V., Higgins, J. P., & Rothstein, H. R. (2021). Introduction to meta-analysis. John Wiley & Sons.
2. Higgins, J. P., & Green, S. (2011). Cochrane handbook for systematic reviews of interventions. John Wiley & Sons.
3. Egger, M., Smith, G. D., Schneider, M., & Minder, C. (1997). Bias in meta-analysis detected by a simple, graphical test. BMJ, 315(7109), 629-634.
