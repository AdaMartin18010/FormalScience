# 14. æ•°æ®åº“ç†è®º (Database Theory)

## ç›®å½•

- [14. æ•°æ®åº“ç†è®º (Database Theory)](#14-æ•°æ®åº“ç†è®º-database-theory)
  - [ç›®å½•](#ç›®å½•)
  - [ğŸ“‹ æ¨¡å—æ¦‚è¿°](#-æ¨¡å—æ¦‚è¿°)
  - [ğŸ—ï¸ ç›®å½•ç»“æ„](#ï¸-ç›®å½•ç»“æ„)
  - [ğŸ”¬ æ ¸å¿ƒç†è®º](#-æ ¸å¿ƒç†è®º)
    - [1. å…³ç³»æ•°æ®åº“ç†è®º](#1-å…³ç³»æ•°æ®åº“ç†è®º)
    - [2. äº‹åŠ¡ç†è®º](#2-äº‹åŠ¡ç†è®º)
    - [3. æŸ¥è¯¢ä¼˜åŒ–ç†è®º](#3-æŸ¥è¯¢ä¼˜åŒ–ç†è®º)
  - [ğŸ’» Rustå®ç°](#-rustå®ç°)
    - [å…³ç³»æ•°æ®åº“æ ¸å¿ƒå®ç°](#å…³ç³»æ•°æ®åº“æ ¸å¿ƒå®ç°)
    - [äº‹åŠ¡ç®¡ç†å®ç°](#äº‹åŠ¡ç®¡ç†å®ç°)
    - [æŸ¥è¯¢ä¼˜åŒ–å®ç°](#æŸ¥è¯¢ä¼˜åŒ–å®ç°)
  - [ğŸ“Š åº”ç”¨ç¤ºä¾‹](#-åº”ç”¨ç¤ºä¾‹)
    - [ç¤ºä¾‹1ï¼šå…³ç³»æ•°æ®åº“æ“ä½œ](#ç¤ºä¾‹1å…³ç³»æ•°æ®åº“æ“ä½œ)
    - [ç¤ºä¾‹2ï¼šäº‹åŠ¡ç®¡ç†](#ç¤ºä¾‹2äº‹åŠ¡ç®¡ç†)
    - [ç¤ºä¾‹3ï¼šæŸ¥è¯¢ä¼˜åŒ–](#ç¤ºä¾‹3æŸ¥è¯¢ä¼˜åŒ–)
  - [ğŸ”¬ ç†è®ºæ‰©å±•](#-ç†è®ºæ‰©å±•)
    - [1. åˆ†å¸ƒå¼æ•°æ®åº“ç†è®º](#1-åˆ†å¸ƒå¼æ•°æ®åº“ç†è®º)
    - [2. å¹¶å‘æ§åˆ¶ç†è®º](#2-å¹¶å‘æ§åˆ¶ç†è®º)
    - [3. æŸ¥è¯¢ä¼˜åŒ–ç†è®º1](#3-æŸ¥è¯¢ä¼˜åŒ–ç†è®º1)
  - [ğŸ¯ æ‰¹åˆ¤æ€§åˆ†æ](#-æ‰¹åˆ¤æ€§åˆ†æ)
    - [ä¸»è¦ç†è®ºè§‚ç‚¹æ¢³ç†](#ä¸»è¦ç†è®ºè§‚ç‚¹æ¢³ç†)
    - [ç†è®ºä¼˜åŠ¿ä¸å±€é™æ€§](#ç†è®ºä¼˜åŠ¿ä¸å±€é™æ€§)
    - [å­¦ç§‘äº¤å‰èåˆ](#å­¦ç§‘äº¤å‰èåˆ)
    - [åˆ›æ–°æ‰¹åˆ¤ä¸æœªæ¥å±•æœ›](#åˆ›æ–°æ‰¹åˆ¤ä¸æœªæ¥å±•æœ›)
  - [ğŸ“š å‚è€ƒæ–‡çŒ®](#-å‚è€ƒæ–‡çŒ®)

## ğŸ“‹ æ¨¡å—æ¦‚è¿°

æ•°æ®åº“ç†è®ºæ˜¯è®¡ç®—æœºç§‘å­¦ä¸­ç ”ç©¶æ•°æ®å­˜å‚¨ã€ç®¡ç†å’ŒæŸ¥è¯¢çš„æ ¸å¿ƒç†è®ºä½“ç³»ã€‚æœ¬æ¨¡å—æ¶µç›–å…³ç³»æ•°æ®åº“ç†è®ºã€äº‹åŠ¡ç®¡ç†ã€æŸ¥è¯¢ä¼˜åŒ–ã€åˆ†å¸ƒå¼æ•°æ®åº“ç­‰æ ¸å¿ƒæ¦‚å¿µï¼Œä¸ºæ„å»ºé«˜æ•ˆã€å¯é çš„æ•°æ®ç®¡ç†ç³»ç»Ÿæä¾›ç†è®ºåŸºç¡€ã€‚

## ğŸ—ï¸ ç›®å½•ç»“æ„

```text
14_Database_Theory/
â”œâ”€â”€ README.md                           # æ¨¡å—æ€»è§ˆ
â”œâ”€â”€ 01_Database_Foundation_Theory.md    # æ•°æ®åº“åŸºç¡€ç†è®º
â”œâ”€â”€ 15.1_Database_Formal_Proofs.md     # æ•°æ®åº“å½¢å¼åŒ–è¯æ˜
â”œâ”€â”€ 15.1_å…³ç³»ä»£æ•°è¯æ˜.md                # å…³ç³»ä»£æ•°è¯æ˜
â”œâ”€â”€ 01_Data_Models/                     # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ 01.1_Relational_Model.md       # å…³ç³»æ¨¡å‹
â”‚   â”œâ”€â”€ 01.2_Document_Model.md         # æ–‡æ¡£æ¨¡å‹
â”‚   â”œâ”€â”€ 01.3_Graph_Model.md            # å›¾æ¨¡å‹
â”‚   â””â”€â”€ 01.4_Key_Value_Model.md        # é”®å€¼æ¨¡å‹
â”œâ”€â”€ 02_Database_Design/                 # æ•°æ®åº“è®¾è®¡
â”‚   â”œâ”€â”€ 02.1_Normalization_Theory.md   # è§„èŒƒåŒ–ç†è®º
â”‚   â”œâ”€â”€ 02.2_Functional_Dependencies.md # å‡½æ•°ä¾èµ–
â”‚   â””â”€â”€ 02.3_Design_Patterns.md        # è®¾è®¡æ¨¡å¼
â”œâ”€â”€ 03_Query_Optimization/              # æŸ¥è¯¢ä¼˜åŒ–
â”‚   â”œâ”€â”€ 03.1_Query_Plans.md            # æŸ¥è¯¢è®¡åˆ’
â”‚   â”œâ”€â”€ 03.2_Cost_Models.md            # æˆæœ¬æ¨¡å‹
â”‚   â””â”€â”€ 03.3_Optimization_Strategies.md # ä¼˜åŒ–ç­–ç•¥
â”œâ”€â”€ 04_Transaction_Management/          # äº‹åŠ¡ç®¡ç†
â”‚   â”œâ”€â”€ 04.1_ACID_Properties.md        # ACIDæ€§è´¨
â”‚   â”œâ”€â”€ 04.2_Concurrency_Control.md    # å¹¶å‘æ§åˆ¶
â”‚   â””â”€â”€ 04.3_Recovery_Mechanisms.md    # æ¢å¤æœºåˆ¶
â”œâ”€â”€ 12.1_Fundamentals/                 # åŸºç¡€ç†è®º
â”œâ”€â”€ 12.2_Data_Models/                  # æ•°æ®æ¨¡å‹
â”œâ”€â”€ 12.3_Query_Optimization/           # æŸ¥è¯¢ä¼˜åŒ–
â””â”€â”€ 12.4_Transaction_Management/       # äº‹åŠ¡ç®¡ç†
```

## ğŸ”¬ æ ¸å¿ƒç†è®º

### 1. å…³ç³»æ•°æ®åº“ç†è®º

**å®šä¹‰ 1.1** (å…³ç³»)
å…³ç³»æ˜¯å…ƒç»„çš„é›†åˆ $R \subseteq D_1 \times D_2 \times \cdots \times D_n$ï¼Œå…¶ä¸­ $D_i$ æ˜¯åŸŸã€‚

**å®šä¹‰ 1.2** (å…³ç³»ä»£æ•°)
å…³ç³»ä»£æ•°åŒ…å«ä»¥ä¸‹åŸºæœ¬æ“ä½œï¼š

- é€‰æ‹©ï¼š$\sigma_P(R) = \{t \in R \mid P(t)\}$
- æŠ•å½±ï¼š$\pi_A(R) = \{t[A] \mid t \in R\}$
- è¿æ¥ï¼š$R \bowtie S = \{t \mid t[R] \in R \land t[S] \in S\}$

**å®šç† 1.1** (å…³ç³»ä»£æ•°å®Œå¤‡æ€§)
å…³ç³»ä»£æ•°æ“ä½œé›† $\{\sigma, \pi, \bowtie, \cup, \cap, - \}$ æ˜¯å…³ç³»å®Œå¤‡çš„ã€‚

### 2. äº‹åŠ¡ç†è®º

**å®šä¹‰ 2.1** (äº‹åŠ¡)
äº‹åŠ¡æ˜¯æ•°æ®åº“æ“ä½œçš„åŸå­å•å…ƒï¼Œæ»¡è¶³ACIDæ€§è´¨ã€‚

**å®šä¹‰ 2.2** (ACIDæ€§è´¨)

- **åŸå­æ€§(Atomicity)**ï¼šäº‹åŠ¡è¦ä¹ˆå…¨éƒ¨æ‰§è¡Œï¼Œè¦ä¹ˆå…¨éƒ¨å›æ»š
- **ä¸€è‡´æ€§(Consistency)**ï¼šäº‹åŠ¡æ‰§è¡Œå‰åæ•°æ®åº“ä¿æŒä¸€è‡´æ€§
- **éš”ç¦»æ€§(Isolation)**ï¼šå¹¶å‘äº‹åŠ¡äº’ä¸å¹²æ‰°
- **æŒä¹…æ€§(Durability)**ï¼šæäº¤çš„äº‹åŠ¡æ°¸ä¹…ä¿å­˜

### 3. æŸ¥è¯¢ä¼˜åŒ–ç†è®º

**å®šä¹‰ 3.1** (æŸ¥è¯¢è®¡åˆ’)
æŸ¥è¯¢è®¡åˆ’æ˜¯æ‰§è¡ŒæŸ¥è¯¢çš„æ“ä½œåºåˆ—ã€‚

**å®šä¹‰ 3.2** (æˆæœ¬æ¨¡å‹)
æˆæœ¬æ¨¡å‹ä¼°ç®—æŸ¥è¯¢æ‰§è¡Œä»£ä»·ï¼š$Cost(Q) = \sum_{op \in Q} cost(op)$

## ğŸ’» Rustå®ç°

### å…³ç³»æ•°æ®åº“æ ¸å¿ƒå®ç°

```rust
use std::collections::{HashMap, HashSet};
use std::fmt;

/// å…³ç³»æ•°æ®åº“æ ¸å¿ƒç±»å‹
#[derive(Debug, Clone)]
pub struct Relation {
    pub schema: Vec<String>,
    pub tuples: Vec<Vec<Value>>,
}

#[derive(Debug, Clone, PartialEq)]
pub enum Value {
    Integer(i64),
    String(String),
    Boolean(bool),
    Null,
}

impl Relation {
    /// åˆ›å»ºæ–°å…³ç³»
    pub fn new(schema: Vec<String>) -> Self {
        Relation {
            schema,
            tuples: Vec::new(),
        }
    }
    
    /// æ’å…¥å…ƒç»„
    pub fn insert(&mut self, tuple: Vec<Value>) -> Result<(), String> {
        if tuple.len() != self.schema.len() {
            return Err("Tuple length doesn't match schema".to_string());
        }
        self.tuples.push(tuple);
        Ok(())
    }
    
    /// é€‰æ‹©æ“ä½œ
    pub fn select<F>(&self, predicate: F) -> Relation 
    where F: Fn(&[Value]) -> bool {
        let filtered_tuples: Vec<Vec<Value>> = self.tuples
            .iter()
            .filter(|tuple| predicate(tuple))
            .cloned()
            .collect();
        
        Relation {
            schema: self.schema.clone(),
            tuples: filtered_tuples,
        }
    }
    
    /// æŠ•å½±æ“ä½œ
    pub fn project(&self, attributes: &[usize]) -> Result<Relation, String> {
        let mut new_schema = Vec::new();
        for &attr_idx in attributes {
            if attr_idx >= self.schema.len() {
                return Err("Invalid attribute index".to_string());
            }
            new_schema.push(self.schema[attr_idx].clone());
        }
        
        let new_tuples: Vec<Vec<Value>> = self.tuples
            .iter()
            .map(|tuple| {
                attributes.iter()
                    .map(|&idx| tuple[idx].clone())
                    .collect()
            })
            .collect();
        
        Ok(Relation {
            schema: new_schema,
            tuples: new_tuples,
        })
    }
    
    /// è‡ªç„¶è¿æ¥
    pub fn natural_join(&self, other: &Relation) -> Relation {
        // æ‰¾åˆ°å…±åŒå±æ€§
        let common_attrs: Vec<usize> = self.schema.iter()
            .enumerate()
            .filter_map(|(i, attr)| {
                other.schema.iter().position(|a| a == attr).map(|j| (i, j))
            })
            .map(|(i, _)| i)
            .collect();
        
        if common_attrs.is_empty() {
            return Relation::new(vec![]);
        }
        
        let mut result_tuples = Vec::new();
        
        for tuple1 in &self.tuples {
            for tuple2 in &other.tuples {
                // æ£€æŸ¥è¿æ¥æ¡ä»¶
                let can_join = common_attrs.iter().all(|&i| {
                    let j = other.schema.iter().position(|a| a == &self.schema[i]).unwrap();
                    tuple1[i] == tuple2[j]
                });
                
                if can_join {
                    let mut joined_tuple = tuple1.clone();
                    // æ·»åŠ éå…±åŒå±æ€§
                    for (j, val) in tuple2.iter().enumerate() {
                        if !common_attrs.contains(&j) {
                            joined_tuple.push(val.clone());
                        }
                    }
                    result_tuples.push(joined_tuple);
                }
            }
        }
        
        let mut result_schema = self.schema.clone();
        for (i, attr) in other.schema.iter().enumerate() {
            if !self.schema.contains(attr) {
                result_schema.push(attr.clone());
            }
        }
        
        Relation {
            schema: result_schema,
            tuples: result_tuples,
        }
    }
}

/// äº‹åŠ¡ç®¡ç†å™¨
#[derive(Debug)]
pub struct TransactionManager {
    active_transactions: HashMap<u64, Transaction>,
    next_txn_id: u64,
}

#[derive(Debug)]
pub struct Transaction {
    pub id: u64,
    pub state: TransactionState,
    pub operations: Vec<Operation>,
    pub locks: HashSet<String>,
}

#[derive(Debug)]
pub enum TransactionState {
    Active,
    Committed,
    Aborted,
}

#[derive(Debug)]
pub enum Operation {
    Read { table: String, key: String },
    Write { table: String, key: String, value: Value },
    Delete { table: String, key: String },
}

impl TransactionManager {
    pub fn new() -> Self {
        TransactionManager {
            active_transactions: HashMap::new(),
            next_txn_id: 1,
        }
    }
    
    /// å¼€å§‹äº‹åŠ¡
    pub fn begin_transaction(&mut self) -> u64 {
        let txn_id = self.next_txn_id;
        self.next_txn_id += 1;
        
        let transaction = Transaction {
            id: txn_id,
            state: TransactionState::Active,
            operations: Vec::new(),
            locks: HashSet::new(),
        };
        
        self.active_transactions.insert(txn_id, transaction);
        txn_id
    }
    
    /// æäº¤äº‹åŠ¡
    pub fn commit(&mut self, txn_id: u64) -> Result<(), String> {
        if let Some(transaction) = self.active_transactions.get_mut(&txn_id) {
            transaction.state = TransactionState::Committed;
            Ok(())
        } else {
            Err("Transaction not found".to_string())
        }
    }
    
    /// å›æ»šäº‹åŠ¡
    pub fn rollback(&mut self, txn_id: u64) -> Result<(), String> {
        if let Some(transaction) = self.active_transactions.get_mut(&txn_id) {
            transaction.state = TransactionState::Aborted;
            Ok(())
        } else {
            Err("Transaction not found".to_string())
        }
    }
}

/// æŸ¥è¯¢ä¼˜åŒ–å™¨
#[derive(Debug)]
pub struct QueryOptimizer {
    cost_model: CostModel,
}

#[derive(Debug)]
pub struct CostModel {
    pub io_cost_per_page: f64,
    pub cpu_cost_per_tuple: f64,
}

impl QueryOptimizer {
    pub fn new() -> Self {
        QueryOptimizer {
            cost_model: CostModel {
                io_cost_per_page: 1.0,
                cpu_cost_per_tuple: 0.1,
            },
        }
    }
    
    /// ä¼°ç®—æŸ¥è¯¢æˆæœ¬
    pub fn estimate_cost(&self, relation: &Relation, operation: &str) -> f64 {
        let tuple_count = relation.tuples.len() as f64;
        let page_count = (tuple_count / 100.0).ceil(); // å‡è®¾æ¯é¡µ100ä¸ªå…ƒç»„
        
        match operation {
            "scan" => page_count * self.cost_model.io_cost_per_page,
            "select" => tuple_count * self.cost_model.cpu_cost_per_tuple,
            "join" => tuple_count * tuple_count * self.cost_model.cpu_cost_per_tuple,
            _ => 0.0,
        }
    }
    
    /// ç”ŸæˆæŸ¥è¯¢è®¡åˆ’
    pub fn generate_plan(&self, query: &str) -> QueryPlan {
        // ç®€åŒ–çš„æŸ¥è¯¢è®¡åˆ’ç”Ÿæˆ
        QueryPlan {
            operations: vec![
                PlanOperation::Scan { table: "users".to_string() },
                PlanOperation::Select { predicate: "age > 18".to_string() },
                PlanOperation::Project { attributes: vec!["name".to_string(), "email".to_string()] },
            ],
            estimated_cost: 100.0,
        }
    }
}

#[derive(Debug)]
pub struct QueryPlan {
    pub operations: Vec<PlanOperation>,
    pub estimated_cost: f64,
}

#[derive(Debug)]
pub enum PlanOperation {
    Scan { table: String },
    Select { predicate: String },
    Project { attributes: Vec<String> },
    Join { left_table: String, right_table: String, condition: String },
}

/// æ•°æ®åº“ç³»ç»Ÿ
#[derive(Debug)]
pub struct DatabaseSystem {
    pub relations: HashMap<String, Relation>,
    pub transaction_manager: TransactionManager,
    pub query_optimizer: QueryOptimizer,
}

impl DatabaseSystem {
    pub fn new() -> Self {
        DatabaseSystem {
            relations: HashMap::new(),
            transaction_manager: TransactionManager::new(),
            query_optimizer: QueryOptimizer::new(),
        }
    }
    
    /// åˆ›å»ºè¡¨
    pub fn create_table(&mut self, name: String, schema: Vec<String>) {
        let relation = Relation::new(schema);
        self.relations.insert(name, relation);
    }
    
    /// æ‰§è¡ŒæŸ¥è¯¢
    pub fn execute_query(&self, query: &str) -> Result<Relation, String> {
        // ç®€åŒ–çš„æŸ¥è¯¢æ‰§è¡Œ
        let plan = self.query_optimizer.generate_plan(query);
        
        // æ‰§è¡ŒæŸ¥è¯¢è®¡åˆ’
        let mut result = Relation::new(vec!["name".to_string(), "email".to_string()]);
        
        // æ¨¡æ‹ŸæŸ¥è¯¢ç»“æœ
        result.tuples.push(vec![
            Value::String("Alice".to_string()),
            Value::String("alice@example.com".to_string()),
        ]);
        
        Ok(result)
    }
}
```

### äº‹åŠ¡ç®¡ç†å®ç°

```rust
use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant};

/// é”ç®¡ç†å™¨
#[derive(Debug)]
pub struct LockManager {
    locks: Arc<Mutex<HashMap<String, LockInfo>>>,
}

#[derive(Debug)]
pub struct LockInfo {
    pub lock_type: LockType,
    pub holder: u64,
    pub waiters: Vec<u64>,
    pub acquired_at: Instant,
}

#[derive(Debug, Clone, PartialEq)]
pub enum LockType {
    Shared,
    Exclusive,
}

impl LockManager {
    pub fn new() -> Self {
        LockManager {
            locks: Arc::new(Mutex::new(HashMap::new())),
        }
    }
    
    /// è·å–é”
    pub fn acquire_lock(&self, resource: &str, txn_id: u64, lock_type: LockType) -> Result<(), String> {
        let mut locks = self.locks.lock().unwrap();
        
        if let Some(lock_info) = locks.get_mut(resource) {
            match (&lock_info.lock_type, &lock_type) {
                (LockType::Shared, LockType::Shared) => {
                    // å…±äº«é”å¯ä»¥å…±äº«
                    if !lock_info.holder == txn_id {
                        lock_info.waiters.push(txn_id);
                    }
                    Ok(())
                },
                _ => {
                    // å…¶ä»–æƒ…å†µéœ€è¦ç­‰å¾…
                    if !lock_info.waiters.contains(&txn_id) {
                        lock_info.waiters.push(txn_id);
                    }
                    Err("Lock not available".to_string())
                }
            }
        } else {
            // åˆ›å»ºæ–°é”
            locks.insert(resource.to_string(), LockInfo {
                lock_type,
                holder: txn_id,
                waiters: Vec::new(),
                acquired_at: Instant::now(),
            });
            Ok(())
        }
    }
    
    /// é‡Šæ”¾é”
    pub fn release_lock(&self, resource: &str, txn_id: u64) -> Result<(), String> {
        let mut locks = self.locks.lock().unwrap();
        
        if let Some(lock_info) = locks.get_mut(resource) {
            if lock_info.holder == txn_id {
                if lock_info.waiters.is_empty() {
                    locks.remove(resource);
                } else {
                    // å°†é”ç»™ä¸‹ä¸€ä¸ªç­‰å¾…è€…
                    let next_holder = lock_info.waiters.remove(0);
                    lock_info.holder = next_holder;
                }
                Ok(())
            } else {
                Err("Not lock holder".to_string())
            }
        } else {
            Err("Lock not found".to_string())
        }
    }
}

/// ä¸¤é˜¶æ®µé”å®šåè®®
#[derive(Debug)]
pub struct TwoPhaseLocking {
    lock_manager: LockManager,
    growing_phase: HashMap<u64, bool>,
}

impl TwoPhaseLocking {
    pub fn new() -> Self {
        TwoPhaseLocking {
            lock_manager: LockManager::new(),
            growing_phase: HashMap::new(),
        }
    }
    
    /// å¼€å§‹äº‹åŠ¡
    pub fn begin_transaction(&mut self, txn_id: u64) {
        self.growing_phase.insert(txn_id, true);
    }
    
    /// è·å–é”
    pub fn acquire_lock(&self, resource: &str, txn_id: u64, lock_type: LockType) -> Result<(), String> {
        if let Some(&growing) = self.growing_phase.get(&txn_id) {
            if growing {
                self.lock_manager.acquire_lock(resource, txn_id, lock_type)
            } else {
                Err("Transaction in shrinking phase".to_string())
            }
        } else {
            Err("Transaction not found".to_string())
        }
    }
    
    /// è¿›å…¥æ”¶ç¼©é˜¶æ®µ
    pub fn enter_shrinking_phase(&mut self, txn_id: u64) {
        self.growing_phase.insert(txn_id, false);
    }
}
```

### æŸ¥è¯¢ä¼˜åŒ–å®ç°

```rust
use std::collections::HashMap;

/// æŸ¥è¯¢ä¼˜åŒ–å™¨
#[derive(Debug)]
pub struct AdvancedQueryOptimizer {
    statistics: Statistics,
    cost_model: CostModel,
}

#[derive(Debug)]
pub struct Statistics {
    pub table_stats: HashMap<String, TableStats>,
}

#[derive(Debug)]
pub struct TableStats {
    pub row_count: usize,
    pub page_count: usize,
    pub column_stats: HashMap<String, ColumnStats>,
}

#[derive(Debug)]
pub struct ColumnStats {
    pub distinct_values: usize,
    pub null_count: usize,
    pub min_value: Option<Value>,
    pub max_value: Option<Value>,
}

impl AdvancedQueryOptimizer {
    pub fn new() -> Self {
        AdvancedQueryOptimizer {
            statistics: Statistics {
                table_stats: HashMap::new(),
            },
            cost_model: CostModel {
                io_cost_per_page: 1.0,
                cpu_cost_per_tuple: 0.1,
                memory_cost_per_tuple: 0.01,
            },
        }
    }
    
    /// æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    pub fn update_statistics(&mut self, table_name: &str, stats: TableStats) {
        self.statistics.table_stats.insert(table_name.to_string(), stats);
    }
    
    /// ä¼°ç®—é€‰æ‹©æ“ä½œçš„é€‰æ‹©æ€§
    pub fn estimate_selectivity(&self, table: &str, predicate: &str) -> f64 {
        if let Some(table_stats) = self.statistics.table_stats.get(table) {
            // ç®€åŒ–çš„é€‰æ‹©æ€§ä¼°ç®—
            match predicate {
                p if p.contains("=") => 1.0 / table_stats.row_count as f64,
                p if p.contains(">") || p.contains("<") => 0.3,
                _ => 0.1,
            }
        } else {
            0.1 // é»˜è®¤é€‰æ‹©æ€§
        }
    }
    
    /// ç”Ÿæˆæœ€ä¼˜æŸ¥è¯¢è®¡åˆ’
    pub fn generate_optimal_plan(&self, query: &str) -> QueryPlan {
        // è§£ææŸ¥è¯¢
        let parsed_query = self.parse_query(query);
        
        // ç”Ÿæˆå€™é€‰è®¡åˆ’
        let candidate_plans = self.generate_candidate_plans(&parsed_query);
        
        // é€‰æ‹©æˆæœ¬æœ€ä½çš„è®¡åˆ’
        candidate_plans.into_iter()
            .min_by(|a, b| a.estimated_cost.partial_cmp(&b.estimated_cost).unwrap())
            .unwrap_or_else(|| QueryPlan {
                operations: vec![],
                estimated_cost: f64::INFINITY,
            })
    }
    
    fn parse_query(&self, query: &str) -> ParsedQuery {
        // ç®€åŒ–çš„æŸ¥è¯¢è§£æ
        ParsedQuery {
            tables: vec!["users".to_string()],
            predicates: vec!["age > 18".to_string()],
            projections: vec!["name".to_string(), "email".to_string()],
        }
    }
    
    fn generate_candidate_plans(&self, query: &ParsedQuery) -> Vec<QueryPlan> {
        let mut plans = Vec::new();
        
        // è®¡åˆ’1ï¼šè¡¨æ‰«æ + è¿‡æ»¤ + æŠ•å½±
        plans.push(QueryPlan {
            operations: vec![
                PlanOperation::TableScan { table: query.tables[0].clone() },
                PlanOperation::Filter { predicate: query.predicates[0].clone() },
                PlanOperation::Project { attributes: query.projections.clone() },
            ],
            estimated_cost: self.estimate_plan_cost(&query),
        });
        
        // è®¡åˆ’2ï¼šå¦‚æœæœ‰ç´¢å¼•ï¼Œä½¿ç”¨ç´¢å¼•æ‰«æ
        if self.has_index(&query.tables[0], &query.predicates[0]) {
            plans.push(QueryPlan {
                operations: vec![
                    PlanOperation::IndexScan { 
                        table: query.tables[0].clone(),
                        index: "age_index".to_string(),
                    },
                    PlanOperation::Project { attributes: query.projections.clone() },
                ],
                estimated_cost: self.estimate_index_plan_cost(&query),
            });
        }
        
        plans
    }
    
    fn estimate_plan_cost(&self, query: &ParsedQuery) -> f64 {
        let table_name = &query.tables[0];
        let row_count = self.statistics.table_stats
            .get(table_name)
            .map(|stats| stats.row_count)
            .unwrap_or(1000);
        
        let selectivity = self.estimate_selectivity(table_name, &query.predicates[0]);
        let filtered_rows = (row_count as f64 * selectivity) as usize;
        
        // æˆæœ¬è®¡ç®—
        let scan_cost = row_count as f64 * self.cost_model.cpu_cost_per_tuple;
        let filter_cost = filtered_rows as f64 * self.cost_model.cpu_cost_per_tuple;
        let project_cost = filtered_rows as f64 * self.cost_model.cpu_cost_per_tuple;
        
        scan_cost + filter_cost + project_cost
    }
    
    fn estimate_index_plan_cost(&self, query: &ParsedQuery) -> f64 {
        // ç´¢å¼•æ‰«ææˆæœ¬é€šå¸¸æ›´ä½
        let table_name = &query.tables[0];
        let row_count = self.statistics.table_stats
            .get(table_name)
            .map(|stats| stats.row_count)
            .unwrap_or(1000);
        
        let selectivity = self.estimate_selectivity(table_name, &query.predicates[0]);
        let filtered_rows = (row_count as f64 * selectivity) as usize;
        
        // ç´¢å¼•æ‰«ææˆæœ¬
        let index_cost = (filtered_rows as f64).log2() * self.cost_model.cpu_cost_per_tuple;
        let project_cost = filtered_rows as f64 * self.cost_model.cpu_cost_per_tuple;
        
        index_cost + project_cost
    }
    
    fn has_index(&self, table: &str, predicate: &str) -> bool {
        // ç®€åŒ–çš„ç´¢å¼•æ£€æŸ¥
        predicate.contains("age") && table == "users"
    }
}

#[derive(Debug)]
pub struct ParsedQuery {
    pub tables: Vec<String>,
    pub predicates: Vec<String>,
    pub projections: Vec<String>,
}

#[derive(Debug)]
pub struct CostModel {
    pub io_cost_per_page: f64,
    pub cpu_cost_per_tuple: f64,
    pub memory_cost_per_tuple: f64,
}
```

## ğŸ“Š åº”ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šå…³ç³»æ•°æ®åº“æ“ä½œ

```rust
fn main() {
    // åˆ›å»ºæ•°æ®åº“ç³»ç»Ÿ
    let mut db = DatabaseSystem::new();
    
    // åˆ›å»ºç”¨æˆ·è¡¨
    db.create_table("users".to_string(), vec![
        "id".to_string(),
        "name".to_string(), 
        "email".to_string(),
        "age".to_string(),
    ]);
    
    // è·å–ç”¨æˆ·è¡¨
    let mut users = db.relations.get_mut("users").unwrap();
    
    // æ’å…¥æ•°æ®
    users.insert(vec![
        Value::Integer(1),
        Value::String("Alice".to_string()),
        Value::String("alice@example.com".to_string()),
        Value::Integer(25),
    ]).unwrap();
    
    users.insert(vec![
        Value::Integer(2),
        Value::String("Bob".to_string()),
        Value::String("bob@example.com".to_string()),
        Value::Integer(30),
    ]).unwrap();
    
    // æŸ¥è¯¢æ“ä½œ
    let young_users = users.select(|tuple| {
        if let Value::Integer(age) = tuple[3] {
            age < 30
        } else {
            false
        }
    });
    
    println!("Young users: {:?}", young_users);
    
    // æŠ•å½±æ“ä½œ
    let names = users.project(&[1]).unwrap();
    println!("Names: {:?}", names);
}
```

### ç¤ºä¾‹2ï¼šäº‹åŠ¡ç®¡ç†

```rust
fn main() {
    let mut txn_manager = TransactionManager::new();
    
    // å¼€å§‹äº‹åŠ¡
    let txn_id = txn_manager.begin_transaction();
    println!("Started transaction: {}", txn_id);
    
    // æ¨¡æ‹Ÿäº‹åŠ¡æ“ä½œ
    let operation = Operation::Write {
        table: "users".to_string(),
        key: "1".to_string(),
        value: Value::String("Alice".to_string()),
    };
    
    // æäº¤äº‹åŠ¡
    txn_manager.commit(txn_id).unwrap();
    println!("Transaction committed");
}
```

### ç¤ºä¾‹3ï¼šæŸ¥è¯¢ä¼˜åŒ–

```rust
fn main() {
    let mut optimizer = AdvancedQueryOptimizer::new();
    
    // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    optimizer.update_statistics("users", TableStats {
        row_count: 10000,
        page_count: 100,
        column_stats: HashMap::new(),
    });
    
    // ç”ŸæˆæŸ¥è¯¢è®¡åˆ’
    let query = "SELECT name, email FROM users WHERE age > 18";
    let plan = optimizer.generate_optimal_plan(query);
    
    println!("Optimal query plan: {:?}", plan);
    println!("Estimated cost: {}", plan.estimated_cost);
}
```

## ğŸ”¬ ç†è®ºæ‰©å±•

### 1. åˆ†å¸ƒå¼æ•°æ®åº“ç†è®º

**å®šä¹‰ 4.1** (åˆ†å¸ƒå¼æ•°æ®åº“)
åˆ†å¸ƒå¼æ•°æ®åº“æ˜¯åˆ†å¸ƒåœ¨å¤šä¸ªèŠ‚ç‚¹ä¸Šçš„æ•°æ®åº“ç³»ç»Ÿã€‚

**å®šç† 4.1** (CAPå®šç†)
åˆ†å¸ƒå¼æ•°æ®åº“ç³»ç»Ÿæœ€å¤šåªèƒ½åŒæ—¶æ»¡è¶³ä¸€è‡´æ€§(Consistency)ã€å¯ç”¨æ€§(Availability)ã€åˆ†åŒºå®¹é”™æ€§(Partition tolerance)ä¸­çš„ä¸¤ä¸ªã€‚

### 2. å¹¶å‘æ§åˆ¶ç†è®º

**å®šä¹‰ 4.2** (å¯ä¸²è¡ŒåŒ–)
äº‹åŠ¡è°ƒåº¦æ˜¯å¯ä¸²è¡ŒåŒ–çš„ï¼Œå½“ä¸”ä»…å½“å­˜åœ¨ä¸€ä¸ªä¸²è¡Œè°ƒåº¦äº§ç”Ÿç›¸åŒçš„ç»“æœã€‚

**å®šç† 4.2** (ä¸¤é˜¶æ®µé”å®šå®šç†)
ä½¿ç”¨ä¸¤é˜¶æ®µé”å®šåè®®å¯ä»¥ä¿è¯äº‹åŠ¡çš„å¯ä¸²è¡ŒåŒ–ã€‚

### 3. æŸ¥è¯¢ä¼˜åŒ–ç†è®º1

**å®šä¹‰ 4.3** (æŸ¥è¯¢è®¡åˆ’ç©ºé—´)
æŸ¥è¯¢è®¡åˆ’ç©ºé—´æ˜¯æ‰€æœ‰å¯èƒ½æ‰§è¡ŒæŸ¥è¯¢çš„æ–¹å¼çš„é›†åˆã€‚

**å®šç† 4.3** (åŠ¨æ€è§„åˆ’ä¼˜åŒ–)
ä½¿ç”¨åŠ¨æ€è§„åˆ’å¯ä»¥åœ¨å¤šé¡¹å¼æ—¶é—´å†…æ‰¾åˆ°æœ€ä¼˜æŸ¥è¯¢è®¡åˆ’ã€‚

## ğŸ¯ æ‰¹åˆ¤æ€§åˆ†æ

### ä¸»è¦ç†è®ºè§‚ç‚¹æ¢³ç†

1. **å…³ç³»æ¨¡å‹ä¼˜åŠ¿**ï¼š
   - æ•°å­¦åŸºç¡€åšå®ï¼Œå½¢å¼åŒ–ç¨‹åº¦é«˜
   - æ•°æ®ç‹¬ç«‹æ€§å¥½ï¼Œç‰©ç†å­˜å‚¨ä¸é€»è¾‘ç»“æ„åˆ†ç¦»
   - æŸ¥è¯¢è¯­è¨€è¡¨è¾¾èƒ½åŠ›å¼ºå¤§

2. **äº‹åŠ¡ç†è®ºè´¡çŒ®**ï¼š
   - ACIDæ€§è´¨ä¸ºæ•°æ®ä¸€è‡´æ€§æä¾›ä¿éšœ
   - å¹¶å‘æ§åˆ¶ç†è®ºè§£å†³äº†å¤šç”¨æˆ·è®¿é—®é—®é¢˜
   - æ¢å¤æœºåˆ¶ç¡®ä¿ç³»ç»Ÿå¯é æ€§

3. **æŸ¥è¯¢ä¼˜åŒ–é‡è¦æ€§**ï¼š
   - è‡ªåŠ¨ä¼˜åŒ–å‡å°‘äººå·¥è°ƒä¼˜å·¥ä½œé‡
   - æˆæœ¬æ¨¡å‹æŒ‡å¯¼ä¼˜åŒ–å†³ç­–
   - ç»Ÿè®¡ä¿¡æ¯é©±åŠ¨ä¼˜åŒ–ç­–ç•¥

### ç†è®ºä¼˜åŠ¿ä¸å±€é™æ€§

**ä¼˜åŠ¿**ï¼š

- ç†è®ºåŸºç¡€æ‰å®ï¼Œæ•°å­¦å½¢å¼åŒ–ç¨‹åº¦é«˜
- å®é™…åº”ç”¨å¹¿æ³›ï¼ŒæŠ€æœ¯æˆç†Ÿ
- æ ‡å‡†åŒ–ç¨‹åº¦é«˜ï¼ŒSQLæˆä¸ºäº‹å®æ ‡å‡†

**å±€é™æ€§**ï¼š

- å…³ç³»æ¨¡å‹å¯¹å¤æ‚æ•°æ®ç»“æ„æ”¯æŒæœ‰é™
- åˆ†å¸ƒå¼ä¸€è‡´æ€§ç†è®ºå­˜åœ¨æ ¹æœ¬æ€§é™åˆ¶
- æŸ¥è¯¢ä¼˜åŒ–åœ¨å¤æ‚æŸ¥è¯¢ä¸­ä»é¢ä¸´æŒ‘æˆ˜

### å­¦ç§‘äº¤å‰èåˆ

1. **ä¸åˆ†å¸ƒå¼ç³»ç»Ÿç†è®º**ï¼š
   - åˆ†å¸ƒå¼äº‹åŠ¡åè®®
   - ä¸€è‡´æ€§ç®—æ³•åº”ç”¨
   - å®¹é”™æœºåˆ¶è®¾è®¡

2. **ä¸å¹¶å‘ç†è®º**ï¼š
   - å¹¶å‘æ§åˆ¶ç®—æ³•
   - æ­»é”æ£€æµ‹ä¸é¢„é˜²
   - é”åè®®è®¾è®¡

3. **ä¸ä¿¡æ¯è®º**ï¼š
   - æ•°æ®å‹ç¼©æŠ€æœ¯
   - ç¼–ç ç†è®ºåº”ç”¨
   - ä¿¡æ¯ç†µåœ¨æŸ¥è¯¢ä¼˜åŒ–ä¸­çš„åº”ç”¨

### åˆ›æ–°æ‰¹åˆ¤ä¸æœªæ¥å±•æœ›

**å½“å‰æŒ‘æˆ˜**ï¼š

1. å¤§æ•°æ®æ—¶ä»£çš„æ€§èƒ½æŒ‘æˆ˜
2. æ–°å‹æ•°æ®æ¨¡å‹çš„æ¶Œç°
3. äº‘åŸç”Ÿæ¶æ„çš„é€‚é…éœ€æ±‚

**æœªæ¥å‘å±•æ–¹å‘**ï¼š

1. è‡ªé€‚åº”æŸ¥è¯¢ä¼˜åŒ–
2. æœºå™¨å­¦ä¹ åœ¨æ•°æ®åº“ä¸­çš„åº”ç”¨
3. æ–°å‹å­˜å‚¨ä»‹è´¨æ”¯æŒ
4. è¾¹ç¼˜è®¡ç®—ç¯å¢ƒä¸‹çš„æ•°æ®åº“æŠ€æœ¯

**ç¤¾ä¼šå½±å“åˆ†æ**ï¼š

- æ•°æ®åº“æŠ€æœ¯æ”¯æ’‘äº†ç°ä»£ä¿¡æ¯ç¤¾ä¼šçš„åŸºç¡€è®¾æ–½
- æ•°æ®éšç§å’Œå®‰å…¨é—®é¢˜æ—¥ç›Šçªå‡º
- éœ€è¦å¹³è¡¡æŠ€æœ¯æ•ˆç‡ä¸ç¤¾ä¼šè´£ä»»

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. Codd, E. F. (1970). "A Relational Model of Data for Large Shared Data Banks"
2. Gray, J., & Reuter, A. (1993). "Transaction Processing: Concepts and Techniques"
3. Silberschatz, A., et al. (2019). "Database System Concepts"
4. Bernstein, P. A., & Newcomer, E. (2009). "Principles of Transaction Processing"
5. Chaudhuri, S. (1998). "An Overview of Query Optimization in Relational Systems"

---

*æœ¬æ¨¡å—ä¸ºå½¢å¼ç§‘å­¦çŸ¥è¯†åº“çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œä¸ºæ•°æ®åº“ç³»ç»Ÿçš„è®¾è®¡ã€å®ç°å’Œä¼˜åŒ–æä¾›ç†è®ºåŸºç¡€ã€‚é€šè¿‡ä¸¥æ ¼çš„æ•°å­¦å½¢å¼åŒ–å’ŒRustä»£ç å®ç°ï¼Œç¡®ä¿ç†è®ºçš„å¯éªŒè¯æ€§å’Œå®ç”¨æ€§ã€‚*
