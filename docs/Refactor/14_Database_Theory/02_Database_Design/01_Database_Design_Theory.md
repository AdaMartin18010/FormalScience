# 12.2.1 æ•°æ®åº“è®¾è®¡ç†è®º

## ç›®å½•

- [12.2.1 æ•°æ®åº“è®¾è®¡ç†è®º](#1221-æ•°æ®åº“è®¾è®¡ç†è®º)
  - [ç›®å½•](#ç›®å½•)
  - [ğŸ“‹ æ¦‚è¿°](#-æ¦‚è¿°)
  - [1. åŸºæœ¬æ¦‚å¿µ](#1-åŸºæœ¬æ¦‚å¿µ)
    - [1.1 æ•°æ®åº“è®¾è®¡å®šä¹‰](#11-æ•°æ®åº“è®¾è®¡å®šä¹‰)
    - [1.2 è®¾è®¡é˜¶æ®µåˆ†ç±»](#12-è®¾è®¡é˜¶æ®µåˆ†ç±»)
  - [2. å½¢å¼åŒ–å®šä¹‰](#2-å½¢å¼åŒ–å®šä¹‰)
    - [2.1 éœ€æ±‚åˆ†æ](#21-éœ€æ±‚åˆ†æ)
    - [2.2 æ¦‚å¿µè®¾è®¡](#22-æ¦‚å¿µè®¾è®¡)
    - [2.3 é€»è¾‘è®¾è®¡](#23-é€»è¾‘è®¾è®¡)
  - [3. å®šç†ä¸è¯æ˜](#3-å®šç†ä¸è¯æ˜)
    - [3.1 è®¾è®¡å®Œæ•´æ€§å®šç†](#31-è®¾è®¡å®Œæ•´æ€§å®šç†)
    - [3.2 æ€§èƒ½ä¼˜åŒ–å®šç†](#32-æ€§èƒ½ä¼˜åŒ–å®šç†)
  - [4. Rustä»£ç å®ç°](#4-rustä»£ç å®ç°)
    - [4.1 éœ€æ±‚åˆ†æç³»ç»Ÿå®ç°](#41-éœ€æ±‚åˆ†æç³»ç»Ÿå®ç°)
    - [4.2 é€»è¾‘è®¾è®¡ç³»ç»Ÿå®ç°](#42-é€»è¾‘è®¾è®¡ç³»ç»Ÿå®ç°)
    - [4.3 ç‰©ç†è®¾è®¡ç³»ç»Ÿå®ç°](#43-ç‰©ç†è®¾è®¡ç³»ç»Ÿå®ç°)
  - [5. ç›¸å…³ç†è®ºä¸äº¤å‰å¼•ç”¨](#5-ç›¸å…³ç†è®ºä¸äº¤å‰å¼•ç”¨)
  - [6. å‚è€ƒæ–‡çŒ®](#6-å‚è€ƒæ–‡çŒ®)
  - [æ‰¹åˆ¤æ€§åˆ†æ](#æ‰¹åˆ¤æ€§åˆ†æ)

## ğŸ“‹ æ¦‚è¿°

æ•°æ®åº“è®¾è®¡ç†è®ºç ”ç©¶å¦‚ä½•è®¾è®¡é«˜æ•ˆã€å¯é ã€å¯ç»´æŠ¤çš„æ•°æ®åº“ç³»ç»Ÿã€‚è¯¥ç†è®ºæ¶µç›–éœ€æ±‚åˆ†æã€æ¦‚å¿µè®¾è®¡ã€é€»è¾‘è®¾è®¡ã€ç‰©ç†è®¾è®¡ç­‰æ ¸å¿ƒæ¦‚å¿µï¼Œä¸ºæ•°æ®åº“ç³»ç»Ÿæ„å»ºæä¾›ç†è®ºåŸºç¡€ã€‚

## 1. åŸºæœ¬æ¦‚å¿µ

### 1.1 æ•°æ®åº“è®¾è®¡å®šä¹‰

**å®šä¹‰ 1.1**ï¼ˆæ•°æ®åº“è®¾è®¡ï¼‰
æ•°æ®åº“è®¾è®¡æ˜¯åˆ›å»ºæ•°æ®åº“ç»“æ„çš„è¿‡ç¨‹ï¼ŒåŒ…æ‹¬è¡¨ç»“æ„ã€å…³ç³»ã€çº¦æŸå’Œç´¢å¼•çš„è®¾è®¡ã€‚

### 1.2 è®¾è®¡é˜¶æ®µåˆ†ç±»

| è®¾è®¡é˜¶æ®µ     | è‹±æ–‡åç§°         | ä¸»è¦ä»»åŠ¡                     | è¾“å‡ºäº§ç‰©         |
|--------------|------------------|------------------------------|------------------|
| éœ€æ±‚åˆ†æ     | Requirements     | æ”¶é›†å’Œåˆ†æç”¨æˆ·éœ€æ±‚           | éœ€æ±‚è§„æ ¼è¯´æ˜ä¹¦   |
| æ¦‚å¿µè®¾è®¡     | Conceptual       | å»ºç«‹æ¦‚å¿µæ•°æ®æ¨¡å‹             | ERå›¾, UMLå›¾      |
| é€»è¾‘è®¾è®¡     | Logical          | è½¬æ¢ä¸ºé€»è¾‘æ•°æ®æ¨¡å‹           | å…³ç³»æ¨¡å¼         |
| ç‰©ç†è®¾è®¡     | Physical         | å®ç°ç‰©ç†å­˜å‚¨ç»“æ„             | æ•°æ®åº“æ¨¡å¼       |

## 2. å½¢å¼åŒ–å®šä¹‰

### 2.1 éœ€æ±‚åˆ†æ

**å®šä¹‰ 2.1**ï¼ˆéœ€æ±‚åˆ†æï¼‰
éœ€æ±‚åˆ†ææ˜¯è¯†åˆ«ã€æ”¶é›†å’Œåˆ†ææ•°æ®åº“ç³»ç»ŸåŠŸèƒ½å’ŒéåŠŸèƒ½éœ€æ±‚çš„è¿‡ç¨‹ã€‚

### 2.2 æ¦‚å¿µè®¾è®¡

**å®šä¹‰ 2.2**ï¼ˆæ¦‚å¿µè®¾è®¡ï¼‰
æ¦‚å¿µè®¾è®¡æ˜¯å°†ç”¨æˆ·éœ€æ±‚è½¬æ¢ä¸ºæ¦‚å¿µæ•°æ®æ¨¡å‹çš„è¿‡ç¨‹ã€‚

### 2.3 é€»è¾‘è®¾è®¡

**å®šä¹‰ 2.3**ï¼ˆé€»è¾‘è®¾è®¡ï¼‰
é€»è¾‘è®¾è®¡æ˜¯å°†æ¦‚å¿µæ¨¡å‹è½¬æ¢ä¸ºç‰¹å®šæ•°æ®æ¨¡å‹çš„é€»è¾‘ç»“æ„ã€‚

## 3. å®šç†ä¸è¯æ˜

### 3.1 è®¾è®¡å®Œæ•´æ€§å®šç†

**å®šç† 3.1**ï¼ˆè®¾è®¡å®Œæ•´æ€§ï¼‰
è‹¥æ•°æ®åº“è®¾è®¡æ»¡è¶³æ‰€æœ‰åŠŸèƒ½éœ€æ±‚ä¸”æ— å†—ä½™ï¼Œåˆ™ç§°è®¾è®¡å®Œæ•´ã€‚

**è¯æ˜**ï¼š
è®¾éœ€æ±‚é›†åˆä¸º $R$ï¼Œè®¾è®¡é›†åˆä¸º $D$ï¼Œè‹¥ $\forall r \in R, \exists d \in D$ æ»¡è¶³ $r$ï¼Œä¸” $D$ ä¸­æ— å†—ä½™å…ƒç´ ï¼Œåˆ™è®¾è®¡å®Œæ•´ã€‚â–¡

### 3.2 æ€§èƒ½ä¼˜åŒ–å®šç†

**å®šç† 3.2**ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
é€šè¿‡é€‚å½“çš„ç´¢å¼•è®¾è®¡å’ŒæŸ¥è¯¢ä¼˜åŒ–ï¼Œæ•°æ®åº“æŸ¥è¯¢æ€§èƒ½å¯æ˜¾è‘—æå‡ã€‚

**è¯æ˜**ï¼š
ç´¢å¼•å°†æŸ¥è¯¢å¤æ‚åº¦ä» $O(n)$ é™ä½åˆ° $O(\log n)$ï¼ŒæŸ¥è¯¢ä¼˜åŒ–å™¨é€‰æ‹©æœ€ä¼˜æ‰§è¡Œè®¡åˆ’ã€‚â–¡

## 4. Rustä»£ç å®ç°

### 4.1 éœ€æ±‚åˆ†æç³»ç»Ÿå®ç°

```rust
use std::collections::{HashMap, HashSet};

#[derive(Debug, Clone)]
pub struct Requirement {
    pub id: String,
    pub name: String,
    pub description: String,
    pub priority: Priority,
    pub category: RequirementCategory,
    pub stakeholders: Vec<String>,
    pub acceptance_criteria: Vec<String>,
}

#[derive(Debug, Clone)]
pub enum Priority {
    High,
    Medium,
    Low,
}

#[derive(Debug, Clone)]
pub enum RequirementCategory {
    Functional,
    NonFunctional,
    Constraint,
}

#[derive(Debug, Clone)]
pub struct RequirementAnalysis {
    pub requirements: HashMap<String, Requirement>,
    pub entities: Vec<Entity>,
    pub relationships: Vec<Relationship>,
    pub constraints: Vec<Constraint>,
}

#[derive(Debug, Clone)]
pub struct Entity {
    pub name: String,
    pub attributes: Vec<Attribute>,
    pub description: String,
    pub business_rules: Vec<String>,
}

#[derive(Debug, Clone)]
pub struct Relationship {
    pub name: String,
    pub entity1: String,
    pub entity2: String,
    pub cardinality: Cardinality,
    pub description: String,
}

#[derive(Debug, Clone)]
pub enum Cardinality {
    OneToOne,
    OneToMany,
    ManyToOne,
    ManyToMany,
}

#[derive(Debug, Clone)]
pub struct Constraint {
    pub name: String,
    pub constraint_type: ConstraintType,
    pub description: String,
    pub affected_entities: Vec<String>,
}

#[derive(Debug, Clone)]
pub enum ConstraintType {
    PrimaryKey,
    ForeignKey,
    Unique,
    Check,
    NotNull,
}

impl RequirementAnalysis {
    pub fn new() -> Self {
        RequirementAnalysis {
            requirements: HashMap::new(),
            entities: Vec::new(),
            relationships: Vec::new(),
            constraints: Vec::new(),
        }
    }
    
    pub fn add_requirement(&mut self, requirement: Requirement) {
        self.requirements.insert(requirement.id.clone(), requirement);
    }
    
    pub fn add_entity(&mut self, entity: Entity) {
        self.entities.push(entity);
    }
    
    pub fn add_relationship(&mut self, relationship: Relationship) {
        self.relationships.push(relationship);
    }
    
    pub fn add_constraint(&mut self, constraint: Constraint) {
        self.constraints.push(constraint);
    }
    
    pub fn analyze_requirements(&self) -> AnalysisReport {
        let mut report = AnalysisReport::new();
        
        // åˆ†æåŠŸèƒ½éœ€æ±‚
        let functional_requirements: Vec<_> = self.requirements.values()
            .filter(|r| matches!(r.category, RequirementCategory::Functional))
            .collect();
        
        report.functional_count = functional_requirements.len();
        
        // åˆ†æéåŠŸèƒ½éœ€æ±‚
        let non_functional_requirements: Vec<_> = self.requirements.values()
            .filter(|r| matches!(r.category, RequirementCategory::NonFunctional))
            .collect();
        
        report.non_functional_count = non_functional_requirements.len();
        
        // åˆ†æä¼˜å…ˆçº§åˆ†å¸ƒ
        let mut priority_distribution = HashMap::new();
        for requirement in self.requirements.values() {
            *priority_distribution.entry(requirement.priority.clone()).or_insert(0) += 1;
        }
        report.priority_distribution = priority_distribution;
        
        // åˆ†æå®ä½“å’Œå…³ç³»
        report.entity_count = self.entities.len();
        report.relationship_count = self.relationships.len();
        report.constraint_count = self.constraints.len();
        
        // æ£€æŸ¥éœ€æ±‚å®Œæ•´æ€§
        report.completeness_score = self.calculate_completeness();
        
        // æ£€æŸ¥ä¸€è‡´æ€§
        report.consistency_score = self.calculate_consistency();
        
        report
    }
    
    fn calculate_completeness(&self) -> f64 {
        let total_requirements = self.requirements.len();
        if total_requirements == 0 {
            return 0.0;
        }
        
        let mut complete_requirements = 0;
        for requirement in self.requirements.values() {
            if !requirement.description.is_empty() && 
               !requirement.acceptance_criteria.is_empty() &&
               !requirement.stakeholders.is_empty() {
                complete_requirements += 1;
            }
        }
        
        complete_requirements as f64 / total_requirements as f64
    }
    
    fn calculate_consistency(&self) -> f64 {
        let mut consistency_score = 1.0;
        
        // æ£€æŸ¥å®ä½“åç§°å”¯ä¸€æ€§
        let mut entity_names = HashSet::new();
        for entity in &self.entities {
            if !entity_names.insert(&entity.name) {
                consistency_score -= 0.1; // é‡å¤å®ä½“åç§°
            }
        }
        
        // æ£€æŸ¥å…³ç³»ä¸­çš„å®ä½“æ˜¯å¦å­˜åœ¨
        for relationship in &self.relationships {
            let entity1_exists = self.entities.iter().any(|e| e.name == relationship.entity1);
            let entity2_exists = self.entities.iter().any(|e| e.name == relationship.entity2);
            
            if !entity1_exists || !entity2_exists {
                consistency_score -= 0.1; // å…³ç³»å¼•ç”¨ä¸å­˜åœ¨çš„å®ä½“
            }
        }
        
        consistency_score.max(0.0)
    }
    
    pub fn generate_er_diagram(&self) -> ERDiagram {
        let mut diagram = ERDiagram::new();
        
        // æ·»åŠ å®ä½“
        for entity in &self.entities {
            diagram.add_entity(entity.clone());
        }
        
        // æ·»åŠ å…³ç³»
        for relationship in &self.relationships {
            diagram.add_relationship(relationship.clone());
        }
        
        diagram
    }
    
    pub fn validate_design(&self) -> Vec<String> {
        let mut errors = Vec::new();
        
        // éªŒè¯å®ä½“
        for entity in &self.entities {
            if entity.name.is_empty() {
                errors.push(format!("Entity has empty name"));
            }
            
            if entity.attributes.is_empty() {
                errors.push(format!("Entity {} has no attributes", entity.name));
            }
        }
        
        // éªŒè¯å…³ç³»
        for relationship in &self.relationships {
            if relationship.entity1 == relationship.entity2 {
                errors.push(format!("Relationship {} connects entity to itself", relationship.name));
            }
        }
        
        // éªŒè¯çº¦æŸ
        for constraint in &self.constraints {
            for entity_name in &constraint.affected_entities {
                if !self.entities.iter().any(|e| &e.name == entity_name) {
                    errors.push(format!("Constraint {} references non-existent entity {}", 
                                      constraint.name, entity_name));
                }
            }
        }
        
        errors
    }
}

#[derive(Debug, Clone)]
pub struct AnalysisReport {
    pub functional_count: usize,
    pub non_functional_count: usize,
    pub priority_distribution: HashMap<Priority, usize>,
    pub entity_count: usize,
    pub relationship_count: usize,
    pub constraint_count: usize,
    pub completeness_score: f64,
    pub consistency_score: f64,
}

impl AnalysisReport {
    pub fn new() -> Self {
        AnalysisReport {
            functional_count: 0,
            non_functional_count: 0,
            priority_distribution: HashMap::new(),
            entity_count: 0,
            relationship_count: 0,
            constraint_count: 0,
            completeness_score: 0.0,
            consistency_score: 0.0,
        }
    }
    
    pub fn print_summary(&self) {
        println!("=== éœ€æ±‚åˆ†ææŠ¥å‘Š ===");
        println!("åŠŸèƒ½éœ€æ±‚æ•°é‡: {}", self.functional_count);
        println!("éåŠŸèƒ½éœ€æ±‚æ•°é‡: {}", self.non_functional_count);
        println!("å®ä½“æ•°é‡: {}", self.entity_count);
        println!("å…³ç³»æ•°é‡: {}", self.relationship_count);
        println!("çº¦æŸæ•°é‡: {}", self.constraint_count);
        println!("å®Œæ•´æ€§è¯„åˆ†: {:.2}", self.completeness_score);
        println!("ä¸€è‡´æ€§è¯„åˆ†: {:.2}", self.consistency_score);
    }
}

#[derive(Debug, Clone)]
pub struct ERDiagram {
    pub entities: Vec<Entity>,
    pub relationships: Vec<Relationship>,
}

impl ERDiagram {
    pub fn new() -> Self {
        ERDiagram {
            entities: Vec::new(),
            relationships: Vec::new(),
        }
    }
    
    pub fn add_entity(&mut self, entity: Entity) {
        self.entities.push(entity);
    }
    
    pub fn add_relationship(&mut self, relationship: Relationship) {
        self.relationships.push(relationship);
    }
    
    pub fn export_dot(&self) -> String {
        let mut dot = String::new();
        dot.push_str("digraph ERDiagram {\n");
        dot.push_str("  rankdir=LR;\n");
        dot.push_str("  node [shape=record];\n\n");
        
        // æ·»åŠ å®ä½“
        for entity in &self.entities {
            dot.push_str(&format!("  {} [label=\"{{{}|", entity.name, entity.name));
            
            for (i, attr) in entity.attributes.iter().enumerate() {
                if i > 0 {
                    dot.push_str("|");
                }
                dot.push_str(&attr.name);
            }
            
            dot.push_str("}}\"];\n");
        }
        
        dot.push_str("\n");
        
        // æ·»åŠ å…³ç³»
        for relationship in &self.relationships {
            let arrow = match relationship.cardinality {
                Cardinality::OneToOne => "->",
                Cardinality::OneToMany => "->",
                Cardinality::ManyToOne => "->",
                Cardinality::ManyToMany => "<->",
            };
            
            dot.push_str(&format!("  {} {} {} [label=\"{}\"];\n", 
                                 relationship.entity1, arrow, relationship.entity2, relationship.name));
        }
        
        dot.push_str("}\n");
        dot
    }
}
```

### 4.2 é€»è¾‘è®¾è®¡ç³»ç»Ÿå®ç°

```rust
use std::collections::HashMap;

#[derive(Debug, Clone)]
pub struct LogicalDesign {
    pub tables: HashMap<String, Table>,
    pub views: HashMap<String, View>,
    pub indexes: Vec<Index>,
    pub constraints: Vec<TableConstraint>,
}

#[derive(Debug, Clone)]
pub struct Table {
    pub name: String,
    pub columns: Vec<Column>,
    pub primary_key: Vec<String>,
    pub foreign_keys: Vec<ForeignKey>,
    pub unique_constraints: Vec<Vec<String>>,
    pub check_constraints: Vec<CheckConstraint>,
}

#[derive(Debug, Clone)]
pub struct Column {
    pub name: String,
    pub data_type: DataType,
    pub is_nullable: bool,
    pub default_value: Option<String>,
    pub auto_increment: bool,
    pub comment: String,
}

#[derive(Debug, Clone)]
pub enum DataType {
    Integer,
    BigInt,
    Float,
    Double,
    Decimal(usize, usize),
    Char(usize),
    Varchar(usize),
    Text,
    Boolean,
    Date,
    DateTime,
    Timestamp,
    Blob,
}

#[derive(Debug, Clone)]
pub struct ForeignKey {
    pub name: String,
    pub columns: Vec<String>,
    pub referenced_table: String,
    pub referenced_columns: Vec<String>,
    pub on_delete: ReferentialAction,
    pub on_update: ReferentialAction,
}

#[derive(Debug, Clone)]
pub enum ReferentialAction {
    Cascade,
    SetNull,
    SetDefault,
    Restrict,
    NoAction,
}

#[derive(Debug, Clone)]
pub struct CheckConstraint {
    pub name: String,
    pub condition: String,
}

#[derive(Debug, Clone)]
pub struct View {
    pub name: String,
    pub definition: String,
    pub columns: Vec<String>,
}

#[derive(Debug, Clone)]
pub struct Index {
    pub name: String,
    pub table_name: String,
    pub columns: Vec<String>,
    pub index_type: IndexType,
    pub unique: bool,
}

#[derive(Debug, Clone)]
pub enum IndexType {
    BTree,
    Hash,
    FullText,
    Spatial,
}

#[derive(Debug, Clone)]
pub struct TableConstraint {
    pub name: String,
    pub table_name: String,
    pub constraint_type: ConstraintType,
    pub definition: String,
}

#[derive(Debug, Clone)]
pub enum ConstraintType {
    PrimaryKey,
    ForeignKey,
    Unique,
    Check,
    NotNull,
}

impl LogicalDesign {
    pub fn new() -> Self {
        LogicalDesign {
            tables: HashMap::new(),
            views: HashMap::new(),
            indexes: Vec::new(),
            constraints: Vec::new(),
        }
    }
    
    pub fn add_table(&mut self, table: Table) {
        self.tables.insert(table.name.clone(), table);
    }
    
    pub fn add_view(&mut self, view: View) {
        self.views.insert(view.name.clone(), view);
    }
    
    pub fn add_index(&mut self, index: Index) {
        self.indexes.push(index);
    }
    
    pub fn add_constraint(&mut self, constraint: TableConstraint) {
        self.constraints.push(constraint);
    }
    
    pub fn normalize_tables(&mut self) -> Vec<String> {
        let mut messages = Vec::new();
        
        for table in self.tables.values_mut() {
            // æ£€æŸ¥1NF
            if !self.is_first_normal_form(table) {
                messages.push(format!("Table {} violates 1NF", table.name));
            }
            
            // æ£€æŸ¥2NF
            if !self.is_second_normal_form(table) {
                messages.push(format!("Table {} violates 2NF", table.name));
            }
            
            // æ£€æŸ¥3NF
            if !self.is_third_normal_form(table) {
                messages.push(format!("Table {} violates 3NF", table.name));
            }
        }
        
        messages
    }
    
    fn is_first_normal_form(&self, table: &Table) -> bool {
        // æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤ç»„
        for column in &table.columns {
            if column.name.contains(',') || column.name.contains(';') {
                return false;
            }
        }
        true
    }
    
    fn is_second_normal_form(&self, table: &Table) -> bool {
        if table.primary_key.len() <= 1 {
            return true; // å•å±æ€§ä¸»é”®è‡ªåŠ¨æ»¡è¶³2NF
        }
        
        // æ£€æŸ¥éƒ¨åˆ†ä¾èµ–ï¼ˆç®€åŒ–å®ç°ï¼‰
        true
    }
    
    fn is_third_normal_form(&self, table: &Table) -> bool {
        // æ£€æŸ¥ä¼ é€’ä¾èµ–ï¼ˆç®€åŒ–å®ç°ï¼‰
        true
    }
    
    pub fn optimize_indexes(&mut self) {
        // ä¸ºå¤–é”®åˆ›å»ºç´¢å¼•
        for table in self.tables.values() {
            for fk in &table.foreign_keys {
                let index_name = format!("idx_{}_{}", table.name, fk.name);
                let index = Index {
                    name: index_name,
                    table_name: table.name.clone(),
                    columns: fk.columns.clone(),
                    index_type: IndexType::BTree,
                    unique: false,
                };
                self.indexes.push(index);
            }
        }
        
        // ä¸ºç»å¸¸æŸ¥è¯¢çš„åˆ—åˆ›å»ºç´¢å¼•
        for table in self.tables.values() {
            for column in &table.columns {
                if column.name.contains("id") || column.name.contains("name") {
                    let index_name = format!("idx_{}_{}", table.name, column.name);
                    let index = Index {
                        name: index_name,
                        table_name: table.name.clone(),
                        columns: vec![column.name.clone()],
                        index_type: IndexType::BTree,
                        unique: false,
                    };
                    self.indexes.push(index);
                }
            }
        }
    }
    
    pub fn generate_sql(&self) -> String {
        let mut sql = String::new();
        
        // ç”ŸæˆCREATE TABLEè¯­å¥
        for table in self.tables.values() {
            sql.push_str(&format!("CREATE TABLE {} (\n", table.name));
            
            for (i, column) in table.columns.iter().enumerate() {
                if i > 0 {
                    sql.push_str(",\n");
                }
                sql.push_str(&format!("  {} {}", column.name, self.data_type_to_sql(&column.data_type)));
                
                if !column.is_nullable {
                    sql.push_str(" NOT NULL");
                }
                
                if let Some(default) = &column.default_value {
                    sql.push_str(&format!(" DEFAULT '{}'", default));
                }
                
                if column.auto_increment {
                    sql.push_str(" AUTO_INCREMENT");
                }
            }
            
            // æ·»åŠ ä¸»é”®çº¦æŸ
            if !table.primary_key.is_empty() {
                sql.push_str(&format!(",\n  PRIMARY KEY ({})", table.primary_key.join(", ")));
            }
            
            // æ·»åŠ å¤–é”®çº¦æŸ
            for fk in &table.foreign_keys {
                sql.push_str(&format!(",\n  CONSTRAINT {} FOREIGN KEY ({}) REFERENCES {}({})", 
                                     fk.name, fk.columns.join(", "), fk.referenced_table, fk.referenced_columns.join(", ")));
            }
            
            sql.push_str("\n);\n\n");
        }
        
        // ç”Ÿæˆç´¢å¼•
        for index in &self.indexes {
            let unique = if index.unique { "UNIQUE " } else { "" };
            sql.push_str(&format!("CREATE {}INDEX {} ON {} ({});\n", 
                                 unique, index.name, index.table_name, index.columns.join(", ")));
        }
        
        sql
    }
    
    fn data_type_to_sql(&self, data_type: &DataType) -> String {
        match data_type {
            DataType::Integer => "INT".to_string(),
            DataType::BigInt => "BIGINT".to_string(),
            DataType::Float => "FLOAT".to_string(),
            DataType::Double => "DOUBLE".to_string(),
            DataType::Decimal(precision, scale) => format!("DECIMAL({}, {})", precision, scale),
            DataType::Char(length) => format!("CHAR({})", length),
            DataType::Varchar(length) => format!("VARCHAR({})", length),
            DataType::Text => "TEXT".to_string(),
            DataType::Boolean => "BOOLEAN".to_string(),
            DataType::Date => "DATE".to_string(),
            DataType::DateTime => "DATETIME".to_string(),
            DataType::Timestamp => "TIMESTAMP".to_string(),
            DataType::Blob => "BLOB".to_string(),
        }
    }
    
    pub fn calculate_statistics(&self) -> DesignStatistics {
        let mut stats = DesignStatistics::new();
        
        stats.table_count = self.tables.len();
        stats.view_count = self.views.len();
        stats.index_count = self.indexes.len();
        stats.constraint_count = self.constraints.len();
        
        // è®¡ç®—å¹³å‡è¡¨å¤§å°
        let mut total_columns = 0;
        for table in self.tables.values() {
            total_columns += table.columns.len();
        }
        
        if stats.table_count > 0 {
            stats.average_columns_per_table = total_columns as f64 / stats.table_count as f64;
        }
        
        // è®¡ç®—å¤–é”®å¯†åº¦
        let mut total_foreign_keys = 0;
        for table in self.tables.values() {
            total_foreign_keys += table.foreign_keys.len();
        }
        
        if stats.table_count > 0 {
            stats.foreign_key_density = total_foreign_keys as f64 / stats.table_count as f64;
        }
        
        stats
    }
}

#[derive(Debug, Clone)]
pub struct DesignStatistics {
    pub table_count: usize,
    pub view_count: usize,
    pub index_count: usize,
    pub constraint_count: usize,
    pub average_columns_per_table: f64,
    pub foreign_key_density: f64,
}

impl DesignStatistics {
    pub fn new() -> Self {
        DesignStatistics {
            table_count: 0,
            view_count: 0,
            index_count: 0,
            constraint_count: 0,
            average_columns_per_table: 0.0,
            foreign_key_density: 0.0,
        }
    }
    
    pub fn print_report(&self) {
        println!("=== é€»è¾‘è®¾è®¡ç»Ÿè®¡ ===");
        println!("è¡¨æ•°é‡: {}", self.table_count);
        println!("è§†å›¾æ•°é‡: {}", self.view_count);
        println!("ç´¢å¼•æ•°é‡: {}", self.index_count);
        println!("çº¦æŸæ•°é‡: {}", self.constraint_count);
        println!("å¹³å‡æ¯è¡¨åˆ—æ•°: {:.2}", self.average_columns_per_table);
        println!("å¤–é”®å¯†åº¦: {:.2}", self.foreign_key_density);
    }
}
```

### 4.3 ç‰©ç†è®¾è®¡ç³»ç»Ÿå®ç°

```rust
use std::collections::HashMap;

#[derive(Debug, Clone)]
pub struct PhysicalDesign {
    pub storage_engine: StorageEngine,
    pub tablespaces: HashMap<String, Tablespace>,
    pub partitions: HashMap<String, Partitioning>,
    pub compression: HashMap<String, Compression>,
    pub caching: HashMap<String, Caching>,
}

#[derive(Debug, Clone)]
pub enum StorageEngine {
    InnoDB,
    MyISAM,
    Memory,
    Archive,
    Custom(String),
}

#[derive(Debug, Clone)]
pub struct Tablespace {
    pub name: String,
    pub file_path: String,
    pub initial_size: u64,
    pub auto_extend: bool,
    pub max_size: Option<u64>,
}

#[derive(Debug, Clone)]
pub struct Partitioning {
    pub table_name: String,
    pub partition_type: PartitionType,
    pub partition_columns: Vec<String>,
    pub partitions: Vec<Partition>,
}

#[derive(Debug, Clone)]
pub enum PartitionType {
    Range,
    List,
    Hash,
    Key,
}

#[derive(Debug, Clone)]
pub struct Partition {
    pub name: String,
    pub value: String,
    pub tablespace: String,
}

#[derive(Debug, Clone)]
pub struct Compression {
    pub table_name: String,
    pub algorithm: CompressionAlgorithm,
    pub level: u8,
}

#[derive(Debug, Clone)]
pub enum CompressionAlgorithm {
    Zlib,
    Lz4,
    Zstd,
    Snappy,
}

#[derive(Debug, Clone)]
pub struct Caching {
    pub table_name: String,
    pub cache_type: CacheType,
    pub cache_size: u64,
    pub ttl: Option<u64>,
}

#[derive(Debug, Clone)]
pub enum CacheType {
    Memory,
    Redis,
    Memcached,
}

impl PhysicalDesign {
    pub fn new() -> Self {
        PhysicalDesign {
            storage_engine: StorageEngine::InnoDB,
            tablespaces: HashMap::new(),
            partitions: HashMap::new(),
            compression: HashMap::new(),
            caching: HashMap::new(),
        }
    }
    
    pub fn set_storage_engine(&mut self, engine: StorageEngine) {
        self.storage_engine = engine;
    }
    
    pub fn add_tablespace(&mut self, tablespace: Tablespace) {
        self.tablespaces.insert(tablespace.name.clone(), tablespace);
    }
    
    pub fn add_partitioning(&mut self, partitioning: Partitioning) {
        self.partitions.insert(partitioning.table_name.clone(), partitioning);
    }
    
    pub fn add_compression(&mut self, compression: Compression) {
        self.compression.insert(compression.table_name.clone(), compression);
    }
    
    pub fn add_caching(&mut self, caching: Caching) {
        self.caching.insert(caching.table_name.clone(), caching);
    }
    
    pub fn optimize_for_performance(&mut self, table_name: &str, access_pattern: AccessPattern) {
        match access_pattern {
            AccessPattern::ReadHeavy => {
                // ä¸ºè¯»å¯†é›†å‹è¡¨æ·»åŠ ç¼“å­˜
                let caching = Caching {
                    table_name: table_name.to_string(),
                    cache_type: CacheType::Memory,
                    cache_size: 1024 * 1024 * 100, // 100MB
                    ttl: Some(3600), // 1å°æ—¶
                };
                self.caching.insert(table_name.to_string(), caching);
            },
            AccessPattern::WriteHeavy => {
                // ä¸ºå†™å¯†é›†å‹è¡¨ä½¿ç”¨InnoDB
                self.storage_engine = StorageEngine::InnoDB;
            },
            AccessPattern::Mixed => {
                // æ··åˆè®¿é—®æ¨¡å¼ä½¿ç”¨InnoDB
                self.storage_engine = StorageEngine::InnoDB;
            },
        }
    }
    
    pub fn generate_ddl(&self) -> String {
        let mut ddl = String::new();
        
        // åˆ›å»ºè¡¨ç©ºé—´
        for tablespace in self.tablespaces.values() {
            ddl.push_str(&format!("CREATE TABLESPACE {}\n", tablespace.name));
            ddl.push_str(&format!("  ADD DATAFILE '{}'\n", tablespace.file_path));
            ddl.push_str(&format!("  INITIAL_SIZE {}\n", tablespace.initial_size));
            
            if tablespace.auto_extend {
                ddl.push_str("  AUTOEXTEND_SIZE 1M\n");
            }
            
            if let Some(max_size) = tablespace.max_size {
                ddl.push_str(&format!("  MAX_SIZE {}\n", max_size));
            }
            
            ddl.push_str(";\n\n");
        }
        
        // åˆ›å»ºåˆ†åŒº
        for partitioning in self.partitions.values() {
            ddl.push_str(&format!("ALTER TABLE {} PARTITION BY ", partitioning.table_name));
            
            match partitioning.partition_type {
                PartitionType::Range => {
                    ddl.push_str(&format!("RANGE ({}) (\n", partitioning.partition_columns.join(", ")));
                },
                PartitionType::List => {
                    ddl.push_str(&format!("LIST ({}) (\n", partitioning.partition_columns.join(", ")));
                },
                PartitionType::Hash => {
                    ddl.push_str(&format!("HASH ({}) PARTITIONS {}\n", 
                                         partitioning.partition_columns.join(", "), 
                                         partitioning.partitions.len()));
                },
                PartitionType::Key => {
                    ddl.push_str(&format!("KEY ({}) PARTITIONS {}\n", 
                                         partitioning.partition_columns.join(", "), 
                                         partitioning.partitions.len()));
                },
            }
            
            if matches!(partitioning.partition_type, PartitionType::Range | PartitionType::List) {
                for (i, partition) in partitioning.partitions.iter().enumerate() {
                    if i > 0 {
                        ddl.push_str(",\n");
                    }
                    ddl.push_str(&format!("  PARTITION {} VALUES LESS THAN ({}) TABLESPACE {}", 
                                         partition.name, partition.value, partition.tablespace));
                }
                ddl.push_str("\n);\n\n");
            }
        }
        
        ddl
    }
    
    pub fn estimate_storage_requirements(&self, table_stats: &HashMap<String, TableStats>) -> StorageEstimate {
        let mut estimate = StorageEstimate::new();
        
        for (table_name, stats) in table_stats {
            let mut table_size = 0u64;
            
            // è®¡ç®—è¡Œå¤§å°
            for column in &stats.columns {
                let column_size = match column.data_type {
                    DataType::Integer => 4,
                    DataType::BigInt => 8,
                    DataType::Float => 4,
                    DataType::Double => 8,
                    DataType::Decimal(_, _) => 8,
                    DataType::Char(length) => length as u64,
                    DataType::Varchar(length) => length as u64 + 2, // é•¿åº¦å‰ç¼€
                    DataType::Text => 65535,
                    DataType::Boolean => 1,
                    DataType::Date => 3,
                    DataType::DateTime => 8,
                    DataType::Timestamp => 4,
                    DataType::Blob => 65535,
                };
                table_size += column_size;
            }
            
            // æ·»åŠ è¡Œå¼€é”€
            table_size += 20; // è¡Œå¤´å¼€é”€
            
            // è®¡ç®—æ€»è¡¨å¤§å°
            let total_table_size = table_size * stats.row_count;
            
            // æ·»åŠ ç´¢å¼•å¤§å°
            let index_size = total_table_size * 20 / 100; // å‡è®¾ç´¢å¼•å 20%
            
            estimate.total_size += total_table_size + index_size;
            estimate.table_sizes.insert(table_name.clone(), total_table_size + index_size);
        }
        
        estimate
    }
}

#[derive(Debug, Clone)]
pub enum AccessPattern {
    ReadHeavy,
    WriteHeavy,
    Mixed,
}

#[derive(Debug, Clone)]
pub struct TableStats {
    pub row_count: u64,
    pub columns: Vec<Column>,
}

#[derive(Debug, Clone)]
pub struct StorageEstimate {
    pub total_size: u64,
    pub table_sizes: HashMap<String, u64>,
}

impl StorageEstimate {
    pub fn new() -> Self {
        StorageEstimate {
            total_size: 0,
            table_sizes: HashMap::new(),
        }
    }
    
    pub fn print_report(&self) {
        println!("=== å­˜å‚¨éœ€æ±‚ä¼°ç®— ===");
        println!("æ€»å­˜å‚¨éœ€æ±‚: {} bytes ({:.2} MB)", 
                self.total_size, self.total_size as f64 / (1024.0 * 1024.0));
        
        for (table_name, size) in &self.table_sizes {
            println!("è¡¨ {}: {} bytes ({:.2} MB)", 
                    table_name, size, *size as f64 / (1024.0 * 1024.0));
        }
    }
}
```

## 5. ç›¸å…³ç†è®ºä¸äº¤å‰å¼•ç”¨

- [æ•°æ®æ¨¡å‹ç†è®º](../01_Data_Models/01_Data_Models_Theory.md)
- [æŸ¥è¯¢ä¼˜åŒ–ç†è®º](../03_Query_Optimization/01_Query_Optimization_Theory.md)
- [äº‹åŠ¡ç®¡ç†ç†è®º](../04_Transaction_Management/01_Transaction_Management_Theory.md)

## 6. å‚è€ƒæ–‡çŒ®

1. Connolly, T. M., & Begg, C. E. (2014). Database Systems: A Practical Approach to Design, Implementation, and Management. Pearson.
2. Elmasri, R., & Navathe, S. B. (2015). Fundamentals of Database Systems. Pearson.
3. Silberschatz, A., Korth, H. F., & Sudarshan, S. (2019). Database System Concepts. McGraw-Hill.

---

**æœ€åæ›´æ–°**: 2024å¹´12æœˆ21æ—¥  
**ç»´æŠ¤è€…**: AIåŠ©æ‰‹  
**ç‰ˆæœ¬**: v1.0

## æ‰¹åˆ¤æ€§åˆ†æ

- å¤šå…ƒç†è®ºè§†è§’ï¼š
  - è¯­ä¹‰åˆ°ç»“æ„ï¼šéœ€æ±‚è¯­ä¹‰â†’æ¦‚å¿µæ¨¡å‹ï¼ˆER/æ¦‚å¿µç±»å›¾ï¼‰â†’é€»è¾‘æ¨¡å‹ï¼ˆå…³ç³»/æ–‡æ¡£/å›¾/åˆ—æ—ï¼‰â†’ç‰©ç†æ¨¡å‹ï¼ˆåˆ†åŒº/ç´¢å¼•/å­˜å‚¨å¸ƒå±€ï¼‰çš„åˆ†å±‚æ˜ å°„ï¼Œåº”ä¸ä¸€è‡´æ€§/äº‹åŠ¡/æŸ¥è¯¢/æ€§èƒ½ååŒè®¾è®¡ã€‚
  - è§„èŒƒåŒ–ä¸åè§„èŒƒåŒ–ï¼šä»¥å‡½æ•°ä¾èµ–/èŒƒå¼æ§åˆ¶å†—ä½™ä¸æ›´æ–°ä»£ä»·ï¼›ç»“åˆæŸ¥è¯¢ç‰¹å¾ä¸å­˜å‚¨/ç½‘ç»œæˆæœ¬è¿›è¡Œåè§„èŒƒåŒ–ä¸ç‰©åŒ–è§†å›¾ã€‚
- å±€é™æ€§åˆ†æï¼š
  - é™æ€è®¾è®¡ä¸åŠ¨æ€è´Ÿè½½ï¼šé™æ€æ¨¡å¼ä¸åŠ¨æ€/å¤šå˜å·¥ä½œè´Ÿè½½èƒŒç¦»ï¼›è·¨ä¸šåŠ¡å›¢é˜Ÿçš„è¯­ä¹‰æ¼‚ç§»ä¸é‡å¤å»ºæ¨¡ã€‚
  - å¤šæ¨¡æ•°æ®ï¼šè·¨æ¨¡å‹ï¼ˆå…³ç³»/æ–‡æ¡£/å›¾/æ—¶åºï¼‰ä¸è·¨å¼•æ“è®¾è®¡ä¸€è‡´æ€§ä¸å¯æ¼”è¿›æ€§æŒ‘æˆ˜ã€‚
- äº‰è®®ä¸åˆ†æ­§ï¼š
  - å•ä¸€çœŸç›¸æº vs å¤šæºååŒï¼›å¼ºä¸€è‡´æ¶æ„ vs é«˜å¯ç”¨ä¸å¼¹æ€§ä¼˜å…ˆã€‚
- åº”ç”¨å‰æ™¯ï¼š
  - æ¶æ„å³æ•°æ®ï¼šä»¥å…ƒæ¨¡å‹/å…ƒæ•°æ®é©±åŠ¨çš„è®¾è®¡â€”ç”Ÿæˆâ€”æ ¡éªŒé—­ç¯ï¼›ä¸å¯è§‚æµ‹æ€§/æ•°æ®æ²»ç†/è´¨é‡é—¨ç¦è”åŠ¨ã€‚
- æ”¹è¿›å»ºè®®ï¼š
  - è¯æ®ä¸åŸºçº¿ï¼šè¾“å‡ºä¾èµ–/èŒƒå¼/æŸ¥è¯¢ç”»åƒè¯æ®ï¼›ç»´æŠ¤è·¨å¼•æ“æ¨¡å¼å¯¹ç…§ä¸æ¼”è¿›ç­–ç•¥ï¼›å°†æ€§èƒ½ä¸ä¸€è‡´æ€§ç›®æ ‡çº³å…¥è®¾è®¡éªŒæ”¶ã€‚
