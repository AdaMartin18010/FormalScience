# 并发编程理论

## 1. 形式化定义

### 1.1 并发系统定义

**定义 8.2.6.1 (并发系统)**
并发系统是一个四元组 $CS = (P, S, T, \rightarrow)$，其中：

- $P$ 是进程集合
- $S$ 是状态集合
- $T$ 是时间域
- $\rightarrow \subseteq S \times P \times S$ 是状态转换关系

**定义 8.2.6.2 (进程)**
进程是一个三元组 $p = (Q, \Sigma, \delta)$，其中：

- $Q$ 是进程状态集合
- $\Sigma$ 是动作集合
- $\delta: Q \times \Sigma \rightarrow Q$ 是状态转换函数

### 1.2 同步原语定义

**定义 8.2.6.3 (互斥锁)**
互斥锁 $M$ 是一个二元组 $(state, owner)$，其中：

- $state \in \{locked, unlocked\}$
- $owner \in P \cup \{\bot\}$

**定义 8.2.6.4 (信号量)**
信号量 $S$ 是一个三元组 $(value, waiting, max)$，其中：

- $value \in \mathbb{N}$ 是当前值
- $waiting \subseteq P$ 是等待队列
- $max \in \mathbb{N}$ 是最大值

## 2. 核心定理

### 2.1 死锁避免定理

**定理 8.2.6.1 (银行家算法)**
如果系统满足安全状态条件，则不会发生死锁：
$$\forall R \in Resources: \sum_{i} allocated_i + available \geq \sum_{i} max_i$$

**证明：**

1. 安全状态定义：存在一个安全序列
2. 银行家算法保证系统始终处于安全状态
3. 安全状态意味着不会发生死锁

### 2.2 线性化定理

**定理 8.2.6.2 (线性化)**
并发对象 $O$ 是线性化的，当且仅当：
$$\exists L: \forall H \in Histories(O): L(H) \in Sequential(O)$$

**证明：**

1. 线性化点存在性：每个操作都有线性化点
2. 顺序一致性：线性化后的历史满足顺序规范
3. 实时性：如果操作 $A$ 在 $B$ 之前完成，则 $A$ 在 $B$ 之前线性化

## 3. 算法实现

### 3.1 互斥锁实现

```rust
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;
use std::thread;
use std::time::Duration;

#[derive(Debug)]
struct SpinLock {
    locked: AtomicBool,
}

impl SpinLock {
    fn new() -> Self {
        Self {
            locked: AtomicBool::new(false),
        }
    }

    fn lock(&self) {
        while self.locked.compare_exchange_weak(
            false,
            true,
            Ordering::Acquire,
            Ordering::Relaxed,
        ).is_err() {
            // 自旋等待
            std::hint::spin_loop();
        }
    }

    fn unlock(&self) {
        self.locked.store(false, Ordering::Release);
    }
}

#[derive(Debug)]
struct Mutex {
    locked: AtomicBool,
    wait_queue: std::sync::Mutex<Vec<std::thread::ThreadId>>,
}

impl Mutex {
    fn new() -> Self {
        Self {
            locked: AtomicBool::new(false),
            wait_queue: std::sync::Mutex::new(Vec::new()),
        }
    }

    fn lock(&self) {
        if self.locked.compare_exchange(
            false,
            true,
            Ordering::Acquire,
            Ordering::Relaxed,
        ).is_err() {
            // 添加到等待队列
            let thread_id = thread::current().id();
            {
                let mut queue = self.wait_queue.lock().unwrap();
                queue.push(thread_id);
            }
            
            // 等待被唤醒
            while self.locked.load(Ordering::Relaxed) {
                thread::park();
            }
        }
    }

    fn unlock(&self) {
        self.locked.store(false, Ordering::Release);
        
        // 唤醒等待的线程
        if let Ok(mut queue) = self.wait_queue.try_lock() {
            if let Some(thread_id) = queue.pop() {
                // 在实际实现中需要找到对应的线程并唤醒
                // 这里简化处理
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::sync::Arc;

    #[test]
    fn test_spin_lock() {
        let lock = Arc::new(SpinLock::new());
        let mut threads = vec![];
        let counter = Arc::new(std::sync::Mutex::new(0));
        
        for _ in 0..10 {
            let lock = Arc::clone(&lock);
            let counter = Arc::clone(&counter);
            
            threads.push(thread::spawn(move || {
                for _ in 0..1000 {
                    lock.lock();
                    {
                        let mut count = counter.lock().unwrap();
                        *count += 1;
                    }
                    lock.unlock();
                }
            }));
        }
        
        for thread in threads {
            thread.join().unwrap();
        }
        
        assert_eq!(*counter.lock().unwrap(), 10000);
    }
}
```

### 3.2 信号量实现

```rust
use std::sync::{Arc, Condvar, Mutex};
use std::thread;

#[derive(Debug)]
struct Semaphore {
    value: Mutex<isize>,
    cvar: Condvar,
}

impl Semaphore {
    fn new(initial: isize) -> Self {
        Self {
            value: Mutex::new(initial),
            cvar: Condvar::new(),
        }
    }

    fn wait(&self) {
        let mut value = self.value.lock().unwrap();
        while *value <= 0 {
            value = self.cvar.wait(value).unwrap();
        }
        *value -= 1;
    }

    fn signal(&self) {
        let mut value = self.value.lock().unwrap();
        *value += 1;
        self.cvar.notify_one();
    }
}

#[derive(Debug)]
struct BoundedBuffer<T> {
    buffer: Mutex<Vec<T>>,
    capacity: usize,
    not_full: Condvar,
    not_empty: Condvar,
}

impl<T> BoundedBuffer<T> {
    fn new(capacity: usize) -> Self {
        Self {
            buffer: Mutex::new(Vec::new()),
            capacity,
            not_full: Condvar::new(),
            not_empty: Condvar::new(),
        }
    }

    fn put(&self, item: T) {
        let mut buffer = self.buffer.lock().unwrap();
        while buffer.len() >= self.capacity {
            buffer = self.not_full.wait(buffer).unwrap();
        }
        buffer.push(item);
        self.not_empty.notify_one();
    }

    fn get(&self) -> T {
        let mut buffer = self.buffer.lock().unwrap();
        while buffer.is_empty() {
            buffer = self.not_empty.wait(buffer).unwrap();
        }
        let item = buffer.remove(0);
        self.not_full.notify_one();
        item
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_semaphore() {
        let semaphore = Arc::new(Semaphore::new(2));
        let counter = Arc::new(Mutex::new(0));
        let mut threads = vec![];
        
        for _ in 0..5 {
            let semaphore = Arc::clone(&semaphore);
            let counter = Arc::clone(&counter);
            
            threads.push(thread::spawn(move || {
                semaphore.wait();
                {
                    let mut count = counter.lock().unwrap();
                    *count += 1;
                    thread::sleep(Duration::from_millis(100));
                }
                semaphore.signal();
            }));
        }
        
        for thread in threads {
            thread.join().unwrap();
        }
        
        assert_eq!(*counter.lock().unwrap(), 5);
    }

    #[test]
    fn test_bounded_buffer() {
        let buffer = Arc::new(BoundedBuffer::new(3));
        let mut threads = vec![];
        
        // 生产者
        for i in 0..5 {
            let buffer = Arc::clone(&buffer);
            threads.push(thread::spawn(move || {
                buffer.put(i);
            }));
        }
        
        // 消费者
        let mut results = vec![];
        for _ in 0..5 {
            let buffer = Arc::clone(&buffer);
            threads.push(thread::spawn(move || {
                buffer.get()
            }));
        }
        
        for thread in threads {
            if let Ok(result) = thread.join() {
                results.push(result);
            }
        }
        
        results.sort();
        assert_eq!(results, vec![0, 1, 2, 3, 4]);
    }
}
```

### 3.3 无锁数据结构

```rust
use std::sync::atomic::{AtomicPtr, Ordering};
use std::ptr;

#[derive(Debug)]
struct Node<T> {
    value: T,
    next: AtomicPtr<Node<T>>,
}

impl<T> Node<T> {
    fn new(value: T) -> Self {
        Self {
            value,
            next: AtomicPtr::new(ptr::null_mut()),
        }
    }
}

#[derive(Debug)]
struct LockFreeStack<T> {
    head: AtomicPtr<Node<T>>,
}

impl<T> LockFreeStack<T> {
    fn new() -> Self {
        Self {
            head: AtomicPtr::new(ptr::null_mut()),
        }
    }

    fn push(&self, value: T) {
        let new_node = Box::into_raw(Box::new(Node::new(value)));
        
        loop {
            let head = self.head.load(Ordering::Relaxed);
            unsafe {
                (*new_node).next.store(head, Ordering::Relaxed);
            }
            
            if self.head.compare_exchange_weak(
                head,
                new_node,
                Ordering::Release,
                Ordering::Relaxed,
            ).is_ok() {
                break;
            }
        }
    }

    fn pop(&self) -> Option<T> {
        loop {
            let head = self.head.load(Ordering::Acquire);
            if head.is_null() {
                return None;
            }
            
            unsafe {
                let next = (*head).next.load(Ordering::Relaxed);
                
                if self.head.compare_exchange_weak(
                    head,
                    next,
                    Ordering::Release,
                    Ordering::Relaxed,
                ).is_ok() {
                    let node = Box::from_raw(head);
                    return Some(node.value);
                }
            }
        }
    }
}

impl<T> Drop for LockFreeStack<T> {
    fn drop(&mut self) {
        while self.pop().is_some() {}
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::sync::Arc;

    #[test]
    fn test_lock_free_stack() {
        let stack = Arc::new(LockFreeStack::new());
        let mut threads = vec![];
        
        // 生产者
        for i in 0..10 {
            let stack = Arc::clone(&stack);
            threads.push(thread::spawn(move || {
                stack.push(i);
            }));
        }
        
        // 消费者
        let mut results = vec![];
        for _ in 0..10 {
            let stack = Arc::clone(&stack);
            threads.push(thread::spawn(move || {
                stack.pop()
            }));
        }
        
        for thread in threads {
            if let Ok(Some(result)) = thread.join() {
                results.push(result);
            }
        }
        
        assert_eq!(results.len(), 10);
    }
}
```

## 4. 并发模型

### 4.1 Actor模型

```rust
use std::sync::mpsc;
use std::thread;

#[derive(Debug)]
enum Message {
    Increment,
    Get,
    Stop,
}

#[derive(Debug)]
struct CounterActor {
    value: i32,
    receiver: mpsc::Receiver<Message>,
    sender: mpsc::Sender<i32>,
}

impl CounterActor {
    fn new(receiver: mpsc::Receiver<Message>, sender: mpsc::Sender<i32>) -> Self {
        Self {
            value: 0,
            receiver,
            sender,
        }
    }

    fn run(mut self) {
        while let Ok(message) = self.receiver.recv() {
            match message {
                Message::Increment => {
                    self.value += 1;
                }
                Message::Get => {
                    let _ = self.sender.send(self.value);
                }
                Message::Stop => {
                    break;
                }
            }
        }
    }
}

#[derive(Debug)]
struct ActorSystem {
    sender: mpsc::Sender<Message>,
    value_sender: mpsc::Sender<i32>,
    value_receiver: mpsc::Receiver<i32>,
}

impl ActorSystem {
    fn new() -> Self {
        let (sender, receiver) = mpsc::channel();
        let (value_sender, value_receiver) = mpsc::channel();
        
        let actor = CounterActor::new(receiver, value_sender);
        thread::spawn(move || actor.run());
        
        Self {
            sender,
            value_sender,
            value_receiver,
        }
    }

    fn increment(&self) {
        let _ = self.sender.send(Message::Increment);
    }

    fn get_value(&self) -> i32 {
        let _ = self.sender.send(Message::Get);
        self.value_receiver.recv().unwrap()
    }

    fn stop(&self) {
        let _ = self.sender.send(Message::Stop);
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_actor_system() {
        let system = ActorSystem::new();
        
        for _ in 0..100 {
            system.increment();
        }
        
        assert_eq!(system.get_value(), 100);
        system.stop();
    }
}
```

## 5. 应用场景

### 5.1 高并发服务器

- Web服务器并发处理
- 数据库连接池管理
- 消息队列系统

### 5.2 并行计算

- 数值计算并行化
- 图像处理并行算法
- 机器学习分布式训练

### 5.3 实时系统

- 游戏引擎并发更新
- 实时数据处理
- 控制系统并发执行

## 6. 相关理论

### 6.1 并发控制理论

- 事务并发控制
- 分布式一致性
- 并发调度算法

### 6.2 同步理论

- 进程同步原语
- 条件变量理论
- 屏障同步机制

### 6.3 内存模型理论

- 内存一致性模型
- 原子操作语义
- 内存屏障理论

## 7. 参考文献

1. Lamport, L. (1978). Time, clocks, and the ordering of events in a distributed system.
2. Herlihy, M., & Wing, J. M. (1990). Linearizability: A correctness condition for concurrent objects.
3. Dijkstra, E. W. (1965). Solution of a problem in concurrent programming control.
4. Hoare, C. A. R. (1974). Monitors: an operating system structuring concept.
5. Lynch, N. A. (1996). Distributed Algorithms.
