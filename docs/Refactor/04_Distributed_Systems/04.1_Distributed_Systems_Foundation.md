# 04.1 分布式系统基础

## 目录

1. [理论基础](#1-理论基础)
2. [分布式系统模型](#2-分布式系统模型)
3. [通信模型](#3-通信模型)
4. [故障模型](#4-故障模型)
5. [一致性模型](#5-一致性模型)
6. [分布式算法基础](#6-分布式算法基础)
7. [实际应用](#7-实际应用)
8. [代码实现](#8-代码实现)
9. [参考文献](#9-参考文献)

## 1. 理论基础

### 1.1 分布式系统定义

**定义 1.1** (分布式系统)
分布式系统是由多个独立计算节点组成的系统，这些节点通过通信网络相互协作，共同完成系统目标。

**特征**：

- **并发性**：多个节点同时执行
- **缺乏全局时钟**：节点间时钟不同步
- **故障独立性**：单个节点故障不影响整个系统
- **消息传递**：节点间通过消息通信

### 1.2 分布式系统分类

**定义 1.2** (系统分类)

1. **紧耦合系统**：节点间通信延迟低，共享内存
2. **松耦合系统**：节点间通信延迟高，无共享内存
3. **同构系统**：所有节点具有相同硬件和软件
4. **异构系统**：节点具有不同的硬件和软件

### 1.3 分布式系统挑战

**挑战 1.1** (CAP定理)
在分布式系统中，最多只能同时满足以下三个特性中的两个：

- **一致性(Consistency)**：所有节点看到相同的数据
- **可用性(Availability)**：系统总是响应请求
- **分区容错性(Partition tolerance)**：网络分区时系统仍能工作

## 2. 分布式系统模型

### 2.1 系统模型

**定义 2.1** (系统模型)
分布式系统模型 $S = (N, C, F)$ 包含：

- $N = \{n_1, n_2, \ldots, n_m\}$：节点集合
- $C \subseteq N \times N$：通信链路集合
- $F$：故障模型

### 2.2 节点状态

**定义 2.2** (节点状态)
节点 $n_i$ 的状态为：
$$s_i = (l_i, m_i, c_i)$$

其中：

- $l_i$ 是本地状态
- $m_i$ 是消息队列
- $c_i$ 是时钟值

### 2.3 全局状态

**定义 2.3** (全局状态)
系统的全局状态为：
$$S = (s_1, s_2, \ldots, s_m)$$

**定义 2.4** (一致性全局状态)
全局状态 $S$ 是一致的，如果：
$$\forall i, j: \text{send}(m) \in s_i \land \text{receive}(m) \in s_j \Rightarrow c_i < c_j$$

## 3. 通信模型

### 3.1 同步通信

**定义 3.1** (同步通信)
在同步通信模型中：

- 消息传递有上界延迟 $\Delta$
- 节点处理时间有上界 $\tau$
- 时钟漂移有上界 $\rho$

**定理 3.1** (同步系统特性)
在同步系统中，可以检测节点故障，且故障检测时间有上界。

### 3.2 异步通信

**定义 3.2** (异步通信)
在异步通信模型中：

- 消息传递延迟无上界
- 节点处理时间无上界
- 时钟漂移无上界

**定理 3.2** (FLP不可能性)
在异步系统中，即使只有一个节点可能故障，也无法实现共识。

### 3.3 部分同步通信

**定义 3.3** (部分同步通信)
在部分同步通信模型中：

- 存在未知但有限的延迟上界
- 存在未知但有限的时钟漂移上界

## 4. 故障模型

### 4.1 故障类型

**定义 4.1** (故障分类)

1. **崩溃故障**：节点停止工作
2. **遗漏故障**：节点丢失消息
3. **拜占庭故障**：节点任意行为
4. **时序故障**：节点违反时序约束

### 4.2 故障检测

**定义 4.2** (故障检测器)
故障检测器是一个分布式算法，用于检测节点故障。

**性质**：

- **完整性**：故障节点最终被所有正确节点检测到
- **准确性**：正确节点不会被检测为故障

### 4.3 故障恢复

**定义 4.3** (故障恢复)
故障恢复机制包括：

1. **故障检测**：识别故障节点
2. **状态恢复**：恢复系统状态
3. **服务重定向**：将服务转移到其他节点

## 5. 一致性模型

### 5.1 强一致性

**定义 5.1** (强一致性)
强一致性要求所有操作按全局顺序执行，所有节点看到相同的操作序列。

**定理 5.1** (强一致性代价)
强一致性需要同步通信，且延迟较高。

### 5.2 最终一致性

**定义 5.2** (最终一致性)
最终一致性要求在没有新更新的情况下，所有节点最终收敛到相同状态。

**定理 5.2** (最终一致性特性)
最终一致性提供高可用性，但可能暂时不一致。

### 5.3 因果一致性

**定义 5.3** (因果一致性)
因果一致性要求因果相关的操作在所有节点上按相同顺序执行。

**定义 5.4** (因果关系)
操作 $o_1$ 因果先于操作 $o_2$，如果：

1. $o_1$ 和 $o_2$ 在同一节点，且 $o_1$ 先于 $o_2$
2. $o_1$ 发送消息，$o_2$ 接收该消息
3. 存在操作 $o_3$，使得 $o_1 \rightarrow o_3 \rightarrow o_2$

## 6. 分布式算法基础

### 6.1 分布式算法模型

**定义 6.1** (分布式算法)
分布式算法 $A = (I, P, O)$ 包含：

- $I$：输入集合
- $P$：处理步骤集合
- $O$：输出集合

### 6.2 算法正确性

**定义 6.2** (安全性)
算法满足安全性，如果坏的事情永远不会发生。

**定义 6.3** (活性)
算法满足活性，如果好的事情最终会发生。

### 6.3 复杂度分析

**定义 6.4** (消息复杂度)
消息复杂度是算法执行过程中传递的消息总数。

**定义 6.5** (时间复杂度)
时间复杂度是算法执行所需的时间轮数。

## 7. 实际应用

### 7.1 分布式数据库

**应用 7.1** (主从复制)
考虑主从复制系统：

- 主节点处理写操作
- 从节点复制主节点数据
- 从节点处理读操作

### 7.2 分布式缓存

**应用 7.2** (一致性哈希)
一致性哈希用于分布式缓存：

- 将数据映射到节点环
- 支持动态节点加入和离开
- 最小化数据迁移

### 7.3 微服务架构

**应用 7.3** (服务发现)
服务发现机制：

- 服务注册和发现
- 负载均衡
- 故障转移

## 8. 代码实现

### 8.1 Rust实现

```rust
use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use std::thread;
use std::time::{Duration, Instant};
use tokio::sync::mpsc;
use uuid::Uuid;

// 节点状态
#[derive(Debug, Clone)]
pub enum NodeState {
    Active,
    Suspicious,
    Failed,
}

// 消息类型
#[derive(Debug, Clone)]
pub enum Message {
    Heartbeat { from: NodeId, timestamp: u64 },
    Data { from: NodeId, key: String, value: String },
    Consensus { from: NodeId, proposal: u64 },
    Ack { from: NodeId, message_id: Uuid },
}

// 节点ID
pub type NodeId = u32;

// 分布式节点
#[derive(Debug)]
pub struct DistributedNode {
    pub id: NodeId,
    pub state: NodeState,
    pub neighbors: Vec<NodeId>,
    pub data: Arc<Mutex<HashMap<String, String>>>,
    pub message_queue: Arc<Mutex<Vec<Message>>>,
    pub clock: Arc<Mutex<u64>>,
}

impl DistributedNode {
    pub fn new(id: NodeId, neighbors: Vec<NodeId>) -> Self {
        DistributedNode {
            id,
            state: NodeState::Active,
            neighbors,
            data: Arc::new(Mutex::new(HashMap::new())),
            message_queue: Arc::new(Mutex::new(Vec::new())),
            clock: Arc::new(Mutex::new(0)),
        }
    }

    // 发送消息
    pub fn send_message(&self, to: NodeId, message: Message) {
        println!("Node {} sending message to Node {}: {:?}", self.id, to, message);
    }

    // 接收消息
    pub fn receive_message(&mut self, message: Message) {
        let mut queue = self.message_queue.lock().unwrap();
        queue.push(message);
        println!("Node {} received message: {:?}", self.id, queue.last().unwrap());
    }

    // 处理消息
    pub fn process_messages(&mut self) {
        let mut queue = self.message_queue.lock().unwrap();
        while let Some(message) = queue.pop() {
            match message {
                Message::Heartbeat { from, timestamp } => {
                    self.handle_heartbeat(from, timestamp);
                }
                Message::Data { from, key, value } => {
                    self.handle_data(from, key, value);
                }
                Message::Consensus { from, proposal } => {
                    self.handle_consensus(from, proposal);
                }
                Message::Ack { from, message_id } => {
                    self.handle_ack(from, message_id);
                }
            }
        }
    }

    // 处理心跳消息
    fn handle_heartbeat(&mut self, from: NodeId, timestamp: u64) {
        println!("Node {} received heartbeat from Node {} at {}", self.id, from, timestamp);
        // 更新邻居状态
    }

    // 处理数据消息
    fn handle_data(&mut self, from: NodeId, key: String, value: String) {
        let mut data = self.data.lock().unwrap();
        data.insert(key.clone(), value.clone());
        println!("Node {} stored data: {} = {}", self.id, key, value);
    }

    // 处理共识消息
    fn handle_consensus(&mut self, from: NodeId, proposal: u64) {
        println!("Node {} received consensus proposal {} from Node {}", self.id, proposal, from);
        // 实现共识算法
    }

    // 处理确认消息
    fn handle_ack(&mut self, from: NodeId, message_id: Uuid) {
        println!("Node {} received ACK from Node {} for message {}", self.id, from, message_id);
    }

    // 生成心跳
    pub fn generate_heartbeat(&self) -> Message {
        let mut clock = self.clock.lock().unwrap();
        *clock += 1;
        Message::Heartbeat {
            from: self.id,
            timestamp: *clock,
        }
    }

    // 存储数据
    pub fn store_data(&self, key: String, value: String) {
        let mut data = self.data.lock().unwrap();
        data.insert(key.clone(), value.clone());
        println!("Node {} stored: {} = {}", self.id, key, value);
    }

    // 获取数据
    pub fn get_data(&self, key: &str) -> Option<String> {
        let data = self.data.lock().unwrap();
        data.get(key).cloned()
    }
}

// 故障检测器
#[derive(Debug)]
pub struct FailureDetector {
    pub node_id: NodeId,
    pub suspects: Arc<Mutex<HashMap<NodeId, Instant>>>,
    pub timeout: Duration,
}

impl FailureDetector {
    pub fn new(node_id: NodeId, timeout: Duration) -> Self {
        FailureDetector {
            node_id,
            suspects: Arc::new(Mutex::new(HashMap::new())),
            timeout,
        }
    }

    // 记录心跳
    pub fn record_heartbeat(&self, from: NodeId) {
        let mut suspects = self.suspects.lock().unwrap();
        suspects.insert(from, Instant::now());
    }

    // 检查故障
    pub fn check_failures(&self) -> Vec<NodeId> {
        let mut suspects = self.suspects.lock().unwrap();
        let mut failed = Vec::new();
        let now = Instant::now();

        suspects.retain(|&node_id, &mut last_heartbeat| {
            if now.duration_since(last_heartbeat) > self.timeout {
                failed.push(node_id);
                false
            } else {
                true
            }
        });

        failed
    }
}

// 一致性哈希
#[derive(Debug)]
pub struct ConsistentHash {
    pub ring: Vec<NodeId>,
    pub virtual_nodes: HashMap<NodeId, Vec<u32>>,
}

impl ConsistentHash {
    pub fn new() -> Self {
        ConsistentHash {
            ring: Vec::new(),
            virtual_nodes: HashMap::new(),
        }
    }

    // 添加节点
    pub fn add_node(&mut self, node_id: NodeId, virtual_count: usize) {
        for i in 0..virtual_count {
            let virtual_id = self.hash(&format!("{}:{}", node_id, i));
            self.ring.push(virtual_id);
            self.virtual_nodes.entry(node_id).or_insert_with(Vec::new).push(virtual_id);
        }
        self.ring.sort();
    }

    // 移除节点
    pub fn remove_node(&mut self, node_id: NodeId) {
        if let Some(virtual_ids) = self.virtual_nodes.remove(&node_id) {
            for virtual_id in virtual_ids {
                if let Some(pos) = self.ring.iter().position(|&x| x == virtual_id) {
                    self.ring.remove(pos);
                }
            }
        }
    }

    // 查找节点
    pub fn get_node(&self, key: &str) -> Option<NodeId> {
        if self.ring.is_empty() {
            return None;
        }

        let hash = self.hash(key);
        let pos = self.ring.binary_search(&hash).unwrap_or_else(|e| e);
        let virtual_id = if pos == self.ring.len() { self.ring[0] } else { self.ring[pos] };

        // 找到对应的物理节点
        for (node_id, virtual_ids) in &self.virtual_nodes {
            if virtual_ids.contains(&virtual_id) {
                return Some(*node_id);
            }
        }
        None
    }

    // 哈希函数
    fn hash(&self, key: &str) -> u32 {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};
        
        let mut hasher = DefaultHasher::new();
        key.hash(&mut hasher);
        hasher.finish() as u32
    }
}

// 分布式系统
#[derive(Debug)]
pub struct DistributedSystem {
    pub nodes: HashMap<NodeId, DistributedNode>,
    pub failure_detectors: HashMap<NodeId, FailureDetector>,
    pub consistent_hash: ConsistentHash,
}

impl DistributedSystem {
    pub fn new() -> Self {
        DistributedSystem {
            nodes: HashMap::new(),
            failure_detectors: HashMap::new(),
            consistent_hash: ConsistentHash::new(),
        }
    }

    // 添加节点
    pub fn add_node(&mut self, node_id: NodeId, neighbors: Vec<NodeId>) {
        let node = DistributedNode::new(node_id, neighbors.clone());
        self.nodes.insert(node_id, node);

        let failure_detector = FailureDetector::new(node_id, Duration::from_secs(5));
        self.failure_detectors.insert(node_id, failure_detector);

        self.consistent_hash.add_node(node_id, 3);
    }

    // 移除节点
    pub fn remove_node(&mut self, node_id: NodeId) {
        self.nodes.remove(&node_id);
        self.failure_detectors.remove(&node_id);
        self.consistent_hash.remove_node(node_id);
    }

    // 存储数据
    pub fn store_data(&mut self, key: String, value: String) {
        if let Some(node_id) = self.consistent_hash.get_node(&key) {
            if let Some(node) = self.nodes.get_mut(&node_id) {
                node.store_data(key, value);
            }
        }
    }

    // 获取数据
    pub fn get_data(&self, key: &str) -> Option<String> {
        if let Some(node_id) = self.consistent_hash.get_node(key) {
            if let Some(node) = self.nodes.get(&node_id) {
                return node.get_data(key);
            }
        }
        None
    }

    // 运行系统
    pub fn run(&mut self, duration: Duration) {
        let start = Instant::now();
        
        while start.elapsed() < duration {
            // 处理所有节点的消息
            for node in self.nodes.values_mut() {
                node.process_messages();
            }

            // 检查故障
            for (node_id, detector) in &self.failure_detectors {
                let failed = detector.check_failures();
                for failed_node in failed {
                    println!("Node {} detected failure of Node {}", node_id, failed_node);
                }
            }

            thread::sleep(Duration::from_millis(100));
        }
    }
}

// 示例：分布式系统演示
pub fn distributed_system_example() {
    println!("=== 分布式系统基础示例 ===");
    
    let mut system = DistributedSystem::new();
    
    // 添加节点
    system.add_node(1, vec![2, 3]);
    system.add_node(2, vec![1, 3]);
    system.add_node(3, vec![1, 2]);
    
    println!("分布式系统创建完成，包含 {} 个节点", system.nodes.len());
    
    // 存储数据
    system.store_data("key1".to_string(), "value1".to_string());
    system.store_data("key2".to_string(), "value2".to_string());
    system.store_data("key3".to_string(), "value3".to_string());
    
    // 获取数据
    if let Some(value) = system.get_data("key1") {
        println!("Retrieved: key1 = {}", value);
    }
    
    if let Some(value) = system.get_data("key2") {
        println!("Retrieved: key2 = {}", value);
    }
    
    // 运行系统
    system.run(Duration::from_secs(5));
    
    println!("分布式系统运行完成");
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_consistent_hash() {
        let mut ch = ConsistentHash::new();
        ch.add_node(1, 3);
        ch.add_node(2, 3);
        ch.add_node(3, 3);
        
        let node1 = ch.get_node("key1");
        let node2 = ch.get_node("key2");
        
        assert!(node1.is_some());
        assert!(node2.is_some());
    }

    #[test]
    fn test_failure_detector() {
        let detector = FailureDetector::new(1, Duration::from_millis(100));
        detector.record_heartbeat(2);
        
        let failures = detector.check_failures();
        assert!(failures.is_empty());
    }

    #[test]
    fn test_distributed_node() {
        let mut node = DistributedNode::new(1, vec![2, 3]);
        node.store_data("test_key".to_string(), "test_value".to_string());
        
        let value = node.get_data("test_key");
        assert_eq!(value, Some("test_value".to_string()));
    }
}

fn main() {
    distributed_system_example();
}
```

### 8.2 Haskell实现

```haskell
{-# LANGUAGE FlexibleContexts #-}
{-# LANGUAGE TypeFamilies #-}
{-# LANGUAGE OverloadedStrings #-}

module DistributedSystemsFoundation where

import Data.Map (Map)
import qualified Data.Map as Map
import Data.Set (Set)
import qualified Data.Set as Set
import Data.List
import Data.Maybe
import Control.Concurrent
import Control.Monad
import System.Random
import Data.Time.Clock
import Data.Time.Clock.POSIX

-- 节点ID类型
type NodeId = Int

-- 消息类型
data Message = Heartbeat NodeId POSIXTime
             | Data NodeId String String
             | Consensus NodeId Int
             | Ack NodeId String
             deriving (Show, Eq)

-- 节点状态
data NodeState = Active | Suspicious | Failed deriving (Show, Eq)

-- 分布式节点
data DistributedNode = DistributedNode
    { nodeId :: NodeId
    , nodeState :: NodeState
    , neighbors :: [NodeId]
    , dataStore :: Map String String
    , messageQueue :: [Message]
    , clock :: POSIXTime
    } deriving (Show)

-- 创建分布式节点
createNode :: NodeId -> [NodeId] -> DistributedNode
createNode id neighbors = DistributedNode
    { nodeId = id
    , nodeState = Active
    , neighbors = neighbors
    , dataStore = Map.empty
    , messageQueue = []
    , clock = 0
    }

-- 发送消息
sendMessage :: DistributedNode -> NodeId -> Message -> IO ()
sendMessage node to message = do
    putStrLn $ "Node " ++ show (nodeId node) ++ " sending message to Node " ++ show to ++ ": " ++ show message

-- 接收消息
receiveMessage :: DistributedNode -> Message -> DistributedNode
receiveMessage node message = node { messageQueue = messageQueue node ++ [message] }

-- 处理消息
processMessages :: DistributedNode -> DistributedNode
processMessages node = foldl processMessage node (messageQueue node)
  where
    processMessage node' (Heartbeat from timestamp) = handleHeartbeat node' from timestamp
    processMessage node' (Data from key value) = handleData node' from key value
    processMessage node' (Consensus from proposal) = handleConsensus node' from proposal
    processMessage node' (Ack from msgId) = handleAck node' from msgId

-- 处理心跳消息
handleHeartbeat :: DistributedNode -> NodeId -> POSIXTime -> DistributedNode
handleHeartbeat node from timestamp = node
  { messageQueue = []
  }

-- 处理数据消息
handleData :: DistributedNode -> NodeId -> String -> String -> DistributedNode
handleData node from key value = node
    { dataStore = Map.insert key value (dataStore node)
    , messageQueue = []
    }

-- 处理共识消息
handleConsensus :: DistributedNode -> NodeId -> Int -> DistributedNode
handleConsensus node from proposal = node
    { messageQueue = []
    }

-- 处理确认消息
handleAck :: DistributedNode -> NodeId -> String -> DistributedNode
handleAck node from msgId = node
    { messageQueue = []
    }

-- 存储数据
storeData :: DistributedNode -> String -> String -> DistributedNode
storeData node key value = node { dataStore = Map.insert key value (dataStore node) }

-- 获取数据
getData :: DistributedNode -> String -> Maybe String
getData node key = Map.lookup key (dataStore node)

-- 故障检测器
data FailureDetector = FailureDetector
    { detectorNodeId :: NodeId
    , suspects :: Map NodeId POSIXTime
    , timeout :: POSIXTime
    } deriving (Show)

-- 创建故障检测器
createFailureDetector :: NodeId -> POSIXTime -> FailureDetector
createFailureDetector nodeId timeout = FailureDetector
    { detectorNodeId = nodeId
    , suspects = Map.empty
    , timeout = timeout
    }

-- 记录心跳
recordHeartbeat :: FailureDetector -> NodeId -> POSIXTime -> FailureDetector
recordHeartbeat detector from timestamp = detector
    { suspects = Map.insert from timestamp (suspects detector)
    }

-- 检查故障
checkFailures :: FailureDetector -> POSIXTime -> ([NodeId], FailureDetector)
checkFailures detector now = (failed, detector { suspects = remaining })
  where
    (failed, remaining) = Map.partition (\timestamp -> now - timestamp > timeout detector) (suspects detector)
    failed = Map.keys failed

-- 一致性哈希
data ConsistentHash = ConsistentHash
    { ring :: [Int]
    , virtualNodes :: Map NodeId [Int]
    } deriving (Show)

-- 创建一致性哈希
createConsistentHash :: ConsistentHash
createConsistentHash = ConsistentHash
    { ring = []
    , virtualNodes = Map.empty
    }

-- 添加节点
addNode :: ConsistentHash -> NodeId -> Int -> ConsistentHash
addNode ch nodeId virtualCount = ch
    { ring = sort $ ring ch ++ virtualIds
    , virtualNodes = Map.insert nodeId virtualIds (virtualNodes ch)
    }
  where
    virtualIds = [hash (show nodeId ++ ":" ++ show i) | i <- [0..virtualCount-1]]

-- 移除节点
removeNode :: ConsistentHash -> NodeId -> ConsistentHash
removeHash ch nodeId = ch
    { ring = ring ch \\ virtualIds
    , virtualNodes = Map.delete nodeId (virtualNodes ch)
    }
  where
    virtualIds = fromMaybe [] $ Map.lookup nodeId (virtualNodes ch)

-- 查找节点
getNode :: ConsistentHash -> String -> Maybe NodeId
getNode ch key
    | null (ring ch) = Nothing
    | otherwise = findPhysicalNode ch virtualId
  where
    hashValue = hash key
    virtualId = findVirtualNode (ring ch) hashValue

-- 查找虚拟节点
findVirtualNode :: [Int] -> Int -> Int
findVirtualNode ring hashValue
    | null ring = 0
    | otherwise = case findIndex (>= hashValue) ring of
        Just i -> ring !! i
        Nothing -> head ring

-- 查找物理节点
findPhysicalNode :: ConsistentHash -> Int -> Maybe NodeId
findPhysicalNode ch virtualId = find (\nodeId -> virtualId `elem` virtualIds) nodeIds
  where
    nodeIds = Map.keys (virtualNodes ch)
    virtualIds = fromMaybe [] $ Map.lookup nodeId (virtualNodes ch)

-- 哈希函数
hash :: String -> Int
hash str = foldl (\acc c -> acc * 31 + fromEnum c) 0 str

-- 分布式系统
data DistributedSystem = DistributedSystem
    { nodes :: Map NodeId DistributedNode
    , failureDetectors :: Map NodeId FailureDetector
    , consistentHash :: ConsistentHash
    } deriving (Show)

-- 创建分布式系统
createDistributedSystem :: DistributedSystem
createDistributedSystem = DistributedSystem
    { nodes = Map.empty
    , failureDetectors = Map.empty
    , consistentHash = createConsistentHash
    }

-- 添加节点
addNodeToSystem :: DistributedSystem -> NodeId -> [NodeId] -> DistributedSystem
addNodeToSystem sys nodeId neighbors = sys
    { nodes = Map.insert nodeId (createNode nodeId neighbors) (nodes sys)
    , failureDetectors = Map.insert nodeId (createFailureDetector nodeId 5) (failureDetectors sys)
    , consistentHash = addNode (consistentHash sys) nodeId 3
    }

-- 移除节点
removeNodeFromSystem :: DistributedSystem -> NodeId -> DistributedSystem
removeNodeFromSystem sys nodeId = sys
    { nodes = Map.delete nodeId (nodes sys)
    , failureDetectors = Map.delete nodeId (failureDetectors sys)
    , consistentHash = removeNode (consistentHash sys) nodeId
    }

-- 存储数据
storeDataInSystem :: DistributedSystem -> String -> String -> DistributedSystem
storeDataInSystem sys key value = case getNode (consistentHash sys) key of
    Just nodeId -> case Map.lookup nodeId (nodes sys) of
        Just node -> sys { nodes = Map.insert nodeId (storeData node key value) (nodes sys) }
        Nothing -> sys
    Nothing -> sys

-- 获取数据
getDataFromSystem :: DistributedSystem -> String -> Maybe String
getDataFromSystem sys key = do
    nodeId <- getNode (consistentHash sys) key
    node <- Map.lookup nodeId (nodes sys)
    getData node key

-- 示例：分布式系统演示
distributedSystemExample :: IO ()
distributedSystemExample = do
    putStrLn "=== 分布式系统基础示例 ==="
    
    let sys = createDistributedSystem
    let sys' = addNodeToSystem sys 1 [2, 3]
    let sys'' = addNodeToSystem sys' 2 [1, 3]
    let sys''' = addNodeToSystem sys'' 3 [1, 2]
    
    putStrLn $ "分布式系统创建完成，包含 " ++ show (Map.size (nodes sys''')) ++ " 个节点"
    
    -- 存储数据
    let sys4 = storeDataInSystem sys''' "key1" "value1"
    let sys5 = storeDataInSystem sys4 "key2" "value2"
    let sys6 = storeDataInSystem sys5 "key3" "value3"
    
    -- 获取数据
    case getDataFromSystem sys6 "key1" of
        Just value -> putStrLn $ "Retrieved: key1 = " ++ value
        Nothing -> putStrLn "Key1 not found"
    
    case getDataFromSystem sys6 "key2" of
        Just value -> putStrLn $ "Retrieved: key2 = " ++ value
        Nothing -> putStrLn "Key2 not found"
    
    putStrLn "分布式系统演示完成"

-- 测试函数
testDistributedSystems :: IO ()
testDistributedSystems = do
    putStrLn "=== 分布式系统基础测试 ==="
    
    -- 测试一致性哈希
    let ch = createConsistentHash
    let ch' = addNode ch 1 3
    let ch'' = addNode ch' 2 3
    let ch''' = addNode ch'' 3 3
    
    let node1 = getNode ch''' "key1"
    let node2 = getNode ch''' "key2"
    
    putStrLn $ "Consistent hash test: " ++ show node1 ++ ", " ++ show node2
    
    -- 测试分布式节点
    let node = createNode 1 [2, 3]
    let node' = storeData node "test_key" "test_value"
    let value = getData node' "test_key"
    
    putStrLn $ "Node test: " ++ show value

-- 主函数
main :: IO ()
main = do
    testDistributedSystems
    distributedSystemExample
```

## 9. 参考文献

1. Tanenbaum, A. S., & Van Steen, M. (2007). *Distributed Systems: Principles and Paradigms*. Prentice Hall.
2. Coulouris, G., Dollimore, J., Kindberg, T., & Blair, G. (2011). *Distributed Systems: Concepts and Design*. Addison-Wesley.
3. Lynch, N. A. (1996). *Distributed Algorithms*. Morgan Kaufmann.
4. Attiya, H., & Welch, J. (2004). *Distributed Computing: Fundamentals, Simulations, and Advanced Topics*. Wiley.
5. Gilbert, S., & Lynch, N. (2002). *Brewer's Conjecture and the Feasibility of Consistent, Available, Partition-Tolerant Web Services*. ACM SIGACT News.
6. Lamport, L. (1978). *Time, Clocks, and the Ordering of Events in a Distributed System*. Communications of the ACM.
7. Fischer, M. J., Lynch, N. A., & Paterson, M. S. (1985). *Impossibility of Distributed Consensus with One Faulty Process*. Journal of the ACM.
8. Chandy, K. M., & Lamport, L. (1985). *Distributed Snapshots: Determining Global States of Distributed Systems*. ACM Transactions on Computer Systems.

---

**相关文档链接**：

- [04.2 分布式算法](../04.2_Distributed_Algorithms.md)
- [04.3 共识理论](../04.3_Consensus_Theory.md)
- [03.1 控制论基础](../../03_Control_Theory/03.1_Control_Theory_Foundation.md)
- [01.1 类型理论基础](../../01_Type_Theory/01.1_Type_Theory_Foundation.md)
- [02.1 形式语言基础](../../02_Formal_Language/02.1_Formal_Language_Foundation.md)
