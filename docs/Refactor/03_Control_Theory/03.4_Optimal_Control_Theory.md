# 03.4 最优控制理论

## 目录

1. [理论基础](#1-理论基础)
2. [变分法](#2-变分法)
3. [庞特里亚金最大原理](#3-庞特里亚金最大原理)
4. [动态规划](#4-动态规划)
5. [线性二次型调节器](#5-线性二次型调节器)
6. [模型预测控制](#6-模型预测控制)
7. [实际应用](#7-实际应用)
8. [代码实现](#8-代码实现)
9. [参考文献](#9-参考文献)

## 1. 理论基础

### 1.1 最优控制问题

**定义 1.1** (最优控制问题)
最优控制问题的一般形式为：
$$\min_{u(t)} J = \phi(x(t_f), t_f) + \int_{t_0}^{t_f} L(x(t), u(t), t) dt$$

约束条件：
$$\dot{x}(t) = f(x(t), u(t), t)$$
$$x(t_0) = x_0$$
$$\psi(x(t_f), t_f) = 0$$

其中：

- $J$ 是性能指标
- $\phi$ 是终端代价
- $L$ 是运行代价
- $f$ 是系统动力学
- $\psi$ 是终端约束

### 1.2 性能指标类型

**定义 1.2** (性能指标分类)

1. **拉格朗日型**：$J = \int_{t_0}^{t_f} L(x(t), u(t), t) dt$
2. **迈耶型**：$J = \phi(x(t_f), t_f)$
3. **波尔扎型**：$J = \phi(x(t_f), t_f) + \int_{t_0}^{t_f} L(x(t), u(t), t) dt$

## 2. 变分法

### 2.1 欧拉-拉格朗日方程

**定理 2.1** (欧拉-拉格朗日方程)
对于泛函：
$$J = \int_{t_0}^{t_f} L(x(t), \dot{x}(t), t) dt$$

最优解满足欧拉-拉格朗日方程：
$$\frac{d}{dt}\frac{\partial L}{\partial \dot{x}} - \frac{\partial L}{\partial x} = 0$$

### 2.2 横截条件

**定理 2.2** (横截条件)
对于自由终端时间问题，横截条件为：
$$\left[L - \dot{x}^T \frac{\partial L}{\partial \dot{x}}\right]_{t_f} = 0$$

## 3. 庞特里亚金最大原理

### 3.1 哈密顿函数

**定义 3.1** (哈密顿函数)
哈密顿函数定义为：
$$H(x, u, \lambda, t) = L(x, u, t) + \lambda^T f(x, u, t)$$

其中 $\lambda$ 是协态变量。

### 3.2 庞特里亚金最大原理

**定理 3.1** (庞特里亚金最大原理)
最优控制 $u^*(t)$ 和最优轨迹 $x^*(t)$ 满足：

1. **状态方程**：$\dot{x} = \frac{\partial H}{\partial \lambda}$
2. **协态方程**：$\dot{\lambda} = -\frac{\partial H}{\partial x}$
3. **最优性条件**：$H(x^*, u^*, \lambda^*, t) \leq H(x^*, u, \lambda^*, t)$
4. **横截条件**：$\lambda(t_f) = \frac{\partial \phi}{\partial x} + \nu^T \frac{\partial \psi}{\partial x}$

### 3.3 边界条件

**定理 3.2** (边界条件)
对于固定终端时间问题：
$$\lambda(t_f) = \frac{\partial \phi}{\partial x}$$

对于自由终端时间问题：
$$H(t_f) = -\frac{\partial \phi}{\partial t_f}$$

## 4. 动态规划

### 4.1 贝尔曼方程

**定理 4.1** (贝尔曼最优性原理)
最优值函数满足贝尔曼方程：
$$V(x, t) = \min_{u} \left[L(x, u, t) + V(f(x, u, t), t + \Delta t)\right]$$

### 4.2 哈密顿-雅可比-贝尔曼方程

**定理 4.2** (HJB方程)
对于连续时间问题，HJB方程为：
$$-\frac{\partial V}{\partial t} = \min_{u} \left[L(x, u, t) + \frac{\partial V}{\partial x} f(x, u, t)\right]$$

## 5. 线性二次型调节器

### 5.1 LQR问题

**定义 5.1** (LQR问题)
线性二次型调节器问题：
$$\min_{u} J = \frac{1}{2}x^T(t_f) S_f x(t_f) + \frac{1}{2}\int_{t_0}^{t_f} (x^T Q x + u^T R u) dt$$

约束：
$$\dot{x} = Ax + Bu$$

### 5.2 最优控制律

**定理 5.1** (LQR最优控制)
最优控制律为：
$$u^*(t) = -R^{-1} B^T P(t) x(t)$$

其中 $P(t)$ 满足黎卡提微分方程：
$$\dot{P} + A^T P + PA - PBR^{-1}B^T P + Q = 0$$

### 5.3 稳态解

**定理 5.2** (稳态LQR)
对于无限时间问题，稳态最优控制为：
$$u^*(t) = -K x(t)$$

其中 $K = R^{-1} B^T P$，$P$ 是代数黎卡提方程的解。

## 6. 模型预测控制

### 6.1 MPC问题

**定义 6.1** (MPC问题)
模型预测控制问题：
$$\min_{u_k, \ldots, u_{k+N-1}} J = \sum_{i=k}^{k+N-1} \|x_i - x_{ref}\|_Q^2 + \|u_i\|_R^2 + \|x_{k+N} - x_{ref}\|_P^2$$

约束：
$$x_{i+1} = Ax_i + Bu_i$$
$$u_{min} \leq u_i \leq u_{max}$$

### 6.2 滚动时域优化

**算法 6.1** (MPC算法)

1. 在时刻 $k$，求解优化问题
2. 应用最优控制序列的第一个控制输入
3. 更新状态，移动到下一时刻
4. 重复步骤1-3

## 7. 实际应用

### 7.1 飞行器轨迹优化

**应用 7.1** (最小时间爬升)
考虑飞机最小时间爬升问题：
$$\min_{u} J = \int_0^{t_f} dt$$

约束：
$$\dot{h} = V \sin(\gamma)$$
$$\dot{V} = \frac{T - D}{m} - g \sin(\gamma)$$
$$\dot{\gamma} = \frac{L \cos(\mu)}{mV} - \frac{g \cos(\gamma)}{V}$$

### 7.2 机器人路径规划

**应用 7.2** (最优路径规划)
考虑机器人最优路径规划：
$$\min_{u} J = \int_0^{t_f} (x^T Q x + u^T R u) dt$$

约束：
$$\dot{x} = f(x) + g(x) u$$
$$x(0) = x_0, \quad x(t_f) = x_f$$

## 8. 代码实现

### 8.1 Rust实现

```rust
use nalgebra::{DMatrix, DVector, Matrix2, Vector2};
use std::f64::consts::PI;

// 最优控制问题结构
#[derive(Debug, Clone)]
pub struct OptimalControlProblem {
    pub t0: f64,
    pub tf: f64,
    pub x0: DVector<f64>,
    pub xf: Option<DVector<f64>>,
}

// LQR控制器
#[derive(Debug, Clone)]
pub struct LQRController {
    pub A: DMatrix<f64>,
    pub B: DMatrix<f64>,
    pub Q: DMatrix<f64>,
    pub R: DMatrix<f64>,
    pub K: DMatrix<f64>,
}

impl LQRController {
    pub fn new(A: DMatrix<f64>, B: DMatrix<f64>, Q: DMatrix<f64>, R: DMatrix<f64>) -> Self {
        let K = Self::solve_algebraic_riccati(&A, &B, &Q, &R);
        LQRController { A, B, Q, R, K }
    }

    // 求解代数黎卡提方程
    fn solve_algebraic_riccati(A: &DMatrix<f64>, B: &DMatrix<f64>, Q: &DMatrix<f64>, R: &DMatrix<f64>) -> DMatrix<f64> {
        let n = A.nrows();
        let mut P = Q.clone();
        
        // 简化的迭代求解
        for _ in 0..100 {
            let P_new = A.transpose() * P.clone() + P.clone() * A - 
                       P.clone() * B * R.try_inverse().unwrap() * B.transpose() * P.clone() + Q.clone();
            
            if (P_new - P.clone()).norm() < 1e-6 {
                break;
            }
            P = P_new;
        }
        
        R.try_inverse().unwrap() * B.transpose() * P
    }

    pub fn control(&self, x: &DVector<f64>) -> DVector<f64> {
        -self.K.clone() * x
    }
}

// 模型预测控制器
#[derive(Debug, Clone)]
pub struct MPCController {
    pub A: DMatrix<f64>,
    pub B: DMatrix<f64>,
    pub Q: DMatrix<f64>,
    pub R: DMatrix<f64>,
    pub P: DMatrix<f64>,
    pub horizon: usize,
    pub umin: f64,
    pub umax: f64,
}

impl MPCController {
    pub fn new(A: DMatrix<f64>, B: DMatrix<f64>, Q: DMatrix<f64>, R: DMatrix<f64>, horizon: usize) -> Self {
        let P = Q.clone(); // 简化的终端权重
        MPCController {
            A, B, Q, R, P, horizon,
            umin: -1.0,
            umax: 1.0,
        }
    }

    pub fn control(&self, x: &DVector<f64>, xref: &DVector<f64>) -> DVector<f64> {
        // 简化的MPC实现
        let mut u_opt = DVector::zeros(self.horizon);
        
        // 使用LQR作为MPC的近似
        let lqr = LQRController::new(self.A.clone(), self.B.clone(), self.Q.clone(), self.R.clone());
        let u = lqr.control(&(x - xref));
        
        // 约束处理
        for i in 0..u.len() {
            u_opt[i] = u[i].max(self.umin).min(self.umax);
        }
        
        DVector::from_column_slice(&[u_opt[0]])
    }
}

// 庞特里亚金最大原理求解器
#[derive(Debug, Clone)]
pub struct PontryaginSolver {
    pub problem: OptimalControlProblem,
}

impl PontryaginSolver {
    pub fn new(problem: OptimalControlProblem) -> Self {
        PontryaginSolver { problem }
    }

    pub fn solve(&self) -> (Vec<DVector<f64>>, Vec<DVector<f64>>, Vec<f64>) {
        // 简化的庞特里亚金最大原理实现
        let n_steps = 100;
        let dt = (self.problem.tf - self.problem.t0) / n_steps as f64;
        
        let mut x_traj = Vec::new();
        let mut u_traj = Vec::new();
        let mut t_traj = Vec::new();
        
        let mut x = self.problem.x0.clone();
        
        for i in 0..n_steps {
            let t = self.problem.t0 + i as f64 * dt;
            
            // 简化的最优控制
            let u = self.simple_optimal_control(&x, t);
            
            x_traj.push(x.clone());
            u_traj.push(u.clone());
            t_traj.push(t);
            
            // 更新状态
            x = x + dt * self.system_dynamics(&x, &u);
        }
        
        (x_traj, u_traj, t_traj)
    }

    fn simple_optimal_control(&self, x: &DVector<f64>, t: f64) -> DVector<f64> {
        // 简化的最优控制律
        DVector::from_column_slice(&[-x[0] - 0.5 * x[1]])
    }

    fn system_dynamics(&self, x: &DVector<f64>, u: &DVector<f64>) -> DVector<f64> {
        // 简化的系统动力学
        DVector::from_column_slice(&[x[1], u[0]])
    }
}

// 动态规划求解器
#[derive(Debug, Clone)]
pub struct DynamicProgrammingSolver {
    pub problem: OptimalControlProblem,
    pub n_states: usize,
    pub n_controls: usize,
}

impl DynamicProgrammingSolver {
    pub fn new(problem: OptimalControlProblem) -> Self {
        DynamicProgrammingSolver {
            problem,
            n_states: 10,
            n_controls: 10,
        }
    }

    pub fn solve(&self) -> DMatrix<f64> {
        let n = self.n_states;
        let mut V = DMatrix::zeros(n, n);
        
        // 简化的动态规划实现
        for i in 0..n {
            for j in 0..n {
                V[(i, j)] = (i as f64 - n as f64 / 2.0).powi(2) + (j as f64 - n as f64 / 2.0).powi(2);
            }
        }
        
        V
    }
}

// 示例：双积分器最优控制
pub fn double_integrator_example() {
    println!("=== 双积分器最优控制示例 ===");
    
    // 系统参数
    let A = DMatrix::from_row_slice(2, 2, &[0.0, 1.0, 0.0, 0.0]);
    let B = DMatrix::from_row_slice(2, 1, &[0.0, 1.0]);
    let Q = DMatrix::identity(2, 2);
    let R = DMatrix::from_element(1, 1, 0.1);
    
    // LQR控制器
    let lqr = LQRController::new(A.clone(), B.clone(), Q.clone(), R.clone());
    println!("LQR控制器创建成功");
    
    // MPC控制器
    let mpc = MPCController::new(A, B, Q, R, 10);
    println!("MPC控制器创建成功");
    
    // 庞特里亚金求解器
    let problem = OptimalControlProblem {
        t0: 0.0,
        tf: 5.0,
        x0: DVector::from_column_slice(&[1.0, 0.0]),
        xf: Some(DVector::from_column_slice(&[0.0, 0.0])),
    };
    
    let pontryagin_solver = PontryaginSolver::new(problem.clone());
    let (x_traj, u_traj, t_traj) = pontryagin_solver.solve();
    println!("庞特里亚金求解完成，轨迹长度: {}", x_traj.len());
    
    // 动态规划求解器
    let dp_solver = DynamicProgrammingSolver::new(problem);
    let value_function = dp_solver.solve();
    println!("动态规划求解完成，值函数维度: {}x{}", value_function.nrows(), value_function.ncols());
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_lqr_controller() {
        let A = DMatrix::from_row_slice(2, 2, &[0.0, 1.0, 0.0, 0.0]);
        let B = DMatrix::from_row_slice(2, 1, &[0.0, 1.0]);
        let Q = DMatrix::identity(2, 2);
        let R = DMatrix::from_element(1, 1, 0.1);
        
        let lqr = LQRController::new(A, B, Q, R);
        let x = DVector::from_column_slice(&[1.0, 0.0]);
        let u = lqr.control(&x);
        
        assert_eq!(u.len(), 1);
    }

    #[test]
    fn test_mpc_controller() {
        let A = DMatrix::from_row_slice(2, 2, &[0.0, 1.0, 0.0, 0.0]);
        let B = DMatrix::from_row_slice(2, 1, &[0.0, 1.0]);
        let Q = DMatrix::identity(2, 2);
        let R = DMatrix::from_element(1, 1, 0.1);
        
        let mpc = MPCController::new(A, B, Q, R, 10);
        let x = DVector::from_column_slice(&[1.0, 0.0]);
        let xref = DVector::from_column_slice(&[0.0, 0.0]);
        let u = mpc.control(&x, &xref);
        
        assert_eq!(u.len(), 1);
    }
}

fn main() {
    double_integrator_example();
}
```

### 8.2 Haskell实现

```haskell
{-# LANGUAGE FlexibleContexts #-}
{-# LANGUAGE TypeFamilies #-}

module OptimalControlTheory where

import Numeric.LinearAlgebra
import Numeric.LinearAlgebra.Data
import Control.Monad
import Data.Maybe

-- 最优控制问题数据类型
data OptimalControlProblem = OptimalControlProblem
    { t0 :: Double
    , tf :: Double
    , x0 :: Vector Double
    , xf :: Maybe (Vector Double)
    } deriving (Show, Eq)

-- LQR控制器
data LQRController = LQRController
    { matrixA :: Matrix Double
    , matrixB :: Matrix Double
    , matrixQ :: Matrix Double
    , matrixR :: Matrix Double
    , gainK :: Matrix Double
    } deriving (Show, Eq)

-- 创建LQR控制器
createLQRController :: Matrix Double -> Matrix Double -> Matrix Double -> Matrix Double -> LQRController
createLQRController a b q r = LQRController a b q r k
  where
    k = solveAlgebraicRiccati a b q r

-- 求解代数黎卡提方程
solveAlgebraicRiccati :: Matrix Double -> Matrix Double -> Matrix Double -> Matrix Double -> Matrix Double
solveAlgebraicRiccati a b q r = k
  where
    n = rows a
    p = iterateRiccati a b q r (ident n) 100
    k = inv r `multiply` tr b `multiply` p

-- 迭代求解黎卡提方程
iterateRiccati :: Matrix Double -> Matrix Double -> Matrix Double -> Matrix Double -> Matrix Double -> Int -> Matrix Double
iterateRiccati a b q r p 0 = p
iterateRiccati a b q r p n = iterateRiccati a b q r p_new (n-1)
  where
    p_new = tr a `multiply` p `multiply` a - 
            tr a `multiply` p `multiply` b `multiply` inv r `multiply` tr b `multiply` p `multiply` a + q

-- LQR控制律
lqrControl :: LQRController -> Vector Double -> Vector Double
lqrControl controller x = -k `multiply` x
  where k = gainK controller

-- 模型预测控制器
data MPCController = MPCController
    { mpcA :: Matrix Double
    , mpcB :: Matrix Double
    , mpcQ :: Matrix Double
    , mpcR :: Matrix Double
    , mpcP :: Matrix Double
    , horizon :: Int
    , umin :: Double
    , umax :: Double
    } deriving (Show, Eq)

-- 创建MPC控制器
createMPCController :: Matrix Double -> Matrix Double -> Matrix Double -> Matrix Double -> Int -> MPCController
createMPCController a b q r h = MPCController a b q r q h (-1.0) 1.0

-- MPC控制律
mpcControl :: MPCController -> Vector Double -> Vector Double -> Vector Double
mpcControl controller x xref = fromList [u_opt]
  where
    lqr = createLQRController (mpcA controller) (mpcB controller) (mpcQ controller) (mpcR controller)
    u = lqrControl lqr (x - xref)
    u_opt = maximum [minimum [u!0, umax controller], umin controller]

-- 庞特里亚金最大原理求解器
data PontryaginSolver = PontryaginSolver
    { problem :: OptimalControlProblem
    } deriving (Show, Eq)

-- 创建庞特里亚金求解器
createPontryaginSolver :: OptimalControlProblem -> PontryaginSolver
createPontryaginSolver = PontryaginSolver

-- 求解最优控制
solvePontryagin :: PontryaginSolver -> (Vector Double, Vector Double, Vector Double)
solvePontryagin solver = (x_traj, u_traj, t_traj)
  where
    n_steps = 100
    dt = (tf (problem solver) - t0 (problem solver)) / fromIntegral n_steps
    
    x_traj = fromList $ take n_steps $ iterate step_x (x0 (problem solver))
    u_traj = fromList $ take n_steps $ map (\i -> simpleOptimalControl (x_traj!i) (t0 (problem solver) + fromIntegral i * dt)) [0..n_steps-1]
    t_traj = fromList $ take n_steps $ map (\i -> t0 (problem solver) + fromIntegral i * dt) [0..n_steps-1]
    
    step_x x = x + scale dt (systemDynamics x (simpleOptimalControl x 0))

-- 简化的最优控制律
simpleOptimalControl :: Vector Double -> Double -> Double
simpleOptimalControl x _t = -x!0 - 0.5 * x!1

-- 系统动力学
systemDynamics :: Vector Double -> Double -> Vector Double
systemDynamics x u = fromList [x!1, u]

-- 动态规划求解器
data DynamicProgrammingSolver = DynamicProgrammingSolver
    { dpProblem :: OptimalControlProblem
    , nStates :: Int
    } deriving (Show, Eq)

-- 创建动态规划求解器
createDPSolver :: OptimalControlProblem -> DynamicProgrammingSolver
createDPSolver problem = DynamicProgrammingSolver problem 10

-- 求解值函数
solveDP :: DynamicProgrammingSolver -> Matrix Double
solveDP solver = valueFunction
  where
    n = nStates solver
    valueFunction = (n><n) [((fromIntegral i - fromIntegral n/2)^2 + (fromIntegral j - fromIntegral n/2)^2) | i <- [0..n-1], j <- [0..n-1]]

-- 示例：双积分器最优控制
doubleIntegratorExample :: IO ()
doubleIntegratorExample = do
    putStrLn "=== 双积分器最优控制示例 ==="
    
    -- 系统参数
    let a = (2><2) [0, 1, 0, 0]
    let b = (2><1) [0, 1]
    let q = ident 2
    let r = (1><1) [0.1]
    
    -- LQR控制器
    let lqr = createLQRController a b q r
    putStrLn "LQR控制器创建成功"
    
    -- MPC控制器
    let mpc = createMPCController a b q r 10
    putStrLn "MPC控制器创建成功"
    
    -- 庞特里亚金求解器
    let problem = OptimalControlProblem 0.0 5.0 (fromList [1.0, 0.0]) (Just $ fromList [0.0, 0.0])
    let pontryaginSolver = createPontryaginSolver problem
    let (xTraj, uTraj, tTraj) = solvePontryagin pontryaginSolver
    putStrLn $ "庞特里亚金求解完成，轨迹长度: " ++ show (size xTraj)
    
    -- 动态规划求解器
    let dpSolver = createDPSolver problem
    let valueFunction = solveDP dpSolver
    putStrLn $ "动态规划求解完成，值函数维度: " ++ show (rows valueFunction) ++ "x" ++ show (cols valueFunction)

-- 测试函数
testOptimalControl :: IO ()
testOptimalControl = do
    putStrLn "=== 最优控制理论测试 ==="
    
    -- 测试LQR控制器
    let a = (2><2) [0, 1, 0, 0]
    let b = (2><1) [0, 1]
    let q = ident 2
    let r = (1><1) [0.1]
    
    let lqr = createLQRController a b q r
    let x = fromList [1.0, 0.0]
    let u = lqrControl lqr x
    putStrLn $ "LQR控制输出: " ++ show u
    
    -- 测试MPC控制器
    let mpc = createMPCController a b q r 10
    let xref = fromList [0.0, 0.0]
    let u_mpc = mpcControl mpc x xref
    putStrLn $ "MPC控制输出: " ++ show u_mpc

-- 主函数
main :: IO ()
main = do
    testOptimalControl
    doubleIntegratorExample
```

## 9. 参考文献

1. Kirk, D. E. (2012). *Optimal Control Theory: An Introduction*. Dover Publications.
2. Bryson, A. E., & Ho, Y. C. (1975). *Applied Optimal Control*. Hemisphere Publishing.
3. Lewis, F. L., Vrabie, D., & Syrmos, V. L. (2012). *Optimal Control*. Wiley.
4. Pontryagin, L. S., Boltyanskii, V. G., Gamkrelidze, R. V., & Mishchenko, E. F. (1962). *The Mathematical Theory of Optimal Processes*. Wiley.
5. Bellman, R. (1957). *Dynamic Programming*. Princeton University Press.
6. Bertsekas, D. P. (2017). *Dynamic Programming and Optimal Control*. Athena Scientific.
7. Camacho, E. F., & Bordons, C. (2007). *Model Predictive Control*. Springer.
8. Rawlings, J. B., & Mayne, D. Q. (2009). *Model Predictive Control: Theory and Design*. Nob Hill Publishing.

---

**相关文档链接**：

- [03.1 控制论基础](../03.1_Control_Theory_Foundation.md)
- [03.2 线性控制理论](../03.2_Linear_Control_Theory.md)
- [03.3 非线性控制理论](../03.3_Nonlinear_Control_Theory.md)
- [01.1 类型理论基础](../../01_Type_Theory/01.1_Type_Theory_Foundation.md)
- [02.1 形式语言基础](../../02_Formal_Language/02.1_Formal_Language_Foundation.md)
