# 18 ä¿¡æ¯ç†è®º (Information Theory)

## æ¨¡å—æ¦‚è¿°

ä¿¡æ¯ç†è®ºæ˜¯ç ”ç©¶ä¿¡æ¯ä¼ è¾“ã€å­˜å‚¨å’Œå¤„ç†çš„æ•°å­¦åˆ†æ”¯ï¼Œä¸ºé€šä¿¡ç³»ç»Ÿã€æ•°æ®å‹ç¼©ã€å¯†ç å­¦ç­‰é¢†åŸŸæä¾›ç†è®ºåŸºç¡€ã€‚æœ¬æ¨¡å—æ¶µç›–ä»ä¿¡æ¯ç†µåˆ°ä¿¡é“ç¼–ç çš„å®Œæ•´ç†è®ºä½“ç³»ï¼ŒåŒ…æ‹¬ä¿¡æ¯åº¦é‡ã€ä¿¡é“å®¹é‡ã€ç¼–ç ç†è®ºå’Œæ•°æ®å‹ç¼©ç­‰æ ¸å¿ƒå†…å®¹ã€‚

## ç›®å½•ç»“æ„

```text
18_Information_Theory/
â”œâ”€â”€ README.md                           # æ¨¡å—æ€»è§ˆ
â”œâ”€â”€ 18.1_Information_Entropy/           # ä¿¡æ¯ç†µ
â”œâ”€â”€ 18.2_Channel_Capacity/              # ä¿¡é“å®¹é‡
â”œâ”€â”€ 18.3_Coding_Theory/                 # ç¼–ç ç†è®º
â”œâ”€â”€ 18.4_Data_Compression/              # æ•°æ®å‹ç¼©
â”œâ”€â”€ 18.5_Error_Correction/              # é”™è¯¯çº æ­£
â”œâ”€â”€ 18.6_Cryptography/                  # å¯†ç å­¦
â”œâ”€â”€ 18.7_Quantum_Information/           # é‡å­ä¿¡æ¯
â”œâ”€â”€ 18.8_Information_Measures/          # ä¿¡æ¯åº¦é‡
â””â”€â”€ Resources/                          # èµ„æºç›®å½•
    â”œâ”€â”€ Examples/                       # ç¤ºä¾‹ä»£ç 
    â”œâ”€â”€ Exercises/                      # ç»ƒä¹ é¢˜
    â””â”€â”€ References/                     # å‚è€ƒæ–‡çŒ®
```

## ç†è®ºåŸºç¡€

### æ ¸å¿ƒæ¦‚å¿µ

**å®šä¹‰ 18.1 (ä¿¡æ¯)** ä¿¡æ¯æ˜¯å‡å°‘ä¸ç¡®å®šæ€§çš„é‡åº¦ï¼Œä¸äº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡ç›¸å…³ã€‚

**å®šä¹‰ 18.2 (ä¿¡æ¯ç†µ)** ä¿¡æ¯ç†µæ˜¯éšæœºå˜é‡ä¸ç¡®å®šæ€§çš„åº¦é‡ï¼š
$$H(X) = -\sum_{i=1}^{n} p_i \log_2 p_i$$

**å®šä¹‰ 18.3 (ä¿¡é“å®¹é‡)** ä¿¡é“å®¹é‡æ˜¯ä¿¡é“èƒ½å¤Ÿå¯é ä¼ è¾“çš„æœ€å¤§ä¿¡æ¯ç‡ï¼š
$$C = \max_{p(x)} I(X; Y)$$

**å®šä¹‰ 18.4 (äº’ä¿¡æ¯)** äº’ä¿¡æ¯æ˜¯ä¸¤ä¸ªéšæœºå˜é‡ä¹‹é—´å…±äº«ä¿¡æ¯çš„åº¦é‡ï¼š
$$I(X; Y) = H(X) - H(X|Y)$$

### åŸºæœ¬å®šç†

**é¦™å†œç¬¬ä¸€å®šç† (æ— æŸç¼–ç å®šç†)**ï¼š
å¯¹äºç¦»æ•£æ— è®°å¿†ä¿¡æºï¼Œå­˜åœ¨ç¼–ç æ–¹æ¡ˆä½¿å¾—å¹³å‡ç é•¿ä»»æ„æ¥è¿‘ä¿¡æºç†µã€‚

**é¦™å†œç¬¬äºŒå®šç† (ä¿¡é“ç¼–ç å®šç†)**ï¼š
å¯¹äºç¦»æ•£æ— è®°å¿†ä¿¡é“ï¼Œå­˜åœ¨ç¼–ç æ–¹æ¡ˆä½¿å¾—é”™è¯¯æ¦‚ç‡ä»»æ„å°ï¼Œå½“ä¸”ä»…å½“ä¿¡æ¯ç‡å°äºä¿¡é“å®¹é‡ã€‚

**é¦™å†œç¬¬ä¸‰å®šç† (ç‡å¤±çœŸå®šç†)**ï¼š
å¯¹äºç»™å®šçš„å¤±çœŸåº¦é‡ï¼Œå­˜åœ¨ç¼–ç æ–¹æ¡ˆä½¿å¾—å¹³å‡å¤±çœŸä»»æ„æ¥è¿‘ç‡å¤±çœŸå‡½æ•°ã€‚

## å½¢å¼åŒ–å®ç°

### åŸºç¡€æ•°æ®ç»“æ„

```rust
use std::collections::HashMap;
use nalgebra::{DMatrix, DVector};
use serde::{Serialize, Deserialize};

// æ¦‚ç‡åˆ†å¸ƒ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ProbabilityDistribution {
    pub probabilities: HashMap<String, f64>,
    pub alphabet: Vec<String>,
}

impl ProbabilityDistribution {
    pub fn new() -> Self {
        ProbabilityDistribution {
            probabilities: HashMap::new(),
            alphabet: vec![],
        }
    }

    pub fn add_symbol(&mut self, symbol: &str, probability: f64) {
        self.probabilities.insert(symbol.to_string(), probability);
        if !self.alphabet.contains(&symbol.to_string()) {
            self.alphabet.push(symbol.to_string());
        }
    }

    pub fn normalize(&mut self) {
        let total: f64 = self.probabilities.values().sum();
        if total > 0.0 {
            for (_, prob) in self.probabilities.iter_mut() {
                *prob /= total;
            }
        }
    }

    pub fn entropy(&self) -> f64 {
        let mut entropy = 0.0;
        for &probability in self.probabilities.values() {
            if probability > 0.0 {
                entropy -= probability * probability.log2();
            }
        }
        entropy
    }

    pub fn joint_entropy(&self, other: &ProbabilityDistribution) -> f64 {
        let mut joint_entropy = 0.0;

        for (symbol1, prob1) in &self.probabilities {
            for (symbol2, prob2) in &other.probabilities {
                let joint_prob = prob1 * prob2;
                if joint_prob > 0.0 {
                    joint_entropy -= joint_prob * joint_prob.log2();
                }
            }
        }

        joint_entropy
    }

    pub fn conditional_entropy(&self, other: &ProbabilityDistribution) -> f64 {
        let mut conditional_entropy = 0.0;

        for (symbol1, prob1) in &self.probabilities {
            for (symbol2, prob2) in &other.probabilities {
                let joint_prob = prob1 * prob2;
                if joint_prob > 0.0 {
                    conditional_entropy -= joint_prob * (joint_prob / prob2).log2();
                }
            }
        }

        conditional_entropy
    }
}

// ä¿¡é“æ¨¡å‹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Channel {
    pub transition_matrix: DMatrix<f64>,
    pub input_alphabet: Vec<String>,
    pub output_alphabet: Vec<String>,
}

impl Channel {
    pub fn new(input_size: usize, output_size: usize) -> Self {
        Channel {
            transition_matrix: DMatrix::zeros(output_size, input_size),
            input_alphabet: (0..input_size).map(|i| format!("x{}", i)).collect(),
            output_alphabet: (0..output_size).map(|i| format!("y{}", i)).collect(),
        }
    }

    pub fn set_transition_probability(&mut self, input: usize, output: usize, probability: f64) {
        if input < self.transition_matrix.ncols() && output < self.transition_matrix.nrows() {
            self.transition_matrix[(output, input)] = probability;
        }
    }

    pub fn normalize_transition_matrix(&mut self) {
        for col in 0..self.transition_matrix.ncols() {
            let col_sum: f64 = self.transition_matrix.column(col).sum();
            if col_sum > 0.0 {
                for row in 0..self.transition_matrix.nrows() {
                    self.transition_matrix[(row, col)] /= col_sum;
                }
            }
        }
    }

    // è®¡ç®—ä¿¡é“å®¹é‡
    pub fn capacity(&self) -> f64 {
        // ç®€åŒ–çš„ä¿¡é“å®¹é‡è®¡ç®—
        let mut max_mutual_info = 0.0;

        // å°è¯•ä¸åŒçš„è¾“å…¥åˆ†å¸ƒ
        for i in 0..10 {
            let input_dist = self.generate_uniform_distribution();
            let mutual_info = self.mutual_information(&input_dist);
            max_mutual_info = max_mutual_info.max(mutual_info);
        }

        max_mutual_info
    }

    fn generate_uniform_distribution(&self) -> ProbabilityDistribution {
        let mut dist = ProbabilityDistribution::new();
        let probability = 1.0 / self.input_alphabet.len() as f64;

        for symbol in &self.input_alphabet {
            dist.add_symbol(symbol, probability);
        }

        dist
    }

    fn mutual_information(&self, input_dist: &ProbabilityDistribution) -> f64 {
        let input_entropy = input_dist.entropy();
        let output_dist = self.output_distribution(input_dist);
        let output_entropy = output_dist.entropy();
        let joint_entropy = self.joint_entropy(input_dist);

        input_entropy + output_entropy - joint_entropy
    }

    fn output_distribution(&self, input_dist: &ProbabilityDistribution) -> ProbabilityDistribution {
        let mut output_dist = ProbabilityDistribution::new();

        for (i, input_symbol) in self.input_alphabet.iter().enumerate() {
            let input_prob = input_dist.probabilities.get(input_symbol).unwrap_or(&0.0);

            for (j, output_symbol) in self.output_alphabet.iter().enumerate() {
                let transition_prob = self.transition_matrix[(j, i)];
                let joint_prob = input_prob * transition_prob;

                let current_prob = output_dist.probabilities.get(output_symbol).unwrap_or(&0.0);
                output_dist.add_symbol(output_symbol, current_prob + joint_prob);
            }
        }

        output_dist
    }

    fn joint_entropy(&self, input_dist: &ProbabilityDistribution) -> f64 {
        let mut joint_entropy = 0.0;

        for (i, input_symbol) in self.input_alphabet.iter().enumerate() {
            let input_prob = input_dist.probabilities.get(input_symbol).unwrap_or(&0.0);

            for (j, output_symbol) in self.output_alphabet.iter().enumerate() {
                let transition_prob = self.transition_matrix[(j, i)];
                let joint_prob = input_prob * transition_prob;

                if joint_prob > 0.0 {
                    joint_entropy -= joint_prob * joint_prob.log2();
                }
            }
        }

        joint_entropy
    }
}

// ç¼–ç å™¨
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Encoder {
    pub codebook: HashMap<String, String>,
    pub average_length: f64,
}

impl Encoder {
    pub fn new() -> Self {
        Encoder {
            codebook: HashMap::new(),
            average_length: 0.0,
        }
    }

    // Huffmanç¼–ç 
    pub fn huffman_encode(&mut self, distribution: &ProbabilityDistribution) {
        let mut nodes: Vec<HuffmanNode> = distribution.probabilities.iter()
            .map(|(symbol, &prob)| HuffmanNode::new_leaf(symbol.clone(), prob))
            .collect();

        // æ„å»ºHuffmanæ ‘
        while nodes.len() > 1 {
            nodes.sort_by(|a, b| b.probability.partial_cmp(&a.probability).unwrap());

            let right = nodes.pop().unwrap();
            let left = nodes.pop().unwrap();

            let parent = HuffmanNode::new_internal(left, right);
            nodes.push(parent);
        }

        if let Some(root) = nodes.pop() {
            self.build_codebook(&root, "");
            self.calculate_average_length(distribution);
        }
    }

    fn build_codebook(&mut self, node: &HuffmanNode, code: &str) {
        match node {
            HuffmanNode::Leaf { symbol, .. } => {
                self.codebook.insert(symbol.clone(), code.to_string());
            },
            HuffmanNode::Internal { left, right, .. } => {
                self.build_codebook(left, &format!("{}0", code));
                self.build_codebook(right, &format!("{}1", code));
            },
        }
    }

    fn calculate_average_length(&mut self, distribution: &ProbabilityDistribution) {
        self.average_length = 0.0;

        for (symbol, probability) in &distribution.probabilities {
            if let Some(code) = self.codebook.get(symbol) {
                self.average_length += probability * code.len() as f64;
            }
        }
    }

    // ç¼–ç æ¶ˆæ¯
    pub fn encode(&self, message: &str) -> String {
        let mut encoded = String::new();

        for symbol in message.chars() {
            if let Some(code) = self.codebook.get(&symbol.to_string()) {
                encoded.push_str(code);
            }
        }

        encoded
    }

    // è§£ç æ¶ˆæ¯
    pub fn decode(&self, encoded_message: &str) -> String {
        let mut decoded = String::new();
        let mut current_code = String::new();

        for bit in encoded_message.chars() {
            current_code.push(bit);

            // æŸ¥æ‰¾åŒ¹é…çš„ç¬¦å·
            for (symbol, code) in &self.codebook {
                if code == &current_code {
                    decoded.push_str(symbol);
                    current_code.clear();
                    break;
                }
            }
        }

        decoded
    }
}

// Huffmanæ ‘èŠ‚ç‚¹
#[derive(Debug, Clone)]
pub enum HuffmanNode {
    Leaf {
        symbol: String,
        probability: f64,
    },
    Internal {
        probability: f64,
        left: Box<HuffmanNode>,
        right: Box<HuffmanNode>,
    },
}

impl HuffmanNode {
    pub fn new_leaf(symbol: String, probability: f64) -> Self {
        HuffmanNode::Leaf { symbol, probability }
    }

    pub fn new_internal(left: HuffmanNode, right: HuffmanNode) -> Self {
        let probability = match (&left, &right) {
            (HuffmanNode::Leaf { probability: p1, .. }, HuffmanNode::Leaf { probability: p2, .. }) => p1 + p2,
            (HuffmanNode::Internal { probability: p1, .. }, HuffmanNode::Leaf { probability: p2, .. }) => p1 + p2,
            (HuffmanNode::Leaf { probability: p1, .. }, HuffmanNode::Internal { probability: p2, .. }) => p1 + p2,
            (HuffmanNode::Internal { probability: p1, .. }, HuffmanNode::Internal { probability: p2, .. }) => p1 + p2,
        };

        HuffmanNode::Internal {
            probability,
            left: Box::new(left),
            right: Box::new(right),
        }
    }
}

// é”™è¯¯çº æ­£ç 
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ErrorCorrectionCode {
    pub generator_matrix: DMatrix<f64>,
    pub parity_check_matrix: DMatrix<f64>,
    pub code_length: usize,
    pub message_length: usize,
    pub minimum_distance: usize,
}

impl ErrorCorrectionCode {
    pub fn new_hamming_code(message_length: usize) -> Self {
        let code_length = message_length + (message_length as f64).log2().ceil() as usize + 1;

        // æ„å»ºç”ŸæˆçŸ©é˜µ
        let mut generator_matrix = DMatrix::zeros(code_length, message_length);

        // å•ä½çŸ©é˜µéƒ¨åˆ†
        for i in 0..message_length {
            generator_matrix[(i, i)] = 1.0;
        }

        // å¥‡å¶æ ¡éªŒä½
        for i in 0..(code_length - message_length) {
            let parity_position = message_length + i;
            let parity_bit = 1 << i;

            for j in 0..message_length {
                if (j + 1) & parity_bit != 0 {
                    generator_matrix[(parity_position, j)] = 1.0;
                }
            }
        }

        // æ„å»ºæ ¡éªŒçŸ©é˜µ
        let mut parity_check_matrix = DMatrix::zeros(code_length - message_length, code_length);

        for i in 0..(code_length - message_length) {
            let parity_position = message_length + i;
            parity_check_matrix[(i, parity_position)] = 1.0;

            let parity_bit = 1 << i;
            for j in 0..message_length {
                if (j + 1) & parity_bit != 0 {
                    parity_check_matrix[(i, j)] = 1.0;
                }
            }
        }

        ErrorCorrectionCode {
            generator_matrix,
            parity_check_matrix,
            code_length,
            message_length,
            minimum_distance: 3,
        }
    }

    // ç¼–ç 
    pub fn encode(&self, message: &DVector<f64>) -> DVector<f64> {
        &self.generator_matrix * message
    }

    // è§£ç 
    pub fn decode(&self, received: &DVector<f64>) -> DVector<f64> {
        // è®¡ç®—ç—‡çŠ¶
        let syndrome = &self.parity_check_matrix * received;

        // æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if syndrome.iter().all(|&x| x == 0.0) {
            // æ— é”™è¯¯ï¼Œç›´æ¥è¿”å›å‰message_lengthä½
            return received.rows(0, self.message_length).into();
        }

        // é”™è¯¯çº æ­£ï¼ˆç®€åŒ–å®ç°ï¼‰
        let mut corrected = received.clone();

        // æ‰¾åˆ°é”™è¯¯ä½ç½®
        let error_position = self.find_error_position(&syndrome);
        if error_position < corrected.len() {
            corrected[error_position] = if corrected[error_position] == 0.0 { 1.0 } else { 0.0 };
        }

        // è¿”å›æ¶ˆæ¯éƒ¨åˆ†
        corrected.rows(0, self.message_length).into()
    }

    fn find_error_position(&self, syndrome: &DVector<f64>) -> usize {
        // ç®€åŒ–çš„é”™è¯¯ä½ç½®æŸ¥æ‰¾
        let mut position = 0;
        for (i, &bit) in syndrome.iter().enumerate() {
            if bit != 0.0 {
                position += 1 << i;
            }
        }
        position - 1
    }
}

// æ•°æ®å‹ç¼©
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DataCompressor {
    pub compression_ratio: f64,
    pub compression_algorithm: CompressionAlgorithm,
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum CompressionAlgorithm {
    Huffman,
    LZ77,
    LZ78,
    LZW,
    Arithmetic,
}

impl DataCompressor {
    pub fn new(algorithm: CompressionAlgorithm) -> Self {
        DataCompressor {
            compression_ratio: 0.0,
            compression_algorithm,
        }
    }

    // LZ77å‹ç¼©
    pub fn lz77_compress(&mut self, data: &str) -> Vec<(usize, usize, char)> {
        let mut compressed = vec![];
        let mut window_size = 4096;
        let mut look_ahead_size = 16;
        let mut current_pos = 0;

        while current_pos < data.len() {
            let look_ahead_start = current_pos;
            let look_ahead_end = (current_pos + look_ahead_size).min(data.len());
            let look_ahead = &data[look_ahead_start..look_ahead_end];

            let window_start = if current_pos > window_size {
                current_pos - window_size
            } else {
                0
            };
            let window = &data[window_start..current_pos];

            // å¯»æ‰¾æœ€é•¿åŒ¹é…
            let (offset, length) = self.find_longest_match(window, look_ahead);

            if length > 2 {
                compressed.push((offset, length, look_ahead.chars().next().unwrap()));
                current_pos += length;
            } else {
                compressed.push((0, 0, data.chars().nth(current_pos).unwrap()));
                current_pos += 1;
            }
        }

        self.calculate_compression_ratio(data.len(), compressed.len() * 3);
        compressed
    }

    fn find_longest_match(&self, window: &str, look_ahead: &str) -> (usize, usize) {
        let mut best_offset = 0;
        let mut best_length = 0;

        for offset in 1..=window.len() {
            let mut length = 0;
            while length < look_ahead.len() &&
                  length < window.len() - offset + 1 &&
                  window.chars().nth(window.len() - offset + length) ==
                  look_ahead.chars().nth(length) {
                length += 1;
            }

            if length > best_length {
                best_length = length;
                best_offset = offset;
            }
        }

        (best_offset, best_length)
    }

    fn calculate_compression_ratio(&mut self, original_size: usize, compressed_size: usize) {
        self.compression_ratio = compressed_size as f64 / original_size as f64;
    }
}
```

### ä¿¡æ¯åº¦é‡å®ç°

```rust
// ä¿¡æ¯åº¦é‡
pub struct InformationMeasures;

impl InformationMeasures {
    // è®¡ç®—ç†µ
    pub fn entropy(probabilities: &[f64]) -> f64 {
        probabilities.iter()
            .filter(|&&p| p > 0.0)
            .map(|&p| -p * p.log2())
            .sum()
    }

    // è®¡ç®—è”åˆç†µ
    pub fn joint_entropy(joint_probabilities: &DMatrix<f64>) -> f64 {
        joint_probabilities.iter()
            .filter(|&&p| p > 0.0)
            .map(|&p| -p * p.log2())
            .sum()
    }

    // è®¡ç®—æ¡ä»¶ç†µ
    pub fn conditional_entropy(joint_probabilities: &DMatrix<f64>, marginal_probabilities: &[f64]) -> f64 {
        let mut conditional_entropy = 0.0;

        for (i, &marginal_prob) in marginal_probabilities.iter().enumerate() {
            if marginal_prob > 0.0 {
                for j in 0..joint_probabilities.ncols() {
                    let joint_prob = joint_probabilities[(i, j)];
                    if joint_prob > 0.0 {
                        conditional_entropy -= joint_prob * (joint_prob / marginal_prob).log2();
                    }
                }
            }
        }

        conditional_entropy
    }

    // è®¡ç®—äº’ä¿¡æ¯
    pub fn mutual_information(joint_probabilities: &DMatrix<f64>,
                             marginal_x: &[f64],
                             marginal_y: &[f64]) -> f64 {
        let mut mutual_info = 0.0;

        for i in 0..joint_probabilities.nrows() {
            for j in 0..joint_probabilities.ncols() {
                let joint_prob = joint_probabilities[(i, j)];
                if joint_prob > 0.0 {
                    let product_prob = marginal_x[i] * marginal_y[j];
                    if product_prob > 0.0 {
                        mutual_info += joint_prob * (joint_prob / product_prob).log2();
                    }
                }
            }
        }

        mutual_info
    }

    // è®¡ç®—KLæ•£åº¦
    pub fn kl_divergence(p: &[f64], q: &[f64]) -> f64 {
        p.iter().zip(q.iter())
            .filter(|(p_val, q_val)| **p_val > 0.0 && **q_val > 0.0)
            .map(|(p_val, q_val)| p_val * (p_val / q_val).log2())
            .sum()
    }

    // è®¡ç®—Jensen-Shannonæ•£åº¦
    pub fn jensen_shannon_divergence(p: &[f64], q: &[f64]) -> f64 {
        let m: Vec<f64> = p.iter().zip(q.iter())
            .map(|(p_val, q_val)| (p_val + q_val) / 2.0)
            .collect();

        (Self::kl_divergence(p, &m) + Self::kl_divergence(q, &m)) / 2.0
    }
}
```

## åº”ç”¨ç¤ºä¾‹

### ä¿¡æ¯ç†µè®¡ç®—

```rust
fn entropy_example() {
    // åˆ›å»ºæ¦‚ç‡åˆ†å¸ƒ
    let mut distribution = ProbabilityDistribution::new();
    distribution.add_symbol("A", 0.5);
    distribution.add_symbol("B", 0.25);
    distribution.add_symbol("C", 0.125);
    distribution.add_symbol("D", 0.125);
    distribution.normalize();

    // è®¡ç®—ç†µ
    let entropy = distribution.entropy();
    println!("ä¿¡æ¯ç†µ: {:.3} bits", entropy);

    // éªŒè¯ç†µçš„æ€§è´¨
    println!("ç†µçš„èŒƒå›´: 0 <= H(X) <= log2(n)");
    println!("æœ€å¤§ç†µ: {:.3} bits", (distribution.alphabet.len() as f64).log2());
}
```

### Huffmanç¼–ç ç¤ºä¾‹

```rust
fn huffman_coding_example() {
    // åˆ›å»ºæ¦‚ç‡åˆ†å¸ƒ
    let mut distribution = ProbabilityDistribution::new();
    distribution.add_symbol("A", 0.4);
    distribution.add_symbol("B", 0.3);
    distribution.add_symbol("C", 0.2);
    distribution.add_symbol("D", 0.1);
    distribution.normalize();

    // åˆ›å»ºHuffmanç¼–ç å™¨
    let mut encoder = Encoder::new();
    encoder.huffman_encode(&distribution);

    println!("Huffmanç¼–ç è¡¨:");
    for (symbol, code) in &encoder.codebook {
        println!("{} -> {}", symbol, code);
    }

    println!("å¹³å‡ç é•¿: {:.3} bits", encoder.average_length);
    println!("ä¿¡æºç†µ: {:.3} bits", distribution.entropy());

    // ç¼–ç å’Œè§£ç 
    let message = "ABACD";
    let encoded = encoder.encode(message);
    let decoded = encoder.decode(&encoded);

    println!("åŸå§‹æ¶ˆæ¯: {}", message);
    println!("ç¼–ç ç»“æœ: {}", encoded);
    println!("è§£ç ç»“æœ: {}", decoded);
}
```

### ä¿¡é“å®¹é‡è®¡ç®—

```rust
fn channel_capacity_example() {
    // åˆ›å»ºäºŒå…ƒå¯¹ç§°ä¿¡é“
    let mut channel = Channel::new(2, 2);
    let error_probability = 0.1;

    // è®¾ç½®è½¬ç§»æ¦‚ç‡
    channel.set_transition_probability(0, 0, 1.0 - error_probability); // P(Y=0|X=0)
    channel.set_transition_probability(0, 1, error_probability);        // P(Y=1|X=0)
    channel.set_transition_probability(1, 0, error_probability);        // P(Y=0|X=1)
    channel.set_transition_probability(1, 1, 1.0 - error_probability); // P(Y=1|X=1)

    // è®¡ç®—ä¿¡é“å®¹é‡
    let capacity = channel.capacity();
    println!("äºŒå…ƒå¯¹ç§°ä¿¡é“å®¹é‡: {:.3} bits/channel use", capacity);

    // ç†è®ºå€¼éªŒè¯
    let theoretical_capacity = 1.0 - (-error_probability * error_probability.log2() -
                                      (1.0 - error_probability) * (1.0 - error_probability).log2());
    println!("ç†è®ºå®¹é‡: {:.3} bits/channel use", theoretical_capacity);
}
```

### é”™è¯¯çº æ­£ç ç¤ºä¾‹

```rust
fn error_correction_example() {
    // åˆ›å»ºHammingç 
    let code = ErrorCorrectionCode::new_hamming_code(4);

    // åŸå§‹æ¶ˆæ¯
    let message = DVector::from_vec(vec![1.0, 0.0, 1.0, 1.0]);
    println!("åŸå§‹æ¶ˆæ¯: {:?}", message.as_slice());

    // ç¼–ç 
    let encoded = code.encode(&message);
    println!("ç¼–ç ç»“æœ: {:?}", encoded.as_slice());

    // æ¨¡æ‹Ÿé”™è¯¯
    let mut received = encoded.clone();
    received[2] = if received[2] == 0.0 { 1.0 } else { 0.0 }; // å¼•å…¥é”™è¯¯
    println!("æ¥æ”¶ä¿¡å·: {:?}", received.as_slice());

    // è§£ç 
    let decoded = code.decode(&received);
    println!("è§£ç ç»“æœ: {:?}", decoded.as_slice());

    // éªŒè¯çº é”™
    let is_correct = decoded == message;
    println!("çº é”™æˆåŠŸ: {}", is_correct);
}
```

### æ•°æ®å‹ç¼©ç¤ºä¾‹

```rust
fn data_compression_example() {
    // åˆ›å»ºå‹ç¼©å™¨
    let mut compressor = DataCompressor::new(CompressionAlgorithm::LZ77);

    // æµ‹è¯•æ•°æ®
    let data = "TOBEORNOTTOBEORTOBEORNOT";
    println!("åŸå§‹æ•°æ®: {}", data);
    println!("åŸå§‹å¤§å°: {} å­—ç¬¦", data.len());

    // å‹ç¼©
    let compressed = compressor.lz77_compress(data);
    println!("å‹ç¼©ç»“æœ: {:?}", compressed);
    println!("å‹ç¼©å¤§å°: {} å…ƒç»„", compressed.len());
    println!("å‹ç¼©æ¯”: {:.3}", compressor.compression_ratio);
}
```

## ç†è®ºæ‰©å±•

### é¦™å†œå®šç†

**å®šç† 18.1 (é¦™å†œç¬¬ä¸€å®šç†)** å¯¹äºç¦»æ•£æ— è®°å¿†ä¿¡æºï¼Œå­˜åœ¨ç¼–ç æ–¹æ¡ˆä½¿å¾—å¹³å‡ç é•¿ $L$ æ»¡è¶³ï¼š
$$H(X) \leq L < H(X) + 1$$

**å®šç† 18.2 (é¦™å†œç¬¬äºŒå®šç†)** å¯¹äºç¦»æ•£æ— è®°å¿†ä¿¡é“ï¼Œå­˜åœ¨ç¼–ç æ–¹æ¡ˆä½¿å¾—é”™è¯¯æ¦‚ç‡ä»»æ„å°ï¼Œå½“ä¸”ä»…å½“ä¿¡æ¯ç‡ $R < C$ã€‚

**å®šç† 18.3 (é¦™å†œç¬¬ä¸‰å®šç†)** å¯¹äºç»™å®šçš„å¤±çœŸåº¦é‡ï¼Œå­˜åœ¨ç¼–ç æ–¹æ¡ˆä½¿å¾—å¹³å‡å¤±çœŸä»»æ„æ¥è¿‘ç‡å¤±çœŸå‡½æ•°ã€‚

### ä¿¡é“ç¼–ç ç†è®º

**å®šä¹‰ 18.5 (ç ç‡)** ç ç‡ $R = \frac{k}{n}$ï¼Œå…¶ä¸­ $k$ æ˜¯ä¿¡æ¯ä½æ•°ï¼Œ$n$ æ˜¯ç å­—é•¿åº¦ã€‚

**å®šä¹‰ 18.6 (æœ€å°è·ç¦»)** ç çš„æœ€å°è·ç¦»æ˜¯ä»»æ„ä¸¤ä¸ªç å­—ä¹‹é—´çš„æœ€å°æ±‰æ˜è·ç¦»ã€‚

**å®šç† 18.4 (çº é”™èƒ½åŠ›)** ç èƒ½å¤Ÿçº æ­£ $t$ ä¸ªé”™è¯¯ï¼Œå½“ä¸”ä»…å½“æœ€å°è·ç¦» $d \geq 2t + 1$ã€‚

## ğŸ¯ æ‰¹åˆ¤æ€§åˆ†æ

### å¤šå…ƒç†è®ºè§†è§’

- é€šä¿¡è§†è§’ï¼šä¿¡æ¯è®ºå…³æ³¨ä¿¡æ¯ä¼ è¾“å’Œé€šä¿¡ç³»ç»Ÿçš„ç†è®ºåŸºç¡€ã€‚
- ç¼–ç è§†è§’ï¼šä¿¡æ¯è®ºæä¾›æ•°æ®ç¼–ç å’Œé”™è¯¯çº æ­£çš„ç†è®ºæ–¹æ³•ã€‚
- å‹ç¼©è§†è§’ï¼šä¿¡æ¯è®ºç ”ç©¶æ•°æ®å‹ç¼©å’Œå­˜å‚¨ä¼˜åŒ–çš„æŠ€æœ¯ã€‚
- é‡å­è§†è§’ï¼šä¿¡æ¯è®ºæ‰©å±•åˆ°é‡å­ä¿¡æ¯å¤„ç†å’Œé‡å­é€šä¿¡ã€‚

### å±€é™æ€§åˆ†æ

- ç†æƒ³åŒ–å‡è®¾ï¼šæŸäº›ç†è®ºå‡è®¾åœ¨å®é™…åº”ç”¨ä¸­éš¾ä»¥æ»¡è¶³ã€‚
- è®¡ç®—å¤æ‚æ€§ï¼šæŸäº›ä¿¡æ¯è®ºç®—æ³•è®¡ç®—å¤æ‚åº¦é«˜ï¼Œéš¾ä»¥å®æ—¶å®ç°ã€‚
- å®ç°å›°éš¾ï¼šç†è®ºæœ€ä¼˜è§£å¯èƒ½åœ¨å®é™…ç¡¬ä»¶ä¸­éš¾ä»¥å®ç°ã€‚
- ä¿¡é“å»ºæ¨¡ï¼šå®é™…é€šä¿¡ä¿¡é“çš„ç²¾ç¡®å»ºæ¨¡å›°éš¾ã€‚

### äº‰è®®ä¸åˆ†æ­§

- ç¼–ç ç­–ç•¥ï¼šä¸åŒç¼–ç ç­–ç•¥çš„æ€§èƒ½å’Œå¤æ‚åº¦æƒè¡¡ã€‚
- å‹ç¼©ç®—æ³•ï¼šæ— æŸå‹ç¼©vsæœ‰æŸå‹ç¼©çš„é€‰æ‹©ã€‚
- ä¿¡é“æ¨¡å‹ï¼šä¸åŒä¿¡é“æ¨¡å‹çš„é€‚ç”¨æ€§å’Œå‡†ç¡®æ€§ã€‚
- é‡å­ä¿¡æ¯ï¼šç»å…¸ä¿¡æ¯è®ºvsé‡å­ä¿¡æ¯è®ºçš„ç†è®ºåœ°ä½ã€‚

### åº”ç”¨å‰æ™¯

- é€šä¿¡ç³»ç»Ÿï¼šç°ä»£é€šä¿¡ç½‘ç»œå’Œæ— çº¿é€šä¿¡ã€‚
- æ•°æ®å­˜å‚¨ï¼šæ•°æ®å‹ç¼©å’Œå­˜å‚¨ä¼˜åŒ–æŠ€æœ¯ã€‚
- å¯†ç å­¦ï¼šä¿¡æ¯è®ºåœ¨å¯†ç å­¦ä¸­çš„åº”ç”¨ã€‚
- é‡å­è®¡ç®—ï¼šé‡å­ä¿¡æ¯å¤„ç†å’Œé‡å­é€šä¿¡ã€‚

### æ”¹è¿›å»ºè®®

- å‘å±•æ›´å®ç”¨çš„ç¼–ç å’Œå‹ç¼©ç®—æ³•ï¼Œå¹³è¡¡æ€§èƒ½å’Œå¤æ‚åº¦ã€‚
- å»ºç«‹æ›´å‡†ç¡®çš„ä¿¡é“æ¨¡å‹ï¼Œé€‚åº”å®é™…é€šä¿¡ç¯å¢ƒã€‚
- åŠ å¼ºä¿¡æ¯è®ºä¸æ–°å…´æŠ€æœ¯çš„ç»“åˆã€‚
- ä¿ƒè¿›ä¿¡æ¯è®ºç†è®ºçš„æ•™è‚²å’Œå·¥ç¨‹åº”ç”¨ã€‚

## ç›¸å…³é“¾æ¥

- [02.08 åˆ†æç†è®º](../../02_Mathematical_Foundations/02.08_Analysis/README.md)
- [11.01 åˆ†å¸ƒå¼ç®—æ³•](../../11_Distributed_Systems_Theory/11.1_Distributed_Algorithms/README.md)
- [19.01 æœºå™¨å­¦ä¹ ](../../19_Artificial_Intelligence_Theory/19.1_Machine_Learning/README.md)

---

**æœ€åæ›´æ–°**ï¼š2025-01-17
**æ¨¡å—çŠ¶æ€**ï¼šâœ… å®Œæˆ
