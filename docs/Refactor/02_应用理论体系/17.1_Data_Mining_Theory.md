# 03. æ•°æ®æŒ–æ˜ç†è®º (Data Mining Theory)

## ğŸ“‹ ç›®å½•

- [03. æ•°æ®æŒ–æ˜ç†è®º (Data Mining Theory)](#03-æ•°æ®æŒ–æ˜ç†è®º-data-mining-theory)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1. å…³è”è§„åˆ™æŒ–æ˜ç†è®º](#1-å…³è”è§„åˆ™æŒ–æ˜ç†è®º)
    - [1.1 å…³è”è§„åˆ™å®šä¹‰](#11-å…³è”è§„åˆ™å®šä¹‰)
    - [1.2 æ”¯æŒåº¦å’Œç½®ä¿¡åº¦](#12-æ”¯æŒåº¦å’Œç½®ä¿¡åº¦)
    - [1.3 Aprioriç®—æ³•](#13-aprioriç®—æ³•)
  - [2. èšç±»åˆ†æç†è®º](#2-èšç±»åˆ†æç†è®º)
    - [2.1 èšç±»å®šä¹‰](#21-èšç±»å®šä¹‰)
    - [2.2 è·ç¦»åº¦é‡](#22-è·ç¦»åº¦é‡)
    - [2.3 èšç±»ç®—æ³•](#23-èšç±»ç®—æ³•)
  - [3. åˆ†ç±»ç®—æ³•ç†è®º](#3-åˆ†ç±»ç®—æ³•ç†è®º)
    - [3.1 åˆ†ç±»å®šä¹‰](#31-åˆ†ç±»å®šä¹‰)
    - [3.2 å†³ç­–æ ‘](#32-å†³ç­–æ ‘)
    - [3.3 æœ´ç´ è´å¶æ–¯](#33-æœ´ç´ è´å¶æ–¯)
  - [4. åºåˆ—æ¨¡å¼æŒ–æ˜](#4-åºåˆ—æ¨¡å¼æŒ–æ˜)
    - [4.1 åºåˆ—æ¨¡å¼å®šä¹‰](#41-åºåˆ—æ¨¡å¼å®šä¹‰)
    - [4.2 åºåˆ—æ¨¡å¼ç®—æ³•](#42-åºåˆ—æ¨¡å¼ç®—æ³•)
    - [4.3 æ—¶é—´åºåˆ—åˆ†æ](#43-æ—¶é—´åºåˆ—åˆ†æ)
  - [5. å¼‚å¸¸æ£€æµ‹ç†è®º](#5-å¼‚å¸¸æ£€æµ‹ç†è®º)
    - [5.1 å¼‚å¸¸å®šä¹‰](#51-å¼‚å¸¸å®šä¹‰)
    - [5.2 ç»Ÿè®¡å¼‚å¸¸æ£€æµ‹](#52-ç»Ÿè®¡å¼‚å¸¸æ£€æµ‹)
    - [5.3 æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹](#53-æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹)
  - [6. é¢‘ç¹æ¨¡å¼æŒ–æ˜](#6-é¢‘ç¹æ¨¡å¼æŒ–æ˜)
    - [6.1 é¢‘ç¹é¡¹é›†](#61-é¢‘ç¹é¡¹é›†)
    - [6.2 FP-Growthç®—æ³•](#62-fp-growthç®—æ³•)
    - [6.3 é—­é¢‘ç¹é¡¹é›†](#63-é—­é¢‘ç¹é¡¹é›†)
  - [7. æ•°æ®é¢„å¤„ç†ç†è®º](#7-æ•°æ®é¢„å¤„ç†ç†è®º)
    - [7.1 æ•°æ®æ¸…æ´—](#71-æ•°æ®æ¸…æ´—)
    - [7.2 ç‰¹å¾é€‰æ‹©](#72-ç‰¹å¾é€‰æ‹©)
    - [7.3 æ•°æ®å˜æ¢](#73-æ•°æ®å˜æ¢)
  - [8. æŒ–æ˜ç»“æœè¯„ä¼°](#8-æŒ–æ˜ç»“æœè¯„ä¼°)
    - [8.1 è¯„ä¼°æŒ‡æ ‡](#81-è¯„ä¼°æŒ‡æ ‡)
    - [8.2 äº¤å‰éªŒè¯](#82-äº¤å‰éªŒè¯)
    - [8.3 æ¨¡å‹é€‰æ‹©](#83-æ¨¡å‹é€‰æ‹©)
  - [ğŸ“Š æ€»ç»“](#-æ€»ç»“)
  - [æ‰¹åˆ¤æ€§åˆ†æ](#æ‰¹åˆ¤æ€§åˆ†æ)
    - [ä¸»è¦ç†è®ºè§‚ç‚¹æ¢³ç†](#ä¸»è¦ç†è®ºè§‚ç‚¹æ¢³ç†)
    - [ä¸»æµè§‚ç‚¹çš„ä¼˜ç¼ºç‚¹åˆ†æ](#ä¸»æµè§‚ç‚¹çš„ä¼˜ç¼ºç‚¹åˆ†æ)
    - [ä¸å…¶ä»–å­¦ç§‘çš„äº¤å‰ä¸èåˆ](#ä¸å…¶ä»–å­¦ç§‘çš„äº¤å‰ä¸èåˆ)
    - [åˆ›æ–°æ€§æ‰¹åˆ¤ä¸æœªæ¥å±•æœ›](#åˆ›æ–°æ€§æ‰¹åˆ¤ä¸æœªæ¥å±•æœ›)
    - [å‚è€ƒæ–‡çŒ®ä¸è¿›ä¸€æ­¥é˜…è¯»](#å‚è€ƒæ–‡çŒ®ä¸è¿›ä¸€æ­¥é˜…è¯»)

---

## 1. å…³è”è§„åˆ™æŒ–æ˜ç†è®º

### 1.1 å…³è”è§„åˆ™å®šä¹‰

**å®šä¹‰ 1.1** (å…³è”è§„åˆ™)
å…³è”è§„åˆ™æ˜¯å½¢å¦‚ $X \rightarrow Y$ çš„è§„åˆ™ï¼Œå…¶ä¸­ $X, Y \subseteq I$ï¼Œ$X \cap Y = \emptyset$ã€‚

**å®šä¹‰ 1.2** (é¡¹é›†)
é¡¹é›†æ˜¯é¡¹ç›®çš„é›†åˆï¼š

$$I = \{i_1, i_2, ..., i_n\}$$

**å®šä¹‰ 1.3** (äº‹åŠ¡)
äº‹åŠ¡æ˜¯é¡¹é›†çš„å­é›†ï¼š

$$T \subseteq I$$

**å®šç† 1.1** (å…³è”è§„åˆ™æ€§è´¨)
å…³è”è§„åˆ™æ»¡è¶³ä¼ é€’æ€§ï¼šå¦‚æœ $X \rightarrow Y$ å’Œ $Y \rightarrow Z$ï¼Œåˆ™ $X \rightarrow Z$ã€‚

**è¯æ˜**ï¼š

```lean
-- å…³è”è§„åˆ™å®šä¹‰
def association_rule (X Y : set item) : Prop :=
X âŠ† I âˆ§ Y âŠ† I âˆ§ X âˆ© Y = âˆ…

-- é¡¹é›†
def itemset : Type :=
set item

-- äº‹åŠ¡
def transaction : Type :=
set item

-- å…³è”è§„åˆ™æ€§è´¨
theorem association_rule_transitivity :
  âˆ€ (X Y Z : set item),
  association_rule X Y â†’
  association_rule Y Z â†’
  association_rule X Z
```

### 1.2 æ”¯æŒåº¦å’Œç½®ä¿¡åº¦

**å®šä¹‰ 1.4** (æ”¯æŒåº¦)
æ”¯æŒåº¦å®šä¹‰ä¸ºï¼š

$$\text{support}(X) = \frac{|\{T \in D : X \subseteq T\}|}{|D|}$$

å…¶ä¸­ $D$ æ˜¯äº‹åŠ¡æ•°æ®åº“ã€‚

**å®šä¹‰ 1.5** (ç½®ä¿¡åº¦)
ç½®ä¿¡åº¦å®šä¹‰ä¸ºï¼š

$$\text{confidence}(X \rightarrow Y) = \frac{\text{support}(X \cup Y)}{\text{support}(X)}$$

**å®šä¹‰ 1.6** (æå‡åº¦)
æå‡åº¦å®šä¹‰ä¸ºï¼š

$$\text{lift}(X \rightarrow Y) = \frac{\text{confidence}(X \rightarrow Y)}{\text{support}(Y)}$$

**å®šç† 1.2** (æ”¯æŒåº¦æ€§è´¨)
æ”¯æŒåº¦æ»¡è¶³å•è°ƒæ€§ï¼šå¦‚æœ $X \subseteq Y$ï¼Œåˆ™ $\text{support}(X) \geq \text{support}(Y)$ã€‚

**è¯æ˜**ï¼š

```lean
-- æ”¯æŒåº¦å®šä¹‰
def support (X : set item) (D : list transaction) : â„ :=
let count := length (filter (Î» T, X âŠ† T) D) in
count / length D

-- ç½®ä¿¡åº¦å®šä¹‰
def confidence (X Y : set item) (D : list transaction) : â„ :=
support (X âˆª Y) D / support X D

-- æå‡åº¦å®šä¹‰
def lift (X Y : set item) (D : list transaction) : â„ :=
confidence X Y D / support Y D

-- æ”¯æŒåº¦å•è°ƒæ€§
theorem support_monotonicity :
  âˆ€ (X Y : set item) (D : list transaction),
  X âŠ† Y â†’ support X D â‰¥ support Y D
```

### 1.3 Aprioriç®—æ³•

**å®šä¹‰ 1.7** (Aprioriç®—æ³•)
Aprioriç®—æ³•æ­¥éª¤ï¼š

1. ç”Ÿæˆå€™é€‰1é¡¹é›†
2. è®¡ç®—æ”¯æŒåº¦ï¼Œç­›é€‰é¢‘ç¹é¡¹é›†
3. ç”Ÿæˆå€™é€‰ké¡¹é›†
4. é‡å¤æ­¥éª¤2-3ç›´åˆ°æ— é¢‘ç¹é¡¹é›†

**å®šä¹‰ 1.8** (å€™é€‰ç”Ÿæˆ)
å€™é€‰ç”Ÿæˆï¼š

$$C_k = \{X \cup Y : X, Y \in L_{k-1}, |X \cap Y| = k-2\}$$

**å®šä¹‰ 1.9** (å‰ªæ)
å‰ªæï¼š

$$L_k = \{X \in C_k : \text{support}(X) \geq \text{min\_support}\}$$

**å®šç† 1.3** (Aprioriæ­£ç¡®æ€§)
Aprioriç®—æ³•èƒ½å¤Ÿæ‰¾åˆ°æ‰€æœ‰é¢‘ç¹é¡¹é›†ã€‚

**è¯æ˜**ï¼š

```lean
-- Aprioriç®—æ³•
def apriori_algorithm (D : list transaction) (min_support : â„) : list (set item) :=
let Lâ‚ := frequent_1_itemsets D min_support in
generate_frequent_itemsets D min_support Lâ‚

-- å€™é€‰ç”Ÿæˆ
def candidate_generation (L_k_minus_1 : list (set item)) : list (set item) :=
filter (Î» X, is_valid_candidate X L_k_minus_1)
(map (Î» (X, Y), X âˆª Y) (pairs L_k_minus_1))

-- å‰ªæ
def pruning (C_k : list (set item)) (D : list transaction) (min_support : â„) : list (set item) :=
filter (Î» X, support X D â‰¥ min_support) C_k

-- Aprioriæ­£ç¡®æ€§
theorem apriori_correctness :
  âˆ€ (D : list transaction) (min_support : â„),
  let frequent_itemsets := apriori_algorithm D min_support in
  âˆ€ (X : set item), X âˆˆ frequent_itemsets â†” support X D â‰¥ min_support
```

## 2. èšç±»åˆ†æç†è®º

### 2.1 èšç±»å®šä¹‰

**å®šä¹‰ 2.1** (èšç±»)
èšç±»æ˜¯å°†æ•°æ®ç‚¹åˆ†ç»„ä¸ºç›¸ä¼¼é›†åˆçš„è¿‡ç¨‹ï¼š

$$C = \{C_1, C_2, ..., C_k\}$$

å…¶ä¸­ $C_i \cap C_j = \emptyset$ å¯¹äº $i \neq j$ã€‚

**å®šä¹‰ 2.2** (èšç±»ç›®æ ‡)
èšç±»ç›®æ ‡å‡½æ•°ï¼š

$$J = \sum_{i=1}^{k} \sum_{x \in C_i} d(x, \mu_i)$$

å…¶ä¸­ $\mu_i$ æ˜¯èšç±»ä¸­å¿ƒã€‚

**å®šä¹‰ 2.3** (èšç±»è´¨é‡)
èšç±»è´¨é‡ï¼š

$$Q(C) = \frac{\text{intra-cluster distance}}{\text{inter-cluster distance}}$$

**å®šç† 2.1** (èšç±»æ€§è´¨)
èšç±»é—®é¢˜æ˜¯NPéš¾é—®é¢˜ã€‚

**è¯æ˜**ï¼š

```lean
-- èšç±»å®šä¹‰
def clustering (X : list vector) (k : â„•) : list (list vector) :=
partition X k

-- èšç±»ç›®æ ‡å‡½æ•°
def clustering_objective (C : list (list vector)) : â„ :=
sum (map (Î» cluster, sum (map (Î» x, distance x (centroid cluster)) cluster)) C)

-- èšç±»è´¨é‡
def clustering_quality (C : list (list vector)) : â„ :=
intra_cluster_distance C / inter_cluster_distance C

-- NPéš¾æ€§è¯æ˜
theorem clustering_np_hard :
  clustering_problem âˆˆ NP âˆ§
  âˆ€ (P : NP_problem), P â‰¤_p clustering_problem
```

### 2.2 è·ç¦»åº¦é‡

**å®šä¹‰ 2.4** (æ¬§å‡ é‡Œå¾—è·ç¦»)
æ¬§å‡ é‡Œå¾—è·ç¦»ï¼š

$$d(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}$$

**å®šä¹‰ 2.5** (æ›¼å“ˆé¡¿è·ç¦»)
æ›¼å“ˆé¡¿è·ç¦»ï¼š

$$d(x, y) = \sum_{i=1}^{n} |x_i - y_i|$$

**å®šä¹‰ 2.6** (ä½™å¼¦ç›¸ä¼¼åº¦)
ä½™å¼¦ç›¸ä¼¼åº¦ï¼š

$$\cos(\theta) = \frac{x \cdot y}{||x|| \cdot ||y||}$$

**å®šç† 2.2** (è·ç¦»åº¦é‡æ€§è´¨)
è·ç¦»åº¦é‡æ»¡è¶³ä¸‰è§’ä¸ç­‰å¼ã€‚

### 2.3 èšç±»ç®—æ³•

**å®šä¹‰ 2.7** (K-meansç®—æ³•)
K-meansç®—æ³•æ­¥éª¤ï¼š

1. éšæœºåˆå§‹åŒ–èšç±»ä¸­å¿ƒ
2. åˆ†é…ï¼šå°†æ¯ä¸ªç‚¹åˆ†é…ç»™æœ€è¿‘çš„ä¸­å¿ƒ
3. æ›´æ–°ï¼šé‡æ–°è®¡ç®—èšç±»ä¸­å¿ƒ
4. é‡å¤æ­¥éª¤2-3ç›´åˆ°æ”¶æ•›

**å®šä¹‰ 2.8** (å±‚æ¬¡èšç±»)
å±‚æ¬¡èšç±»ï¼š

1. æ¯ä¸ªç‚¹ä½œä¸ºä¸€ä¸ªèšç±»
2. åˆå¹¶æœ€è¿‘çš„ä¸¤ä¸ªèšç±»
3. é‡å¤æ­¥éª¤2ç›´åˆ°åªå‰©ä¸€ä¸ªèšç±»

**å®šä¹‰ 2.9** (DBSCANç®—æ³•)
DBSCANç®—æ³•ï¼š

1. æ ‡è®°æ ¸å¿ƒç‚¹
2. è¿æ¥æ ¸å¿ƒç‚¹å½¢æˆèšç±»
3. åˆ†é…è¾¹ç•Œç‚¹

**å®šç† 2.3** (K-meansæ”¶æ•›æ€§)
K-meansç®—æ³•åœ¨æœ‰é™æ­¥å†…æ”¶æ•›ã€‚

## 3. åˆ†ç±»ç®—æ³•ç†è®º

### 3.1 åˆ†ç±»å®šä¹‰

**å®šä¹‰ 3.1** (åˆ†ç±»é—®é¢˜)
åˆ†ç±»é—®é¢˜æ˜¯å­¦ä¹ æ˜ å°„ï¼š

$$f: \mathcal{X} \rightarrow \mathcal{Y}$$

å…¶ä¸­ $\mathcal{Y} = \{1, 2, ..., k\}$ã€‚

**å®šä¹‰ 3.2** (åˆ†ç±»å™¨)
åˆ†ç±»å™¨æ˜¯å‡½æ•°ï¼š

$$h: \mathcal{X} \rightarrow \mathcal{Y}$$

**å®šä¹‰ 3.3** (åˆ†ç±»è¯¯å·®)
åˆ†ç±»è¯¯å·®ï¼š

$$\epsilon(h) = P(h(X) \neq Y)$$

**å®šç† 3.1** (è´å¶æ–¯æœ€ä¼˜åˆ†ç±»å™¨)
è´å¶æ–¯æœ€ä¼˜åˆ†ç±»å™¨ï¼š

$$h^*(x) = \arg\max_{y} P(Y = y | X = x)$$

**è¯æ˜**ï¼š

```lean
-- åˆ†ç±»é—®é¢˜å®šä¹‰
def classification_problem (X : Type) (Y : Type) : Type :=
X â†’ Y

-- åˆ†ç±»å™¨
def classifier (X : Type) (Y : Type) : Type :=
X â†’ Y

-- åˆ†ç±»è¯¯å·®
def classification_error (h : classifier X Y) (D : list (X Ã— Y)) : â„ :=
let errors := filter (Î» (x, y), h x â‰  y) D in
length errors / length D

-- è´å¶æ–¯æœ€ä¼˜åˆ†ç±»å™¨
def bayes_optimal_classifier (X : Type) (Y : Type) : classifier X Y :=
Î» x, argmax (Î» y, posterior_probability y x)

-- æœ€ä¼˜æ€§è¯æ˜
theorem bayes_optimality :
  âˆ€ (h : classifier X Y),
  expected_error bayes_optimal_classifier â‰¤ expected_error h
```

### 3.2 å†³ç­–æ ‘

**å®šä¹‰ 3.4** (å†³ç­–æ ‘)
å†³ç­–æ ‘æ˜¯æ ‘å½¢ç»“æ„ï¼š

$$T = (V, E, \text{split}, \text{leaf})$$

å…¶ä¸­ $V$ æ˜¯èŠ‚ç‚¹é›†åˆï¼Œ$E$ æ˜¯è¾¹é›†åˆã€‚

**å®šä¹‰ 3.5** (ä¿¡æ¯å¢ç›Š)
ä¿¡æ¯å¢ç›Šï¼š

$$\text{IG}(S, A) = H(S) - \sum_{v \in \text{values}(A)} \frac{|S_v|}{|S|} H(S_v)$$

**å®šä¹‰ 3.6** (åŸºå°¼æŒ‡æ•°)
åŸºå°¼æŒ‡æ•°ï¼š

$$\text{Gini}(S) = 1 - \sum_{i=1}^{k} p_i^2$$

**å®šç† 3.2** (å†³ç­–æ ‘æœ€ä¼˜æ€§)
ä¿¡æ¯å¢ç›Šæœ€å¤§çš„åˆ†è£‚æ˜¯æœ€ä¼˜åˆ†è£‚ã€‚

### 3.3 æœ´ç´ è´å¶æ–¯

**å®šä¹‰ 3.7** (æœ´ç´ è´å¶æ–¯)
æœ´ç´ è´å¶æ–¯å‡è®¾ç‰¹å¾ç‹¬ç«‹ï¼š

$$P(Y = y | X = x) \propto P(Y = y) \prod_{i=1}^{n} P(X_i = x_i | Y = y)$$

**å®šä¹‰ 3.8** (æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘)
æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ï¼š

$$P(X_i = x_i | Y = y) = \frac{count(x_i, y) + \alpha}{count(y) + \alpha|V_i|}$$

**å®šä¹‰ 3.9** (æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨)
æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼š

$$h(x) = \arg\max_{y} P(Y = y) \prod_{i=1}^{n} P(X_i = x_i | Y = y)$$

**å®šç† 3.3** (æœ´ç´ è´å¶æ–¯æ€§è´¨)
æœ´ç´ è´å¶æ–¯åœ¨ç‰¹å¾ç‹¬ç«‹æ—¶æ˜¯æœ€ä¼˜çš„ã€‚

## 4. åºåˆ—æ¨¡å¼æŒ–æ˜

### 4.1 åºåˆ—æ¨¡å¼å®šä¹‰

**å®šä¹‰ 4.1** (åºåˆ—)
åºåˆ—æ˜¯é¡¹é›†çš„æœ‰åºåˆ—è¡¨ï¼š

$$S = \langle s_1, s_2, ..., s_n \rangle$$

å…¶ä¸­ $s_i \subseteq I$ã€‚

**å®šä¹‰ 4.2** (å­åºåˆ—)
å­åºåˆ—ï¼š

$$S' = \langle s_{i_1}, s_{i_2}, ..., s_{i_k} \rangle$$

å…¶ä¸­ $1 \leq i_1 < i_2 < ... < i_k \leq n$ã€‚

**å®šä¹‰ 4.3** (åºåˆ—æ¨¡å¼)
åºåˆ—æ¨¡å¼æ˜¯é¢‘ç¹çš„å­åºåˆ—ï¼š

$$\text{support}(S') \geq \text{min\_support}$$

**å®šç† 4.1** (åºåˆ—æ¨¡å¼æ€§è´¨)
åºåˆ—æ¨¡å¼æ»¡è¶³åå•è°ƒæ€§ã€‚

**è¯æ˜**ï¼š

```lean
-- åºåˆ—å®šä¹‰
def sequence : Type :=
list (set item)

-- å­åºåˆ—
def subsequence (S S' : sequence) : Prop :=
âˆƒ (indices : list â„•),
  sorted indices âˆ§
  S' = map (Î» i, S[i]) indices

-- åºåˆ—æ¨¡å¼
def sequence_pattern (S : sequence) (D : list sequence) (min_support : â„) : Prop :=
support S D â‰¥ min_support

-- åå•è°ƒæ€§
theorem sequence_pattern_antimonotonicity :
  âˆ€ (Sâ‚ Sâ‚‚ : sequence) (D : list sequence) (min_support : â„),
  Sâ‚ âŠ† Sâ‚‚ â†’ sequence_pattern Sâ‚‚ D min_support â†’ sequence_pattern Sâ‚ D min_support
```

### 4.2 åºåˆ—æ¨¡å¼ç®—æ³•

**å®šä¹‰ 4.4** (GSPç®—æ³•)
GSP (Generalized Sequential Patterns) ç®—æ³•ï¼š

1. ç”Ÿæˆå€™é€‰1åºåˆ—
2. è®¡ç®—æ”¯æŒåº¦ï¼Œç­›é€‰é¢‘ç¹åºåˆ—
3. ç”Ÿæˆå€™é€‰kåºåˆ—
4. é‡å¤æ­¥éª¤2-3ç›´åˆ°æ— é¢‘ç¹åºåˆ—

**å®šä¹‰ 4.5** (å€™é€‰ç”Ÿæˆ)
å€™é€‰ç”Ÿæˆï¼š

$$C_k = \{S_1 \oplus S_2 : S_1, S_2 \in L_{k-1}\}$$

å…¶ä¸­ $\oplus$ æ˜¯åºåˆ—è¿æ¥æ“ä½œã€‚

**å®šä¹‰ 4.6** (åºåˆ—è¿æ¥)
åºåˆ—è¿æ¥ï¼š

$$S_1 \oplus S_2 = \langle s_1, s_2, ..., s_{n-1}, s_n \cup \{item\}\rangle$$

**å®šç† 4.2** (GSPç®—æ³•æ­£ç¡®æ€§)
GSPç®—æ³•èƒ½å¤Ÿæ‰¾åˆ°æ‰€æœ‰é¢‘ç¹åºåˆ—æ¨¡å¼ã€‚

### 4.3 æ—¶é—´åºåˆ—åˆ†æ

**å®šä¹‰ 4.7** (æ—¶é—´åºåˆ—)
æ—¶é—´åºåˆ—æ˜¯æ—¶é—´ç´¢å¼•çš„æ•°æ®ï¼š

$$X(t) = \{x_1, x_2, ..., x_n\}$$

**å®šä¹‰ 4.8** (è¶‹åŠ¿åˆ†æ)
è¶‹åŠ¿åˆ†æï¼š

$$T(t) = \alpha + \beta t + \epsilon_t$$

**å®šä¹‰ 4.9** (å­£èŠ‚æ€§åˆ†æ)
å­£èŠ‚æ€§åˆ†æï¼š

$$S(t) = A \sin(\omega t + \phi)$$

**å®šç† 4.3** (æ—¶é—´åºåˆ—åˆ†è§£)
æ—¶é—´åºåˆ—å¯ä»¥åˆ†è§£ä¸ºè¶‹åŠ¿ã€å­£èŠ‚æ€§å’Œéšæœºæˆåˆ†ã€‚

## 5. å¼‚å¸¸æ£€æµ‹ç†è®º

### 5.1 å¼‚å¸¸å®šä¹‰

**å®šä¹‰ 5.1** (å¼‚å¸¸)
å¼‚å¸¸æ˜¯ä¸æ­£å¸¸æ¨¡å¼æ˜¾è‘—ä¸åŒçš„æ•°æ®ç‚¹ï¼š

$$x \text{ is anomalous} \Leftrightarrow d(x, \text{normal\_pattern}) > \text{threshold}$$

**å®šä¹‰ 5.2** (å¼‚å¸¸ç±»å‹)
å¼‚å¸¸ç±»å‹ï¼š

1. ç‚¹å¼‚å¸¸ï¼šå•ä¸ªæ•°æ®ç‚¹å¼‚å¸¸
2. ä¸Šä¸‹æ–‡å¼‚å¸¸ï¼šåœ¨ç‰¹å®šä¸Šä¸‹æ–‡ä¸­å¼‚å¸¸
3. é›†ä½“å¼‚å¸¸ï¼šä¸€ç»„æ•°æ®ç‚¹å¼‚å¸¸

**å®šä¹‰ 5.3** (å¼‚å¸¸åˆ†æ•°)
å¼‚å¸¸åˆ†æ•°ï¼š

$$s(x) = f(d(x, \text{normal\_pattern}))$$

**å®šç† 5.1** (å¼‚å¸¸æ£€æµ‹æ€§è´¨)
å¼‚å¸¸æ£€æµ‹æ˜¯åŠç›‘ç£å­¦ä¹ é—®é¢˜ã€‚

**è¯æ˜**ï¼š

```lean
-- å¼‚å¸¸å®šä¹‰
def anomaly (x : vector) (normal_pattern : set vector) (threshold : â„) : Prop :=
min_distance x normal_pattern > threshold

-- å¼‚å¸¸ç±»å‹
inductive anomaly_type :=
| point_anomaly : vector â†’ anomaly_type
| contextual_anomaly : vector â†’ context â†’ anomaly_type
| collective_anomaly : list vector â†’ anomaly_type

-- å¼‚å¸¸åˆ†æ•°
def anomaly_score (x : vector) (model : anomaly_detector) : â„ :=
model.score x

-- åŠç›‘ç£æ€§è´¨
theorem anomaly_detection_semi_supervised :
  âˆ€ (D : dataset) (anomalies : list vector),
  semi_supervised_learning D anomalies
```

### 5.2 ç»Ÿè®¡å¼‚å¸¸æ£€æµ‹

**å®šä¹‰ 5.4** (Z-score)
Z-scoreï¼š

$$z(x) = \frac{x - \mu}{\sigma}$$

**å®šä¹‰ 5.5** (IQRæ–¹æ³•)
IQRæ–¹æ³•ï¼š

$$x \text{ is anomalous} \Leftrightarrow x < Q_1 - 1.5 \times IQR \text{ or } x > Q_3 + 1.5 \times IQR$$

**å®šä¹‰ 5.6** (é©¬æ°è·ç¦»)
é©¬æ°è·ç¦»ï¼š

$$d_M(x, \mu) = \sqrt{(x - \mu)^T \Sigma^{-1} (x - \mu)}$$

**å®šç† 5.2** (ç»Ÿè®¡å¼‚å¸¸æ£€æµ‹æ€§è´¨)
ç»Ÿè®¡æ–¹æ³•å‡è®¾æ•°æ®æœä»ç‰¹å®šåˆ†å¸ƒã€‚

### 5.3 æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹

**å®šä¹‰ 5.7** (éš”ç¦»æ£®æ—)
éš”ç¦»æ£®æ—ä½¿ç”¨éšæœºåˆ†å‰²ï¼š

$$h(x) = \text{path length in isolation tree}$$

**å®šä¹‰ 5.8** (å±€éƒ¨å¼‚å¸¸å› å­)
å±€éƒ¨å¼‚å¸¸å› å­ï¼š

$$\text{LOF}(x) = \frac{\text{avg LRD of neighbors}}{\text{LRD}(x)}$$

**å®šä¹‰ 5.9** (è‡ªç¼–ç å™¨)
è‡ªç¼–ç å™¨é‡æ„è¯¯å·®ï¼š

$$\text{anomaly score} = ||x - \text{decoder}(\text{encoder}(x))||$$

**å®šç† 5.3** (æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹ä¼˜åŠ¿)
æœºå™¨å­¦ä¹ æ–¹æ³•èƒ½å¤Ÿå­¦ä¹ å¤æ‚çš„æ•°æ®åˆ†å¸ƒã€‚

## 6. é¢‘ç¹æ¨¡å¼æŒ–æ˜

### 6.1 é¢‘ç¹é¡¹é›†

**å®šä¹‰ 6.1** (é¢‘ç¹é¡¹é›†)
é¢‘ç¹é¡¹é›†æ˜¯æ”¯æŒåº¦è¶…è¿‡é˜ˆå€¼çš„é¡¹é›†ï¼š

$$\text{support}(X) \geq \text{min\_support}$$

**å®šä¹‰ 6.2** (æœ€å¤§é¢‘ç¹é¡¹é›†)
æœ€å¤§é¢‘ç¹é¡¹é›†æ˜¯é¢‘ç¹é¡¹é›†ï¼Œå…¶æ‰€æœ‰è¶…é›†éƒ½ä¸æ˜¯é¢‘ç¹çš„ã€‚

**å®šä¹‰ 6.3** (é—­é¢‘ç¹é¡¹é›†)
é—­é¢‘ç¹é¡¹é›†æ˜¯é¢‘ç¹é¡¹é›†ï¼Œå…¶æ‰€æœ‰è¶…é›†çš„æ”¯æŒåº¦éƒ½å°äºå®ƒã€‚

**å®šç† 6.1** (é¢‘ç¹é¡¹é›†æ€§è´¨)
é¢‘ç¹é¡¹é›†æ»¡è¶³åå•è°ƒæ€§ã€‚

**è¯æ˜**ï¼š

```lean
-- é¢‘ç¹é¡¹é›†å®šä¹‰
def frequent_itemset (X : set item) (D : list transaction) (min_support : â„) : Prop :=
support X D â‰¥ min_support

-- æœ€å¤§é¢‘ç¹é¡¹é›†
def maximal_frequent_itemset (X : set item) (D : list transaction) (min_support : â„) : Prop :=
frequent_itemset X D min_support âˆ§
âˆ€ (Y : set item), X âŠ‚ Y â†’ Â¬ frequent_itemset Y D min_support

-- é—­é¢‘ç¹é¡¹é›†
def closed_frequent_itemset (X : set item) (D : list transaction) (min_support : â„) : Prop :=
frequent_itemset X D min_support âˆ§
âˆ€ (Y : set item), X âŠ‚ Y â†’ support Y D < support X D

-- åå•è°ƒæ€§
theorem frequent_itemset_antimonotonicity :
  âˆ€ (X Y : set item) (D : list transaction) (min_support : â„),
  X âŠ† Y â†’ frequent_itemset Y D min_support â†’ frequent_itemset X D min_support
```

### 6.2 FP-Growthç®—æ³•

**å®šä¹‰ 6.4** (FPæ ‘)
FPæ ‘æ˜¯å‹ç¼©çš„é¢‘ç¹æ¨¡å¼æ ‘ï¼š

$$T = (V, E, \text{count})$$

å…¶ä¸­æ¯ä¸ªèŠ‚ç‚¹å­˜å‚¨é¡¹å’Œè®¡æ•°ã€‚

**å®šä¹‰ 6.5** (æ¡ä»¶æ¨¡å¼åŸº)
æ¡ä»¶æ¨¡å¼åŸºï¼š

$$B_p = \{(prefix, count) : p \text{ in prefix}\}$$

**å®šä¹‰ 6.6** (æ¡ä»¶FPæ ‘)
æ¡ä»¶FPæ ‘ï¼š

$$T_p = \text{FP-tree}(B_p)$$

**å®šç† 6.2** (FP-Growthæ­£ç¡®æ€§)
FP-Growthç®—æ³•èƒ½å¤Ÿæ‰¾åˆ°æ‰€æœ‰é¢‘ç¹é¡¹é›†ã€‚

### 6.3 é—­é¢‘ç¹é¡¹é›†

**å®šä¹‰ 6.7** (é—­åŒ…æ“ä½œ)
é—­åŒ…æ“ä½œï¼š

$$\text{closure}(X) = \bigcap \{T \in D : X \subseteq T\}$$

**å®šä¹‰ 6.8** (é—­é¢‘ç¹é¡¹é›†æŒ–æ˜)
é—­é¢‘ç¹é¡¹é›†æŒ–æ˜ï¼š

1. ç”Ÿæˆé¢‘ç¹é¡¹é›†
2. è®¡ç®—é—­åŒ…
3. ç­›é€‰é—­é¢‘ç¹é¡¹é›†

**å®šä¹‰ 6.9** (æœ€å°ç”Ÿæˆå™¨)
æœ€å°ç”Ÿæˆå™¨ï¼š

$$X \text{ is minimal generator} \Leftrightarrow \text{closure}(X) = X \text{ and } \forall Y \subset X, \text{closure}(Y) \neq X$$

**å®šç† 6.3** (é—­é¢‘ç¹é¡¹é›†æ€§è´¨)
é—­é¢‘ç¹é¡¹é›†èƒ½å¤Ÿè¡¨ç¤ºæ‰€æœ‰é¢‘ç¹é¡¹é›†ã€‚

## 7. æ•°æ®é¢„å¤„ç†ç†è®º

### 7.1 æ•°æ®æ¸…æ´—

**å®šä¹‰ 7.1** (æ•°æ®æ¸…æ´—)
æ•°æ®æ¸…æ´—æ˜¯æ£€æµ‹å’Œä¿®æ­£æ•°æ®é”™è¯¯çš„è¿‡ç¨‹ï¼š

$$\text{clean}(D) = \{f(x) : x \in D\}$$

å…¶ä¸­ $f$ æ˜¯æ¸…æ´—å‡½æ•°ã€‚

**å®šä¹‰ 7.2** (ç¼ºå¤±å€¼å¤„ç†)
ç¼ºå¤±å€¼å¤„ç†ï¼š

1. åˆ é™¤ï¼šç§»é™¤åŒ…å«ç¼ºå¤±å€¼çš„è®°å½•
2. å¡«å……ï¼šç”¨ç»Ÿè®¡å€¼å¡«å……ç¼ºå¤±å€¼
3. æ’å€¼ï¼šç”¨æ’å€¼æ–¹æ³•å¡«å……ç¼ºå¤±å€¼

**å®šä¹‰ 7.3** (å¼‚å¸¸å€¼å¤„ç†)
å¼‚å¸¸å€¼å¤„ç†ï¼š

1. åˆ é™¤ï¼šç§»é™¤å¼‚å¸¸å€¼
2. ä¿®æ­£ï¼šç”¨åˆç†å€¼æ›¿æ¢å¼‚å¸¸å€¼
3. æ ‡è®°ï¼šå°†å¼‚å¸¸å€¼æ ‡è®°ä¸ºç‰¹æ®Šå€¼

**å®šç† 7.1** (æ•°æ®æ¸…æ´—é‡è¦æ€§)
æ•°æ®æ¸…æ´—èƒ½å¤Ÿæ˜¾è‘—æé«˜æŒ–æ˜è´¨é‡ã€‚

**è¯æ˜**ï¼š

```lean
-- æ•°æ®æ¸…æ´—å®šä¹‰
def data_cleaning (D : list record) : list record :=
map clean_function D

-- ç¼ºå¤±å€¼å¤„ç†
def missing_value_handling (D : list record) : list record :=
let strategy := choose_strategy D in
apply_strategy D strategy

-- å¼‚å¸¸å€¼å¤„ç†
def outlier_handling (D : list record) : list record :=
let outliers := detect_outliers D in
handle_outliers D outliers

-- æ¸…æ´—é‡è¦æ€§
theorem cleaning_importance :
  âˆ€ (D D' : list record),
  D' = data_cleaning D â†’
  mining_quality D' > mining_quality D
```

### 7.2 ç‰¹å¾é€‰æ‹©

**å®šä¹‰ 7.4** (ç‰¹å¾é€‰æ‹©)
ç‰¹å¾é€‰æ‹©æ˜¯é€‰æ‹©ç›¸å…³ç‰¹å¾çš„è¿‡ç¨‹ï¼š

$$F' = \text{select}(F, \text{criterion})$$

å…¶ä¸­ $F$ æ˜¯ç‰¹å¾é›†ï¼Œ$F'$ æ˜¯é€‰æ‹©çš„ç‰¹å¾ã€‚

**å®šä¹‰ 7.5** (è¿‡æ»¤æ–¹æ³•)
è¿‡æ»¤æ–¹æ³•ä½¿ç”¨ç»Ÿè®¡æŒ‡æ ‡ï¼š

$$\text{score}(f) = I(f; y)$$

å…¶ä¸­ $I$ æ˜¯äº’ä¿¡æ¯ã€‚

**å®šä¹‰ 7.6** (åŒ…è£…æ–¹æ³•)
åŒ…è£…æ–¹æ³•ä½¿ç”¨äº¤å‰éªŒè¯ï¼š

$$\text{score}(S) = \text{CV}(f_S)$$

å…¶ä¸­ $f_S$ æ˜¯ä½¿ç”¨ç‰¹å¾é›† $S$ è®­ç»ƒçš„æ¨¡å‹ã€‚

**å®šç† 7.2** (ç‰¹å¾é€‰æ‹©æ€§è´¨)
ç‰¹å¾é€‰æ‹©èƒ½å¤Ÿå‡å°‘ç»´åº¦å’Œè¿‡æ‹Ÿåˆã€‚

### 7.3 æ•°æ®å˜æ¢

**å®šä¹‰ 7.7** (æ ‡å‡†åŒ–)
æ ‡å‡†åŒ–ï¼š

$$x' = \frac{x - \mu}{\sigma}$$

**å®šä¹‰ 7.8** (å½’ä¸€åŒ–)
å½’ä¸€åŒ–ï¼š

$$x' = \frac{x - x_{min}}{x_{max} - x_{min}}$$

**å®šä¹‰ 7.9** (ç¦»æ•£åŒ–)
ç¦»æ•£åŒ–ï¼š

$$x' = \text{bin}(x, \text{bins})$$

**å®šç† 7.3** (æ•°æ®å˜æ¢æ€§è´¨)
æ•°æ®å˜æ¢èƒ½å¤Ÿæ”¹å–„ç®—æ³•æ€§èƒ½ã€‚

## 8. æŒ–æ˜ç»“æœè¯„ä¼°

### 8.1 è¯„ä¼°æŒ‡æ ‡

**å®šä¹‰ 8.1** (å‡†ç¡®ç‡)
å‡†ç¡®ç‡ï¼š

$$\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}$$

**å®šä¹‰ 8.2** (ç²¾ç¡®ç‡å’Œå¬å›ç‡)
ç²¾ç¡®ç‡ï¼š$P = \frac{TP}{TP + FP}$
å¬å›ç‡ï¼š$R = \frac{TP}{TP + FN}$

**å®šä¹‰ 8.3** (F1åˆ†æ•°)
F1åˆ†æ•°ï¼š

$$F1 = \frac{2 \times P \times R}{P + R}$$

**å®šç† 8.1** (è¯„ä¼°æŒ‡æ ‡æ€§è´¨)
ä¸åŒè¯„ä¼°æŒ‡æ ‡é€‚ç”¨äºä¸åŒåœºæ™¯ã€‚

**è¯æ˜**ï¼š

```lean
-- å‡†ç¡®ç‡
def accuracy (predictions : list bool) (labels : list bool) : â„ :=
let correct := count (Î» (p, l), p = l) (zip predictions labels) in
correct / length predictions

-- ç²¾ç¡®ç‡
def precision (predictions : list bool) (labels : list bool) : â„ :=
let tp := count (Î» (p, l), p âˆ§ l) (zip predictions labels) in
let fp := count (Î» (p, l), p âˆ§ Â¬l) (zip predictions labels) in
tp / (tp + fp)

-- å¬å›ç‡
def recall (predictions : list bool) (labels : list bool) : â„ :=
let tp := count (Î» (p, l), p âˆ§ l) (zip predictions labels) in
let fn := count (Î» (p, l), Â¬p âˆ§ l) (zip predictions labels) in
tp / (tp + fn)

-- F1åˆ†æ•°
def f1_score (predictions : list bool) (labels : list bool) : â„ :=
let p := precision predictions labels in
let r := recall predictions labels in
2 * p * r / (p + r)
```

### 8.2 äº¤å‰éªŒè¯

**å®šä¹‰ 8.4** (KæŠ˜äº¤å‰éªŒè¯)
KæŠ˜äº¤å‰éªŒè¯æ­¥éª¤ï¼š

1. å°†æ•°æ®åˆ†ä¸ºKä¸ªå­é›†
2. ä½¿ç”¨K-1ä¸ªå­é›†è®­ç»ƒï¼Œ1ä¸ªå­é›†éªŒè¯
3. é‡å¤Kæ¬¡ï¼Œæ¯æ¬¡ä½¿ç”¨ä¸åŒçš„éªŒè¯é›†
4. è®¡ç®—å¹³å‡æ€§èƒ½

**å®šä¹‰ 8.5** (ç•™ä¸€æ³•äº¤å‰éªŒè¯)
ç•™ä¸€æ³•äº¤å‰éªŒè¯æ˜¯KæŠ˜äº¤å‰éªŒè¯çš„ç‰¹ä¾‹ï¼ŒK=nã€‚

**å®šä¹‰ 8.6** (åˆ†å±‚äº¤å‰éªŒè¯)
åˆ†å±‚äº¤å‰éªŒè¯ä¿æŒç±»åˆ«æ¯”ä¾‹ï¼š

$$\frac{|S_k \cap C_i|}{|S_k|} = \frac{|C_i|}{|S|}$$

**å®šç† 8.2** (äº¤å‰éªŒè¯æ€§è´¨)
äº¤å‰éªŒè¯èƒ½å¤Ÿæ— åä¼°è®¡æ¨¡å‹æ€§èƒ½ã€‚

### 8.3 æ¨¡å‹é€‰æ‹©

**å®šä¹‰ 8.7** (AICå‡†åˆ™)
AICå‡†åˆ™ï¼š

$$\text{AIC} = 2k - 2\ln(L)$$

å…¶ä¸­ $k$ æ˜¯å‚æ•°ä¸ªæ•°ï¼Œ$L$ æ˜¯ä¼¼ç„¶å‡½æ•°ã€‚

**å®šä¹‰ 8.8** (BICå‡†åˆ™)
BICå‡†åˆ™ï¼š

$$\text{BIC} = \ln(n)k - 2\ln(L)$$

å…¶ä¸­ $n$ æ˜¯æ ·æœ¬æ•°ã€‚

**å®šä¹‰ 8.9** (äº¤å‰éªŒè¯é€‰æ‹©)
äº¤å‰éªŒè¯é€‰æ‹©ï¼š

$$\hat{f} = \arg\min_f \text{CV}(f)$$

**å®šç† 8.3** (æ¨¡å‹é€‰æ‹©æ€§è´¨)
æ¨¡å‹é€‰æ‹©èƒ½å¤Ÿå¹³è¡¡åå·®å’Œæ–¹å·®ã€‚

## ğŸ“Š æ€»ç»“

æ•°æ®æŒ–æ˜ç†è®ºæä¾›äº†ä»å¤§è§„æ¨¡æ•°æ®ä¸­å‘ç°æœ‰ç”¨æ¨¡å¼çš„æ•°å­¦æ¡†æ¶ã€‚é€šè¿‡å…³è”è§„åˆ™æŒ–æ˜ã€èšç±»åˆ†æã€åˆ†ç±»ç®—æ³•ç­‰æ–¹æ³•ï¼Œæ•°æ®æŒ–æ˜èƒ½å¤Ÿå®ç°çŸ¥è¯†å‘ç°å’Œæ¨¡å¼è¯†åˆ«ã€‚

## æ‰¹åˆ¤æ€§åˆ†æ

### ä¸»è¦ç†è®ºè§‚ç‚¹æ¢³ç†

1. **å…³è”è§„åˆ™æŒ–æ˜**ï¼šæä¾›äº†å‘ç°æ•°æ®å…³è”å…³ç³»çš„æ–¹æ³•
2. **èšç±»åˆ†æ**ï¼šå®ç°äº†æ— ç›‘ç£çš„æ•°æ®åˆ†ç»„
3. **åˆ†ç±»ç®—æ³•**ï¼šæä¾›äº†æœ‰ç›‘ç£çš„æ¨¡å¼è¯†åˆ«
4. **å¼‚å¸¸æ£€æµ‹**ï¼šå®ç°äº†å¼‚å¸¸æ¨¡å¼è¯†åˆ«

### ä¸»æµè§‚ç‚¹çš„ä¼˜ç¼ºç‚¹åˆ†æ

**ä¼˜ç‚¹**ï¼š

- èƒ½å¤Ÿä»å¤§è§„æ¨¡æ•°æ®ä¸­å‘ç°æ¨¡å¼
- å…·æœ‰å¹¿æ³›çš„åº”ç”¨ä»·å€¼
- ç†è®ºä½“ç³»å®Œæ•´

**ç¼ºç‚¹**ï¼š

- éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®
- æ¨¡å‹å¯è§£é‡Šæ€§å·®
- å®¹æ˜“è¿‡æ‹Ÿåˆ

### ä¸å…¶ä»–å­¦ç§‘çš„äº¤å‰ä¸èåˆ

- **ç»Ÿè®¡å­¦**ï¼šæä¾›ç†è®ºåŸºç¡€
- **æœºå™¨å­¦ä¹ **ï¼šæä¾›ç®—æ³•æ–¹æ³•
- **æ•°æ®åº“ç†è®º**ï¼šæä¾›æ•°æ®ç®¡ç†

### åˆ›æ–°æ€§æ‰¹åˆ¤ä¸æœªæ¥å±•æœ›

1. **æ·±åº¦å­¦ä¹ æŒ–æ˜**ï¼šåˆ©ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œæ•°æ®æŒ–æ˜
2. **å¯è§£é‡Šæ€§**ï¼šæé«˜æ¨¡å‹é€æ˜åº¦
3. **é²æ£’æ€§**ï¼šæé«˜æ¨¡å‹ç¨³å®šæ€§

### å‚è€ƒæ–‡çŒ®ä¸è¿›ä¸€æ­¥é˜…è¯»

1. Han, J., et al. (2011). Data mining: Concepts and techniques.
2. Witten, I. H., et al. (2016). Data mining: Practical machine learning tools and techniques.
3. Aggarwal, C. C. (2015). Data mining: The textbook.
