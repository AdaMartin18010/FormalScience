# 08.05 ä¼¦ç†å­¦ (Ethics)

[è¿”å›å“²å­¦ç§‘å­¦ä¸»ç›®å½•](../README.md) | [è¿”å›ä¸»ç´¢å¼•](../../00_Master_Index/00_ä¸»ç´¢å¼•-å½¢å¼ç§‘å­¦ä½“ç³».md)

**æ–‡æ¡£ç¼–å·**: 08.05-00-ETHICS  
**åˆ›å»ºæ—¶é—´**: 2025-01-02  
**æœ€åæ›´æ–°**: 2025-01-02  
**ç‰ˆæœ¬**: 1.1

---

## 08.05.0 ä¸»é¢˜æ ‘å½¢ç¼–å·ç›®å½•

- 08.05.01 [å…ƒä¼¦ç†å­¦ (Meta-Ethics)](./01_Meta_Ethics)
- 08.05.02 [è§„èŒƒä¼¦ç†å­¦ (Normative Ethics)](./02_Normative_Ethics)
- 08.05.03 [åº”ç”¨ä¼¦ç†å­¦ (Applied Ethics)](./03_Applied_Ethics)
- 08.05.04 [AIä¼¦ç†å­¦ (AI Ethics)](./04_AI_Ethics)

---

## 08.05.1 ä¸»é¢˜åˆ†å±‚ç»“æ„ä¸å¯¼èˆª

- [è¿”å›å“²å­¦ç§‘å­¦ä¸»ç›®å½•](../README.md)
- [è¿”å›ä¸»ç´¢å¼•](../../00_Master_Index/00_ä¸»ç´¢å¼•-å½¢å¼ç§‘å­¦ä½“ç³».md)
- [è·³è½¬ï¼šæ¦‚è¿°](#æ¦‚è¿°)
- [è·³è½¬ï¼šæ ¸å¿ƒç›®æ ‡](#æ ¸å¿ƒç›®æ ‡)
- [è·³è½¬ï¼šç›®å½•ç»“æ„](#ç›®å½•ç»“æ„)
- [è·³è½¬ï¼šé¢†åŸŸé›†æˆ](#ä¸å…¶ä»–é¢†åŸŸçš„é›†æˆ)
- [è·³è½¬ï¼šå½¢å¼åˆ†æå·¥å…·](#å½¢å¼åˆ†æå·¥å…·)
- [è·³è½¬ï¼šè®¡ç®—å®ç°](#è®¡ç®—å®ç°)

---

## 08.05.2 äº¤å‰å¼•ç”¨ç¤ºä¾‹

- [08.05.01 å…ƒä¼¦ç†å­¦](./01_Meta_Ethics) â†” [08.02.01 è®¤è¯†è®ºåŸºç¡€](../02_Epistemology/01_Epistemological_Foundations.md)
- [08.05.02 è§„èŒƒä¼¦ç†å­¦](./02_Normative_Ethics) â†” [08.01.01 æœ¬ä½“è®ºåŸºç¡€](../01_Metaphysics/01_Ontological_Foundations.md)
- [08.05.04 AIä¼¦ç†å­¦](./04_AI_Ethics) â†” [13.01.01 äººå·¥æ™ºèƒ½åŸºç¡€](../../13_Artificial_Intelligence_Theory/01_AI_Foundations.md)

---

# ä»¥ä¸‹ä¸ºåŸæœ‰å†…å®¹ï¼ˆä¿ç•™ï¼‰

## ğŸ“‹ æ¦‚è¿°

ä¼¦ç†å­¦æ˜¯å“²å­¦çš„åˆ†æ”¯ï¼Œç ”ç©¶é“å¾·è¡Œä¸ºã€ä»·å€¼è§‚ã€å–„æ¶åˆ¤æ–­çš„åŸºç¡€å’Œç†è®ºæ¡†æ¶ã€‚å®ƒæ¢è®¨ä»€ä¹ˆæ˜¯æ­£ç¡®çš„è¡Œä¸ºï¼Œä»€ä¹ˆæ˜¯å¥½çš„ç”Ÿæ´»ï¼Œä»¥åŠäººç±»åº”è¯¥å¦‚ä½•è¡ŒåŠ¨çš„è§„èŒƒæ€§é—®é¢˜ã€‚æœ¬ç›®å½•é‡‡ç”¨å½¢å¼ç§‘å­¦çš„æ–¹æ³•ç ”ç©¶ä¼¦ç†å­¦ï¼Œå»ºç«‹ä¸¥æ ¼çš„ä¼¦ç†ç†è®ºæ¡†æ¶ï¼Œå¹¶é€šè¿‡å½¢å¼è¯­è¨€è¡¨è¾¾é“å¾·è§„èŒƒä¸æ¨ç†ã€‚

æœ¬éƒ¨åˆ†åŒ…å«è§„èŒƒä¼¦ç†å­¦ã€å…ƒä¼¦ç†å­¦ã€åº”ç”¨ä¼¦ç†å­¦å’ŒAIä¼¦ç†å­¦çš„ç³»ç»ŸåŒ–å¤„ç†ï¼Œä¸ºä¼¦ç†å­¦ç ”ç©¶æä¾›æ•°å­¦åŒ–å’Œè®¡ç®—åŒ–çš„åŸºç¡€ã€‚

## ğŸ¯ æ ¸å¿ƒç›®æ ‡

1. **æ¦‚å¿µæ¸…æ™°åŒ–**ï¼šä¸ºä¼¦ç†å­¦å…³é”®æ¦‚å¿µå»ºç«‹ç²¾ç¡®çš„å½¢å¼åŒ–è¡¨è¿°
2. **ä¼¦ç†ç†è®ºå½¢å¼åŒ–**ï¼šå°†ä¸»è¦ä¼¦ç†ç†è®ºè½¬åŒ–ä¸ºå½¢å¼ç³»ç»Ÿ
3. **é“å¾·æ¨ç†æ¨¡å‹**ï¼šå»ºç«‹ç»“æ„åŒ–çš„é“å¾·æ¨ç†å’Œå†³ç­–æ¡†æ¶
4. **ä¼¦ç†ç†è®ºè¯„ä¼°**ï¼šæä¾›æ¯”è¾ƒä¸åŒä¼¦ç†ç†è®ºçš„å½¢å¼åŒ–æ ‡å‡†
5. **æ•´åˆåº”ç”¨**ï¼šå°†ä¼¦ç†å­¦å½¢å¼åŒ–ä¸æŠ€æœ¯å‘å±•å’ŒAIç³»ç»Ÿè®¾è®¡ç›¸ç»“åˆ

## ğŸ“š ç›®å½•ç»“æ„

ä¼¦ç†å­¦éƒ¨åˆ†æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç»„ç»‡ï¼š

1. **[å…ƒä¼¦ç†å­¦ (Meta-Ethics)](./01_Meta_Ethics/)**: ç ”ç©¶ä¼¦ç†å­¦çš„å…ƒç†è®ºé—®é¢˜ï¼Œå¦‚é“å¾·å®åœ¨è®ºã€è®¤è¯†è®ºå’Œè¯­ä¹‰å­¦ã€‚

2. **[è§„èŒƒä¼¦ç†å­¦ (Normative Ethics)](./02_Normative_Ethics/)**: ç ”ç©¶é“å¾·è§„èŒƒå’ŒåŸåˆ™çš„ç†è®ºï¼Œå¦‚åŠŸåˆ©ä¸»ä¹‰ã€ä¹‰åŠ¡è®ºå’Œå¾·æ€§ä¼¦ç†å­¦çš„å½¢å¼åŒ–ã€‚

3. **[åº”ç”¨ä¼¦ç†å­¦ (Applied Ethics)](./03_Applied_Ethics/)**: åˆ†æç‰¹å®šé¢†åŸŸçš„ä¼¦ç†é—®é¢˜ã€‚

4. **[AIä¼¦ç†å­¦ (AI Ethics)](./04_AI_Ethics/)**: æ¢è®¨äººå·¥æ™ºèƒ½å’Œæ™ºèƒ½ç³»ç»Ÿçš„ä¼¦ç†é—®é¢˜ï¼Œå¦‚æœºå™¨ä¼¦ç†å’ŒAIä¼¦ç†åŸåˆ™ã€‚

## ğŸ”„ ä¸å…¶ä»–é¢†åŸŸçš„é›†æˆ

ä¼¦ç†å­¦ä½œä¸ºæ¡¥æ¢è¿æ¥ä»¥ä¸‹é¢†åŸŸï¼š

- **è®¤è¯†è®º**ï¼šé“å¾·è®¤çŸ¥å’Œé“å¾·çŸ¥è¯†çš„æœ¬è´¨
- **å½¢è€Œä¸Šå­¦**ï¼šé“å¾·ç°å®çš„æœ¬ä½“è®ºåœ°ä½
- **è¯­è¨€å“²å­¦**ï¼šé“å¾·è¯­è¨€çš„è¯­ä¹‰å’Œè¯­ç”¨åˆ†æ
- **å¿ƒçµå“²å­¦**ï¼šé“å¾·å¿ƒç†å­¦å’Œé“å¾·åŠ¨æœº
- **ç§‘å­¦å“²å­¦**ï¼šç§‘å­¦å®è·µçš„ä¼¦ç†ç»´åº¦
- **è®¡ç®—ç§‘å­¦**ï¼šä¼¦ç†æ¨ç†çš„è®¡ç®—æ¨¡å‹

## ğŸ” å½¢å¼åˆ†æå·¥å…·

ä¼¦ç†å­¦ç ”ç©¶é‡‡ç”¨ä»¥ä¸‹å½¢å¼åŒ–å·¥å…·ï¼š

1. **é“å¾·ç³»ç»Ÿå½¢å¼åŒ–**ï¼š$Ethics = \langle P, V, R, A, C \rangle$ å…¶ä¸­ï¼š
   - $P$ è¡¨ç¤ºé“å¾·åŸåˆ™é›†åˆ
   - $V$ è¡¨ç¤ºé“å¾·ä»·å€¼é›†åˆ
   - $R$ è¡¨ç¤ºé“å¾·æ¨ç†è§„åˆ™
   - $A$ è¡¨ç¤ºè¡Œä¸ºé›†åˆ
   - $C$ è¡¨ç¤ºè¡Œä¸ºç»“æœé›†åˆ

2. **é“å¾·ç†è®ºç»“æ„**ï¼š$Theory = \langle Core, Derived, Applications \rangle$ å…¶ä¸­ï¼š
   - $Core$ è¡¨ç¤ºæ ¸å¿ƒé“å¾·å…¬ç†
   - $Derived$ è¡¨ç¤ºæ´¾ç”Ÿçš„é“å¾·åŸåˆ™
   - $Applications$ è¡¨ç¤ºå…·ä½“åº”ç”¨æŒ‡å¯¼

3. **é“å¾·è¯„ä»·å‡½æ•°**ï¼š$Moral: A \times C \times P \rightarrow V$ å…¶ä¸­ï¼š
   - $A$ è¡¨ç¤ºè¡Œä¸ºåŸŸ
   - $C$ è¡¨ç¤ºæƒ…å¢ƒåŸŸ
   - $P$ è¡¨ç¤ºä¸»ä½“åŸŸ
   - $V$ è¡¨ç¤ºé“å¾·ä»·å€¼åŸŸ

4. **ç†è®ºæ¯”è¾ƒæŒ‡æ ‡**ï¼š$Better(T_1, T_2) \iff Metrics(T_1) > Metrics(T_2)$ å…¶ä¸­æŒ‡æ ‡åŒ…æ‹¬ï¼š
   - ä¸€è‡´æ€§
   - æ™®éæ€§
   - è§£é‡ŠåŠ›
   - å®ç”¨æ€§
   - ç›´è§‰ç¬¦åˆåº¦

## ğŸ’» è®¡ç®—å®ç°

ä¼¦ç†å­¦çš„å„ä¸ªæ–¹é¢éƒ½é…æœ‰ç›¸åº”çš„è®¡ç®—æ¨¡å‹ï¼š

```rust
// ç¤ºä¾‹ï¼šä¼¦ç†ç†è®ºè¯„ä¼°æ¡†æ¶
pub struct EthicalTheory {
    name: String,
    core_principles: Vec<MoralPrinciple>,
    derived_rules: Vec<MoralRule>,
    value_weights: HashMap<Value, f64>,
}

impl EthicalTheory {
    pub fn evaluate_action(&self, action: &Action, context: &Context) -> MoralEvaluation {
        // è®¡ç®—è¡Œä¸ºçš„é“å¾·è¯„ä»·
        let mut evaluation = 0.0;
        
        for principle in &self.core_principles {
            let principle_score = principle.apply_to(action, context);
            let principle_weight = self.get_principle_weight(principle);
            evaluation += principle_score * principle_weight;
        }
        
        MoralEvaluation {
            value: evaluation,
            classification: self.classify_evaluation(evaluation),
            justification: self.generate_justification(action, context, evaluation),
        }
    }
    
    pub fn consistency_score(&self) -> f64 {
        // è®¡ç®—ç†è®ºçš„å†…éƒ¨ä¸€è‡´æ€§
        let cases = generate_test_cases();
        let evaluations = cases.iter()
            .map(|(action, context)| self.evaluate_action(action, context))
            .collect::<Vec<_>>();
        
        calculate_consistency(&evaluations)
    }
    
    pub fn universality_score(&self) -> f64 {
        // è®¡ç®—ç†è®ºçš„æ™®éé€‚ç”¨æ€§
        let diverse_contexts = generate_diverse_contexts();
        let adaptability_scores = diverse_contexts.iter()
            .map(|context| self.adaptability_in_context(context))
            .collect::<Vec<_>>();
        
        calculate_average(&adaptability_scores)
    }
    
    pub fn compare_with(&self, other: &EthicalTheory) -> TheoryComparison {
        // æ¯”è¾ƒä¸å…¶ä»–ç†è®ºçš„å·®å¼‚
        TheoryComparison {
            consistency_diff: self.consistency_score() - other.consistency_score(),
            universality_diff: self.universality_score() - other.universality_score(),
            intuition_alignment_diff: self.intuition_alignment() - other.intuition_alignment(),
        }
    }
}
```

## ğŸ“š ä¸»è¦å‚è€ƒæ–‡çŒ®

1. Kant, I. (1785). *Groundwork for the Metaphysics of Morals*
2. Mill, J. S. (1863). *Utilitarianism*
3. Aristotle. (c. 350 BCE). *Nicomachean Ethics*
4. Hare, R. M. (1952). *The Language of Morals*
5. Rawls, J. (1971). *A Theory of Justice*
6. MacIntyre, A. (1981). *After Virtue*
7. Singer, P. (1979). *Practical Ethics*
8. Floridi, L. & Sanders, J. W. (2004). *On the Morality of Artificial Agents*
9. Gert, B. (2004). *Common Morality: Deciding What to Do*
10. Wallach, W. & Allen, C. (2009). *Moral Machines: Teaching Robots Right from Wrong*

## ğŸ”— äº¤å‰å¼•ç”¨

- [è®¤è¯†è®º](../02_Epistemology/README.md) - é“å¾·çŸ¥è¯†å’Œé“å¾·è®¤è¯†è®º
- [æ–¹æ³•è®º](../03_Methodology/README.md) - ä¼¦ç†ç ”ç©¶æ–¹æ³•
- [ç§‘å­¦å“²å­¦](../04_Philosophy_of_Science/README.md) - ç§‘å­¦ç ”ç©¶çš„ä¼¦ç†ç»´åº¦
