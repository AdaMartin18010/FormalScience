# 05.2.2 最优控制理论

## 📋 概述

最优控制理论是现代控制理论的核心分支，研究如何设计控制律使得系统性能指标达到最优。最优控制理论为复杂系统的控制设计提供了严格的数学基础，广泛应用于航空航天、机器人、经济系统等领域。

## 🎯 核心目标

1. **性能指标优化**：最小化或最大化特定的性能指标
2. **约束条件处理**：在系统约束下寻找最优解
3. **动态优化**：处理时变系统的优化问题
4. **数值算法**：提供有效的数值求解方法

## 📚 目录

- [05.2.2 最优控制理论](#0522-最优控制理论)
  - [📋 概述](#-概述)
  - [🎯 核心目标](#-核心目标)
  - [📚 目录](#-目录)
  - [1. 基本概念](#1-基本概念)
    - [1.1 最优控制问题](#11-最优控制问题)
    - [1.2 性能指标分类](#12-性能指标分类)
    - [1.3 最优性条件](#13-最优性条件)
  - [2. 变分法基础](#2-变分法基础)
    - [2.1 欧拉-拉格朗日方程](#21-欧拉-拉格朗日方程)
    - [2.2 横截条件](#22-横截条件)
    - [2.3 约束变分法](#23-约束变分法)
  - [3. 极大值原理](#3-极大值原理)
    - [3.1 庞特里亚金极大值原理](#31-庞特里亚金极大值原理)
    - [3.2 横截条件](#32-横截条件)
    - [3.3 极大值原理的应用](#33-极大值原理的应用)
  - [4. 动态规划](#4-动态规划)
    - [4.1 贝尔曼最优性原理](#41-贝尔曼最优性原理)
    - [4.2 哈密顿-雅可比-贝尔曼方程](#42-哈密顿-雅可比-贝尔曼方程)
    - [4.3 线性二次型问题的解](#43-线性二次型问题的解)
  - [5. 线性二次型问题](#5-线性二次型问题)
    - [5.1 有限时间LQ问题](#51-有限时间lq问题)
    - [5.2 无限时间LQ问题](#52-无限时间lq问题)
    - [5.3 跟踪问题](#53-跟踪问题)
  - [6. 数值方法](#6-数值方法)
    - [6.1 梯度法](#61-梯度法)
    - [6.2 共轭梯度法](#62-共轭梯度法)
    - [6.3 直接法](#63-直接法)
  - [7. 代码实现](#7-代码实现)
    - [7.1 最优控制问题框架](#71-最优控制问题框架)
    - [7.2 线性二次型问题求解器](#72-线性二次型问题求解器)
    - [7.3 动态规划求解器](#73-动态规划求解器)
  - [8. 应用示例](#8-应用示例)
    - [8.1 倒立摆最优控制](#81-倒立摆最优控制)
    - [8.2 时间最优控制](#82-时间最优控制)
  - [9. 相关理论](#9-相关理论)
    - [9.1 与变分法的关系](#91-与变分法的关系)
    - [9.2 与动态规划的关系](#92-与动态规划的关系)
    - [9.3 与鲁棒控制的关系](#93-与鲁棒控制的关系)
  - [10. 参考文献](#10-参考文献)
  - [批判性分析](#批判性分析)
    - [多元理论视角](#多元理论视角)
    - [局限性分析](#局限性分析)
    - [争议与分歧](#争议与分歧)
    - [应用前景](#应用前景)
    - [改进建议](#改进建议)

## 1. 基本概念

### 1.1 最优控制问题

**定义 1.1.1** (最优控制问题)
最优控制问题定义为：

$$\min_{u(t)} J = \int_{t_0}^{t_f} L(x(t), u(t), t)dt + \phi(x(t_f), t_f)$$

约束条件：
$$
\begin{align}
\dot{x}(t) &= f(x(t), u(t), t) \\
x(t_0) &= x_0 \\
u(t) &\in U(t)
\end{align}
$$

其中：

- $J$ 是性能指标
- $L$ 是拉格朗日函数
- $\phi$ 是终端代价函数
- $U(t)$ 是控制约束集

### 1.2 性能指标分类

**定义 1.2.1** (性能指标类型)

1. **拉格朗日型**：$J = \int_{t_0}^{t_f} L(x(t), u(t), t)dt$
2. **迈耶型**：$J = \phi(x(t_f), t_f)$
3. **波尔扎型**：$J = \int_{t_0}^{t_f} L(x(t), u(t), t)dt + \phi(x(t_f), t_f)$

### 1.3 最优性条件

**定义 1.3.1** (最优性)
控制 $u^*(t)$ 是最优的，如果对于所有允许的控制 $u(t)$，都有：

$$J(u^*) \leq J(u)$$

## 2. 变分法基础

### 2.1 欧拉-拉格朗日方程

**定理 2.1.1** (欧拉-拉格朗日方程)
对于泛函：

$$J = \int_{t_0}^{t_f} L(x(t), \dot{x}(t), t)dt$$

其极值条件为：

$$\frac{\partial L}{\partial x} - \frac{d}{dt}\frac{\partial L}{\partial \dot{x}} = 0$$

**证明**：
设 $x^*(t)$ 是极值函数，$\eta(t)$ 是任意变分函数，满足 $\eta(t_0) = \eta(t_f) = 0$。
定义 $x(t, \alpha) = x^*(t) + \alpha\eta(t)$，则：

$$J(\alpha) = \int_{t_0}^{t_f} L(x(t, \alpha), \dot{x}(t, \alpha), t)dt$$

极值条件为 $\frac{dJ}{d\alpha}\big|_{\alpha=0} = 0$，即：

$$\int_{t_0}^{t_f} \left(\frac{\partial L}{\partial x}\eta + \frac{\partial L}{\partial \dot{x}}\dot{\eta}\right)dt = 0$$

使用分部积分：

$$\int_{t_0}^{t_f} \frac{\partial L}{\partial \dot{x}}\dot{\eta}dt = \frac{\partial L}{\partial \dot{x}}\eta\big|_{t_0}^{t_f} - \int_{t_0}^{t_f} \frac{d}{dt}\frac{\partial L}{\partial \dot{x}}\eta dt$$

由于 $\eta(t_0) = \eta(t_f) = 0$，得到：

$$\int_{t_0}^{t_f} \left(\frac{\partial L}{\partial x} - \frac{d}{dt}\frac{\partial L}{\partial \dot{x}}\right)\eta dt = 0$$

由于 $\eta(t)$ 是任意的，因此：

$$\frac{\partial L}{\partial x} - \frac{d}{dt}\frac{\partial L}{\partial \dot{x}} = 0$$

### 2.2 横截条件

**定理 2.2.1** (横截条件)
如果终端状态 $x(t_f)$ 是自由的，则横截条件为：

$$\frac{\partial L}{\partial \dot{x}}\big|_{t=t_f} = 0$$

如果终端时间 $t_f$ 是自由的，则横截条件为：

$$L - \frac{\partial L}{\partial \dot{x}}\dot{x}\big|_{t=t_f} = 0$$

### 2.3 约束变分法

**定理 2.3.1** (约束变分法)
对于带约束的变分问题：

$$\min J = \int_{t_0}^{t_f} L(x(t), \dot{x}(t), t)dt$$

约束条件：
$$g(x(t), \dot{x}(t), t) = 0$$

极值条件为：

$$\frac{\partial L}{\partial x} - \frac{d}{dt}\frac{\partial L}{\partial \dot{x}} + \lambda(t)\left(\frac{\partial g}{\partial x} - \frac{d}{dt}\frac{\partial g}{\partial \dot{x}}\right) = 0$$

其中 $\lambda(t)$ 是拉格朗日乘子。

## 3. 极大值原理

### 3.1 庞特里亚金极大值原理

**定理 3.1.1** (庞特里亚金极大值原理)
对于最优控制问题：

$$\min_{u(t)} J = \int_{t_0}^{t_f} L(x(t), u(t), t)dt + \phi(x(t_f), t_f)$$

约束条件：
$$\dot{x}(t) = f(x(t), u(t), t)$$

最优控制 $u^*(t)$ 满足：

$$u^*(t) = \arg\min_{u(t) \in U(t)} H(x^*(t), u(t), \lambda^*(t), t)$$

其中哈密顿函数为：

$$H(x, u, \lambda, t) = L(x, u, t) + \lambda^T f(x, u, t)$$

协态变量 $\lambda(t)$ 满足：

$$\dot{\lambda}(t) = -\frac{\partial H}{\partial x}$$

**证明**：
使用变分法，考虑控制变分 $\delta u(t)$ 对性能指标的影响：

$$\delta J = \int_{t_0}^{t_f} \left(\frac{\partial L}{\partial x}\delta x + \frac{\partial L}{\partial u}\delta u\right)dt + \frac{\partial \phi}{\partial x}\delta x(t_f)$$

状态变分满足：

$$\delta \dot{x} = \frac{\partial f}{\partial x}\delta x + \frac{\partial f}{\partial u}\delta u$$

引入协态变量 $\lambda(t)$，定义哈密顿函数：

$$H = L + \lambda^T f$$

则：

$$\delta J = \int_{t_0}^{t_f} \left(\frac{\partial H}{\partial x}\delta x + \frac{\partial H}{\partial u}\delta u + \lambda^T\delta \dot{x} - \lambda^T\frac{\partial f}{\partial x}\delta x\right)dt + \frac{\partial \phi}{\partial x}\delta x(t_f)$$

使用分部积分：

$$\int_{t_0}^{t_f} \lambda^T\delta \dot{x} dt = \lambda^T\delta x\big|_{t_0}^{t_f} - \int_{t_0}^{t_f} \dot{\lambda}^T\delta x dt$$

因此：

$$\delta J = \int_{t_0}^{t_f} \left(\frac{\partial H}{\partial u}\delta u + \left(\frac{\partial H}{\partial x} + \dot{\lambda}^T\right)\delta x\right)dt + \left(\lambda^T + \frac{\partial \phi}{\partial x}\right)\delta x(t_f)$$

为了 $\delta J = 0$，需要：

$$\frac{\partial H}{\partial u} = 0, \quad \dot{\lambda} = -\frac{\partial H}{\partial x}, \quad \lambda(t_f) = -\frac{\partial \phi}{\partial x}$$

### 3.2 横截条件

**定理 3.2.1** (横截条件)
对于极大值原理，横截条件为：

$$\lambda(t_f) = -\frac{\partial \phi}{\partial x(t_f)}$$

如果终端状态固定，则 $\delta x(t_f) = 0$，横截条件自动满足。

### 3.3 极大值原理的应用

**例 3.3.1** (时间最优控制)
考虑时间最优控制问题：

$$\min_{u(t)} J = \int_0^{t_f} dt = t_f$$

约束条件：
$$\dot{x}(t) = f(x(t), u(t), t)$$

哈密顿函数为：
$$H = 1 + \lambda^T f$$

最优控制满足：
$$u^*(t) = \arg\min_{u(t) \in U} \lambda^T(t) f(x^*(t), u(t), t)$$

## 4. 动态规划

### 4.1 贝尔曼最优性原理

**定理 4.1.1** (贝尔曼最优性原理)
最优控制策略具有以下性质：无论初始状态和初始决策如何，剩余决策必须构成相对于由第一个决策产生的状态的最优策略。

**形式化表述**：
设 $V(x, t)$ 是从状态 $x$ 和时间 $t$ 开始的最优值函数，则：

$$V(x, t) = \min_{u(t)} \left\{L(x, u, t)dt + V(x + f(x, u, t)dt, t + dt)\right\}$$

### 4.2 哈密顿-雅可比-贝尔曼方程

**定理 4.2.1** (HJB方程)
最优值函数 $V(x, t)$ 满足偏微分方程：

$$-\frac{\partial V}{\partial t} = \min_{u \in U} \left\{L(x, u, t) + \frac{\partial V}{\partial x}f(x, u, t)\right\}$$

边界条件：
$$V(x, t_f) = \phi(x, t_f)$$

**证明**：
从贝尔曼最优性原理：

$$V(x, t) = \min_{u(t)} \left\{L(x, u, t)dt + V(x + f(x, u, t)dt, t + dt)\right\}$$

展开 $V(x + f(x, u, t)dt, t + dt)$ 到一阶：

$$V(x + f(x, u, t)dt, t + dt) = V(x, t) + \frac{\partial V}{\partial x}f(x, u, t)dt + \frac{\partial V}{\partial t}dt + o(dt)$$

代入得到：

$$V(x, t) = \min_{u(t)} \left\{L(x, u, t)dt + V(x, t) + \frac{\partial V}{\partial x}f(x, u, t)dt + \frac{\partial V}{\partial t}dt + o(dt)\right\}$$

简化得到HJB方程。

### 4.3 线性二次型问题的解

**定理 4.3.1** (LQ问题的HJB解)
对于线性二次型问题：

$$\min_{u(t)} J = \int_{t_0}^{t_f} (x^TQx + u^TRu)dt + x^T(t_f)Sx(t_f)$$

约束条件：
$$\dot{x} = Ax + Bu$$

最优值函数为：
$$V(x, t) = x^TP(t)x$$

其中 $P(t)$ 满足黎卡提微分方程：

$$-\dot{P} = A^TP + PA - PBR^{-1}B^TP + Q$$

边界条件：
$$P(t_f) = S$$

最优控制为：
$$u^*(t) = -R^{-1}B^TP(t)x(t)$$

## 5. 线性二次型问题

### 5.1 有限时间LQ问题

**定义 5.1.1** (有限时间LQ问题)
有限时间线性二次型问题定义为：

$$\min_{u(t)} J = \int_{t_0}^{t_f} (x^T(t)Q(t)x(t) + u^T(t)R(t)u(t))dt + x^T(t_f)Sx(t_f)$$

约束条件：
$$\dot{x}(t) = A(t)x(t) + B(t)u(t)$$

**定理 5.1.1** (LQ问题解)
LQ问题的最优控制为：

$$u^*(t) = -R^{-1}(t)B^T(t)P(t)x(t)$$

其中 $P(t)$ 是黎卡提微分方程的解：

$$-\dot{P}(t) = A^T(t)P(t) + P(t)A(t) - P(t)B(t)R^{-1}(t)B^T(t)P(t) + Q(t)$$

边界条件：
$$P(t_f) = S$$

### 5.2 无限时间LQ问题

**定义 5.2.1** (无限时间LQ问题)
无限时间线性二次型问题定义为：

$$\min_{u(t)} J = \int_{0}^{\infty} (x^T(t)Qx(t) + u^T(t)Ru(t))dt$$

约束条件：
$$\dot{x}(t) = Ax(t) + Bu(t)$$

**定理 5.2.1** (无限时间LQ问题解)
如果系统 $(A,B)$ 可控且 $(A,Q^{1/2})$ 可观，则无限时间LQ问题的最优控制为：

$$u^*(t) = -R^{-1}B^TPx(t)$$

其中 $P$ 是代数黎卡提方程的正定解：

$$A^TP + PA - PBR^{-1}B^TP + Q = 0$$

### 5.3 跟踪问题

**定义 5.3.1** (LQ跟踪问题)
LQ跟踪问题定义为：

$$\min_{u(t)} J = \int_{t_0}^{t_f} ((x(t) - r(t))^TQ(t)(x(t) - r(t)) + u^T(t)R(t)u(t))dt$$

约束条件：
$$\dot{x}(t) = A(t)x(t) + B(t)u(t)$$

**定理 5.3.1** (跟踪问题解)
跟踪问题的最优控制为：

$$u^*(t) = -R^{-1}(t)B^T(t)(P(t)x(t) - g(t))$$

其中 $P(t)$ 和 $g(t)$ 满足：

$$-\dot{P}(t) = A^T(t)P(t) + P(t)A(t) - P(t)B(t)R^{-1}(t)B^T(t)P(t) + Q(t)$$

$$-\dot{g}(t) = (A^T(t) - P(t)B(t)R^{-1}(t)B^T(t))g(t) + Q(t)r(t)$$

边界条件：
$$P(t_f) = 0, \quad g(t_f) = 0$$

## 6. 数值方法

### 6.1 梯度法

**算法 6.1.1** (梯度法)

1. 初始化控制序列 $u^{(0)}(t)$
2. 计算梯度 $\nabla J(u^{(k)})$
3. 更新控制：$u^{(k+1)}(t) = u^{(k)}(t) - \alpha \nabla J(u^{(k)})$
4. 重复步骤2-3直到收敛

### 6.2 共轭梯度法

**算法 6.2.1** (共轭梯度法)

1. 初始化 $u^{(0)}(t)$ 和搜索方向 $d^{(0)}(t) = -\nabla J(u^{(0)})$
2. 计算步长：$\alpha_k = \arg\min_{\alpha} J(u^{(k)} + \alpha d^{(k)})$
3. 更新控制：$u^{(k+1)}(t) = u^{(k)}(t) + \alpha_k d^{(k)}(t)$
4. 计算新的梯度：$\nabla J(u^{(k+1)})$
5. 更新搜索方向：$d^{(k+1)}(t) = -\nabla J(u^{(k+1)}) + \beta_k d^{(k)}(t)$
6. 重复步骤2-5直到收敛

### 6.3 直接法

**算法 6.3.1** (直接法)

1. 将连续时间问题离散化
2. 将控制序列参数化
3. 使用非线性规划求解参数优化问题

## 7. 代码实现

### 7.1 最优控制问题框架

```rust
use nalgebra::{DMatrix, DVector};
use std::f64::consts::PI;

/// 最优控制问题
pub struct OptimalControlProblem {
    pub t0: f64,
    pub tf: f64,
    pub x0: DVector<f64>,
    pub xf: Option<DVector<f64>>,
}

/// 性能指标
pub trait CostFunction {
    fn lagrangian(&self, x: &DVector<f64>, u: &DVector<f64>, t: f64) -> f64;
    fn terminal_cost(&self, x: &DVector<f64>, t: f64) -> f64;
}

/// 系统动力学
pub trait SystemDynamics {
    fn dynamics(&self, x: &DVector<f64>, u: &DVector<f64>, t: f64) -> DVector<f64>;
    fn jacobian_x(&self, x: &DVector<f64>, u: &DVector<f64>, t: f64) -> DMatrix<f64>;
    fn jacobian_u(&self, x: &DVector<f64>, u: &DVector<f64>, t: f64) -> DMatrix<f64>;
}

/// 最优控制求解器
pub struct OptimalControlSolver<C, S> {
    cost: C,
    system: S,
    problem: OptimalControlProblem,
}

impl<C: CostFunction, S: SystemDynamics> OptimalControlSolver<C, S> {
    pub fn new(cost: C, system: S, problem: OptimalControlProblem) -> Self {
        Self { cost, system, problem }
    }

    /// 使用极大值原理求解
    pub fn solve_maximum_principle(&self, dt: f64) -> (Vec<DVector<f64>>, Vec<DVector<f64>>) {
        let n_steps = ((self.problem.tf - self.problem.t0) / dt) as usize;
        let mut x = vec![self.problem.x0.clone(); n_steps + 1];
        let mut u = vec![DVector::zeros(1); n_steps];
        let mut lambda = vec![DVector::zeros(x[0].len()); n_steps + 1];

        // 初始化协态变量
        if let Some(xf) = &self.problem.xf {
            lambda[n_steps] = xf - &x[n_steps];
        }

        // 前向积分状态方程
        for k in 0..n_steps {
            let t = self.problem.t0 + k as f64 * dt;
            let uk = self.compute_optimal_control(&x[k], &lambda[k + 1], t);
            u[k] = uk.clone();

            let dx = self.system.dynamics(&x[k], &uk, t) * dt;
            x[k + 1] = &x[k] + &dx;
        }

        // 后向积分协态方程
        for k in (0..n_steps).rev() {
            let t = self.problem.t0 + k as f64 * dt;
            let dlambda = -self.system.jacobian_x(&x[k], &u[k], t).transpose() * &lambda[k + 1] * dt;
            lambda[k] = &lambda[k + 1] + &dlambda;
        }

        (x, u)
    }

    /// 计算最优控制
    fn compute_optimal_control(&self, x: &DVector<f64>, lambda: &DVector<f64>, t: f64) -> DVector<f64> {
        // 使用梯度法求解最优控制
        let mut u = DVector::zeros(1);
        let learning_rate = 0.01;

        for _ in 0..100 {
            let gradient = self.control_gradient(x, &u, lambda, t);
            u = &u - &(gradient * learning_rate);
        }

        u
    }

    /// 计算控制梯度
    fn control_gradient(&self, x: &DVector<f64>, u: &DVector<f64>, lambda: &DVector<f64>, t: f64) -> DVector<f64> {
        let dL_du = self.cost_gradient_u(x, u, t);
        let df_du = self.system.jacobian_u(x, u, t);
        dL_du + df_du.transpose() * lambda
    }

    /// 计算拉格朗日函数对控制的梯度
    fn cost_gradient_u(&self, x: &DVector<f64>, u: &DVector<f64>, t: f64) -> DVector<f64> {
        // 数值梯度
        let h = 1e-6;
        let mut gradient = DVector::zeros(u.len());

        for i in 0..u.len() {
            let mut u_plus = u.clone();
            u_plus[i] += h;
            let mut u_minus = u.clone();
            u_minus[i] -= h;

            let cost_plus = self.cost.lagrangian(x, &u_plus, t);
            let cost_minus = self.cost.lagrangian(x, &u_minus, t);

            gradient[i] = (cost_plus - cost_minus) / (2.0 * h);
        }

        gradient
    }
}
```

### 7.2 线性二次型问题求解器

```rust
/// 线性二次型问题
pub struct LQProblem {
    pub A: DMatrix<f64>,
    pub B: DMatrix<f64>,
    pub Q: DMatrix<f64>,
    pub R: DMatrix<f64>,
    pub S: DMatrix<f64>,
    pub t0: f64,
    pub tf: f64,
}

impl LQProblem {
    /// 求解有限时间LQ问题
    pub fn solve_finite_time(&self, x0: &DVector<f64>, dt: f64) -> (Vec<DVector<f64>>, Vec<DVector<f64>>) {
        let n_steps = ((self.tf - self.t0) / dt) as usize;
        let mut x = vec![x0.clone(); n_steps + 1];
        let mut u = vec![DVector::zeros(self.B.ncols()); n_steps];

        // 后向积分黎卡提方程
        let mut P = self.S.clone();
        let mut P_history = vec![P.clone(); n_steps + 1];

        for k in (0..n_steps).rev() {
            let t = self.t0 + k as f64 * dt;

            // 黎卡提微分方程
            let dP = -(self.A.transpose() * &P + &P * &self.A - &P * &self.B * &self.R.inverse() * &self.B.transpose() * &P + &self.Q) * dt;
            P = &P + &dP;
            P_history[k] = P.clone();
        }

        // 前向积分状态方程
        for k in 0..n_steps {
            let t = self.t0 + k as f64 * dt;

            // 最优控制
            let K = &self.R.inverse() * &self.B.transpose() * &P_history[k];
            u[k] = -K * &x[k];

            // 状态更新
            let dx = (&self.A * &x[k] + &self.B * &u[k]) * dt;
            x[k + 1] = &x[k] + &dx;
        }

        (x, u)
    }

    /// 求解无限时间LQ问题
    pub fn solve_infinite_time(&self, x0: &DVector<f64>) -> DMatrix<f64> {
        // 使用迭代方法求解代数黎卡提方程
        let mut P = DMatrix::identity(self.A.nrows(), self.A.nrows());
        let R_inv = self.R.inverse();

        for _ in 0..100 {
            let P_new = &self.A.transpose() * &P + &P * &self.A - &P * &self.B * &R_inv * &self.B.transpose() * &P + &self.Q;

            let diff = (&P_new - &P).norm();
            P = P_new;

            if diff < 1e-6 {
                break;
            }
        }

        P
    }
}
```

### 7.3 动态规划求解器

```rust
/// 动态规划求解器
pub struct DynamicProgrammingSolver<C, S> {
    cost: C,
    system: S,
    problem: OptimalControlProblem,
}

impl<C: CostFunction, S: SystemDynamics> DynamicProgrammingSolver<C, S> {
    pub fn new(cost: C, system: S, problem: OptimalControlProblem) -> Self {
        Self { cost, system, problem }
    }

    /// 使用动态规划求解
    pub fn solve(&self, dt: f64, dx: f64) -> (Vec<DVector<f64>>, Vec<DVector<f64>>) {
        let n_steps = ((self.problem.tf - self.problem.t0) / dt) as usize;
        let n_states = ((10.0) / dx) as usize; // 假设状态范围[-5, 5]

        // 初始化值函数
        let mut V = vec![vec![f64::INFINITY; n_states]; n_steps + 1];
        let mut policy = vec![vec![0; n_states]; n_steps];

        // 终端条件
        for i in 0..n_states {
            let x = (i as f64 - n_states as f64 / 2.0) * dx;
            let state = DVector::from_column_slice(&[x]);
            V[n_steps][i] = self.cost.terminal_cost(&state, self.problem.tf);
        }

        // 后向递归
        for k in (0..n_steps).rev() {
            let t = self.problem.t0 + k as f64 * dt;

            for i in 0..n_states {
                let x = (i as f64 - n_states as f64 / 2.0) * dx;
                let state = DVector::from_column_slice(&[x]);

                let mut min_cost = f64::INFINITY;
                let mut best_u = 0.0;

                // 搜索最优控制
                for u_idx in 0..100 {
                    let u_val = (u_idx as f64 - 50.0) * 0.1;
                    let control = DVector::from_column_slice(&[u_val]);

                    let dx = self.system.dynamics(&state, &control, t) * dt;
                    let next_state = &state + &dx;

                    let next_x = next_state[0];
                    let next_i = ((next_x / dx) + n_states as f64 / 2.0) as usize;

                    if next_i < n_states {
                        let cost = self.cost.lagrangian(&state, &control, t) * dt + V[k + 1][next_i];

                        if cost < min_cost {
                            min_cost = cost;
                            best_u = u_val;
                        }
                    }
                }

                V[k][i] = min_cost;
                policy[k][i] = best_u as i32;
            }
        }

        // 前向模拟最优轨迹
        let mut x = vec![self.problem.x0.clone(); n_steps + 1];
        let mut u = vec![DVector::zeros(1); n_steps];

        for k in 0..n_steps {
            let x_val = x[k][0];
            let i = ((x_val / dx) + n_states as f64 / 2.0) as usize;

            if i < n_states {
                u[k] = DVector::from_column_slice(&[policy[k][i] as f64]);
            }

            let t = self.problem.t0 + k as f64 * dt;
            let dx = self.system.dynamics(&x[k], &u[k], t) * dt;
            x[k + 1] = &x[k] + &dx;
        }

        (x, u)
    }
}
```

## 8. 应用示例

### 8.1 倒立摆最优控制

```rust
/// 倒立摆最优控制示例
pub fn inverted_pendulum_optimal_control() {
    // 系统参数
    let M = 0.5; // 小车质量
    let m = 0.2; // 摆杆质量
    let b = 0.1; // 摩擦系数
    let I = 0.006; // 转动惯量
    let g = 9.8; // 重力加速度
    let l = 0.3; // 摆杆长度

    // 状态空间模型
    let p = I * (M + m) + M * m * l * l;

    let A = DMatrix::from_row_slice(4, 4, &[
        0.0, 1.0, 0.0, 0.0,
        0.0, -(I + m * l * l) * b / p, m * m * g * l * l / p, 0.0,
        0.0, 0.0, 0.0, 1.0,
        0.0, -m * l * b / p, m * g * l * (M + m) / p, 0.0
    ]);

    let B = DMatrix::from_column_slice(4, 1, &[
        0.0,
        (I + m * l * l) / p,
        0.0,
        m * l / p
    ]);

    // 性能指标权重
    let Q = DMatrix::diagonal(4, &[1.0, 1.0, 10.0, 10.0]);
    let R = DMatrix::from_element(1, 1, 0.1);
    let S = DMatrix::diagonal(4, &[1.0, 1.0, 10.0, 10.0]);

    let lq_problem = LQProblem {
        A, B, Q, R, S,
        t0: 0.0,
        tf: 10.0,
    };

    // 初始状态：小车位置=0.1m，摆杆角度=0.1rad
    let x0 = DVector::from_column_slice(&[0.1, 0.0, 0.1, 0.0]);

    // 求解最优控制
    let (x, u) = lq_problem.solve_finite_time(&x0, 0.01);

    println!("倒立摆最优控制结果：");
    for (i, (state, control)) in x.iter().zip(u.iter()).enumerate() {
        if i % 100 == 0 {
            println!("t={:.1}s: 位置={:.3}m, 角度={:.3}rad, 控制={:.3}N",
                i as f64 * 0.01, state[0], state[2], control[0]);
        }
    }
}
```

### 8.2 时间最优控制

```rust
/// 时间最优控制示例
pub fn time_optimal_control_example() {
    // 双积分器系统
    let A = DMatrix::from_row_slice(2, 2, &[0.0, 1.0, 0.0, 0.0]);
    let B = DMatrix::from_column_slice(2, 1, &[0.0, 1.0]);

    // 时间最优控制问题
    struct TimeOptimalCost;

    impl CostFunction for TimeOptimalCost {
        fn lagrangian(&self, _x: &DVector<f64>, _u: &DVector<f64>, _t: f64) -> f64 {
            1.0 // 最小化时间
        }

        fn terminal_cost(&self, _x: &DVector<f64>, _t: f64) -> f64 {
            0.0
        }
    }

    struct DoubleIntegrator;

    impl SystemDynamics for DoubleIntegrator {
        fn dynamics(&self, x: &DVector<f64>, u: &DVector<f64>, _t: f64) -> DVector<f64> {
            DVector::from_column_slice(&[x[1], u[0]])
        }

        fn jacobian_x(&self, _x: &DVector<f64>, _u: &DVector<f64>, _t: f64) -> DMatrix<f64> {
            DMatrix::from_row_slice(2, 2, &[0.0, 1.0, 0.0, 0.0])
        }

        fn jacobian_u(&self, _x: &DVector<f64>, _u: &DVector<f64>, _t: f64) -> DMatrix<f64> {
            DMatrix::from_column_slice(2, 1, &[0.0, 1.0])
        }
    }

    let problem = OptimalControlProblem {
        t0: 0.0,
        tf: 5.0,
        x0: DVector::from_column_slice(&[1.0, 0.0]),
        xf: Some(DVector::from_column_slice(&[0.0, 0.0])),
    };

    let solver = OptimalControlSolver::new(TimeOptimalCost, DoubleIntegrator, problem);
    let (x, u) = solver.solve_maximum_principle(0.01);

    println!("时间最优控制结果：");
    for (i, (state, control)) in x.iter().zip(u.iter()).enumerate() {
        if i % 100 == 0 {
            println!("t={:.1}s: 位置={:.3}m, 速度={:.3}m/s, 控制={:.3}m/s²",
                i as f64 * 0.01, state[0], state[1], control[0]);
        }
    }
}
```

## 9. 相关理论

### 9.1 与变分法的关系

最优控制理论是变分法的推广：

1. **约束处理**：最优控制理论可以处理微分方程约束
2. **控制约束**：可以处理控制变量的约束条件
3. **数值方法**：提供了更有效的数值求解方法

### 9.2 与动态规划的关系

最优控制理论与动态规划密切相关：

1. **贝尔曼方程**：动态规划提供了求解最优控制问题的框架
2. **值函数**：通过值函数可以构造最优控制律
3. **数值实现**：动态规划提供了数值求解方法

### 9.3 与鲁棒控制的关系

最优控制理论为鲁棒控制提供了基础：

1. **标称设计**：基于标称模型设计最优控制器
2. **鲁棒性分析**：分析最优控制器对参数不确定性的鲁棒性
3. **鲁棒优化**：在不确定性下进行优化设计

## 10. 参考文献

1. Kirk, D. E. (2012). Optimal Control Theory: An Introduction. Dover Publications.
2. Lewis, F. L., Vrabie, D., & Syrmos, V. L. (2012). Optimal Control. John Wiley & Sons.
3. Bryson, A. E., & Ho, Y. C. (1975). Applied Optimal Control: Optimization, Estimation, and Control. Hemisphere.
4. Pontryagin, L. S., Boltyanskii, V. G., Gamkrelidze, R. V., & Mishchenko, E. F. (1962). The Mathematical Theory of Optimal Processes. Interscience.
5. Bellman, R. (1957). Dynamic Programming. Princeton University Press.
6. Bertsekas, D. P. (2017). Dynamic Programming and Optimal Control. Athena Scientific.
7. Anderson, B. D., & Moore, J. B. (1990). Optimal Control: Linear Quadratic Methods. Prentice Hall.
8. Kwakernaak, H., & Sivan, R. (1972). Linear Optimal Control Systems. Wiley-Interscience.

---

**相关文档**：

- [05.2.1 现代控制理论](05.2.1_现代控制理论.md)
- [05.2.3 鲁棒控制理论](05.2.3_鲁棒控制理论.md)
- [05.3.1 非线性控制理论](05.3.1_非线性控制理论.md)
- [05.3.2 自适应控制理论](05.3.2_自适应控制理论.md)

## 批判性分析

### 多元理论视角

**变分/极大值视角**：提供必要条件（EL/Hamiltonian/MP），理论优雅但易陷局部最优与数值不稳。

**动态规划视角**：以HJB为核心具充分性，但维度灾难限制高维应用。

**工程数值视角**：直接法/间接法、轨迹优化、SQP/内点广泛使用，收敛与全局性缺乏统一保证。

### 局限性分析

**模型依赖与稳健性**：标称最优对模型误差敏感，性能与稳定裕度可能在实际中退化。

**约束复杂性**：路径/终端/输入饱和/安全约束会显著增加求解难度与计算成本。

**实时性**：在线优化（MPC）在高维系统或硬实时场景受限于算力与可预见性。

### 争议与分歧

**必要vs充分**：MP给出必要条件，HJB提供充分条件但难解；二者在工程中的优先级与取舍常有分歧。

**全局vs局部**：是否追求全局最优还是工程上“足够好”的局部最优，领域偏好不同。

**最优vs鲁棒**：性能最优与最坏情形保证的权衡，鲁棒最优化与分布鲁棒优化的边界与成本争议大。

### 应用前景

**MPC与工业落地**：在流程、能源、化工、自动驾驶中继续扩张，重视软硬约束与经济MPC。

**轨迹优化与自主系统**：航天/机器人/物流的在线轨迹生成与再规划需求旺盛。

**数据同化与学习增强**：将强化学习/模仿学习与最优控制结合，实现可迁移的控制策略。

### 改进建议

**鲁棒-最优融合**：引入不确定性集与风险度量（CVaR/DRSO），实现性能-鲁棒协同。

**可计算性工程**：开发可预期实时性的求解器、暖启动与分布式并行计算。

**安全与保证**：结合CBF、安全约束MPC与形式化方法，提供可验证的安全最优控制。
