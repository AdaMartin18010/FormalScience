# 09.7 微架构设计理论（Microarchitecture Design Theory）

[返回计算机体系结构理论主题索引](README.md)

> 本文档系统整理微架构设计理论，包括流水线、乱序执行、缓存一致性、微操作等，严格树形编号、目录、本地跳转锚点与交叉引用，内容持续规范化中。

---

## 微架构设计理论

## 1. 形式化定义

### 1.1 微架构基础

**定义 9.1.03.1 (微架构)**
微架构 $\mu$ 是处理器内部实现，定义为：
$$\mu = (\mathcal{P}, \mathcal{C}, \mathcal{B}, \mathcal{M})$$
其中：

- $\mathcal{P}$ 是流水线结构
- $\mathcal{C}$ 是缓存层次
- $\mathcal{B}$ 是分支预测器
- $\mathcal{M}$ 是内存子系统

**定义 9.1.03.2 (流水线)**
流水线 $\mathcal{P}$ 是一个五元组：
$$\mathcal{P} = (S, R, H, D, W)$$
其中：

- $S$ 是流水线级数
- $R$ 是流水线寄存器
- $H$ 是冒险检测
- $D$ 是数据通路
- $W$ 是写回单元

**定义 9.1.03.3 (缓存层次)**
缓存层次 $\mathcal{C}$ 是一个偏序集：
$$\mathcal{C} = (L, \prec, \text{size}, \text{latency})$$
其中 $L$ 是缓存级别，$\prec$ 表示包含关系。

### 1.2 性能模型

**定义 9.1.03.4 (CPI模型)**
每条指令平均周期数：
$$\text{CPI} = \text{CPI}_{\text{ideal}} + \text{CPI}_{\text{stall}} + \text{CPI}_{\text{branch}} + \text{CPI}_{\text{cache}}$$

**定义 9.1.03.5 (流水线效率)**
流水线效率：
$$\eta = \frac{\text{Instructions}}{\text{Cycles}} = \frac{1}{\text{CPI}}$$

## 2. 核心定理

### 2.1 流水线性能定理

**定理 9.1.03.1 (流水线加速比)**
理想流水线的加速比为：
$$S = \frac{n \times T_s}{T_s + (n-1) \times T_p}$$
其中 $n$ 是流水线级数，$T_s$ 是串行执行时间，$T_p$ 是流水线周期。

**证明：**

1. 串行执行时间：$T_s = n \times T_p$
2. 流水线执行时间：$T_p + (n-1) \times T_p$
3. 加速比计算

### 2.2 分支预测定理

**定理 9.1.03.2 (分支预测准确率)**
分支预测准确率对性能的影响：
$$\text{CPI}_{\text{branch}} = \text{branch\_freq} \times (1 - \text{accuracy}) \times \text{penalty}$$

**证明：**

1. 分支频率影响
2. 预测错误导致流水线清空
3. 性能损失计算

## 3. 算法实现

### 3.1 五级流水线实现

```rust
use std::collections::HashMap;

// 流水线阶段
#[derive(Debug, Clone)]
enum PipelineStage {
    Fetch,
    Decode,
    Execute,
    Memory,
    WriteBack,
}

// 流水线寄存器
#[derive(Debug, Clone)]
struct PipelineRegister {
    instruction: Option<Instruction>,
    stage: PipelineStage,
    valid: bool,
    stall: bool,
    flush: bool,
    pc: usize,
    rs1_data: Option<i32>,
    rs2_data: Option<i32>,
    alu_result: Option<i32>,
    memory_data: Option<i32>,
}

// 五级流水线CPU
#[derive(Debug)]
struct FiveStagePipeline {
    registers: [i32; 32],
    memory: HashMap<usize, u8>,
    pc: usize,
    pipeline: Vec<PipelineRegister>,
    clock_cycles: usize,
    instructions_executed: usize,
    stalls: usize,
    flushes: usize,
}

impl FiveStagePipeline {
    fn new() -> Self {
        let mut pipeline = Vec::new();
        for _ in 0..5 {
            pipeline.push(PipelineRegister {
                instruction: None,
                stage: PipelineStage::Fetch,
                valid: false,
                stall: false,
                flush: false,
                pc: 0,
                rs1_data: None,
                rs2_data: None,
                alu_result: None,
                memory_data: None,
            });
        }
        
        Self {
            registers: [0; 32],
            memory: HashMap::new(),
            pc: 0,
            pipeline,
            clock_cycles: 0,
            instructions_executed: 0,
            stalls: 0,
            flushes: 0,
        }
    }

    // 流水线执行一个周期
    fn cycle(&mut self, program: &[Instruction]) {
        // 写回阶段
        self.write_back_stage();
        
        // 内存阶段
        self.memory_stage();
        
        // 执行阶段
        self.execute_stage();
        
        // 译码阶段
        self.decode_stage();
        
        // 取指阶段
        self.fetch_stage(program);
        
        self.clock_cycles += 1;
    }

    // 取指阶段
    fn fetch_stage(&mut self, program: &[Instruction]) {
        let fetch_reg = &mut self.pipeline[0];
        
        if !fetch_reg.stall {
            let instruction_index = self.pc / 4;
            if instruction_index < program.len() {
                fetch_reg.instruction = Some(program[instruction_index].clone());
                fetch_reg.valid = true;
                fetch_reg.stage = PipelineStage::Fetch;
                fetch_reg.pc = self.pc;
                self.pc += 4;
            } else {
                fetch_reg.valid = false;
            }
        }
    }

    // 译码阶段
    fn decode_stage(&mut self) {
        let decode_reg = &mut self.pipeline[1];
        let fetch_reg = &self.pipeline[0];
        
        if fetch_reg.valid && !fetch_reg.stall {
            decode_reg.instruction = fetch_reg.instruction.clone();
            decode_reg.valid = true;
            decode_reg.stage = PipelineStage::Decode;
            decode_reg.pc = fetch_reg.pc;
            
            // 读取寄存器值
            if let Some(instruction) = &decode_reg.instruction {
                match instruction {
                    Instruction::Add(_, rs1, rs2) |
                    Instruction::Sub(_, rs1, rs2) |
                    Instruction::Beq(rs1, rs2, _) => {
                        decode_reg.rs1_data = Some(self.registers[*rs1]);
                        decode_reg.rs2_data = Some(self.registers[*rs2]);
                    }
                    Instruction::Addi(_, rs1, _) |
                    Instruction::Lw(_, rs1, _) |
                    Instruction::Sw(_, rs1, _) => {
                        decode_reg.rs1_data = Some(self.registers[*rs1]);
                    }
                    _ => {}
                }
            }
        } else {
            decode_reg.valid = false;
        }
    }

    // 执行阶段
    fn execute_stage(&mut self) {
        let execute_reg = &mut self.pipeline[2];
        let decode_reg = &self.pipeline[1];
        
        if decode_reg.valid && !decode_reg.stall {
            execute_reg.instruction = decode_reg.instruction.clone();
            execute_reg.valid = true;
            execute_reg.stage = PipelineStage::Execute;
            execute_reg.pc = decode_reg.pc;
            execute_reg.rs1_data = decode_reg.rs1_data;
            execute_reg.rs2_data = decode_reg.rs2_data;
            
            // ALU操作
            if let Some(instruction) = &execute_reg.instruction {
                match instruction {
                    Instruction::Add(_, _, _) => {
                        if let (Some(rs1), Some(rs2)) = (execute_reg.rs1_data, execute_reg.rs2_data) {
                            execute_reg.alu_result = Some(rs1 + rs2);
                        }
                    }
                    Instruction::Sub(_, _, _) => {
                        if let (Some(rs1), Some(rs2)) = (execute_reg.rs1_data, execute_reg.rs2_data) {
                            execute_reg.alu_result = Some(rs1 - rs2);
                        }
                    }
                    Instruction::Addi(_, _, imm) => {
                        if let Some(rs1) = execute_reg.rs1_data {
                            execute_reg.alu_result = Some(rs1 + *imm);
                        }
                    }
                    Instruction::Beq(_, _, offset) => {
                        if let (Some(rs1), Some(rs2)) = (execute_reg.rs1_data, execute_reg.rs2_data) {
                            if rs1 == rs2 {
                                // 分支预测错误，需要清空流水线
                                self.flush_pipeline();
                                self.pc = (execute_reg.pc as i32 + *offset) as usize;
                                self.flushes += 1;
                            }
                        }
                    }
                    _ => {}
                }
            }
        } else {
            execute_reg.valid = false;
        }
    }

    // 内存阶段
    fn memory_stage(&mut self) {
        let memory_reg = &mut self.pipeline[3];
        let execute_reg = &self.pipeline[2];
        
        if execute_reg.valid && !execute_reg.stall {
            memory_reg.instruction = execute_reg.instruction.clone();
            memory_reg.valid = true;
            memory_reg.stage = PipelineStage::Memory;
            memory_reg.pc = execute_reg.pc;
            memory_reg.alu_result = execute_reg.alu_result;
            
            // 内存访问
            if let Some(instruction) = &memory_reg.instruction {
                match instruction {
                    Instruction::Lw(_, _, offset) => {
                        if let (Some(rs1), Some(alu_result)) = (execute_reg.rs1_data, execute_reg.alu_result) {
                            let address = (rs1 + *offset) as usize;
                            let value = self.load_word(address);
                            memory_reg.memory_data = Some(value);
                        }
                    }
                    Instruction::Sw(_, _, offset) => {
                        if let (Some(rs1), Some(rs2)) = (execute_reg.rs1_data, execute_reg.rs2_data) {
                            let address = (rs1 + *offset) as usize;
                            self.store_word(address, rs2);
                        }
                    }
                    _ => {}
                }
            }
        } else {
            memory_reg.valid = false;
        }
    }

    // 写回阶段
    fn write_back_stage(&mut self) {
        let writeback_reg = &self.pipeline[4];
        
        if writeback_reg.valid && !writeback_reg.stall {
            if let Some(instruction) = &writeback_reg.instruction {
                match instruction {
                    Instruction::Add(rd, _, _) |
                    Instruction::Sub(rd, _, _) |
                    Instruction::Addi(rd, _, _) => {
                        if let Some(alu_result) = writeback_reg.alu_result {
                            self.registers[*rd] = alu_result;
                        }
                    }
                    Instruction::Lw(rd, _, _) => {
                        if let Some(memory_data) = writeback_reg.memory_data {
                            self.registers[*rd] = memory_data;
                        }
                    }
                    _ => {}
                }
            }
            self.instructions_executed += 1;
        }
    }

    // 清空流水线
    fn flush_pipeline(&mut self) {
        for i in 0..4 {
            self.pipeline[i].flush = true;
            self.pipeline[i].valid = false;
        }
    }

    // 内存访问函数
    fn load_word(&self, address: usize) -> i32 {
        let mut value = 0u32;
        for i in 0..4 {
            let byte = self.memory.get(&(address + i)).copied().unwrap_or(0);
            value |= (byte as u32) << (i * 8);
        }
        value as i32
    }

    fn store_word(&mut self, address: usize, value: i32) {
        let value_u = value as u32;
        for i in 0..4 {
            let byte = ((value_u >> (i * 8)) & 0xFF) as u8;
            self.memory.insert(address + i, byte);
        }
    }

    // 运行程序
    fn run(&mut self, program: &[Instruction]) -> Result<(), String> {
        let max_cycles = program.len() * 10;
        
        for _ in 0..max_cycles {
            self.cycle(program);
            
            if self.instructions_executed >= program.len() {
                break;
            }
        }
        
        Ok(())
    }

    // 获取性能统计
    fn get_performance_stats(&self) -> (usize, f64, f64, f64) {
        let cpi = if self.instructions_executed > 0 {
            self.clock_cycles as f64 / self.instructions_executed as f64
        } else {
            0.0
        };
        
        let stall_rate = if self.clock_cycles > 0 {
            self.stalls as f64 / self.clock_cycles as f64
        } else {
            0.0
        };
        
        let flush_rate = if self.instructions_executed > 0 {
            self.flushes as f64 / self.instructions_executed as f64
        } else {
            0.0
        };
        
        (self.instructions_executed, cpi, stall_rate, flush_rate)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_five_stage_pipeline() {
        let mut cpu = FiveStagePipeline::new();
        
        let program = vec![
            Instruction::Addi(1, 0, 5),  // x1 = 5
            Instruction::Addi(2, 0, 3),  // x2 = 3
            Instruction::Add(3, 1, 2),   // x3 = x1 + x2
        ];
        
        cpu.run(&program).unwrap();
        let (instructions, cpi, stall_rate, flush_rate) = cpu.get_performance_stats();
        
        assert_eq!(cpu.registers[3], 8);
        assert!(cpi > 0.0);
    }
}
```

### 3.2 分支预测器实现

```rust
use std::collections::HashMap;

// 分支预测器类型
#[derive(Debug)]
enum BranchPredictor {
    StaticAlwaysTaken,
    StaticAlwaysNotTaken,
    Bimodal(usize),           // 2-bit饱和计数器
    GShare(usize, usize),     // 全局历史 + 模式历史表
    Tournament(usize, usize), // 混合预测器
}

// 2-bit饱和计数器
#[derive(Debug, Clone)]
enum SaturatingCounter {
    StronglyNotTaken = 0,
    WeaklyNotTaken = 1,
    WeaklyTaken = 2,
    StronglyTaken = 3,
}

impl SaturatingCounter {
    fn new() -> Self {
        Self::WeaklyNotTaken
    }

    fn update(&mut self, taken: bool) {
        match self {
            Self::StronglyNotTaken => {
                if taken { *self = Self::WeaklyNotTaken; }
            }
            Self::WeaklyNotTaken => {
                if taken { *self = Self::WeaklyTaken; } else { *self = Self::StronglyNotTaken; }
            }
            Self::WeaklyTaken => {
                if taken { *self = Self::StronglyTaken; } else { *self = Self::WeaklyNotTaken; }
            }
            Self::StronglyTaken => {
                if !taken { *self = Self::WeaklyTaken; }
            }
        }
    }

    fn predict(&self) -> bool {
        matches!(self, Self::WeaklyTaken | Self::StronglyTaken)
    }
}

// 分支预测器实现
struct BranchPredictorImpl {
    predictor_type: BranchPredictor,
    bimodal_table: HashMap<usize, SaturatingCounter>,
    global_history: usize,
    gshare_table: HashMap<usize, SaturatingCounter>,
    tournament_table: HashMap<usize, SaturatingCounter>,
    predictions: usize,
    correct_predictions: usize,
}

impl BranchPredictorImpl {
    fn new(predictor_type: BranchPredictor) -> Self {
        Self {
            predictor_type,
            bimodal_table: HashMap::new(),
            global_history: 0,
            gshare_table: HashMap::new(),
            tournament_table: HashMap::new(),
            predictions: 0,
            correct_predictions: 0,
        }
    }

    // 预测分支
    fn predict(&mut self, pc: usize) -> bool {
        self.predictions += 1;
        
        match &self.predictor_type {
            BranchPredictor::StaticAlwaysTaken => true,
            BranchPredictor::StaticAlwaysNotTaken => false,
            BranchPredictor::Bimodal(table_size) => {
                let index = pc % table_size;
                let counter = self.bimodal_table.entry(index).or_insert_with(SaturatingCounter::new);
                counter.predict()
            }
            BranchPredictor::GShare(history_bits, table_size) => {
                let index = (pc ^ self.global_history) % table_size;
                let counter = self.gshare_table.entry(index).or_insert_with(SaturatingCounter::new);
                counter.predict()
            }
            BranchPredictor::Tournament(selector_bits, table_size) => {
                let selector_index = pc % table_size;
                let selector = self.tournament_table.entry(selector_index).or_insert_with(SaturatingCounter::new);
                
                // 简化的混合预测：选择bimodal或gshare
                if selector.predict() {
                    // 使用gshare
                    let index = (pc ^ self.global_history) % table_size;
                    let counter = self.gshare_table.entry(index).or_insert_with(SaturatingCounter::new);
                    counter.predict()
                } else {
                    // 使用bimodal
                    let index = pc % table_size;
                    let counter = self.bimodal_table.entry(index).or_insert_with(SaturatingCounter::new);
                    counter.predict()
                }
            }
        }
    }

    // 更新预测器
    fn update(&mut self, pc: usize, taken: bool, predicted: bool) {
        if predicted == taken {
            self.correct_predictions += 1;
        }
        
        match &self.predictor_type {
            BranchPredictor::StaticAlwaysTaken |
            BranchPredictor::StaticAlwaysNotTaken => {
                // 静态预测器不需要更新
            }
            BranchPredictor::Bimodal(table_size) => {
                let index = pc % table_size;
                if let Some(counter) = self.bimodal_table.get_mut(&index) {
                    counter.update(taken);
                }
            }
            BranchPredictor::GShare(history_bits, table_size) => {
                let index = (pc ^ self.global_history) % table_size;
                if let Some(counter) = self.gshare_table.get_mut(&index) {
                    counter.update(taken);
                }
                
                // 更新全局历史
                self.global_history = ((self.global_history << 1) | (taken as usize)) & ((1 << history_bits) - 1);
            }
            BranchPredictor::Tournament(selector_bits, table_size) => {
                let selector_index = pc % table_size;
                if let Some(selector) = self.tournament_table.get_mut(&selector_index) {
                    // 更新选择器：如果gshare预测正确而bimodal错误，或相反
                    let gshare_index = (pc ^ self.global_history) % table_size;
                    let bimodal_index = pc % table_size;
                    
                    let gshare_correct = if let Some(counter) = self.gshare_table.get(&gshare_index) {
                        counter.predict() == taken
                    } else {
                        false
                    };
                    
                    let bimodal_correct = if let Some(counter) = self.bimodal_table.get(&bimodal_index) {
                        counter.predict() == taken
                    } else {
                        false
                    };
                    
                    if gshare_correct != bimodal_correct {
                        selector.update(gshare_correct);
                    }
                }
                
                // 更新gshare
                let index = (pc ^ self.global_history) % table_size;
                if let Some(counter) = self.gshare_table.get_mut(&index) {
                    counter.update(taken);
                }
                
                // 更新bimodal
                let index = pc % table_size;
                if let Some(counter) = self.bimodal_table.get_mut(&index) {
                    counter.update(taken);
                }
                
                // 更新全局历史
                self.global_history = ((self.global_history << 1) | (taken as usize)) & 0xFF;
            }
        }
    }

    // 获取预测准确率
    fn get_accuracy(&self) -> f64 {
        if self.predictions > 0 {
            self.correct_predictions as f64 / self.predictions as f64
        } else {
            0.0
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_branch_predictor() {
        let mut predictor = BranchPredictorImpl::new(BranchPredictor::Bimodal(1024));
        
        // 测试循环分支
        for _ in 0..100 {
            let predicted = predictor.predict(0x1000);
            predictor.update(0x1000, true, predicted);
        }
        
        let accuracy = predictor.get_accuracy();
        assert!(accuracy > 0.5); // 应该学习到循环模式
    }
}
```

### 3.3 缓存层次实现

```rust
use std::collections::HashMap;

// 缓存行
#[derive(Debug, Clone)]
struct CacheLine {
    tag: usize,
    data: Vec<u8>,
    valid: bool,
    dirty: bool,
    lru_counter: usize,
}

// 缓存级别
#[derive(Debug)]
struct CacheLevel {
    lines: Vec<CacheLine>,
    line_size: usize,
    num_sets: usize,
    associativity: usize,
    hits: usize,
    misses: usize,
    clock: usize,
}

impl CacheLevel {
    fn new(line_size: usize, num_sets: usize, associativity: usize) -> Self {
        let num_lines = num_sets * associativity;
        let mut lines = Vec::with_capacity(num_lines);
        
        for _ in 0..num_lines {
            lines.push(CacheLine {
                tag: 0,
                data: vec![0; line_size],
                valid: false,
                dirty: false,
                lru_counter: 0,
            });
        }
        
        Self {
            lines,
            line_size,
            num_sets,
            associativity,
            hits: 0,
            misses: 0,
            clock: 0,
        }
    }

    // 访问缓存
    fn access(&mut self, address: usize, is_write: bool) -> bool {
        let (set_index, tag) = self.address_to_index_tag(address);
        self.clock += 1;
        
        if let Some(line_index) = self.find_line(set_index, tag) {
            // 缓存命中
            self.hits += 1;
            self.lines[line_index].lru_counter = self.clock;
            if is_write {
                self.lines[line_index].dirty = true;
            }
            true
        } else {
            // 缓存未命中
            self.misses += 1;
            let victim_index = self.select_victim(set_index);
            
            // 如果被替换的行是脏的，需要写回
            if self.lines[victim_index].valid && self.lines[victim_index].dirty {
                // 这里应该写回下一级缓存或内存
            }
            
            // 加载新数据
            self.lines[victim_index].tag = tag;
            self.lines[victim_index].valid = true;
            self.lines[victim_index].dirty = is_write;
            self.lines[victim_index].lru_counter = self.clock;
            
            false
        }
    }

    fn address_to_index_tag(&self, address: usize) -> (usize, usize) {
        let set_index = (address / self.line_size) % self.num_sets;
        let tag = address / (self.line_size * self.num_sets);
        (set_index, tag)
    }

    fn find_line(&self, set_index: usize, tag: usize) -> Option<usize> {
        let start = set_index * self.associativity;
        let end = start + self.associativity;
        
        for i in start..end {
            if self.lines[i].valid && self.lines[i].tag == tag {
                return Some(i);
            }
        }
        None
    }

    fn select_victim(&self, set_index: usize) -> usize {
        let start = set_index * self.associativity;
        let end = start + self.associativity;
        
        let mut victim = start;
        let mut oldest = self.lines[start].lru_counter;
        
        for i in start..end {
            if !self.lines[i].valid {
                return i;
            }
            if self.lines[i].lru_counter < oldest {
                oldest = self.lines[i].lru_counter;
                victim = i;
            }
        }
        victim
    }

    fn get_hit_rate(&self) -> f64 {
        let total_accesses = self.hits + self.misses;
        if total_accesses > 0 {
            self.hits as f64 / total_accesses as f64
        } else {
            0.0
        }
    }
}

// 缓存层次
#[derive(Debug)]
struct CacheHierarchy {
    levels: Vec<CacheLevel>,
    memory_accesses: usize,
}

impl CacheHierarchy {
    fn new() -> Self {
        let mut levels = Vec::new();
        
        // L1数据缓存：32KB，8路组相联，64字节行
        levels.push(CacheLevel::new(64, 64, 8));
        
        // L2缓存：256KB，8路组相联，64字节行
        levels.push(CacheLevel::new(64, 512, 8));
        
        // L3缓存：8MB，16路组相联，64字节行
        levels.push(CacheLevel::new(64, 8192, 16));
        
        Self {
            levels,
            memory_accesses: 0,
        }
    }

    // 访问缓存层次
    fn access(&mut self, address: usize, is_write: bool) -> usize {
        for (level, cache) in self.levels.iter_mut().enumerate() {
            if cache.access(address, is_write) {
                return level; // 在该级别命中
            }
        }
        
        // 所有缓存都未命中，访问内存
        self.memory_accesses += 1;
        self.levels.len()
    }

    // 获取整体命中率
    fn get_overall_hit_rate(&self) -> f64 {
        let mut total_hits = 0;
        let mut total_misses = 0;
        
        for cache in &self.levels {
            total_hits += cache.hits;
            total_misses += cache.misses;
        }
        
        let total_accesses = total_hits + total_misses + self.memory_accesses;
        if total_accesses > 0 {
            total_hits as f64 / total_accesses as f64
        } else {
            0.0
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_cache_hierarchy() {
        let mut hierarchy = CacheHierarchy::new();
        
        // 测试局部性访问
        for i in 0..1000 {
            hierarchy.access(i * 64, false); // 读取
        }
        
        // 重复访问相同地址
        for _ in 0..100 {
            hierarchy.access(0, false);
        }
        
        let hit_rate = hierarchy.get_overall_hit_rate();
        assert!(hit_rate > 0.0);
    }
}
```

## 4. 应用场景

### 4.1 处理器设计

- 高性能处理器设计
- 低功耗处理器设计
- 嵌入式处理器设计

### 4.2 性能优化

- 流水线优化
- 缓存优化
- 分支预测优化

### 4.3 系统设计

- 多核架构设计
- 内存子系统设计
- I/O系统设计

## 5. 相关理论

### 5.1 计算机组织

- 数字逻辑设计
- 时序逻辑设计
- 组合逻辑设计

### 5.2 性能分析

- 性能建模
- 瓶颈分析
- 可扩展性分析

### 5.3 并行计算

- 指令级并行
- 数据级并行
- 线程级并行

## 6. 参考文献

1. Hennessy, J. L., & Patterson, D. A. (2017). Computer Architecture: A Quantitative Approach.
2. Patterson, D. A., & Hennessy, J. L. (2017). Computer Organization and Design: The Hardware/Software Interface.
3. Smith, A. J. (1982). Cache memories.
4. Yeh, T., & Patt, Y. N. (1991). Two-level adaptive training branch prediction.
5. McFarling, S. (1993). Combining branch predictors.

## 批判性分析

- 本节内容待补充：请从多元理论视角、局限性、争议点、应用前景等方面进行批判性分析。
