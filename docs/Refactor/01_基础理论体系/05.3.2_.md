# 05.3.2 自适应控制理论

## 📋 概述

自适应控制理论是现代控制理论的重要分支，研究如何设计控制器使其能够自动调整参数以适应系统参数的变化或未知性。自适应控制理论为处理参数不确定性和时变系统提供了强有力的工具，广泛应用于机器人、航空航天、工业过程控制等领域。

## 🎯 核心目标

1. **参数估计**：在线估计系统未知参数
2. **控制器调整**：根据参数估计调整控制器
3. **稳定性保证**：保证自适应系统的稳定性
4. **性能优化**：优化系统性能指标

## 📚 目录

- [05.3.2 自适应控制理论](#0532-自适应控制理论)
  - [📋 概述](#-概述)
  - [🎯 核心目标](#-核心目标)
  - [📚 目录](#-目录)
  - [1. 基本概念](#1-基本概念)
    - [1.1 自适应控制定义](#11-自适应控制定义)
    - [1.2 自适应控制分类](#12-自适应控制分类)
    - [1.3 自适应控制问题](#13-自适应控制问题)
  - [2. 参数自适应控制](#2-参数自适应控制)
    - [2.1 线性参数化系统](#21-线性参数化系统)
    - [2.2 参数估计律](#22-参数估计律)
    - [2.3 自适应控制律](#23-自适应控制律)
  - [3. 模型参考自适应控制](#3-模型参考自适应控制)
    - [3.1 参考模型](#31-参考模型)
    - [3.2 MRAC控制律](#32-mrac控制律)
    - [3.3 稳定性分析](#33-稳定性分析)
  - [4. 神经网络自适应控制](#4-神经网络自适应控制)
    - [4.1 神经网络逼近](#41-神经网络逼近)
    - [4.2 神经网络自适应律](#42-神经网络自适应律)
    - [4.3 鲁棒神经网络控制](#43-鲁棒神经网络控制)
  - [5. 鲁棒自适应控制](#5-鲁棒自适应控制)
    - [5.1 死区自适应控制](#51-死区自适应控制)
    - [5.2 σ修正](#52-σ修正)
    - [5.3 投影算法](#53-投影算法)
  - [6. 自适应观测器](#6-自适应观测器)
    - [6.1 自适应观测器设计](#61-自适应观测器设计)
    - [6.2 输出反馈自适应控制](#62-输出反馈自适应控制)
  - [7. 代码实现](#7-代码实现)
    - [7.1 自适应控制系统框架](#71-自适应控制系统框架)
    - [7.2 鲁棒自适应控制](#72-鲁棒自适应控制)
    - [7.3 自适应观测器](#73-自适应观测器)
  - [8. 应用示例](#8-应用示例)
    - [8.1 倒立摆自适应控制](#81-倒立摆自适应控制)
    - [8.2 模型参考自适应控制示例](#82-模型参考自适应控制示例)
    - [8.3 神经网络自适应控制示例](#83-神经网络自适应控制示例)
  - [9. 相关理论](#9-相关理论)
    - [9.1 与线性控制理论的关系](#91-与线性控制理论的关系)
    - [9.2 与非线性控制理论的关系](#92-与非线性控制理论的关系)
    - [9.3 与鲁棒控制的关系](#93-与鲁棒控制的关系)
  - [10. 参考文献](#10-参考文献)
  - [批判性分析](#批判性分析)
    - [多元理论视角](#多元理论视角)
    - [局限性分析](#局限性分析)
    - [争议与分歧](#争议与分歧)
    - [应用前景](#应用前景)
    - [改进建议](#改进建议)

## 1. 基本概念

### 1.1 自适应控制定义

**定义 1.1.1** (自适应控制)
自适应控制是一种控制策略，其中控制器能够自动调整其参数以适应系统参数的变化或未知性。

**形式化定义**：
对于系统 $\dot{x} = f(x, \theta, u)$，其中 $\theta$ 是未知参数，自适应控制律为：

$$u = u_0(x, \hat{\theta}) + u_a(x, \hat{\theta})$$

其中 $\hat{\theta}$ 是参数估计，$u_a$ 是自适应项。

### 1.2 自适应控制分类

**定义 1.2.1** (自适应控制类型)

1. **直接自适应控制**：直接调整控制器参数
2. **间接自适应控制**：先估计系统参数，再设计控制器
3. **模型参考自适应控制**：使系统输出跟踪参考模型输出
4. **神经网络自适应控制**：使用神经网络逼近未知函数

### 1.3 自适应控制问题

**定义 1.3.1** (自适应控制问题)
自适应控制问题定义为：

1. **参数估计**：设计参数估计律 $\dot{\hat{\theta}} = \tau(x, u, t)$
2. **控制器设计**：设计控制律 $u = u(x, \hat{\theta}, t)$
3. **稳定性分析**：保证闭环系统稳定性
4. **性能分析**：分析系统性能指标

## 2. 参数自适应控制

### 2.1 线性参数化系统

**定义 2.1.1** (线性参数化系统)
线性参数化系统可以表示为：

$$\dot{x} = A(\theta)x + B(\theta)u = \sum_{i=1}^{p} \theta_i (A_i x + B_i u)$$

其中 $\theta_i$ 是未知参数，$A_i$ 和 $B_i$ 是已知矩阵。

**例 2.1.1** (倒立摆参数自适应)
倒立摆系统的参数化模型：

$$
\begin{align}
\dot{x}_1 &= x_2 \\
\dot{x}_2 &= \theta_1 \sin(x_1) + \theta_2 x_2 + \theta_3 u
\end{align}
$$

其中 $\theta_1 = \frac{mgL}{I}$, $\theta_2 = -\frac{b}{I}$, $\theta_3 = \frac{1}{I}$。

### 2.2 参数估计律

**定理 2.2.1** (参数估计律)
对于系统 $\dot{x} = A(\theta)x + B(\theta)u$，参数估计律为：

$$\dot{\hat{\theta}} = -\Gamma \phi(x, u) e^T P$$

其中：

- $\Gamma > 0$ 是自适应增益矩阵
- $\phi(x, u)$ 是回归向量
- $e = x - x_d$ 是跟踪误差
- $P > 0$ 是正定矩阵

**证明**：
考虑李雅普诺夫函数：

$$V = \frac{1}{2}e^T Pe + \frac{1}{2}\tilde{\theta}^T \Gamma^{-1} \tilde{\theta}$$

其中 $\tilde{\theta} = \hat{\theta} - \theta$ 是参数误差。

其导数为：

$$\dot{V} = e^T P \dot{e} + \tilde{\theta}^T \Gamma^{-1} \dot{\hat{\theta}}$$

由于 $\dot{e} = A(\theta)x + B(\theta)u - \dot{x}_d$，代入得到：

$$\dot{V} = e^T P(A(\theta)x + B(\theta)u - \dot{x}_d) + \tilde{\theta}^T \Gamma^{-1} \dot{\hat{\theta}}$$

选择控制律：

$$u = B^{-1}(\hat{\theta})(-A(\hat{\theta})x + \dot{x}_d - Ke)$$

其中 $K$ 使得 $A - BK$ 稳定。

则：

$$\dot{V} = e^T P(A - BK)e + \tilde{\theta}^T \Gamma^{-1} \dot{\hat{\theta}} + e^T P \phi(x, u) \tilde{\theta}$$

选择参数估计律：

$$\dot{\hat{\theta}} = -\Gamma \phi(x, u) e^T P$$

则：

$$\dot{V} = e^T P(A - BK)e \leq 0$$

因此系统是稳定的。

### 2.3 自适应控制律

**定理 2.3.1** (自适应控制律)
对于线性参数化系统，自适应控制律为：

$$u = B^{-1}(\hat{\theta})(-A(\hat{\theta})x + \dot{x}_d - Ke)$$

其中 $K$ 是反馈增益矩阵，使得 $A - BK$ 稳定。

## 3. 模型参考自适应控制

### 3.1 参考模型

**定义 3.1.1** (参考模型)
参考模型定义为：

$$\dot{x}_m = A_m x_m + B_m r$$

其中 $A_m$ 是稳定的系统矩阵，$B_m$ 是输入矩阵，$r$ 是参考输入。

**例 3.1.1** (二阶参考模型)
二阶参考模型：

$$
\begin{align}
\dot{x}_{m1} &= x_{m2} \\
\dot{x}_{m2} &= -a_1 x_{m1} - a_2 x_{m2} + b r
\end{align}
$$

其中 $a_1, a_2 > 0$ 使得系统稳定。

### 3.2 MRAC控制律

**定理 3.2.1** (MRAC控制律)
对于系统 $\dot{x} = A(\theta)x + B(\theta)u$，MRAC控制律为：

$$u = K_x^T x + K_r^T r$$

其中自适应律为：

$$
\begin{align}
\dot{K}_x &= -\Gamma_x x e^T P B \\
\dot{K}_r &= -\Gamma_r r e^T P B
\end{align}
$$

其中 $e = x - x_m$ 是跟踪误差。

**证明**：
跟踪误差动态为：

$$\dot{e} = A(\theta)x + B(\theta)u - A_m x_m - B_m r$$

代入控制律：

$$\dot{e} = A(\theta)x + B(\theta)(K_x^T x + K_r^T r) - A_m x_m - B_m r$$

整理得到：

$$\dot{e} = A_m e + B(\theta)(K_x^T - K_x^{*T})x + B(\theta)(K_r^T - K_r^{*T})r$$

其中 $K_x^*$ 和 $K_r^*$ 是理想增益。

考虑李雅普诺夫函数：

$$V = \frac{1}{2}e^T Pe + \frac{1}{2}\text{tr}(\tilde{K}_x^T \Gamma_x^{-1} \tilde{K}_x) + \frac{1}{2}\text{tr}(\tilde{K}_r^T \Gamma_r^{-1} \tilde{K}_r)$$

其中 $\tilde{K}_x = K_x - K_x^*$, $\tilde{K}_r = K_r - K_r^*$。

其导数为：

$$\dot{V} = e^T P \dot{e} + \text{tr}(\tilde{K}_x^T \Gamma_x^{-1} \dot{K}_x) + \text{tr}(\tilde{K}_r^T \Gamma_r^{-1} \dot{K}_r)$$

选择自适应律：

$$
\begin{align}
\dot{K}_x &= -\Gamma_x x e^T P B \\
\dot{K}_r &= -\Gamma_r r e^T P B
\end{align}
$$

则：

$$\dot{V} = e^T P A_m e \leq 0$$

因此系统是稳定的。

### 3.3 稳定性分析

**定理 3.3.1** (MRAC稳定性)
如果参考模型稳定且满足持续激励条件，则MRAC系统是渐近稳定的。

**持续激励条件**：
存在常数 $T > 0$ 和 $\alpha > 0$，使得：

$$\int_t^{t+T} \begin{bmatrix} x(\tau) \\ r(\tau) \end{bmatrix} \begin{bmatrix} x(\tau) \\ r(\tau) \end{bmatrix}^T d\tau \geq \alpha I$$

## 4. 神经网络自适应控制

### 4.1 神经网络逼近

**定义 4.1.1** (神经网络逼近)
对于未知函数 $f(x)$，可以使用神经网络逼近：

$$f(x) = W^T \phi(x) + \epsilon(x)$$

其中：

- $W$ 是权重矩阵
- $\phi(x)$ 是基函数向量
- $\epsilon(x)$ 是逼近误差

**例 4.1.1** (径向基函数网络)
径向基函数网络：

$$\phi_i(x) = \exp\left(-\frac{\|x - c_i\|^2}{2\sigma_i^2}\right)$$

其中 $c_i$ 是中心，$\sigma_i$ 是宽度参数。

### 4.2 神经网络自适应律

**定理 4.2.1** (神经网络自适应律)
神经网络权重自适应律为：

$$\dot{W} = -\Gamma \phi(x) e^T P$$

其中 $\Gamma > 0$ 是自适应增益矩阵。

**证明**：
考虑李雅普诺夫函数：

$$V = \frac{1}{2}e^T Pe + \frac{1}{2}\text{tr}(\tilde{W}^T \Gamma^{-1} \tilde{W})$$

其中 $\tilde{W} = \hat{W} - W$ 是权重误差。

其导数为：

$$\dot{V} = e^T P \dot{e} + \text{tr}(\tilde{W}^T \Gamma^{-1} \dot{\hat{W}})$$

由于 $\dot{e} = f(x) - \hat{f}(x) - Ke = \tilde{W}^T \phi(x) + \epsilon(x) - Ke$，

选择自适应律：

$$\dot{\hat{W}} = -\Gamma \phi(x) e^T P$$

则：

$$\dot{V} = e^T P(\tilde{W}^T \phi(x) + \epsilon(x) - Ke) + \text{tr}(\tilde{W}^T \Gamma^{-1} \dot{\hat{W}})$$

$$= e^T P \epsilon(x) - e^T P K e \leq -\lambda_{\min}(K) \|e\|^2 + \|\epsilon\| \|e\|$$

如果逼近误差有界，则系统是稳定的。

### 4.3 鲁棒神经网络控制

**定理 4.3.1** (鲁棒神经网络控制)
考虑逼近误差，鲁棒控制律为：

$$u = \hat{f}(x) + v_r$$

其中鲁棒项 $v_r$ 为：

$$v_r = -\eta \frac{e}{\|e\| + \delta}$$

其中 $\eta > \|\epsilon\|$ 是鲁棒增益，$\delta > 0$ 是小常数。

## 5. 鲁棒自适应控制

### 5.1 死区自适应控制

**定义 5.1.1** (死区自适应控制)
死区自适应控制使用死区函数来防止参数漂移：

$$
\dot{\hat{\theta}} = \begin{cases}
-\Gamma \phi(x, u) e^T P & \text{if } \|e\| > \delta \\
0 & \text{if } \|e\| \leq \delta
\end{cases}
$$

其中 $\delta > 0$ 是死区宽度。

### 5.2 σ修正

**定义 5.2.1** (σ修正)
σ修正自适应律为：

$$\dot{\hat{\theta}} = -\Gamma \phi(x, u) e^T P - \sigma \hat{\theta}$$

其中 $\sigma > 0$ 是修正参数。

### 5.3 投影算法

**定义 5.3.1** (投影算法)
投影算法确保参数估计在已知范围内：

$$\dot{\hat{\theta}} = \text{Proj}(-\Gamma \phi(x, u) e^T P, \hat{\theta})$$

其中投影算子定义为：

$$
\text{Proj}(\tau, \hat{\theta}) = \begin{cases}
\tau & \text{if } \hat{\theta} \in \Omega \text{ or } \nabla P(\hat{\theta})^T \tau \leq 0 \\
\tau - \frac{\nabla P(\hat{\theta}) \nabla P(\hat{\theta})^T}{\|\nabla P(\hat{\theta})\|^2} \tau & \text{otherwise}
\end{cases}
$$

其中 $P(\hat{\theta})$ 是参数约束函数。

## 6. 自适应观测器

### 6.1 自适应观测器设计

**定义 6.1.1** (自适应观测器)
对于系统 $\dot{x} = A(\theta)x + B(\theta)u$，$y = Cx$，自适应观测器为：

$$\dot{\hat{x}} = A(\hat{\theta})\hat{x} + B(\hat{\theta})u + L(y - \hat{y})$$

其中 $\hat{y} = C\hat{x}$，$L$ 是观测器增益。

**定理 6.1.1** (自适应观测器律)
参数估计律为：

$$\dot{\hat{\theta}} = -\Gamma \phi(\hat{x}, u) e_y^T P$$

其中 $e_y = y - \hat{y}$ 是输出误差。

### 6.2 输出反馈自适应控制

**定理 6.2.1** (输出反馈自适应控制)
对于系统 $\dot{x} = A(\theta)x + B(\theta)u$，$y = Cx$，输出反馈自适应控制律为：

$$u = K(\hat{\theta}) \hat{x}$$

其中 $\hat{x}$ 由自适应观测器提供。

## 7. 代码实现

### 7.1 自适应控制系统框架

```rust
use nalgebra::{DMatrix, DVector};
use std::f64::consts::PI;

/// 自适应控制系统
pub struct AdaptiveControlSystem {
    pub theta_hat: DVector<f64>,
    pub gamma: DMatrix<f64>,
    pub P: DMatrix<f64>,
    pub K: DMatrix<f64>,
}

impl AdaptiveControlSystem {
    pub fn new(n_params: usize) -> Self {
        Self {
            theta_hat: DVector::zeros(n_params),
            gamma: DMatrix::identity(n_params, n_params) * 10.0,
            P: DMatrix::identity(2, 2),
            K: DMatrix::from_row_slice(1, 2, &[2.0, 2.0]),
        }
    }

    /// 参数自适应律
    pub fn update_parameters(&mut self, phi: &DVector<f64>, e: &DVector<f64>) {
        let update = &self.gamma * phi * e.transpose() * &self.P;
        self.theta_hat = &self.theta_hat - &update.column(0);
    }

    /// 计算控制输入
    pub fn compute_control(&self, x: &DVector<f64>, xd: &DVector<f64>, xd_dot: &DVector<f64>) -> DVector<f64> {
        let e = x - xd;
        let phi = self.regression_vector(x);

        // 自适应控制律
        let u_nominal = -&self.K * &e + xd_dot;
        let u_adaptive = &phi.transpose() * &self.theta_hat;

        DVector::from_column_slice(&[u_nominal[0] + u_adaptive[0]])
    }

    /// 回归向量
    fn regression_vector(&self, x: &DVector<f64>) -> DVector<f64> {
        DVector::from_column_slice(&[
            x[0].sin(),
            x[1],
            1.0
        ])
    }
}

/// 模型参考自适应控制系统
pub struct MRACSystem {
    pub Kx: DVector<f64>,
    pub Kr: DVector<f64>,
    pub gamma_x: DMatrix<f64>,
    pub gamma_r: DMatrix<f64>,
    pub Am: DMatrix<f64>,
    pub Bm: DVector<f64>,
    pub P: DMatrix<f64>,
}

impl MRACSystem {
    pub fn new() -> Self {
        Self {
            Kx: DVector::zeros(2),
            Kr: DVector::zeros(1),
            gamma_x: DMatrix::identity(2, 2) * 10.0,
            gamma_r: DMatrix::identity(1, 1) * 10.0,
            Am: DMatrix::from_row_slice(2, 2, &[-1.0, 1.0, -1.0, -1.0]),
            Bm: DVector::from_column_slice(&[0.0, 1.0]),
            P: DMatrix::identity(2, 2),
        }
    }

    /// 更新参考模型
    pub fn update_reference_model(&mut self, xm: &mut DVector<f64>, r: f64, dt: f64) {
        let dxm = &self.Am * xm + &self.Bm * r;
        *xm = xm + &(dxm * dt);
    }

    /// 更新自适应参数
    pub fn update_parameters(&mut self, x: &DVector<f64>, r: f64, e: &DVector<f64>) {
        let update_x = &self.gamma_x * x * e.transpose() * &self.P * DVector::from_column_slice(&[0.0, 1.0]);
        let update_r = &self.gamma_r * DVector::from_column_slice(&[r]) * e.transpose() * &self.P * DVector::from_column_slice(&[0.0, 1.0]);

        self.Kx = &self.Kx - &update_x;
        self.Kr = &self.Kr - &update_r;
    }

    /// 计算控制输入
    pub fn compute_control(&self, x: &DVector<f64>, r: f64) -> f64 {
        self.Kx.transpose() * x + self.Kr[0] * r
    }
}

/// 神经网络自适应控制系统
pub struct NeuralAdaptiveSystem {
    pub weights: DMatrix<f64>,
    pub centers: Vec<DVector<f64>>,
    pub widths: Vec<f64>,
    pub gamma: DMatrix<f64>,
    pub P: DMatrix<f64>,
}

impl NeuralAdaptiveSystem {
    pub fn new(n_neurons: usize, input_dim: usize) -> Self {
        let mut centers = Vec::new();
        let mut widths = Vec::new();

        for i in 0..n_neurons {
            centers.push(DVector::from_column_slice(&[
                (i as f64 - n_neurons as f64 / 2.0) * 0.5,
                (i as f64 - n_neurons as f64 / 2.0) * 0.5
            ]));
            widths.push(1.0);
        }

        Self {
            weights: DMatrix::zeros(n_neurons, 1),
            centers,
            widths,
            gamma: DMatrix::identity(n_neurons, n_neurons) * 10.0,
            P: DMatrix::identity(2, 2),
        }
    }

    /// 计算径向基函数
    pub fn compute_basis_functions(&self, x: &DVector<f64>) -> DVector<f64> {
        let mut phi = DVector::zeros(self.centers.len());

        for i in 0..self.centers.len() {
            let diff = x - &self.centers[i];
            let distance_squared = diff.transpose() * &diff;
            phi[i] = (-distance_squared / (2.0 * self.widths[i] * self.widths[i])).exp();
        }

        phi
    }

    /// 神经网络输出
    pub fn output(&self, x: &DVector<f64>) -> f64 {
        let phi = self.compute_basis_functions(x);
        (self.weights.transpose() * &phi)[0]
    }

    /// 更新权重
    pub fn update_weights(&mut self, x: &DVector<f64>, e: &DVector<f64>) {
        let phi = self.compute_basis_functions(x);
        let update = &self.gamma * &phi * e.transpose() * &self.P * DVector::from_column_slice(&[0.0, 1.0]);
        self.weights = &self.weights - &update;
    }

    /// 计算控制输入
    pub fn compute_control(&self, x: &DVector<f64>, xd: &DVector<f64>, xd_dot: &DVector<f64>) -> f64 {
        let e = x - xd;
        let K = DMatrix::from_row_slice(1, 2, &[2.0, 2.0]);

        let u_nominal = -K * e + xd_dot;
        let u_neural = self.output(x);

        u_nominal[0] + u_neural
    }
}
```

### 7.2 鲁棒自适应控制

```rust
/// 鲁棒自适应控制系统
pub struct RobustAdaptiveSystem {
    pub theta_hat: DVector<f64>,
    pub gamma: DMatrix<f64>,
    pub sigma: f64,
    pub eta: f64,
    pub delta: f64,
}

impl RobustAdaptiveSystem {
    pub fn new(n_params: usize) -> Self {
        Self {
            theta_hat: DVector::zeros(n_params),
            gamma: DMatrix::identity(n_params, n_params) * 10.0,
            sigma: 0.1,
            eta: 1.0,
            delta: 0.1,
        }
    }

    /// σ修正自适应律
    pub fn sigma_modification(&mut self, phi: &DVector<f64>, e: &DVector<f64>) {
        let update = &self.gamma * phi * e[0] - &self.gamma * &self.theta_hat * self.sigma;
        self.theta_hat = &self.theta_hat - &update;
    }

    /// 死区自适应律
    pub fn deadzone_modification(&mut self, phi: &DVector<f64>, e: &DVector<f64>) {
        if e.norm() > self.delta {
            let update = &self.gamma * phi * e[0];
            self.theta_hat = &self.theta_hat - &update;
        }
    }

    /// 投影算法
    pub fn projection_algorithm(&mut self, phi: &DVector<f64>, e: &DVector<f64>) {
        let tau = &self.gamma * phi * e[0];

        // 简单的投影：限制参数范围
        for i in 0..self.theta_hat.len() {
            self.theta_hat[i] = self.theta_hat[i].max(-10.0).min(10.0);
        }

        self.theta_hat = &self.theta_hat - &tau;
    }

    /// 鲁棒控制项
    pub fn robust_control_term(&self, e: &DVector<f64>) -> f64 {
        if e.norm() > self.delta {
            -self.eta * e[0] / (e.norm() + self.delta)
        } else {
            0.0
        }
    }
}
```

### 7.3 自适应观测器

```rust
/// 自适应观测器
pub struct AdaptiveObserver {
    pub x_hat: DVector<f64>,
    pub theta_hat: DVector<f64>,
    pub L: DMatrix<f64>,
    pub gamma: DMatrix<f64>,
    pub P: DMatrix<f64>,
}

impl AdaptiveObserver {
    pub fn new(n_states: usize, n_params: usize) -> Self {
        Self {
            x_hat: DVector::zeros(n_states),
            theta_hat: DVector::zeros(n_params),
            L: DMatrix::from_row_slice(2, 1, &[2.0, 2.0]),
            gamma: DMatrix::identity(n_params, n_params) * 10.0,
            P: DMatrix::identity(2, 2),
        }
    }

    /// 更新观测器状态
    pub fn update_state(&mut self, u: f64, y: f64, dt: f64) {
        // 简化的系统模型
        let A = DMatrix::from_row_slice(2, 2, &[0.0, 1.0, 0.0, 0.0]);
        let B = DVector::from_column_slice(&[0.0, 1.0]);
        let C = DMatrix::from_row_slice(1, 2, &[1.0, 0.0]);

        let y_hat = [&C * &self.x_hat](0);
        let e_y = y - y_hat;

        // 观测器动态
        let dx_hat = &A * &self.x_hat + &B * u + &self.L * e_y;
        self.x_hat = &self.x_hat + &(dx_hat * dt);

        // 参数估计
        let phi = self.regression_vector(&self.x_hat, u);
        let update = &self.gamma * &phi * e_y;
        self.theta_hat = &self.theta_hat - &update;
    }

    /// 回归向量
    fn regression_vector(&self, x: &DVector<f64>, u: f64) -> DVector<f64> {
        DVector::from_column_slice(&[
            x[0].sin(),
            x[1],
            u
        ])
    }
}
```

## 8. 应用示例

### 8.1 倒立摆自适应控制

```rust
/// 倒立摆自适应控制示例
pub fn inverted_pendulum_adaptive_control() {
    let mut adaptive_system = AdaptiveControlSystem::new(3);

    // 系统参数（未知）
    let true_theta = DVector::from_column_slice(&[4.9, -0.1, 0.0]);

    // 仿真参数
    let dt = 0.01;
    let t_final = 10.0;
    let steps = (t_final / dt) as usize;

    let mut x = DVector::from_column_slice(&[0.5, 0.0]);
    let mut t = 0.0;

    println!("倒立摆自适应控制仿真结果：");

    for step in 0..steps {
        // 期望轨迹
        let xd = DVector::from_column_slice(&[0.5 * (t).sin(), 0.5 * (t).cos()]);
        let xd_dot = DVector::from_column_slice(&[0.5 * (t).cos(), -0.5 * (t).sin()]);

        // 计算控制输入
        let u = adaptive_system.compute_control(&x, &xd, &xd_dot);

        // 系统动态（使用真实参数）
        let phi = adaptive_system.regression_vector(&x);
        let dx = DVector::from_column_slice(&[
            x[1],
            phi.transpose() * &true_theta + u[0]
        ]) * dt;

        x = &x + &dx;

        // 更新自适应参数
        let e = &x - &xd;
        adaptive_system.update_parameters(&phi, &e);

        t += dt;

        if step % 100 == 0 {
            println!("t={:.1}s: 实际角度={:.3}rad, 期望角度={:.3}rad, 参数估计=[{:.3}, {:.3}, {:.3}]",
                t, x[0], xd[0], adaptive_system.theta_hat[0],
                adaptive_system.theta_hat[1], adaptive_system.theta_hat[2]);
        }
    }

    println!("最终参数估计: [{:.3}, {:.3}, {:.3}]",
        adaptive_system.theta_hat[0], adaptive_system.theta_hat[1], adaptive_system.theta_hat[2]);
    println!("真实参数: [{:.3}, {:.3}, {:.3}]",
        true_theta[0], true_theta[1], true_theta[2]);
}
```

### 8.2 模型参考自适应控制示例

```rust
/// 模型参考自适应控制示例
pub fn mrac_example() {
    let mut mrac_system = MRACSystem::new();

    // 仿真参数
    let dt = 0.01;
    let t_final = 10.0;
    let steps = (t_final / dt) as usize;

    let mut x = DVector::from_column_slice(&[0.5, 0.0]);
    let mut xm = DVector::from_column_slice(&[0.0, 0.0]);
    let mut t = 0.0;

    println!("模型参考自适应控制仿真结果：");

    for step in 0..steps {
        // 参考输入
        let r = 0.5 * (t).sin();

        // 更新参考模型
        mrac_system.update_reference_model(&mut xm, r, dt);

        // 计算控制输入
        let u = mrac_system.compute_control(&x, r);

        // 系统动态
        let dx = DVector::from_column_slice(&[
            x[1],
            -x[0].sin() - 0.1 * x[1] + u
        ]) * dt;

        x = &x + &dx;

        // 更新自适应参数
        let e = &x - &xm;
        mrac_system.update_parameters(&x, r, &e);

        t += dt;

        if step % 100 == 0 {
            println!("t={:.1}s: 实际状态=[{:.3}, {:.3}], 参考状态=[{:.3}, {:.3}], 控制={:.3}",
                t, x[0], x[1], xm[0], xm[1], u);
        }
    }
}
```

### 8.3 神经网络自适应控制示例

```rust
/// 神经网络自适应控制示例
pub fn neural_adaptive_control_example() {
    let mut neural_system = NeuralAdaptiveSystem::new(10, 2);

    // 仿真参数
    let dt = 0.01;
    let t_final = 10.0;
    let steps = (t_final / dt) as usize;

    let mut x = DVector::from_column_slice(&[0.5, 0.0]);
    let mut t = 0.0;

    println!("神经网络自适应控制仿真结果：");

    for step in 0..steps {
        // 期望轨迹
        let xd = DVector::from_column_slice(&[0.5 * (t).sin(), 0.5 * (t).cos()]);
        let xd_dot = DVector::from_column_slice(&[0.5 * (t).cos(), -0.5 * (t).sin()]);

        // 计算控制输入
        let u = neural_system.compute_control(&x, &xd, &xd_dot);

        // 系统动态（包含未知非线性项）
        let unknown_nonlinearity = 0.1 * x[0].sin() * x[1].cos();
        let dx = DVector::from_column_slice(&[
            x[1],
            u + unknown_nonlinearity
        ]) * dt;

        x = &x + &dx;

        // 更新神经网络权重
        let e = &x - &xd;
        neural_system.update_weights(&x, &e);

        t += dt;

        if step % 100 == 0 {
            println!("t={:.1}s: 实际状态=[{:.3}, {:.3}], 期望状态=[{:.3}, {:.3}], 控制={:.3}",
                t, x[0], x[1], xd[0], xd[1], u);
        }
    }
}
```

## 9. 相关理论

### 9.1 与线性控制理论的关系

自适应控制理论扩展了线性控制理论：

1. **参数不确定性**：处理参数未知或时变的系统
2. **在线学习**：实时学习和调整控制器参数
3. **鲁棒性**：结合鲁棒控制理论处理不确定性

### 9.2 与非线性控制理论的关系

自适应控制理论与非线性控制理论结合：

1. **非线性自适应**：处理非线性系统的参数自适应
2. **神经网络控制**：使用神经网络逼近未知非线性函数
3. **反步法自适应**：结合反步法设计自适应控制器

### 9.3 与鲁棒控制的关系

自适应控制理论与鲁棒控制理论互补：

1. **不确定性类型**：自适应控制处理参数不确定性，鲁棒控制处理有界不确定性
2. **设计方法**：自适应控制在线学习，鲁棒控制离线设计
3. **性能保证**：两者都提供性能保证，但方法不同

## 10. 参考文献

1. Ioannou, P. A., & Sun, J. (2012). Robust Adaptive Control. Dover Publications.
2. Narendra, K. S., & Annaswamy, A. M. (2012). Stable Adaptive Systems. Dover Publications.
3. Sastry, S., & Bodson, M. (2011). Adaptive Control: Stability, Convergence and Robustness. Dover Publications.
4. Krstic, M., Kanellakopoulos, I., & Kokotovic, P. V. (1995). Nonlinear and Adaptive Control Design. John Wiley & Sons.
5. Lewis, F. L., Jagannathan, S., & Yesildirek, A. (1999). Neural Network Control of Robot Manipulators and Nonlinear Systems. CRC Press.
6. Astrom, K. J., & Wittenmark, B. (2013). Adaptive Control. Dover Publications.
7. Landau, I. D., Lozano, R., M'Saad, M., & Karimi, A. (2011). Adaptive Control: Algorithms, Analysis and Applications. Springer.
8. Tao, G. (2014). Adaptive Control Design and Analysis. John Wiley & Sons.

---

**相关文档**：

- [05.2.1 现代控制理论](05.2.1_现代控制理论.md)
- [05.2.2 最优控制理论](05.2.2_最优控制理论.md)
- [05.2.3 鲁棒控制理论](05.2.3_鲁棒控制理论.md)
- [05.3.1 非线性控制理论](05.3.1_非线性控制理论.md)

## 批判性分析

### 多元理论视角

**辨识-控制一体视角**：参数估计与控制律协同保证稳定与跟踪，但辨识激励与闭环性能存在内在张力。

**鲁棒融合视角**：σ修正、死区、投影等缓解漂移与噪声影响，代价是稳态误差与保守性。

**学习增强视角**：NN/RBF等提升逼近能力，但引入可解释性与稳定性保证难题。

### 局限性分析

**持续激励(PE)要求**：缺乏充分激励时，参数不可辨识，导致收敛与性能无保证。

**非线性与时变**：强非线性/快速时变下，经典梯度/最小二乘适用性下降，需要复合自适应与鲁棒项。

**噪声与扰动**：测噪与未建模动态会诱导参数发散；正则化提高稳健性但牺牲性能。

**实现复杂度**：在线估计、投影/饱和与观测器耦合使设计调参复杂、验证成本高。

### 争议与分歧

**直接vs间接**：直接法响应快但稳定保证难，间接法理论清晰但对估计质量敏感。

**最优vs稳定优先**：是否引入性能最优目标（如最小方差）与稳定性约束的权衡路径。

**学习规模化**：大规模神经自适应的安全性与可验证性仍存分歧。

### 应用前景

**航天/机器人**：负载变化、环境不确定下的在线适配需求强。

**工业过程与能源**：慢漂移、工况切换下的性能保持与节能优化。

**人机协作与医疗**：个体差异与时变特性需要安全可证的自适应策略。

### 改进建议

**PE替代与激励设计**：采用复合自适应、有限记忆/指令滤波等构造“等效激励”。

**鲁棒-自适应一体化**：结合H∞/CBF/观测器，实现安全约束与最坏情况保证。

**可证学习**：在自适应律中嵌入证据界与不确定度量（贝叶斯/区间），提升可验证性。
