# å·¥ä½œæµå¼•æ“è®¾è®¡ä¸å®ç°åˆ†æ

## ğŸ“‹ ç›®å½•

- [1 ä¸€ã€ç†è®ºå±‚é¢åˆ†æ](#1-ä¸€ç†è®ºå±‚é¢åˆ†æ)
  - [1.1 ç†è®ºåŸºç¡€](#11-ç†è®ºåŸºç¡€)
    - [1.1.1 çŠ¶æ€è½¬æ¢æ¨¡å‹](#111-çŠ¶æ€è½¬æ¢æ¨¡å‹)
    - [1.1.2 æŒä¹…æ€§æ¨¡å‹](#112-æŒä¹…æ€§æ¨¡å‹)
    - [1.1.3 å¹¶å‘å¤„ç†æ¨¡å‹](#113-å¹¶å‘å¤„ç†æ¨¡å‹)
  - [1.2 è¯„ä¼°ç»´åº¦](#12-è¯„ä¼°ç»´åº¦)
- [2 äºŒã€æ¶æ„å±‚é¢åˆ†æ](#2-äºŒæ¶æ„å±‚é¢åˆ†æ)
  - [2.1 æ¶æ„è®¾è®¡è€ƒé‡](#21-æ¶æ„è®¾è®¡è€ƒé‡)
    - [1.1.1 æ ¸å¿ƒç»„ä»¶æ¶æ„](#111-æ ¸å¿ƒç»„ä»¶æ¶æ„)
    - [1.1.2 æ‰©å±•æ€§è®¾è®¡](#112-æ‰©å±•æ€§è®¾è®¡)
    - [1.1.3 å¯ç”¨æ€§è®¾è®¡](#113-å¯ç”¨æ€§è®¾è®¡)
  - [2.2 è¯„ä¼°ç»´åº¦](#22-è¯„ä¼°ç»´åº¦)
- [3 ä¸‰ã€é›†æˆå±‚é¢åˆ†æ](#3-ä¸‰é›†æˆå±‚é¢åˆ†æ)
  - [3.1 ä¸ç°æœ‰ç³»ç»Ÿé›†æˆ](#31-ä¸ç°æœ‰ç³»ç»Ÿé›†æˆ)
    - [1.1.1 æ¥å£è®¾è®¡](#111-æ¥å£è®¾è®¡)
    - [1.1.2 é€šä¿¡æ¨¡å¼](#112-é€šä¿¡æ¨¡å¼)
    - [1.1.3 ç¼–æ’ä¸åè°ƒ](#113-ç¼–æ’ä¸åè°ƒ)
  - [3.2 è¯„ä¼°ç»´åº¦](#32-è¯„ä¼°ç»´åº¦)
- [4 å››ã€å®ç°å±‚é¢åˆ†æ](#4-å››å®ç°å±‚é¢åˆ†æ)
  - [4.1 Rustå®ç°è€ƒé‡](#41-rustå®ç°è€ƒé‡)
    - [1.1.1 ç±»å‹ç³»ç»Ÿåº”ç”¨](#111-ç±»å‹ç³»ç»Ÿåº”ç”¨)
    - [1.1.2 å¹¶å‘å¤„ç†](#112-å¹¶å‘å¤„ç†)
    - [1.1.3 é”™è¯¯å¤„ç†ç­–ç•¥](#113-é”™è¯¯å¤„ç†ç­–ç•¥)
  - [4.2 è¯„ä¼°ç»´åº¦](#42-è¯„ä¼°ç»´åº¦)
- [5 äº”ã€å·¥ä½œæµå¼•æ“å®ç°æ–¹æ¡ˆ](#5-äº”å·¥ä½œæµå¼•æ“å®ç°æ–¹æ¡ˆ)
  - [5.1 æ ¸å¿ƒæ¶æ„è®¾è®¡](#51-æ ¸å¿ƒæ¶æ„è®¾è®¡)
  - [5.2 åŸºäºRustç±»å‹ç³»ç»Ÿçš„å·¥ä½œæµçŠ¶æ€æ¨¡å‹](#52-åŸºäºrustç±»å‹ç³»ç»Ÿçš„å·¥ä½œæµçŠ¶æ€æ¨¡å‹)
  - [5.3 äº‹ä»¶æº¯æºå®ç°](#53-äº‹ä»¶æº¯æºå®ç°)
  - [5.4 æ´»åŠ¨æ‰§è¡Œå™¨å®ç°](#54-æ´»åŠ¨æ‰§è¡Œå™¨å®ç°)
  - [5.5 APIæ¥å£è®¾è®¡](#55-apiæ¥å£è®¾è®¡)
- [6 å…­ã€å®ç°æ­¥éª¤ä¸è·¯çº¿å›¾](#6-å…­å®ç°æ­¥éª¤ä¸è·¯çº¿å›¾)
  - [6.1 ç¬¬ä¸€é˜¶æ®µ æ ¸å¿ƒå¼•æ“å®ç° (3-4å‘¨)](#61-ç¬¬ä¸€é˜¶æ®µ-æ ¸å¿ƒå¼•æ“å®ç°-3-4å‘¨)
  - [6.2 ç¬¬äºŒé˜¶æ®µ æ´»åŠ¨æ‰§è¡Œä¸è°ƒåº¦ (2-3å‘¨)](#62-ç¬¬äºŒé˜¶æ®µ-æ´»åŠ¨æ‰§è¡Œä¸è°ƒåº¦-2-3å‘¨)
  - [6.3 ç¬¬ä¸‰é˜¶æ®µ APIå’Œé›†æˆ (2-3å‘¨)](#63-ç¬¬ä¸‰é˜¶æ®µ-apiå’Œé›†æˆ-2-3å‘¨)
  - [6.4 ç¬¬å››é˜¶æ®µ è¿ç»´ä¸å¯è§‚æµ‹æ€§ (2å‘¨)](#64-ç¬¬å››é˜¶æ®µ-è¿ç»´ä¸å¯è§‚æµ‹æ€§-2å‘¨)
  - [6.5 æ€»ç»“ æ€§èƒ½ä¸æˆç†Ÿåº¦è¯„ä¼°ç»´åº¦](#65-æ€»ç»“-æ€§èƒ½ä¸æˆç†Ÿåº¦è¯„ä¼°ç»´åº¦)
- [7 ä¸ƒã€æ ¸å¿ƒä»£ç å®ç°ç¤ºä¾‹](#7-ä¸ƒæ ¸å¿ƒä»£ç å®ç°ç¤ºä¾‹)
  - [7.1 æ ¸å¿ƒçŠ¶æ€æœºå®ç°](#71-æ ¸å¿ƒçŠ¶æ€æœºå®ç°)
  - [7.2 äº‹ä»¶å­˜å‚¨å®ç°](#72-äº‹ä»¶å­˜å‚¨å®ç°)
  - [7.3 å·¥ä½œæµå¼•æ“æ ¸å¿ƒå®ç°](#73-å·¥ä½œæµå¼•æ“æ ¸å¿ƒå®ç°)
  - [7.4 å·¥ä½œæµå¼•æ“æ ¸å¿ƒå®ç°ç»­](#74-å·¥ä½œæµå¼•æ“æ ¸å¿ƒå®ç°ç»­)
  - [7.5 æ´»åŠ¨æ‰§è¡Œå™¨å®ç°](#75-æ´»åŠ¨æ‰§è¡Œå™¨å®ç°)
- [8 å…«ã€å·¥ä½œæµå¼•æ“å®ç°è·¯çº¿å›¾](#8-å…«å·¥ä½œæµå¼•æ“å®ç°è·¯çº¿å›¾)
  - [8.1 é˜¶æ®µä¸€ åŸå‹ä¸åŸºç¡€æ¡†æ¶ (4-6å‘¨)](#81-é˜¶æ®µä¸€-åŸå‹ä¸åŸºç¡€æ¡†æ¶-4-6å‘¨)
  - [8.2 é˜¶æ®µäºŒ åŠŸèƒ½å®Œå–„ä¸é›†æˆ (4-6å‘¨)](#82-é˜¶æ®µäºŒ-åŠŸèƒ½å®Œå–„ä¸é›†æˆ-4-6å‘¨)
  - [8.3 é˜¶æ®µä¸‰ é«˜çº§åŠŸèƒ½ä¸ä¼˜åŒ– (6-8å‘¨)](#83-é˜¶æ®µä¸‰-é«˜çº§åŠŸèƒ½ä¸ä¼˜åŒ–-6-8å‘¨)
  - [8.4 é˜¶æ®µå›› æ‰©å±•ä¸æˆç†Ÿ (6-8å‘¨)](#84-é˜¶æ®µå››-æ‰©å±•ä¸æˆç†Ÿ-6-8å‘¨)
- [9 ä¹ã€æ‰©å±•æ€§ä¸æœªæ¥å‘å±•æ–¹å‘](#9-ä¹æ‰©å±•æ€§ä¸æœªæ¥å‘å±•æ–¹å‘)
  - [9.1 åˆ†å¸ƒå¼å·¥ä½œæµå¼•æ“](#91-åˆ†å¸ƒå¼å·¥ä½œæµå¼•æ“)
  - [9.2 å·¥ä½œæµå®šä¹‰DSL](#92-å·¥ä½œæµå®šä¹‰dsl)
  - [9.3 å·¥ä½œæµå¯è§†åŒ–å’Œç›‘æ§](#93-å·¥ä½œæµå¯è§†åŒ–å’Œç›‘æ§)
- [10 åã€æ€»ç»“ä¸å»ºè®®](#10-åæ€»ç»“ä¸å»ºè®®)
  - [10.1 æ€»ä½“æ¶æ„è¯„ä¼°](#101-æ€»ä½“æ¶æ„è¯„ä¼°)
    - [1.1.1 ä¼˜åŠ¿](#111-ä¼˜åŠ¿)
    - [1.1.2 æŒ‘æˆ˜](#112-æŒ‘æˆ˜)
  - [10.2 å®æ–½å»ºè®®](#102-å®æ–½å»ºè®®)
    - [2.2.1 å¯¹äºå°å‹é¡¹ç›®æˆ–MVPé˜¶æ®µ](#221-å¯¹äºå°å‹é¡¹ç›®æˆ–mvpé˜¶æ®µ)
    - [2.2.2 å¯¹äºå¤§å‹ä¼ä¸šåº”ç”¨](#222-å¯¹äºå¤§å‹ä¼ä¸šåº”ç”¨)
  - [10.3 å¯è¡Œæ€§è¯„åˆ†](#103-å¯è¡Œæ€§è¯„åˆ†)
  - [10.4 ä¸å¼€æºæ–¹æ¡ˆæ¯”è¾ƒ](#104-ä¸å¼€æºæ–¹æ¡ˆæ¯”è¾ƒ)
  - [10.5 æœ€ç»ˆå»ºè®®](#105-æœ€ç»ˆå»ºè®®)
- [11 åä¸€ã€ç¤ºä¾‹å·¥ä½œæµå®šä¹‰å®ç°](#11-åä¸€ç¤ºä¾‹å·¥ä½œæµå®šä¹‰å®ç°)
  - [11.1 è®¢å•å·¥ä½œæµçŠ¶æ€å®šä¹‰](#111-è®¢å•å·¥ä½œæµçŠ¶æ€å®šä¹‰)
  - [11.2 è®¢å•å·¥ä½œæµäº‹ä»¶å®šä¹‰](#112-è®¢å•å·¥ä½œæµäº‹ä»¶å®šä¹‰)
  - [11.3 è®¢å•å·¥ä½œæµå®šä¹‰](#113-è®¢å•å·¥ä½œæµå®šä¹‰)

---

## 1 ä¸€ã€ç†è®ºå±‚é¢åˆ†æ

### 1.1 ç†è®ºåŸºç¡€

#### 1.1.1 çŠ¶æ€è½¬æ¢æ¨¡å‹

å·¥ä½œæµæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªçŠ¶æ€è½¬æ¢ç³»ç»Ÿ,éœ€è¦éµå¾ªä»¥ä¸‹ç†è®ºåŸºç¡€:

- **æœ‰é™çŠ¶æ€æœº(FSM)**: å®šä¹‰æ˜ç¡®çš„çŠ¶æ€ã€äº‹ä»¶å’Œè½¬æ¢è§„åˆ™
- **Petriç½‘**: é€‚ç”¨äºè¡¨è¾¾å¹¶è¡Œåˆ†æ”¯ä¸åŒæ­¥
- **Ï€æ¼”ç®—**: æè¿°åŠ¨æ€é€šä¿¡è¿‡ç¨‹

#### 1.1.2 æŒä¹…æ€§æ¨¡å‹

é•¿æ—¶é—´è¿è¡Œçš„å·¥ä½œæµå¿…é¡»è€ƒè™‘æŒä¹…æ€§:

- **äº‹ä»¶æº¯æºç†è®º**: é€šè¿‡äº‹ä»¶åºåˆ—é‡å»ºçŠ¶æ€
- **å¹‚ç­‰æ€§ç†è®º**: ç¡®ä¿æ“ä½œå¯å®‰å…¨é‡å¤æ‰§è¡Œ
- **æœ€ç»ˆä¸€è‡´æ€§**: åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­å¤„ç†çŠ¶æ€åŒæ­¥

#### 1.1.3 å¹¶å‘å¤„ç†æ¨¡å‹

- **Actoræ¨¡å‹**: é€šè¿‡æ¶ˆæ¯ä¼ é€’åè°ƒå¹¶å‘å®ä½“
- **CSP(é€šä¿¡é¡ºåºè¿›ç¨‹)**: æ˜ç¡®å®šä¹‰è¿›ç¨‹é€šä¿¡æ¨¡å¼
- **åŸå­æ“ä½œä¸äº‹åŠ¡ç†è®º**: ç¡®ä¿çŠ¶æ€è½¬æ¢çš„ä¸€è‡´æ€§

### 1.2 è¯„ä¼°ç»´åº¦

| ç†è®ºå±‚é¢ç»´åº¦ | æƒé‡ | è¯„åˆ†æ ‡å‡† |
|------------|------|---------|
| çŠ¶æ€æ¨¡å‹å®Œå¤‡æ€§ | é«˜ | èƒ½å¦è¡¨è¾¾å¤æ‚ä¸šåŠ¡é€»è¾‘,åŒ…æ‹¬æ¡ä»¶åˆ†æ”¯ã€å¹¶è¡Œå’Œå¾ªç¯ |
| æŒä¹…åŒ–ä¿è¯ | é«˜ | åœ¨ç³»ç»Ÿå´©æºƒåæ¢å¤èƒ½åŠ› |
| å½¢å¼åŒ–éªŒè¯èƒ½åŠ› | ä¸­ | æ˜¯å¦æ”¯æŒå¯¹å·¥ä½œæµå±æ€§è¿›è¡Œå½¢å¼åŒ–éªŒè¯ |
| äº‹åŠ¡ä¸è¡¥å¿æ¨¡å‹ | é«˜ | å¤„ç†åˆ†å¸ƒå¼äº‹åŠ¡ä¸€è‡´æ€§çš„èƒ½åŠ› |
| å¹¶å‘å¤„ç†æ¨¡å‹ | ä¸­ | å¤„ç†å¹¶è¡Œæ‰§è¡Œå’Œç«äº‰æ¡ä»¶çš„èƒ½åŠ› |

## 2 äºŒã€æ¶æ„å±‚é¢åˆ†æ

### 2.1 æ¶æ„è®¾è®¡è€ƒé‡

#### 1.1.1 æ ¸å¿ƒç»„ä»¶æ¶æ„

å·¥ä½œæµå¼•æ“éœ€è¦ä»¥ä¸‹æ ¸å¿ƒç»„ä»¶:

- **å·¥ä½œæµå®šä¹‰å­˜å‚¨**: ä¿å­˜å·¥ä½œæµæ¨¡æ¿å’Œå®šä¹‰
- **å·¥ä½œæµå®ä¾‹ç®¡ç†å™¨**: åˆ›å»ºå’Œç®¡ç†å·¥ä½œæµå®ä¾‹
- **ä»»åŠ¡è°ƒåº¦å™¨**: åˆ†é…å’Œç›‘æ§ä»»åŠ¡æ‰§è¡Œ
- **çŠ¶æ€ç®¡ç†å™¨**: ç»´æŠ¤å’Œè½¬æ¢å·¥ä½œæµçŠ¶æ€
- **æŒä¹…åŒ–ç»„ä»¶**: ç¡®ä¿çŠ¶æ€å’Œäº‹ä»¶æŒä¹…åŒ–
- **æ´»åŠ¨æ‰§è¡Œå™¨**: æ‰§è¡Œå…·ä½“ä»»åŠ¡çš„ç»„ä»¶

#### 1.1.2 æ‰©å±•æ€§è®¾è®¡

- **æ’ä»¶æ¶æ„**: æ”¯æŒæ‰©å±•æ´»åŠ¨ç±»å‹å’Œè¿æ¥å™¨
- **ç‰ˆæœ¬åŒ–**: æ”¯æŒå·¥ä½œæµå®šä¹‰çš„ç‰ˆæœ¬ç®¡ç†
- **æ‰©ç¼©å®¹**: æ”¯æŒæ°´å¹³æ‰©å±•ä»¥å¤„ç†ä¸åŒè´Ÿè½½

#### 1.1.3 å¯ç”¨æ€§è®¾è®¡

- **æ•…éšœéš”ç¦»**: ç¡®ä¿å•ä¸ªå·¥ä½œæµå¤±è´¥ä¸å½±å“å…¶ä»–å®ä¾‹
- **è‡ªåŠ¨æ¢å¤**: ä»æ•…éšœç‚¹è‡ªåŠ¨æ¢å¤æ‰§è¡Œ
- **çŠ¶æ€ä¿æŠ¤**: é˜²æ­¢çŠ¶æ€æŸåå’Œä¸ä¸€è‡´

### 2.2 è¯„ä¼°ç»´åº¦

| æ¶æ„å±‚é¢ç»´åº¦ | æƒé‡ | è¯„åˆ†æ ‡å‡† |
|------------|------|---------|
| é«˜å¯ç”¨æ€§ | é«˜ | ç³»ç»Ÿæ•…éšœåçš„æ¢å¤èƒ½åŠ›å’Œæ— å•ç‚¹æ•…éšœè®¾è®¡ |
| å¯æ‰©å±•æ€§ | é«˜ | å¤„ç†å¢é•¿è´Ÿè½½çš„èƒ½åŠ›å’Œèµ„æºåˆ©ç”¨æ•ˆç‡ |
| æ¨¡å—è€¦åˆåº¦ | ä¸­ | ç»„ä»¶é—´è€¦åˆç¨‹åº¦å’Œæ›¿æ¢æ€§ |
| å¯ç›‘æ§æ€§ | ä¸­ | ç³»ç»Ÿå†…éƒ¨çŠ¶æ€çš„å¯è§‚å¯Ÿç¨‹åº¦ |
| å®‰å…¨æ€§ | ä¸­ | è®¿é—®æ§åˆ¶å’Œéš”ç¦»ä¿è¯ |

## 3 ä¸‰ã€é›†æˆå±‚é¢åˆ†æ

### 3.1 ä¸ç°æœ‰ç³»ç»Ÿé›†æˆ

#### 1.1.1 æ¥å£è®¾è®¡

- **APIè®¾è®¡**: RESTå’ŒgRPCæ¥å£è®¾è®¡
- **äº‹ä»¶æ¥å£**: åŸºäºäº‹ä»¶çš„é›†æˆæœºåˆ¶
- **SDKè®¾è®¡**: å®¢æˆ·ç«¯åº“çš„æ˜“ç”¨æ€§

#### 1.1.2 é€šä¿¡æ¨¡å¼

- **åŒæ­¥é€šä¿¡**: ç›´æ¥APIè°ƒç”¨æ¨¡å¼
- **å¼‚æ­¥é€šä¿¡**: åŸºäºæ¶ˆæ¯é˜Ÿåˆ—çš„é›†æˆ
- **å›è°ƒæœºåˆ¶**: é€šçŸ¥å¤–éƒ¨ç³»ç»Ÿçš„æ–¹æ³•

#### 1.1.3 ç¼–æ’ä¸åè°ƒ

- **æœåŠ¡é—´ç¼–æ’**: å·¥ä½œæµå¼•æ“ä½œä¸ºç¼–æ’å™¨çš„è§’è‰²
- **å¼‚æ„ç³»ç»Ÿé›†æˆ**: ä¸ä¸åŒæŠ€æœ¯æ ˆç³»ç»Ÿé›†æˆ
- **æ•°æ®è½¬æ¢**: å¤„ç†ä¸åŒç³»ç»Ÿé—´çš„æ•°æ®æ ¼å¼

### 3.2 è¯„ä¼°ç»´åº¦

| é›†æˆå±‚é¢ç»´åº¦ | æƒé‡ | è¯„åˆ†æ ‡å‡† |
|------------|------|---------|
| æ¥å£å®Œå¤‡æ€§ | é«˜ | æ¥å£è¦†ç›–æ‰€éœ€åŠŸèƒ½çš„ç¨‹åº¦ |
| åè®®å…¼å®¹æ€§ | ä¸­ | æ”¯æŒå¤šç§é›†æˆåè®®çš„èƒ½åŠ› |
| å¼‚æ­¥å¤„ç†èƒ½åŠ› | é«˜ | å¤„ç†éå®æ—¶å“åº”ç³»ç»Ÿçš„èƒ½åŠ› |
| é”™è¯¯å¤„ç†æœºåˆ¶ | é«˜ | å¤„ç†é›†æˆè¿‡ç¨‹ä¸­é”™è¯¯çš„æœºåˆ¶å®Œå¤‡æ€§ |
| é›†æˆä¾¿æ·æ€§ | ä¸­ | ä¸ç°æœ‰ç³»ç»Ÿé›†æˆçš„éš¾æ˜“ç¨‹åº¦ |

## 4 å››ã€å®ç°å±‚é¢åˆ†æ

### 4.1 Rustå®ç°è€ƒé‡

#### 1.1.1 ç±»å‹ç³»ç»Ÿåº”ç”¨

- **ç±»å‹çŠ¶æ€æ¨¡å¼**: ä½¿ç”¨Rustç±»å‹ç³»ç»Ÿä¿è¯çŠ¶æ€è½¬æ¢å®‰å…¨æ€§
- **å¯å˜æ€§æ§åˆ¶**: ä¸¥æ ¼åŒºåˆ†å¯å˜å’Œä¸å¯å˜å¼•ç”¨
- **ç‰¹å¾æŠ½è±¡**: ä¸ºä¸åŒç»„ä»¶å®šä¹‰æ¸…æ™°æ¥å£

#### 1.1.2 å¹¶å‘å¤„ç†

- **ä»»åŠ¡å¹¶è¡Œ**: ä½¿ç”¨tokioæ”¯æŒé«˜æ•ˆä»»åŠ¡è°ƒåº¦
- **é”ä¸åŒæ­¥åŸºå…ƒ**: é€‰æ‹©åˆé€‚çš„åŒæ­¥åŸè¯­
- **å¼‚æ­¥å¤„ç†**: é€‚å½“ä½¿ç”¨å¼‚æ­¥ç¼–ç¨‹æ¨¡å‹

#### 1.1.3 é”™è¯¯å¤„ç†ç­–ç•¥

- **é”™è¯¯ç±»å‹å±‚æ¬¡**: æ„å»ºæœ‰æ„ä¹‰çš„é”™è¯¯ç±»å‹å±‚æ¬¡ç»“æ„
- **æ•…éšœä¼ æ’­**: å®šä¹‰é”™è¯¯å¦‚ä½•åœ¨ç»„ä»¶é—´ä¼ æ’­
- **å›æ»šæœºåˆ¶**: å®ç°å‡ºé”™æ—¶çš„çŠ¶æ€å›æ»š

### 4.2 è¯„ä¼°ç»´åº¦

| å®ç°å±‚é¢ç»´åº¦ | æƒé‡ | è¯„åˆ†æ ‡å‡† |
|------------|------|---------|
| ç±»å‹å®‰å…¨æ€§ | é«˜ | åˆ©ç”¨Rustç±»å‹ç³»ç»Ÿä¿è¯å®‰å…¨çš„ç¨‹åº¦ |
| å†…å­˜æ•ˆç‡ | ä¸­ | ç³»ç»Ÿå†…å­˜ä½¿ç”¨æ•ˆç‡ |
| å¹¶å‘å¤„ç†èƒ½åŠ› | é«˜ | å¤„ç†å¹¶å‘ä»»åŠ¡çš„æ•ˆç‡å’Œå®‰å…¨æ€§ |
| é”™è¯¯å¤„ç†å®Œå¤‡æ€§ | é«˜ | é”™è¯¯å¤„ç†å’Œæ¢å¤ç­–ç•¥çš„å®Œå¤‡æ€§ |
| ä»£ç å¯ç»´æŠ¤æ€§ | ä¸­ | ä»£ç ç»“æ„å’Œæ–‡æ¡£çš„æ¸…æ™°åº¦ |

## 5 äº”ã€å·¥ä½œæµå¼•æ“å®ç°æ–¹æ¡ˆ

ç»¼åˆä¸Šè¿°åˆ†æ,æˆ‘è®¾è®¡äº†ä»¥ä¸‹è‡ªå»ºå·¥ä½œæµå¼•æ“çš„å®ç°æ–¹æ¡ˆ:

### 5.1 æ ¸å¿ƒæ¶æ„è®¾è®¡

```text
+---------------------+      +----------------------+
|  å·¥ä½œæµå®šä¹‰æœåŠ¡      |      |   å·¥ä½œæµå®ä¾‹æœåŠ¡     |
+---------------------+      +----------------------+
          |                             |
          v                             v
+---------------------+      +----------------------+
|  å·¥ä½œæµç‰ˆæœ¬å­˜å‚¨      |      |   å®ä¾‹çŠ¶æ€ç®¡ç†å™¨     |
+---------------------+      +----------------------+
                                       |
                                       v
+-------------------------------------------------+
|                 æ´»åŠ¨æ‰§è¡Œå™¨                      |
|  +-------------+  +------------+  +-----------+ |
|  | HTTPæ´»åŠ¨    |  | è„šæœ¬æ´»åŠ¨   |  | è‡ªå®šä¹‰æ´»åŠ¨ | |
|  +-------------+  +------------+  +-----------+ |
+-------------------------------------------------+
                       |
                       v
+-------------------------------------------------+
|                  æŒä¹…åŒ–å±‚                       |
|  +-------------+  +------------+  +-----------+ |
|  | äº‹ä»¶å­˜å‚¨    |  | çŠ¶æ€å­˜å‚¨   |  | å®šä¹‰å­˜å‚¨  | |
|  +-------------+  +------------+  +-----------+ |
+-------------------------------------------------+
```

### 5.2 åŸºäºRustç±»å‹ç³»ç»Ÿçš„å·¥ä½œæµçŠ¶æ€æ¨¡å‹

```rust
/// å·¥ä½œæµçŠ¶æ€ç‰¹å¾
pub trait WorkflowState: Send + Sync + Clone + 'static {
    /// å”¯ä¸€æ ‡è¯†ç¬¦
    fn state_type(&self) -> &'static str;
    
    /// æ˜¯å¦ä¸ºç»ˆæ€
    fn is_terminal(&self) -> bool;
}

/// å·¥ä½œæµäº‹ä»¶ç‰¹å¾
pub trait WorkflowEvent: Send + Sync + Clone + 'static {
    /// å”¯ä¸€æ ‡è¯†ç¬¦
    fn event_type(&self) -> &'static str;
    
    /// äº‹ä»¶æ•°æ®
    fn payload(&self) -> &serde_json::Value;
}

/// å·¥ä½œæµè½¬æ¢å™¨
pub struct WorkflowTransition<S: WorkflowState, E: WorkflowEvent> {
    /// æºçŠ¶æ€
    from_state: String,
    
    /// ç›®æ ‡çŠ¶æ€
    to_state: String,
    
    /// è§¦å‘äº‹ä»¶ç±»å‹
    event_type: String,
    
    /// æ¡ä»¶æ£€æŸ¥ (å¯é€‰)
    condition: Option<Box<dyn Fn(&S, &E, &WorkflowContext) -> bool + Send + Sync>>,
    
    /// è½¬æ¢å‰åŠ¨ä½œ (å¯é€‰)
    pre_action: Option<Box<dyn Fn(&S, &E, &mut WorkflowContext) -> BoxFuture<'static, Result<(), WorkflowError>> + Send + Sync>>,
    
    /// è½¬æ¢ååŠ¨ä½œ (å¯é€‰)
    post_action: Option<Box<dyn Fn(&S, &E, &mut WorkflowContext) -> BoxFuture<'static, Result<(), WorkflowError>> + Send + Sync>>,
}

/// å·¥ä½œæµå®šä¹‰
pub struct WorkflowDefinition<S: WorkflowState, E: WorkflowEvent> {
    /// å·¥ä½œæµç±»å‹
    workflow_type: String,
    
    /// ç‰ˆæœ¬
    version: String,
    
    /// åˆå§‹çŠ¶æ€
    initial_state: S,
    
    /// çŠ¶æ€è½¬æ¢è¡¨
    transitions: Vec<WorkflowTransition<S, E>>,
    
    /// è¶…æ—¶é…ç½®
    timeout_config: Option<WorkflowTimeoutConfig>,
    
    /// é‡è¯•ç­–ç•¥
    retry_policy: Option<RetryPolicy>,
}

/// å·¥ä½œæµå®ä¾‹
pub struct WorkflowInstance<S: WorkflowState, E: WorkflowEvent> {
    /// å®ä¾‹ID
    id: String,
    
    /// å·¥ä½œæµç±»å‹
    workflow_type: String,
    
    /// å·¥ä½œæµç‰ˆæœ¬
    workflow_version: String,
    
    /// å½“å‰çŠ¶æ€
    current_state: S,
    
    /// ä¸Šä¸‹æ–‡æ•°æ®
    context: WorkflowContext,
    
    /// äº‹ä»¶å†å²
    event_history: Vec<HistoricalEvent<E>>,
    
    /// åˆ›å»ºæ—¶é—´
    created_at: DateTime<Utc>,
    
    /// æœ€åæ›´æ–°æ—¶é—´
    updated_at: DateTime<Utc>,
    
    /// å®Œæˆæ—¶é—´ (å¦‚æœå·²å®Œæˆ)
    completed_at: Option<DateTime<Utc>>,
}
```

### 5.3 äº‹ä»¶æº¯æºå®ç°

```rust
/// äº‹ä»¶å­˜å‚¨æ¥å£
#[async_trait]
pub trait EventStore: Send + Sync {
    /// é™„åŠ äº‹ä»¶åˆ°å·¥ä½œæµå®ä¾‹
    async fn append_event<E: WorkflowEvent>(
        &self,
        workflow_id: &str,
        event: E,
        expected_version: Option<u64>,
    ) -> Result<u64, EventStoreError>;
    
    /// è¯»å–å·¥ä½œæµå®ä¾‹äº‹ä»¶
    async fn read_events<E: WorkflowEvent + DeserializeOwned>(
        &self,
        workflow_id: &str,
    ) -> Result<Vec<HistoricalEvent<E>>, EventStoreError>;
    
    /// ä»æŒ‡å®šç‰ˆæœ¬å¼€å§‹è¯»å–äº‹ä»¶
    async fn read_events_from<E: WorkflowEvent + DeserializeOwned>(
        &self,
        workflow_id: &str, 
        start_version: u64,
    ) -> Result<Vec<HistoricalEvent<E>>, EventStoreError>;
}

/// å·¥ä½œæµå¼•æ“
pub struct WorkflowEngine<S: WorkflowState, E: WorkflowEvent> {
    /// å·¥ä½œæµå®šä¹‰æ³¨å†Œè¡¨
    definition_registry: Arc<RwLock<HashMap<String, WorkflowDefinition<S, E>>>>,
    
    /// äº‹ä»¶å­˜å‚¨
    event_store: Arc<dyn EventStore>,
    
    /// å·¥ä½œæµçŠ¶æ€å­˜å‚¨
    state_store: Arc<dyn WorkflowStateStore<S>>,
    
    /// æ´»åŠ¨æ‰§è¡Œå™¨
    activity_executor: Arc<dyn ActivityExecutor>,
}

impl<S: WorkflowState + DeserializeOwned, E: WorkflowEvent + DeserializeOwned> WorkflowEngine<S, E> {
    /// åˆ›å»ºæ–°å·¥ä½œæµå®ä¾‹
    pub async fn create_workflow(
        &self,
        workflow_type: &str,
        input: serde_json::Value,
    ) -> Result<String, WorkflowError> {
        // 1. è·å–å·¥ä½œæµå®šä¹‰
        let definition = self.get_latest_definition(workflow_type).await?;
        
        // 2. åˆ›å»ºæ–°å·¥ä½œæµID
        let workflow_id = Uuid::new_v4().to_string();
        
        // 3. åˆ›å»ºåˆå§‹ä¸Šä¸‹æ–‡
        let mut context = WorkflowContext::new();
        context.set_input(input);
        
        // 4. åˆ›å»ºå·¥ä½œæµå®ä¾‹
        let instance = WorkflowInstance {
            id: workflow_id.clone(),
            workflow_type: workflow_type.to_string(),
            workflow_version: definition.version.clone(),
            current_state: definition.initial_state.clone(),
            context,
            event_history: Vec::new(),
            created_at: Utc::now(),
            updated_at: Utc::now(),
            completed_at: None,
        };
        
        // 5. ä¿å­˜åˆå§‹çŠ¶æ€
        self.state_store.save_state(&workflow_id, &instance.current_state, 0).await?;
        
        // 6. è§¦å‘å·¥ä½œæµåˆ›å»ºäº‹ä»¶
        self.trigger_event(
            &workflow_id,
            // åˆ›å»ºå·¥ä½œæµåˆ›å»ºäº‹ä»¶...
        ).await?;
        
        Ok(workflow_id)
    }
    
    /// è§¦å‘å·¥ä½œæµäº‹ä»¶
    pub async fn trigger_event(
        &self,
        workflow_id: &str,
        event: E,
    ) -> Result<S, WorkflowError> {
        // 1. åŠ è½½å½“å‰å·¥ä½œæµå®ä¾‹
        let instance = self.load_instance(workflow_id).await?;
        
        // 2. è·å–å·¥ä½œæµå®šä¹‰
        let definition = self.get_definition(&instance.workflow_type, &instance.workflow_version).await?;
        
        // 3. æŸ¥æ‰¾é€‚ç”¨çš„è½¬æ¢
        let transition = definition.find_transition(&instance.current_state, &event)?;
        
        // 4. æ£€æŸ¥æ¡ä»¶æ˜¯å¦æ»¡è¶³
        if let Some(condition) = &transition.condition {
            if !condition(&instance.current_state, &event, &instance.context) {
                return Err(WorkflowError::ConditionNotMet);
            }
        }
        
        // 5. æ‰§è¡Œå‰ç½®åŠ¨ä½œ
        let mut context = instance.context.clone();
        if let Some(pre_action) = &transition.pre_action {
            pre_action(&instance.current_state, &event, &mut context).await?;
        }
        
        // 6. æ‰§è¡ŒçŠ¶æ€è½¬æ¢
        let new_state = self.create_state(&transition.to_state)?;
        
        // 7. ä¿å­˜äº‹ä»¶
        let event_version = self.event_store.append_event(
            workflow_id,
            event.clone(),
            Some(instance.event_history.len() as u64),
        ).await?;
        
        // 8. ä¿å­˜æ–°çŠ¶æ€
        self.state_store.save_state(workflow_id, &new_state, event_version).await?;
        
        // 9. æ‰§è¡Œåç½®åŠ¨ä½œ
        if let Some(post_action) = &transition.post_action {
            post_action(&instance.current_state, &event, &mut context).await?;
        }
        
        // 10. æ£€æŸ¥æ˜¯å¦å®Œæˆ
        if new_state.is_terminal() {
            // æ›´æ–°å®ŒæˆçŠ¶æ€...
        }
        
        Ok(new_state)
    }
    
    /// åŠ è½½å·¥ä½œæµå®ä¾‹
    async fn load_instance(&self, workflow_id: &str) -> Result<WorkflowInstance<S, E>, WorkflowError> {
        // 1. è·å–å½“å‰çŠ¶æ€
        let state = self.state_store.get_state(workflow_id).await?;
        
        // 2. è·å–äº‹ä»¶å†å²
        let events = self.event_store.read_events::<E>(workflow_id).await?;
        
        // 3. åŠ è½½å·¥ä½œæµç±»å‹å’Œç‰ˆæœ¬
        let metadata = self.state_store.get_metadata(workflow_id).await?;
        
        // 4. é‡å»ºä¸Šä¸‹æ–‡
        let mut context = WorkflowContext::new();
        for event in &events {
            // åº”ç”¨äº‹ä»¶å¯¹ä¸Šä¸‹æ–‡çš„å½±å“...
        }
        
        Ok(WorkflowInstance {
            id: workflow_id.to_string(),
            workflow_type: metadata.workflow_type,
            workflow_version: metadata.workflow_version,
            current_state: state,
            context,
            event_history: events,
            created_at: metadata.created_at,
            updated_at: metadata.updated_at,
            completed_at: metadata.completed_at,
        })
    }
}
```

### 5.4 æ´»åŠ¨æ‰§è¡Œå™¨å®ç°

```rust
/// æ´»åŠ¨å®šä¹‰
pub struct ActivityDefinition {
    /// æ´»åŠ¨ç±»å‹
    activity_type: String,
    
    /// ç‰ˆæœ¬
    version: String,
    
    /// è¶…æ—¶è®¾ç½®
    timeout: Duration,
    
    /// é‡è¯•ç­–ç•¥
    retry_policy: Option<RetryPolicy>,
    
    /// æ´»åŠ¨å¤„ç†å™¨
    handler: Box<dyn Fn(serde_json::Value) -> BoxFuture<'static, Result<serde_json::Value, ActivityError>> + Send + Sync>,
}

/// æ´»åŠ¨æ‰§è¡Œå™¨
#[async_trait]
pub trait ActivityExecutor: Send + Sync {
    /// æ³¨å†Œæ´»åŠ¨å®šä¹‰
    async fn register_activity(&self, definition: ActivityDefinition) -> Result<(), ActivityError>;
    
    /// æ‰§è¡Œæ´»åŠ¨
    async fn execute_activity(
        &self,
        activity_type: &str,
        input: serde_json::Value,
        correlation_id: &str,
    ) -> Result<serde_json::Value, ActivityError>;
}

/// æœ¬åœ°æ´»åŠ¨æ‰§è¡Œå™¨å®ç°
pub struct LocalActivityExecutor {
    /// æ´»åŠ¨å®šä¹‰æ³¨å†Œè¡¨
    definitions: RwLock<HashMap<String, ActivityDefinition>>,
    
    /// æ‰§è¡Œå†å²
    execution_history: RwLock<HashMap<String, ActivityExecution>>,
    
    /// æŒ‡æ ‡æ”¶é›†
    metrics: Arc<Metrics>,
}

#[async_trait]
impl ActivityExecutor for LocalActivityExecutor {
    async fn register_activity(&self, definition: ActivityDefinition) -> Result<(), ActivityError> {
        let mut definitions = self.definitions.write().await;
        let key = format!("{}:{}", definition.activity_type, definition.version);
        definitions.insert(key, definition);
        Ok(())
    }
    
    #[instrument(skip(self, input), fields(activity_type = %activity_type, correlation_id = %correlation_id))]
    async fn execute_activity(
        &self,
        activity_type: &str,
        input: serde_json::Value,
        correlation_id: &str,
    ) -> Result<serde_json::Value, ActivityError> {
        // 1. è®¡æ—¶å¼€å§‹
        let timer = self.metrics.start_timer(&format!("activity.{}.duration", activity_type));
        
        // 2. è®°å½•æ´»åŠ¨å¼€å§‹
        info!("å¼€å§‹æ‰§è¡Œæ´»åŠ¨: {}", activity_type);
        self.metrics.increment_counter(&format!("activity.{}.started", activity_type));
        
        // 3. æŸ¥æ‰¾æ´»åŠ¨å®šä¹‰
        let definitions = self.definitions.read().await;
        let latest_version = self.get_latest_version(activity_type, &definitions)?;
        let key = format!("{}:{}", activity_type, latest_version);
        
        let definition = definitions.get(&key)
            .ok_or_else(|| ActivityError::ActivityNotFound(activity_type.to_string()))?;
        
        // 4. ä½¿ç”¨è¶…æ—¶å’Œé‡è¯•ç­–ç•¥æ‰§è¡Œ
        let result = if let Some(retry_policy) = &definition.retry_policy {
            self.execute_with_retry(&definition.handler, input.clone(), retry_policy, definition.timeout).await
        } else {
            tokio::time::timeout(
                definition.timeout,
                (definition.handler)(input.clone())
            ).await.map_err(|_| ActivityError::Timeout)??
        };
        
        // 5. è®°å½•æ‰§è¡Œå†å²
        let mut history = self.execution_history.write().await;
        history.insert(correlation_id.to_string(), ActivityExecution {
            activity_type: activity_type.to_string(),
            activity_version: latest_version,
            input,
            output: result.clone(),
            started_at: Utc::now() - timer.elapsed_duration(),
            completed_at: Utc::now(),
            status: "completed".to_string(),
        });
        
        // 6. è®°å½•æˆåŠŸæŒ‡æ ‡
        self.metrics.increment_counter(&format!("activity.{}.completed", activity_type));
        timer.observe_duration();
        
        Ok(result)
    }
}
```

### 5.5 APIæ¥å£è®¾è®¡

```rust
/// å·¥ä½œæµAPIæ§åˆ¶å™¨
pub struct WorkflowApiController<S: WorkflowState, E: WorkflowEvent> {
    workflow_engine: Arc<WorkflowEngine<S, E>>,
}

impl<S: WorkflowState + DeserializeOwned, E: WorkflowEvent + DeserializeOwned> WorkflowApiController<S, E> {
    // REST APIå®ç°
    
    /// åˆ›å»ºå·¥ä½œæµå®ä¾‹
    #[instrument(skip(self, req), fields(workflow_type = %req.workflow_type))]
    async fn create_workflow(&self, req: web::Json<CreateWorkflowRequest>) -> impl Responder {
        match self.workflow_engine.create_workflow(&req.workflow_type, req.input.clone()).await {
            Ok(workflow_id) => HttpResponse::Created().json(json!({
                "workflow_id": workflow_id,
                "status": "created"
            })),
            Err(e) => {
                error!("åˆ›å»ºå·¥ä½œæµå¤±è´¥: {:?}", e);
                
                let status_code = match e {
                    WorkflowError::WorkflowNotFound(_) => StatusCode::NOT_FOUND,
                    WorkflowError::ValidationError(_) => StatusCode::BAD_REQUEST,
                    _ => StatusCode::INTERNAL_SERVER_ERROR,
                };
                
                HttpResponse::build(status_code).json(json!({
                    "error": e.to_string()
                }))
            }
        }
    }
    
    /// è§¦å‘å·¥ä½œæµäº‹ä»¶
    #[instrument(skip(self, req), fields(workflow_id = %workflow_id))]
    async fn trigger_event(&self, workflow_id: web::Path<String>, req: web::Json<TriggerEventRequest>) -> impl Responder {
        // ä»è¯·æ±‚åˆ›å»ºäº‹ä»¶...
        let event = self.create_event_from_request(&req).map_err(|e| {
            HttpResponse::BadRequest().json(json!({
                "error": format!("æ— æ•ˆäº‹ä»¶: {}", e)
            }))
        })?;
        
        match self.workflow_engine.trigger_event(&workflow_id, event).await {
            Ok(new_state) => HttpResponse::Ok().json(json!({
                "workflow_id": *workflow_id,
                "new_state": new_state.state_type(),
                "is_terminal": new_state.is_terminal()
            })),
            Err(e) => {
                error!("è§¦å‘äº‹ä»¶å¤±è´¥: {:?}", e);
                
                let status_code = match e {
                    WorkflowError::WorkflowNotFound(_) => StatusCode::NOT_FOUND,
                    WorkflowError::InvalidTransition => StatusCode::BAD_REQUEST,
                    WorkflowError::ConditionNotMet => StatusCode::BAD_REQUEST,
                    _ => StatusCode::INTERNAL_SERVER_ERROR,
                };
                
                HttpResponse::build(status_code).json(json!({
                    "error": e.to_string()
                }))
            }
        }
    }
    
    /// è·å–å·¥ä½œæµçŠ¶æ€
    #[instrument(skip(self), fields(workflow_id = %workflow_id))]
    async fn get_workflow_state(&self, workflow_id: web::Path<String>) -> impl Responder {
        match self.workflow_engine.get_workflow_state(&workflow_id).await {
            Ok(state_info) => HttpResponse::Ok().json(state_info),
            Err(e) => {
                error!("è·å–å·¥ä½œæµçŠ¶æ€å¤±è´¥: {:?}", e);
                
                let status_code = match e {
                    WorkflowError::WorkflowNotFound(_) => StatusCode::NOT_FOUND,
                    _ => StatusCode::INTERNAL_SERVER_ERROR,
                };
                
                HttpResponse::build(status_code).json(json!({
                    "error": e.to_string()
                }))
            }
        }
    }
    
    /// è·å–å·¥ä½œæµå†å²
    #[instrument(skip(self), fields(workflow_id = %workflow_id))]
    async fn get_workflow_history(&self, workflow_id: web::Path<String>) -> impl Responder {
        match self.workflow_engine.get_workflow_history(&workflow_id).await {
            Ok(history) => HttpResponse::Ok().json(history),
            Err(e) => {
                error!("è·å–å·¥ä½œæµå†å²å¤±è´¥: {:?}", e);
                
                let status_code = match e {
                    WorkflowError::WorkflowNotFound(_) => StatusCode::NOT_FOUND,
                    _ => StatusCode::INTERNAL_SERVER_ERROR,
                };
                
                HttpResponse::build(status_code).json(json!({
                    "error": e.to_string()
                }))
            }
        }
    }
}
```

## 6 å…­ã€å®ç°æ­¥éª¤ä¸è·¯çº¿å›¾

åŸºäºåˆ†æ,æˆ‘æ¨èä»¥ä¸‹å®ç°æ­¥éª¤:

### 6.1 ç¬¬ä¸€é˜¶æ®µ æ ¸å¿ƒå¼•æ“å®ç° (3-4å‘¨)

1. **è®¾è®¡å·¥ä½œæµæ¨¡å‹** (1å‘¨)
   - å®šä¹‰å·¥ä½œæµçŠ¶æ€ã€äº‹ä»¶ã€è½¬æ¢æ¥å£
   - å®ç°åŸºç¡€å·¥ä½œæµå®šä¹‰å’Œå®ä¾‹ç»“æ„
   - ç¼–å†™å•å…ƒæµ‹è¯•éªŒè¯æ¨¡å‹

2. **å®ç°æŒä¹…åŒ–å±‚** (1å‘¨)
   - å¼€å‘äº‹ä»¶å­˜å‚¨æ¥å£åŠPostgreSQLå®ç°
   - å®ç°çŠ¶æ€å­˜å‚¨åŠæŸ¥è¯¢æ¥å£
   - è®¾è®¡å®ç°å¿«ç…§æœºåˆ¶

3. **æ ¸å¿ƒå¼•æ“å®ç°** (1-2å‘¨)
   - å®Œæˆå·¥ä½œæµå®ä¾‹åˆ›å»ºå’Œæ‰§è¡Œé€»è¾‘
   - å®ç°çŠ¶æ€è½¬æ¢å’Œäº‹ä»¶å¤„ç†
   - æ„å»ºé”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶

### 6.2 ç¬¬äºŒé˜¶æ®µ æ´»åŠ¨æ‰§è¡Œä¸è°ƒåº¦ (2-3å‘¨)

1. **æ´»åŠ¨æ¨¡å‹ä¸æ‰§è¡Œå™¨** (1å‘¨)
   - è®¾è®¡æ´»åŠ¨æ¥å£å’Œç”Ÿå‘½å‘¨æœŸ
   - å®ç°åŸºç¡€æ´»åŠ¨ç±»å‹(HTTPã€è„šæœ¬ç­‰)
   - æ„å»ºæ´»åŠ¨ç»“æœå¤„ç†é€»è¾‘

1. **ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ** (1-2å‘¨)
   - å®ç°åŸºäºtokioçš„ä»»åŠ¡è°ƒåº¦
   - å®Œæˆé‡è¯•å’Œè¶…æ—¶å¤„ç†
   - å¼€å‘èµ„æºé™åˆ¶å’Œé˜Ÿåˆ—æœºåˆ¶

### 6.3 ç¬¬ä¸‰é˜¶æ®µ APIå’Œé›†æˆ (2-3å‘¨)

1. **APIå±‚å®ç°** (1å‘¨)
   - è®¾è®¡å¹¶å®ç°REST API
   - å¼€å‘gRPCæœåŠ¡æ¥å£
   - ç¼–å†™OpenAPIè§„èŒƒ

1. **é›†æˆåŠŸèƒ½** (1-2å‘¨)
   - å®ç°å›è°ƒå’Œé€šçŸ¥æœºåˆ¶
   - æ·»åŠ å¤–éƒ¨ç³»ç»Ÿè¿æ¥å™¨
   - å¼€å‘äº‹ä»¶è®¢é˜…æ¥å£

### 6.4 ç¬¬å››é˜¶æ®µ è¿ç»´ä¸å¯è§‚æµ‹æ€§ (2å‘¨)

1. **ç›‘æ§ä¸æŒ‡æ ‡** (1å‘¨)
   - æ·»åŠ PrometheusæŒ‡æ ‡æ”¶é›†
   - å®ç°å…³é”®äº‹ä»¶æ—¥å¿—
   - é›†æˆåˆ†å¸ƒå¼è¿½è¸ª

1. **ç®¡ç†åŠŸèƒ½** (1å‘¨)
   - å¼€å‘è¿è¡Œæ—¶é…ç½®ç®¡ç†
   - å®ç°å·¥ä½œæµæš‚åœå’Œæ¢å¤
   - æ·»åŠ æ€§èƒ½è°ƒä¼˜é€‰é¡¹

### 6.5 æ€»ç»“ æ€§èƒ½ä¸æˆç†Ÿåº¦è¯„ä¼°ç»´åº¦

| ç»´åº¦ | åˆæœŸé˜¶æ®µ | æˆç†Ÿé˜¶æ®µ | å‡çº§è·¯å¾„ |
|-----|---------|---------|---------|
| å¹¶å‘å¤„ç†èƒ½åŠ› | å•æœºå¤šçº¿ç¨‹ | åˆ†å¸ƒå¼æ‰§è¡Œ | é€šè¿‡åˆ†å¸ƒå¼äº‹ä»¶æºè®¾è®¡å®ç°æ‰©å±• |
| æŒä¹…åŒ–æ€§èƒ½ | å•åº“äº‹åŠ¡ä¿è¯ | å¤šçº§å­˜å‚¨ä¸ç¼“å­˜ | æ·»åŠ è¯»å†™åˆ†ç¦»å’Œç¼“å­˜å±‚ |
| å¯ç”¨æ€§ | å•ç‚¹éƒ¨ç½² | å¤šå‰¯æœ¬é«˜å¯ç”¨ | å®ç°ä¸»å¤‡åˆ‡æ¢å’ŒçŠ¶æ€å¤åˆ¶ |
| æ‰©å±•æ€§ | åŸºç¡€æ´»åŠ¨ç±»å‹ | æ’ä»¶ç”Ÿæ€ç³»ç»Ÿ | è®¾è®¡æ’ä»¶æ¥å£å’Œæ³¨å†Œæœºåˆ¶ |
| ç›‘æ§èƒ½åŠ› | åŸºç¡€æŒ‡æ ‡å’Œæ—¥å¿— | å®Œæ•´å¯è§‚æµ‹æ€§æ ˆ | é€æ­¥æ·»åŠ è¯¦ç»†æŒ‡æ ‡å’Œè¿½è¸ªç‚¹ |

## 7 ä¸ƒã€æ ¸å¿ƒä»£ç å®ç°ç¤ºä¾‹

ä¸ºäº†æ›´å…·ä½“åœ°å±•ç¤ºå·¥ä½œæµå¼•æ“çš„å®ç°,ä¸‹é¢æä¾›å‡ ä¸ªå…³é”®ç»„ä»¶çš„è¯¦ç»†ä»£ç :

### 7.1 æ ¸å¿ƒçŠ¶æ€æœºå®ç°

```rust
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;
use serde::{Serialize, Deserialize};
use async_trait::async_trait;
use futures::future::BoxFuture;
use uuid::Uuid;
use chrono::{DateTime, Utc};
use tracing::{info, error, instrument};

/// å·¥ä½œæµçŠ¶æ€ç‰¹å¾
#[async_trait]
pub trait WorkflowState: Send + Sync + Clone + 'static {
    /// çŠ¶æ€ç±»å‹åç§°
    fn state_type(&self) -> &'static str;
    
    /// æ˜¯å¦ä¸ºç»ˆæ€
    fn is_terminal(&self) -> bool;
    
    /// å°†çŠ¶æ€åºåˆ—åŒ–ä¸ºJSON
    fn to_json(&self) -> Result<serde_json::Value, serde_json::Error>;
    
    /// ä»JSONååºåˆ—åŒ–çŠ¶æ€
    fn from_json(json: &serde_json::Value) -> Result<Self, serde_json::Error> where Self: Sized;
}

/// å·¥ä½œæµäº‹ä»¶ç‰¹å¾
#[async_trait]
pub trait WorkflowEvent: Send + Sync + Clone + 'static {
    /// äº‹ä»¶ç±»å‹åç§°
    fn event_type(&self) -> &'static str;
    
    /// è·å–äº‹ä»¶è½½è·
    fn payload(&self) -> &serde_json::Value;
    
    /// å°†äº‹ä»¶åºåˆ—åŒ–ä¸ºJSON
    fn to_json(&self) -> Result<serde_json::Value, serde_json::Error>;
    
    /// ä»JSONååºåˆ—åŒ–äº‹ä»¶
    fn from_json(json: &serde_json::Value) -> Result<Self, serde_json::Error> where Self: Sized;
}

/// å·¥ä½œæµä¸Šä¸‹æ–‡,å­˜å‚¨å·¥ä½œæµæ‰§è¡ŒæœŸé—´çš„æ•°æ®
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct WorkflowContext {
    /// è¾“å…¥æ•°æ®
    input: serde_json::Value,
    
    /// è¾“å‡ºæ•°æ®
    output: Option<serde_json::Value>,
    
    /// å˜é‡å­˜å‚¨
    variables: HashMap<String, serde_json::Value>,
    
    /// ä¸´æ—¶æ•°æ®(ä¸ä¼šæŒä¹…åŒ–)
    #[serde(skip)]
    transient_data: HashMap<String, serde_json::Value>,
}

impl WorkflowContext {
    pub fn new() -> Self {
        Self {
            input: serde_json::Value::Null,
            output: None,
            variables: HashMap::new(),
            transient_data: HashMap::new(),
        }
    }
    
    pub fn set_input(&mut self, input: serde_json::Value) {
        self.input = input;
    }
    
    pub fn set_output(&mut self, output: serde_json::Value) {
        self.output = Some(output);
    }
    
    pub fn get_variable(&self, name: &str) -> Option<&serde_json::Value> {
        self.variables.get(name)
    }
    
    pub fn set_variable(&mut self, name: &str, value: serde_json::Value) {
        self.variables.insert(name.to_string(), value);
    }
    
    pub fn get_transient(&self, name: &str) -> Option<&serde_json::Value> {
        self.transient_data.get(name)
    }
    
    pub fn set_transient(&mut self, name: &str, value: serde_json::Value) {
        self.transient_data.insert(name.to_string(), value);
    }
}

/// å†å²äº‹ä»¶è®°å½•
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct HistoricalEvent<E: WorkflowEvent> {
    /// äº‹ä»¶
    pub event: E,
    
    /// äº‹ä»¶åºåˆ—å·
    pub sequence: u64,
    
    /// å‘ç”Ÿæ—¶é—´
    pub timestamp: DateTime<Utc>,
    
    /// å…ƒæ•°æ®
    pub metadata: serde_json::Value,
}

/// å·¥ä½œæµè½¬æ¢å®šä¹‰
pub struct WorkflowTransition<S: WorkflowState, E: WorkflowEvent> {
    /// æºçŠ¶æ€ç±»å‹
    pub from_state: String,
    
    /// ç›®æ ‡çŠ¶æ€ç±»å‹
    pub to_state: String,
    
    /// è§¦å‘äº‹ä»¶ç±»å‹
    pub event_type: String,
    
    /// è½¬æ¢æ¡ä»¶(å¯é€‰)
    pub condition: Option<Box<dyn Fn(&S, &E, &WorkflowContext) -> bool + Send + Sync>>,
    
    /// è½¬æ¢å‰åŠ¨ä½œ(å¯é€‰)
    pub pre_action: Option<Box<dyn Fn(&S, &E, &mut WorkflowContext) -> BoxFuture<'static, Result<(), WorkflowError>> + Send + Sync>>,
    
    /// è½¬æ¢ååŠ¨ä½œ(å¯é€‰)
    pub post_action: Option<Box<dyn Fn(&S, &E, &mut WorkflowContext) -> BoxFuture<'static, Result<(), WorkflowError>> + Send + Sync>>,
}

/// å·¥ä½œæµå®šä¹‰
pub struct WorkflowDefinition<S: WorkflowState, E: WorkflowEvent> {
    /// å·¥ä½œæµç±»å‹
    pub workflow_type: String,
    
    /// ç‰ˆæœ¬
    pub version: String,
    
    /// åˆå§‹çŠ¶æ€
    pub initial_state: S,
    
    /// çŠ¶æ€è½¬æ¢è¡¨
    pub transitions: Vec<WorkflowTransition<S, E>>,
    
    /// è¶…æ—¶é…ç½®(å¯é€‰)
    pub timeout_config: Option<WorkflowTimeoutConfig>,
    
    /// é‡è¯•ç­–ç•¥(å¯é€‰)
    pub retry_policy: Option<RetryPolicy>,
}

impl<S: WorkflowState, E: WorkflowEvent> WorkflowDefinition<S, E> {
    /// æŸ¥æ‰¾é€‚ç”¨çš„è½¬æ¢
    pub fn find_transition(&self, current_state: &S, event: &E) -> Result<&WorkflowTransition<S, E>, WorkflowError> {
        for transition in &self.transitions {
            if transition.from_state == current_state.state_type() && 
               transition.event_type == event.event_type() {
                return Ok(transition);
            }
        }
        
        Err(WorkflowError::InvalidTransition(format!(
            "ä»çŠ¶æ€ {} æ²¡æœ‰é’ˆå¯¹äº‹ä»¶ {} çš„æœ‰æ•ˆè½¬æ¢",
            current_state.state_type(),
            event.event_type()
        )))
    }
}

/// å·¥ä½œæµå®ä¾‹
pub struct WorkflowInstance<S: WorkflowState, E: WorkflowEvent> {
    /// å®ä¾‹ID
    pub id: String,
    
    /// å·¥ä½œæµç±»å‹
    pub workflow_type: String,
    
    /// å·¥ä½œæµç‰ˆæœ¬
    pub workflow_version: String,
    
    /// å½“å‰çŠ¶æ€
    pub current_state: S,
    
    /// ä¸Šä¸‹æ–‡æ•°æ®
    pub context: WorkflowContext,
    
    /// äº‹ä»¶å†å²
    pub event_history: Vec<HistoricalEvent<E>>,
    
    /// åˆ›å»ºæ—¶é—´
    pub created_at: DateTime<Utc>,
    
    /// æœ€åæ›´æ–°æ—¶é—´
    pub updated_at: DateTime<Utc>,
    
    /// å®Œæˆæ—¶é—´(å¦‚æœå·²å®Œæˆ)
    pub completed_at: Option<DateTime<Utc>>,
}

/// å·¥ä½œæµé”™è¯¯ç±»å‹
#[derive(Debug, thiserror::Error)]
pub enum WorkflowError {
    #[error("å·¥ä½œæµ {0} æœªæ‰¾åˆ°")]
    WorkflowNotFound(String),
    
    #[error("å·¥ä½œæµå®ä¾‹ {0} æœªæ‰¾åˆ°")]
    InstanceNotFound(String),
    
    #[error("æ— æ•ˆçš„çŠ¶æ€è½¬æ¢: {0}")]
    InvalidTransition(String),
    
    #[error("è½¬æ¢æ¡ä»¶æœªæ»¡è¶³")]
    ConditionNotMet,
    
    #[error("çŠ¶æ€æŒä¹…åŒ–é”™è¯¯: {0}")]
    StatePersistenceError(String),
    
    #[error("äº‹ä»¶å­˜å‚¨é”™è¯¯: {0}")]
    EventStoreError(String),
    
    #[error("æ´»åŠ¨æ‰§è¡Œé”™è¯¯: {0}")]
    ActivityError(String),
    
    #[error("åºåˆ—åŒ–é”™è¯¯: {0}")]
    SerializationError(String),
    
    #[error("å¹¶å‘ä¿®æ”¹å†²çª")]
    ConcurrencyConflict,
    
    #[error("å·¥ä½œæµè¶…æ—¶")]
    WorkflowTimeout,
    
    #[error("éªŒè¯é”™è¯¯: {0}")]
    ValidationError(String),
    
    #[error("å†…éƒ¨é”™è¯¯: {0}")]
    InternalError(String),
}
```

### 7.2 äº‹ä»¶å­˜å‚¨å®ç°

```rust
use sqlx::{PgPool, postgres::PgQueryResult};
use serde::{Serialize, Deserialize};
use chrono::{DateTime, Utc};
use async_trait::async_trait;
use tracing::{info, error, instrument};
use std::sync::Arc;

/// äº‹ä»¶å­˜å‚¨æ¥å£
#[async_trait]
pub trait EventStore: Send + Sync {
    /// é™„åŠ äº‹ä»¶åˆ°å·¥ä½œæµå®ä¾‹
    async fn append_event<E: WorkflowEvent + Serialize>(
        &self,
        workflow_id: &str,
        event: E,
        expected_version: Option<u64>,
    ) -> Result<u64, EventStoreError>;
    
    /// è¯»å–å·¥ä½œæµå®ä¾‹äº‹ä»¶
    async fn read_events<E: WorkflowEvent + for<'de> Deserialize<'de>>(
        &self,
        workflow_id: &str,
    ) -> Result<Vec<HistoricalEvent<E>>, EventStoreError>;
    
    /// ä»æŒ‡å®šç‰ˆæœ¬å¼€å§‹è¯»å–äº‹ä»¶
    async fn read_events_from<E: WorkflowEvent + for<'de> Deserialize<'de>>(
        &self,
        workflow_id: &str, 
        start_version: u64,
    ) -> Result<Vec<HistoricalEvent<E>>, EventStoreError>;
}

/// äº‹ä»¶å­˜å‚¨é”™è¯¯
#[derive(Debug, thiserror::Error)]
pub enum EventStoreError {
    #[error("æ•°æ®åº“é”™è¯¯: {0}")]
    DatabaseError(String),
    
    #[error("åºåˆ—åŒ–é”™è¯¯: {0}")]
    SerializationError(String),
    
    #[error("å·¥ä½œæµå®ä¾‹ {0} æœªæ‰¾åˆ°")]
    WorkflowNotFound(String),
    
    #[error("å¹¶å‘ä¿®æ”¹å†²çª,é¢„æœŸç‰ˆæœ¬ {expected},å®é™…ç‰ˆæœ¬ {actual}")]
    ConcurrencyConflict { expected: u64, actual: u64 },
    
    #[error("å†…éƒ¨é”™è¯¯: {0}")]
    InternalError(String),
}

/// PostgreSQLäº‹ä»¶å­˜å‚¨å®ç°
pub struct PostgresEventStore {
    db_pool: PgPool,
}

impl PostgresEventStore {
    pub fn new(db_pool: PgPool) -> Self {
        Self { db_pool }
    }
}

#[async_trait]
impl EventStore for PostgresEventStore {
    #[instrument(skip(self, event), fields(workflow_id = %workflow_id))]
    async fn append_event<E: WorkflowEvent + Serialize>(
        &self,
        workflow_id: &str,
        event: E,
        expected_version: Option<u64>,
    ) -> Result<u64, EventStoreError> {
        // æŸ¥è¯¢å½“å‰æœ€å¤§ç‰ˆæœ¬
        let current_version = sqlx::query_scalar::<_, Option<i64>>(
            "SELECT MAX(sequence) FROM event_store WHERE workflow_id = $1"
        )
        .bind(workflow_id)
        .fetch_one(&self.db_pool)
        .await
        .map_err(|e| EventStoreError::DatabaseError(e.to_string()))?
        .unwrap_or(0) as u64;
        
        // æ£€æŸ¥å¹¶å‘ä¿®æ”¹
        if let Some(expected) = expected_version {
            if current_version != expected {
                return Err(EventStoreError::ConcurrencyConflict { 
                    expected, 
                    actual: current_version 
                });
            }
        }
        
        // åºåˆ—åŒ–äº‹ä»¶
        let event_data = serde_json::to_value(&event)
            .map_err(|e| EventStoreError::SerializationError(e.to_string()))?;
            
        let event_type = event.event_type();
        let new_version = current_version + 1;
        let timestamp = Utc::now();
        
        // æ’å…¥äº‹ä»¶
        sqlx::query(
            "INSERT INTO event_store (
                workflow_id, 
                event_type, 
                event_data, 
                sequence, 
                occurred_at, 
                metadata
            ) VALUES ($1, $2, $3, $4, $5, $6)"
        )
        .bind(workflow_id)
        .bind(event_type)
        .bind(&event_data)
        .bind(new_version as i64)
        .bind(timestamp)
        .bind(serde_json::json!({})) // å…ƒæ•°æ®
        .execute(&self.db_pool)
        .await
        .map_err(|e| EventStoreError::DatabaseError(e.to_string()))?;
        
        info!(version = new_version, "äº‹ä»¶å·²é™„åŠ ");
        Ok(new_version)
    }
    
    #[instrument(skip(self), fields(workflow_id = %workflow_id))]
    async fn read_events<E: WorkflowEvent + for<'de> Deserialize<'de>>(
        &self,
        workflow_id: &str,
    ) -> Result<Vec<HistoricalEvent<E>>, EventStoreError> {
        self.read_events_from::<E>(workflow_id, 0).await
    }
    
    #[instrument(skip(self), fields(workflow_id = %workflow_id, start_version = start_version))]
    async fn read_events_from<E: WorkflowEvent + for<'de> Deserialize<'de>>(
        &self,
        workflow_id: &str, 
        start_version: u64,
    ) -> Result<Vec<HistoricalEvent<E>>, EventStoreError> {
        // æŸ¥è¯¢äº‹ä»¶
        let records = sqlx::query!(
            r#"
            SELECT 
                event_type, 
                event_data, 
                sequence, 
                occurred_at, 
                metadata
            FROM 
                event_store
            WHERE 
                workflow_id = $1 AND sequence >= $2
            ORDER BY 
                sequence ASC
            "#,
            workflow_id,
            start_version as i64
        )
        .fetch_all(&self.db_pool)
        .await
        .map_err(|e| EventStoreError::DatabaseError(e.to_string()))?;
        
        if records.is_empty() && start_version == 0 {
            return Err(EventStoreError::WorkflowNotFound(workflow_id.to_string()));
        }
        
        // ååºåˆ—åŒ–äº‹ä»¶
        let mut events = Vec::with_capacity(records.len());
        
        for record in records {
            let event_data: serde_json::Value = record.event_data.clone();
            let event = serde_json::from_value::<E>(event_data.clone())
                .map_err(|e| EventStoreError::SerializationError(
                    format!("æ— æ³•ååºåˆ—åŒ–äº‹ä»¶ {}: {}", record.event_type, e)
                ))?;
                
            events.push(HistoricalEvent {
                event,
                sequence: record.sequence as u64,
                timestamp: record.occurred_at,
                metadata: record.metadata,
            });
        }
        
        info!(events_count = events.len(), "å·²è¯»å–äº‹ä»¶");
        Ok(events)
    }
}
```

### 7.3 å·¥ä½œæµå¼•æ“æ ¸å¿ƒå®ç°

```rust
/// å·¥ä½œæµå¼•æ“
pub struct WorkflowEngine<S: WorkflowState, E: WorkflowEvent> {
    /// å·¥ä½œæµå®šä¹‰æ³¨å†Œè¡¨
    definition_registry: Arc<RwLock<HashMap<String, WorkflowDefinition<S, E>>>>,
    
    /// å·¥ä½œæµç‰ˆæœ¬ç´¢å¼•
    version_index: Arc<RwLock<HashMap<String, Vec<String>>>>,
    
    /// äº‹ä»¶å­˜å‚¨
    event_store: Arc<dyn EventStore>,
    
    /// å·¥ä½œæµçŠ¶æ€å­˜å‚¨
    state_store: Arc<dyn WorkflowStateStore<S>>,
    
    /// æ´»åŠ¨æ‰§è¡Œå™¨
    activity_executor: Arc<dyn ActivityExecutor>,
    
    /// ç›‘æ§æŒ‡æ ‡
    metrics: Arc<Metrics>,
}

impl<S, E> WorkflowEngine<S, E> 
where 
    S: WorkflowState + for<'de> Deserialize<'de> + Serialize,
    E: WorkflowEvent + for<'de> Deserialize<'de> + Serialize,
{
    pub fn new(
        event_store: Arc<dyn EventStore>,
        state_store: Arc<dyn WorkflowStateStore<S>>,
        activity_executor: Arc<dyn ActivityExecutor>,
        metrics: Arc<Metrics>,
    ) -> Self {
        Self {
            definition_registry: Arc::new(RwLock::new(HashMap::new())),
            version_index: Arc::new(RwLock::new(HashMap::new())),
            event_store,
            state_store,
            activity_executor,
            metrics,
        }
    }
    
    /// æ³¨å†Œå·¥ä½œæµå®šä¹‰
    pub async fn register_workflow_definition(
        &self,
        definition: WorkflowDefinition<S, E>,
    ) -> Result<(), WorkflowError> {
        let mut registry = self.definition_registry.write().await;
        let mut version_index = self.version_index.write().await;
        
        let key = format!("{}:{}", definition.workflow_type, definition.version);
        registry.insert(key, definition.clone());
        
        // æ›´æ–°ç‰ˆæœ¬ç´¢å¼•
        let versions = version_index
            .entry(definition.workflow_type.clone())
            .or_insert_with(Vec::new);
            
        if !versions.contains(&definition.version) {
            versions.push(definition.version.clone());
            versions.sort_by(|a, b| version_compare(b, a)); // é™åºæ’åˆ—,æœ€æ–°ç‰ˆæœ¬åœ¨å‰
        }
        
        info!(
            workflow_type = %definition.workflow_type,
            version = %definition.version,
            "å·¥ä½œæµå®šä¹‰å·²æ³¨å†Œ"
        );
        
        Ok(())
    }
    
    /// è·å–æœ€æ–°ç‰ˆæœ¬çš„å·¥ä½œæµå®šä¹‰
    async fn get_latest_definition(&self, workflow_type: &str) -> Result<WorkflowDefinition<S, E>, WorkflowError> {
        let version_index = self.version_index.read().await;
        let registry = self.definition_registry.read().await;
        
        let versions = version_index.get(workflow_type)
            .ok_or_else(|| WorkflowError::WorkflowNotFound(workflow_type.to_string()))?;
            
        if versions.is_empty() {
            return Err(WorkflowError::WorkflowNotFound(workflow_type.to_string()));
        }
        
        let latest_version = &versions[0]; // æœ€æ–°ç‰ˆæœ¬åœ¨é¦–ä½
        let key = format!("{}:{}", workflow_type, latest_version);
        
        let definition = registry.get(&key)
            .ok_or_else(|| WorkflowError::WorkflowNotFound(format!("{}:{}", workflow_type, latest_version)))?;
            
        Ok(definition.clone())
    }
    
    /// è·å–æŒ‡å®šç‰ˆæœ¬çš„å·¥ä½œæµå®šä¹‰
    async fn get_definition(
        &self,
        workflow_type: &str,
        version: &str,
    ) -> Result<WorkflowDefinition<S, E>, WorkflowError> {
        let registry = self.definition_registry.read().await;
        let key = format!("{}:{}", workflow_type, version);
        
        let definition = registry.get(&key)
            .ok_or_else(|| WorkflowError::WorkflowNotFound(key))?;
            
        Ok(definition.clone())
    }
    
    /// åˆ›å»ºå·¥ä½œæµå®ä¾‹
    #[instrument(skip(self, input), fields(workflow_type = %workflow_type))]
    pub async fn create_workflow(
        &self,
        workflow_type: &str,
        input: serde_json::Value,
    ) -> Result<String, WorkflowError> {
        let timer = self.metrics.start_timer("workflow.create.duration");
        
        // 1. è·å–å·¥ä½œæµå®šä¹‰
        let definition = self.get_latest_definition(workflow_type).await?;
        
        // 2. åˆ›å»ºå·¥ä½œæµID
        let workflow_id = Uuid::new_v4().to_string();
        
        // 3. åˆ›å»ºåˆå§‹ä¸Šä¸‹æ–‡
        let mut context = WorkflowContext::new();
        context.set_input(input);
        
        // 4. åˆ›å»ºå·¥ä½œæµåˆå§‹çŠ¶æ€
        let initial_state = definition.initial_state.clone();
        
        // 5. ä¿å­˜åˆå§‹çŠ¶æ€å’Œå…ƒæ•°æ®
        self.state_store.save_initial_state(
            &workflow_id,
            &initial_state,
            workflow_type,
            &definition.version,
            &context,
        ).await.map_err(|e| WorkflowError::StatePersistenceError(e.to_string()))?;
        
        info!(
            workflow_id = %workflow_id,
            initial_state = %initial_state.state_type(),
            "å·¥ä½œæµå®ä¾‹å·²åˆ›å»º"
        );
        
        self.metrics.increment_counter("workflow.created");
        timer.observe_duration();
        
        // è¿”å›å·¥ä½œæµID
        Ok(workflow_id)
    }
    
    /// è§¦å‘å·¥ä½œæµäº‹ä»¶
    #[instrument(skip(self, event), fields(workflow_id = %workflow_id, event_type = %event.event_type()))]
    pub async fn trigger_event(
        &self,
        workflow_id: &str,
        event: E,
    ) -> Result<S, WorkflowError> {
        let timer = self.metrics.start_timer(&format!("workflow.event.{}.duration", event.event_type()));
        
        // 1. åŠ è½½å·¥ä½œæµå®ä¾‹
        let instance = self.load_instance(workflow_id).await?;
        
        info!(
            current_state = %instance.current_state.state_type(),
            "åŠ è½½å·¥ä½œæµå®ä¾‹çŠ¶æ€"
        );
        
        // 2. è·å–å·¥ä½œæµå®šä¹‰
        let definition = self.get_definition(&instance.workflow_type, &instance.workflow_version).await?;
        
        // 3. æŸ¥æ‰¾é€‚ç”¨çš„è½¬æ¢
        let transition = definition.find_transition(&instance.current_state, &event)?;
        
        // 4. æ£€æŸ¥è½¬æ¢æ¡ä»¶
        if let Some(condition) = &transition.condition {
            if !condition(&instance.current_state, &event, &instance.context) {
                return Err(WorkflowError::ConditionNotMet);
            }
        }
        
        // 5. æ‰§è¡Œè½¬æ¢å‰åŠ¨ä½œ
        let mut context = instance.context.clone();
        if let Some(pre_action) = &transition.pre_action {
            pre_action(&instance.current_state, &event, &mut context).await?;
        }
        
        // 6. åˆ›å»ºæ–°çŠ¶æ€
        let new_state = self.create_state(&transition.to_state)?;
        
        // 7. ä¿å­˜äº‹ä»¶
        let event_version = self.event_store.append_event(
            workflow_id,
            event.clone(),
            Some(instance.event_history.len() as u64),
        ).await.map_err(|e| match e {
            EventStoreError::ConcurrencyConflict { .. } => WorkflowError::ConcurrencyConflict,
            _ => WorkflowError::EventStoreError(e.to_string()),
        })?;
        
        // 8. ä¿å­˜æ–°çŠ¶æ€
        self.state_store.save_state(
            workflow_id,
            &new_state,
            event_version,
            &context,
        ).await.map_err(|e| WorkflowError::StatePersistenceError(e.to_string()))?;
        
        info!(
            new_state = %new_state.state_type(),
            "çŠ¶æ€è½¬æ¢æˆåŠŸ"
        );
        
        // 9. æ‰§è¡Œè½¬æ¢ååŠ¨ä½œ
        if let Some(post_action) = &transition.post_action {
            post_action(&instance.current_state, &event, &mut context).await?;
        }
        
        // 10. å¦‚æœæ˜¯ç»ˆæ€,æ›´æ–°å®Œæˆæ—¶é—´
        if new_state.is_terminal() {
            self.state_store.mark_completed(workflow_id).await
                .map_err(|e| WorkflowError::StatePersistenceError(e.to_string()))?;
                
            info!("å·¥ä½œæµå·²å®Œæˆ");
            self.metrics.increment_counter("workflow.completed");
        }
        
        self.metrics.increment_counter(&format!("workflow.event.{}.processed", event.event_type()));
        timer.observe_duration();
        
        Ok(new_state)
    }
    
    /// åˆ›å»ºç‰¹å®šç±»å‹çš„çŠ¶æ€å®ä¾‹
    fn create_state(&self, state_type: &str) -> Result<S, WorkflowError> {
        // è¿™é‡Œéœ€è¦å…·ä½“å®ç°æ¥æ ¹æ®çŠ¶æ€ç±»å‹åç§°åˆ›å»ºçŠ¶æ€å®ä¾‹
        // åœ¨å®é™…å®ç°ä¸­,å¯èƒ½ä¼šä½¿ç”¨å·¥å‚æ¨¡å¼æˆ–åå°„æœºåˆ¶
        // æ­¤å¤„ç®€åŒ–ä¸ºé”™è¯¯è¿”å›
        Err(WorkflowError::InternalError(format!("åˆ›å»ºçŠ¶æ€å®ä¾‹çš„å…·ä½“å®ç°ç¼ºå¤±: {}", state_type)))
    }
    
    /// åŠ è½½å·¥ä½œæµå®ä¾‹
    #[instrument(skip(self), fields(workflow_id = %workflow_id))]
    async fn load_instance(&self, workflow_id: &str) -> Result<WorkflowInstance<S, E>, WorkflowError> {
        // 1. è·å–å…ƒæ•°æ®å’Œå½“å‰çŠ¶æ€
        let (metadata, state, context) = self.state_store.get_state_with_metadata(workflow_id).await
            .map_err(|e| match e {
                StateStoreError::WorkflowNotFound(_) => WorkflowError::InstanceNotFound(workflow_id.to_string()),
                _ => WorkflowError::StatePersistenceError(e.to_string()),
            })?;
            
        // 2. è·å–äº‹ä»¶å†å²
        let events = self.event_store.read_events::<E>(workflow_id).await
            .map_err(|e| match e {
                EventStoreError::WorkflowNotFound(_) => WorkflowError::InstanceNotFound(workflow_id.to_string()),
                _ => WorkflowError::EventStoreError(e.to_string()),
            })?;
            
        Ok(WorkflowInstance {
            id: workflow_id.to_string(),
            workflow_type: metadata.workflow_type,
            workflow_version: metadata.workflow_version,
            current_state: state,
            context,
            event_history: events,
            created_at: metadata.created_at,
            updated_at: metadata.updated_at,
            completed_at: metadata.completed_at,
        })
    }
    
    /// è·å–å·¥ä½œæµçŠ¶æ€
    #[instrument(skip(self), fields(workflow_id = %workflow_id))]
    pub async fn get_workflow_state(&self, workflow_id: &str) -> Result<WorkflowStateInfo, WorkflowError> {
        let (metadata, state, _) = self.state_store.get_state_with_metadata(workflow_id).await
            .map_err(|e| match e {
                StateStoreError::WorkflowNotFound(_) => WorkflowError::InstanceNotFound(workflow_id.to_string()),
                _ => WorkflowError::StatePersistenceError(e.to_string()),
            })?;
            
        Ok(WorkflowStateInfo {
            workflow_id: workflow_id.to_string(),
            workflow_type: metadata.workflow_type,
            workflow_version: metadata.workflow_version,
            current_state: state.state_type().to_string(),
            is_terminal: state.is_terminal(),
            created_at: metadata.created_at,
            updated_at: metadata.updated_at,
            completed_at: metadata.completed_at,
        })
    }
    
    /// è·å–å·¥ä½œæµå†å²
    #[instrument(skip(self), fields(workflow_id = %workflow_id))]
    pub async fn get_workflow_history(&self, workflow_id: &str) -> Result<WorkflowHistory<E>, WorkflowError> {
        let instance =
# å·¥ä½œæµå¼•æ“è®¾è®¡ä¸å®ç°åˆ†æï¼ˆç»­ï¼‰

### 7.4 å·¥ä½œæµå¼•æ“æ ¸å¿ƒå®ç°ç»­

```rust
/// å·¥ä½œæµå¼•æ“
impl<S, E> WorkflowEngine<S, E> 
where 
    S: WorkflowState + for<'de> Deserialize<'de> + Serialize,
    E: WorkflowEvent + for<'de> Deserialize<'de> + Serialize,
{
    /// è·å–å·¥ä½œæµå†å²
    #[instrument(skip(self), fields(workflow_id = %workflow_id))]
    pub async fn get_workflow_history(&self, workflow_id: &str) -> Result<WorkflowHistory<E>, WorkflowError> {
        let instance = self.load_instance(workflow_id).await?;
        
        Ok(WorkflowHistory {
            workflow_id: workflow_id.to_string(),
            workflow_type: instance.workflow_type,
            workflow_version: instance.workflow_version,
            events: instance.event_history,
            current_state: instance.current_state.state_type().to_string(),
            created_at: instance.created_at,
            completed_at: instance.completed_at,
        })
    }
    
    /// æ‰§è¡Œæ´»åŠ¨
    #[instrument(skip(self, input), fields(activity_type = %activity_type, workflow_id = %workflow_id))]
    pub async fn execute_activity(
        &self,
        workflow_id: &str,
        activity_type: &str,
        input: serde_json::Value,
    ) -> Result<serde_json::Value, WorkflowError> {
        let timer = self.metrics.start_timer(&format!("workflow.activity.{}.duration", activity_type));
        self.metrics.increment_counter(&format!("workflow.activity.{}.started", activity_type));
        
        // ç”Ÿæˆç›¸å…³ID
        let correlation_id = format!("{}-{}", workflow_id, Uuid::new_v4());
        
        // æ‰§è¡Œæ´»åŠ¨
        let result = self.activity_executor.execute_activity(activity_type, input, &correlation_id).await
            .map_err(|e| WorkflowError::ActivityError(e.to_string()))?;
            
        self.metrics.increment_counter(&format!("workflow.activity.{}.completed", activity_type));
        timer.observe_duration();
        
        Ok(result)
    }
    
    /// é‡è¯•å·¥ä½œæµæµ
    #[instrument(skip(self), fields(workflow_id = %workflow_id))]
    pub async fn retry_workflow(&self, workflow_id: &str) -> Result<(), WorkflowError> {
        // 1. è·å–å·¥ä½œæµçŠ¶æ€
        let info = self.get_workflow_state(workflow_id).await?;
        
        // 2. æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å·²å®Œæˆ
        if info.completed_at.is_some() {
            return Err(WorkflowError::ValidationError("æ— æ³•é‡è¯•å·²å®Œæˆçš„å·¥ä½œæµ".to_string()));
        }
        
        // 3. è·å–æœ€åä¸€ä¸ªäº‹ä»¶
        let history = self.get_workflow_history(workflow_id).await?;
        let last_event = history.events.last()
            .ok_or_else(|| WorkflowError::ValidationError("å·¥ä½œæµå†å²ä¸ºç©º,æ— æ³•é‡è¯•".to_string()))?;
            
        // 4. åˆ›å»ºé‡è¯•äº‹ä»¶
        let retry_event = self.create_retry_event(&last_event.event)?;
        
        // 5. è§¦å‘é‡è¯•äº‹ä»¶
        self.trigger_event(workflow_id, retry_event).await?;
        
        info!("å·¥ä½œæµé‡è¯•å·²å¯åŠ¨");
        self.metrics.increment_counter("workflow.retried");
        
        Ok(())
    }
    
    /// åˆ›å»ºé‡è¯•äº‹ä»¶
    fn create_retry_event(&self, last_event: &E) -> Result<E, WorkflowError> {
        // è¿™é‡Œéœ€è¦å…·ä½“å®ç°æ¥åˆ›å»ºé‡è¯•äº‹ä»¶
        // åœ¨å®é™…åº”ç”¨ä¸­,å¯èƒ½æ ¹æ®ä¸Šä¸€ä¸ªäº‹ä»¶æ„é€ é€‚å½“çš„é‡è¯•äº‹ä»¶
        // æ­¤å¤„ç®€åŒ–ä¸ºé”™è¯¯è¿”å›
        Err(WorkflowError::InternalError("åˆ›å»ºé‡è¯•äº‹ä»¶çš„å…·ä½“å®ç°ç¼ºå¤±".to_string()))
    }
    
    /// æš‚åœå·¥ä½œæµ
    #[instrument(skip(self), fields(workflow_id = %workflow_id))]
    pub async fn pause_workflow(&self, workflow_id: &str, reason: Option<String>) -> Result<(), WorkflowError> {
        // 1. è·å–å·¥ä½œæµçŠ¶æ€
        let info = self.get_workflow_state(workflow_id).await?;
        
        // 2. æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å·²å®Œæˆ
        if info.completed_at.is_some() {
            return Err(WorkflowError::ValidationError("æ— æ³•æš‚åœå·²å®Œæˆçš„å·¥ä½œæµ".to_string()));
        }
        
        // 3. åˆ›å»ºæš‚åœäº‹ä»¶
        let pause_event = self.create_pause_event(reason)?;
        
        // 4. è§¦å‘æš‚åœäº‹ä»¶
        self.trigger_event(workflow_id, pause_event).await?;
        
        info!("å·¥ä½œæµå·²æš‚åœ");
        self.metrics.increment_counter("workflow.paused");
        
        Ok(())
    }
    
    /// åˆ›å»ºæš‚åœäº‹ä»¶
    fn create_pause_event(&self, reason: Option<String>) -> Result<E, WorkflowError> {
        // è¿™é‡Œéœ€è¦å…·ä½“å®ç°æ¥åˆ›å»ºæš‚åœäº‹ä»¶
        // æ­¤å¤„ç®€åŒ–ä¸ºé”™è¯¯è¿”å›
        Err(WorkflowError::InternalError("åˆ›å»ºæš‚åœäº‹ä»¶çš„å…·ä½“å®ç°ç¼ºå¤±".to_string()))
    }
    
    /// æ¢å¤å·¥ä½œæµ
    #[instrument(skip(self), fields(workflow_id = %workflow_id))]
    pub async fn resume_workflow(&self, workflow_id: &str) -> Result<(), WorkflowError> {
        // 1. è·å–å·¥ä½œæµå®ä¾‹
        let instance = self.load_instance(workflow_id).await?;
        
        // 2. æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å¤„äºæš‚åœçŠ¶æ€
        if instance.current_state.state_type() != "paused" {
            return Err(WorkflowError::ValidationError("åªèƒ½æ¢å¤å¤„äºæš‚åœçŠ¶æ€çš„å·¥ä½œæµ".to_string()));
        }
        
        // 3. åˆ›å»ºæ¢å¤äº‹ä»¶
        let resume_event = self.create_resume_event()?;
        
        // 4. è§¦å‘æ¢å¤äº‹ä»¶
        self.trigger_event(workflow_id, resume_event).await?;
        
        info!("å·¥ä½œæµå·²æ¢å¤");
        self.metrics.increment_counter("workflow.resumed");
        
        Ok(())
    }
    
    /// åˆ›å»ºæ¢å¤äº‹ä»¶
    fn create_resume_event(&self) -> Result<E, WorkflowError> {
        // è¿™é‡Œéœ€è¦å…·ä½“å®ç°æ¥åˆ›å»ºæ¢å¤äº‹ä»¶
        // æ­¤å¤„ç®€åŒ–ä¸ºé”™è¯¯è¿”å›
        Err(WorkflowError::InternalError("åˆ›å»ºæ¢å¤äº‹ä»¶çš„å…·ä½“å®ç°ç¼ºå¤±".to_string()))
    }
    
    /// ç»ˆæ­¢å·¥ä½œæµ
    #[instrument(skip(self), fields(workflow_id = %workflow_id))]
    pub async fn terminate_workflow(&self, workflow_id: &str, reason: String) -> Result<(), WorkflowError> {
        // 1. è·å–å·¥ä½œæµçŠ¶æ€
        let info = self.get_workflow_state(workflow_id).await?;
        
        // 2. æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å·²å®Œæˆ
        if info.completed_at.is_some() {
            return Err(WorkflowError::ValidationError("æ— æ³•ç»ˆæ­¢å·²å®Œæˆçš„å·¥ä½œæµ".to_string()));
        }
        
        // 3. åˆ›å»ºç»ˆæ­¢äº‹ä»¶
        let terminate_event = self.create_terminate_event(reason)?;
        
        // 4. è§¦å‘ç»ˆæ­¢äº‹ä»¶
        self.trigger_event(workflow_id, terminate_event).await?;
        
        info!("å·¥ä½œæµå·²ç»ˆæ­¢");
        self.metrics.increment_counter("workflow.terminated");
        
        Ok(())
    }
    
    /// åˆ›å»ºç»ˆæ­¢äº‹ä»¶
    fn create_terminate_event(&self, reason: String) -> Result<E, WorkflowError> {
        // è¿™é‡Œéœ€è¦å…·ä½“å®ç°æ¥åˆ›å»ºç»ˆæ­¢äº‹ä»¶
        // æ­¤å¤„ç®€åŒ–ä¸ºé”™è¯¯è¿”å›
        Err(WorkflowError::InternalError("åˆ›å»ºç»ˆæ­¢äº‹ä»¶çš„å…·ä½“å®ç°ç¼ºå¤±".to_string()))
    }
    
    /// è°ƒåº¦å¹¶ç›‘æ§å·¥ä½œæµæ‰§è¡Œä¸­çš„è¶…æ—¶
    pub async fn start_timeout_monitor(&self, check_interval: Duration) -> tokio::task::JoinHandle<()> {
        let engine = Arc::new(self.clone());
        
        tokio::spawn(async move {
            let mut interval = tokio::time::interval(check_interval);
            
            loop {
                interval.tick().await;
                if let Err(e) = engine.check_timeouts().await {
                    error!("æ£€æŸ¥å·¥ä½œæµè¶…æ—¶å¤±è´¥: {:?}", e);
                }
            }
        })
    }
    
    async fn check_timeouts(&self) -> Result<(), WorkflowError> {
        // è·å–å¯èƒ½è¶…æ—¶çš„å·¥ä½œæµ
        let potentially_timed_out = self.state_store.find_potentially_timed_out().await
            .map_err(|e| WorkflowError::StatePersistenceError(e.to_string()))?;
            
        for workflow_id in potentially_timed_out {
            // æ£€æŸ¥å·¥ä½œæµæ˜¯å¦ç¡®å®è¶…æ—¶
            match self.load_instance(&workflow_id).await {
                Ok(instance) => {
                    let definition = self.get_definition(&instance.workflow_type, &instance.workflow_version).await?;
                    
                    if let Some(timeout_config) = &definition.timeout_config {
                        let now = Utc::now();
                        
                        // æ£€æŸ¥å·¥ä½œæµæ‰§è¡Œæ—¶é—´æ˜¯å¦è¶…æ—¶
                        if let Some(workflow_timeout) = timeout_config.workflow_timeout {
                            if now - instance.created_at > workflow_timeout {
                                info!(workflow_id = %workflow_id, "å·¥ä½œæµæ‰§è¡Œè¶…æ—¶");
                                
                                // åˆ›å»ºå¹¶è§¦å‘è¶…æ—¶äº‹ä»¶
                                if let Ok(timeout_event) = self.create_timeout_event() {
                                    if let Err(e) = self.trigger_event(&workflow_id, timeout_event).await {
                                        error!(workflow_id = %workflow_id, error = %e, "å¤„ç†å·¥ä½œæµè¶…æ—¶å¤±è´¥");
                                    }
                                }
                            }
                        }
                        
                        // æ£€æŸ¥å·¥ä½œæµçŠ¶æ€è¶…æ—¶
                        if let Some(state_timeouts) = &timeout_config.state_timeouts {
                            let current_state = instance.current_state.state_type();
                            
                            if let Some(timeout) = state_timeouts.get(current_state) {
                                // è·å–æœ€åä¸€æ¬¡çŠ¶æ€æ›´æ–°æ—¶é—´
                                if now - instance.updated_at > *timeout {
                                    info!(
                                        workflow_id = %workflow_id, 
                                        state = %current_state, 
                                        "å·¥ä½œæµçŠ¶æ€è¶…æ—¶"
                                    );
                                    
                                    // åˆ›å»ºå¹¶è§¦å‘çŠ¶æ€è¶…æ—¶äº‹ä»¶
                                    if let Ok(state_timeout_event) = self.create_state_timeout_event(current_state) {
                                        if let Err(e) = self.trigger_event(&workflow_id, state_timeout_event).await {
                                            error!(
                                                workflow_id = %workflow_id, 
                                                state = %current_state,
                                                error = %e, 
                                                "å¤„ç†çŠ¶æ€è¶…æ—¶å¤±è´¥"
                                            );
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                Err(e) => {
                    error!(workflow_id = %workflow_id, error = %e, "åŠ è½½å·¥ä½œæµå®ä¾‹å¤±è´¥");
                }
            }
        }
        
        Ok(())
    }
    
    /// åˆ›å»ºè¶…æ—¶äº‹ä»¶
    fn create_timeout_event(&self) -> Result<E, WorkflowError> {
        // è¿™é‡Œéœ€è¦å…·ä½“å®ç°æ¥åˆ›å»ºè¶…æ—¶äº‹ä»¶
        // æ­¤å¤„ç®€åŒ–ä¸ºé”™è¯¯è¿”å›
        Err(WorkflowError::InternalError("åˆ›å»ºè¶…æ—¶äº‹ä»¶çš„å…·ä½“å®ç°ç¼ºå¤±".to_string()))
    }
    
    /// åˆ›å»ºçŠ¶æ€è¶…æ—¶äº‹ä»¶
    fn create_state_timeout_event(&self, state: &str) -> Result<E, WorkflowError> {
        // è¿™é‡Œéœ€è¦å…·ä½“å®ç°æ¥åˆ›å»ºçŠ¶æ€è¶…æ—¶äº‹ä»¶
        // æ­¤å¤„ç®€åŒ–ä¸ºé”™è¯¯è¿”å›
        Err(WorkflowError::InternalError("åˆ›å»ºçŠ¶æ€è¶…æ—¶äº‹ä»¶çš„å…·ä½“å®ç°ç¼ºå¤±".to_string()))
    }
}

/// å·¥ä½œæµè¶…æ—¶é…ç½®
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct WorkflowTimeoutConfig {
    /// æ•´ä¸ªå·¥ä½œæµçš„æ‰§è¡Œè¶…æ—¶
    pub workflow_timeout: Option<chrono::Duration>,
    
    /// ç‰¹å®šçŠ¶æ€çš„è¶…æ—¶è®¾ç½®
    pub state_timeouts: Option<HashMap<String, chrono::Duration>>,
    
    /// æ´»åŠ¨è¶…æ—¶
    pub activity_timeout: Option<chrono::Duration>,
}

/// å·¥ä½œæµçŠ¶æ€ä¿¡æ¯(APIè¿”å›)
#[derive(Debug, Serialize, Deserialize)]
pub struct WorkflowStateInfo {
    pub workflow_id: String,
    pub workflow_type: String,
    pub workflow_version: String,
    pub current_state: String,
    pub is_terminal: bool,
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
    pub completed_at: Option<DateTime<Utc>>,
}

/// å·¥ä½œæµå†å²(APIè¿”å›)
#[derive(Debug, Serialize, Deserialize)]
pub struct WorkflowHistory<E: WorkflowEvent> {
    pub workflow_id: String,
    pub workflow_type: String,
    pub workflow_version: String,
    pub events: Vec<HistoricalEvent<E>>,
    pub current_state: String,
    pub created_at: DateTime<Utc>,
    pub completed_at: Option<DateTime<Utc>>,
}

/// ç‰ˆæœ¬æ¯”è¾ƒå‡½æ•°
fn version_compare(a: &str, b: &str) -> std::cmp::Ordering {
    let parse_version = |v: &str| -> Vec<u32> {
        v.split('.')
            .filter_map(|s| s.parse::<u32>().ok())
            .collect()
    };
    
    let va = parse_version(a);
    let vb = parse_version(b);
    
    for (a_num, b_num) in va.iter().zip(vb.iter()) {
        match a_num.cmp(b_num) {
            std::cmp::Ordering::Equal => continue,
            other => return other,
        }
    }
    
    va.len().cmp(&vb.len())
}
```

### 7.5 æ´»åŠ¨æ‰§è¡Œå™¨å®ç°

```rust
use std::sync::Arc;
use std::collections::HashMap;
use tokio::sync::RwLock;
use chrono::{DateTime, Utc};
use serde::{Serialize, Deserialize};
use async_trait::async_trait;
use tracing::{info, error, instrument};

/// æ´»åŠ¨å®šä¹‰
pub struct ActivityDefinition {
    /// æ´»åŠ¨ç±»å‹
    pub activity_type: String,
    
    /// ç‰ˆæœ¬
    pub version: String,
    
    /// æ´»åŠ¨æè¿°
    pub description: Option<String>,
    
    /// è¶…æ—¶è®¾ç½®
    pub timeout: std::time::Duration,
    
    /// é‡è¯•ç­–ç•¥
    pub retry_policy: Option<RetryPolicy>,
    
    /// æ´»åŠ¨å¤„ç†å™¨
    pub handler: Box<dyn Fn(serde_json::Value) -> BoxFuture<'static, Result<serde_json::Value, ActivityError>> + Send + Sync>,
}

/// æ´»åŠ¨æ‰§è¡Œè®°å½•
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct ActivityExecution {
    /// æ´»åŠ¨ç±»å‹
    pub activity_type: String,
    
    /// æ´»åŠ¨ç‰ˆæœ¬
    pub activity_version: String,
    
    /// è¾“å…¥æ•°æ®
    pub input: serde_json::Value,
    
    /// è¾“å‡ºæ•°æ®
    pub output: serde_json::Value,
    
    /// å¼€å§‹æ—¶é—´
    pub started_at: DateTime<Utc>,
    
    /// å®Œæˆæ—¶é—´
    pub completed_at: DateTime<Utc>,
    
    /// æ‰§è¡ŒçŠ¶æ€
    pub status: String,
}

/// æ´»åŠ¨é”™è¯¯
#[derive(Debug, thiserror::Error)]
pub enum ActivityError {
    #[error("æ´»åŠ¨ {0} æœªæ‰¾åˆ°")]
    ActivityNotFound(String),
    
    #[error("æ´»åŠ¨æ‰§è¡Œè¶…æ—¶")]
    Timeout,
    
    #[error("é‡è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™")]
    ExhaustedRetries,
    
    #[error("è¾“å…¥éªŒè¯å¤±è´¥: {0}")]
    ValidationError(String),
    
    #[error("æ‰§è¡Œé”™è¯¯: {0}")]
    ExecutionError(String),
    
    #[error("åºåˆ—åŒ–é”™è¯¯: {0}")]
    SerializationError(String),
    
    #[error("HTTPé”™è¯¯: {0}")]
    HttpError(String),
    
    #[error("å†…éƒ¨é”™è¯¯: {0}")]
    InternalError(String),
}

/// é‡è¯•ç­–ç•¥
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct RetryPolicy {
    /// æœ€å¤§é‡è¯•æ¬¡æ•°
    pub max_attempts: u32,
    
    /// åˆå§‹é‡è¯•é—´éš”
    pub initial_interval: std::time::Duration,
    
    /// æœ€å¤§é‡è¯•é—´éš”
    pub max_interval: std::time::Duration,
    
    /// é€€é¿ç³»æ•°
    pub backoff_coefficient: f64,
    
    /// ä¸å¯é‡è¯•çš„é”™è¯¯ç±»å‹
    pub non_retryable_errors: Vec<String>,
}

/// æ´»åŠ¨æ‰§è¡Œå™¨ç‰¹è´¨
#[async_trait]
pub trait ActivityExecutor: Send + Sync {
    /// æ³¨å†Œæ´»åŠ¨å®šä¹‰
    async fn register_activity(&self, definition: ActivityDefinition) -> Result<(), ActivityError>;
    
    /// æ‰§è¡Œæ´»åŠ¨
    async fn execute_activity(
        &self, 
        activity_type: &str, 
        input: serde_json::Value,
        correlation_id: &str,
    ) -> Result<serde_json::Value, ActivityError>;
    
    /// è·å–æ´»åŠ¨æ‰§è¡Œå†å²
    async fn get_activity_execution(&self, correlation_id: &str) -> Result<ActivityExecution, ActivityError>;
}

/// æœ¬åœ°æ´»åŠ¨æ‰§è¡Œå™¨
pub struct LocalActivityExecutor {
    /// æ´»åŠ¨å®šä¹‰æ³¨å†Œè¡¨
    definitions: RwLock<HashMap<String, ActivityDefinition>>,
    
    /// æœ€æ–°ç‰ˆæœ¬ç´¢å¼•
    version_index: RwLock<HashMap<String, String>>,
    
    /// æ‰§è¡Œå†å²
    execution_history: RwLock<HashMap<String, ActivityExecution>>,
    
    /// æŒ‡æ ‡æ”¶é›†
    metrics: Arc<Metrics>,
}

impl LocalActivityExecutor {
    pub fn new(metrics: Arc<Metrics>) -> Self {
        Self {
            definitions: RwLock::new(HashMap::new()),
            version_index: RwLock::new(HashMap::new()),
            execution_history: RwLock::new(HashMap::new()),
            metrics,
        }
    }
    
    /// è·å–æ´»åŠ¨æœ€æ–°ç‰ˆæœ¬
    async fn get_latest_version(&self, activity_type: &str) -> Result<String, ActivityError> {
        let version_index = self.version_index.read().await;
        
        version_index.get(activity_type)
            .cloned()
            .ok_or_else(|| ActivityError::ActivityNotFound(activity_type.to_string()))
    }
    
    /// ä½¿ç”¨é‡è¯•ç­–ç•¥æ‰§è¡Œå‡½æ•°
    async fn execute_with_retry<F, Fut, T, E>(
        &self,
        f: F,
        input: serde_json::Value,
        retry_policy: &RetryPolicy,
        timeout: std::time::Duration,
    ) -> Result<T, ActivityError>
    where
        F: Fn(serde_json::Value) -> Fut + Send + Sync,
        Fut: Future<Output = Result<T, E>> + Send,
        E: std::error::Error + Send + 'static,
    {
        let mut attempt = 0;
        let mut last_error = None;
        let mut backoff = retry_policy.initial_interval;
        
        while attempt < retry_policy.max_attempts {
            attempt += 1;
            
            match tokio::time::timeout(timeout, f(input.clone())).await {
                Ok(Ok(result)) => {
                    return Ok(result);
                },
                Ok(Err(e)) => {
                    // æ£€æŸ¥æ˜¯å¦æ˜¯ä¸å¯é‡è¯•çš„é”™è¯¯
                    let error_str = e.to_string();
                    if retry_policy.non_retryable_errors.iter().any(|non_retryable| error_str.contains(non_retryable)) {
                        return Err(ActivityError::ExecutionError(error_str));
                    }
                    
                    // è®°å½•é”™è¯¯,å‡†å¤‡é‡è¯•
                    last_error = Some(error_str);
                    
                    // å¦‚æœè¿™æ˜¯æœ€åä¸€æ¬¡å°è¯•,ä¸éœ€è¦ç­‰å¾…,ç›´æ¥è¿”å›é”™è¯¯
                    if attempt >= retry_policy.max_attempts {
                        break;
                    }
                    
                    // ç­‰å¾…é€€é¿æ—¶é—´
                    tokio::time::sleep(backoff).await;
                    
                    // è®¡ç®—ä¸‹ä¸€æ¬¡é€€é¿æ—¶é—´
                    backoff = std::cmp::min(
                        std::time::Duration::from_secs_f64(backoff.as_secs_f64() * retry_policy.backoff_coefficient),
                        retry_policy.max_interval,
                    );
                },
                Err(_) => {
                    return Err(ActivityError::Timeout);
                }
            }
        }
        
        // é‡è¯•æ¬¡æ•°å·²ç”¨å°½
        if let Some(last_error) = last_error {
            Err(ActivityError::ExecutionError(format!("é‡è¯•å·²ç”¨å°½: {}", last_error)))
        } else {
            Err(ActivityError::ExhaustedRetries)
        }
    }
}

#[async_trait]
impl ActivityExecutor for LocalActivityExecutor {
    #[instrument(skip(self, definition))]
    async fn register_activity(&self, definition: ActivityDefinition) -> Result<(), ActivityError> {
        let activity_type = definition.activity_type.clone();
        let version = definition.version.clone();
        let key = format!("{}:{}", activity_type, version);
        
        // æ›´æ–°å®šä¹‰æ³¨å†Œè¡¨
        {
            let mut definitions = self.definitions.write().await;
            definitions.insert(key, definition);
        }
        
        // æ›´æ–°ç‰ˆæœ¬ç´¢å¼•
        let mut version_index = self.version_index.write().await;
        let current_latest = version_index.get(&activity_type).cloned();
        
        if let Some(current) = current_latest {
            if version_compare(&version, &current) == std::cmp::Ordering::Greater {
                version_index.insert(activity_type.clone(), version.clone());
            }
        } else {
            version_index.insert(activity_type.clone(), version.clone());
        }
        
        info!(
            activity_type = %activity_type,
            version = %version,
            "æ´»åŠ¨å·²æ³¨å†Œ"
        );
        
        Ok(())
    }
    
    #[instrument(skip(self, input), fields(activity_type = %activity_type, correlation_id = %correlation_id))]
    async fn execute_activity(
        &self,
        activity_type: &str,
        input: serde_json::Value,
        correlation_id: &str,
    ) -> Result<serde_json::Value, ActivityError> {
        // 1. è®¡æ—¶å¼€å§‹
        let timer = self.metrics.start_timer(&format!("activity.{}.duration", activity_type));
        self.metrics.increment_counter(&format!("activity.{}.started", activity_type));
        
        info!("å¼€å§‹æ‰§è¡Œæ´»åŠ¨");
        
        // 2. è·å–æ´»åŠ¨æœ€æ–°ç‰ˆæœ¬
        let latest_version = self.get_latest_version(activity_type).await?;
        let key = format!("{}:{}", activity_type, latest_version);
        
        // 3. è·å–æ´»åŠ¨å®šä¹‰
        let definition = {
            let definitions = self.definitions.read().await;
            definitions.get(&key)
                .cloned()
                .ok_or_else(|| ActivityError::ActivityNotFound(format!("{} v{}", activity_type, latest_version)))?
        };
        
        // 4. æ‰§è¡Œæ´»åŠ¨
        let start_time = Utc::now();
        let result = if let Some(retry_policy) = &definition.retry_policy {
            self.execute_with_retry(
                &definition.handler,
                input.clone(),
                retry_policy,
                definition.timeout,
            ).await
        } else {
            // æ— é‡è¯•ç­–ç•¥,ç›´æ¥æ‰§è¡Œ
            match tokio::time::timeout(definition.timeout, (definition.handler)(input.clone())).await {
                Ok(result) => result,
                Err(_) => Err(ActivityError::Timeout),
            }
        };
        
        // 5. è®°å½•ç»“æœ
        let end_time = Utc::now();
        
        match &result {
            Ok(output) => {
                // è®°å½•æˆåŠŸæ‰§è¡Œ
                let execution = ActivityExecution {
                    activity_type: activity_type.to_string(),
                    activity_version: latest_version,
                    input,
                    output: output.clone(),
                    started_at: start_time,
                    completed_at: end_time,
                    status: "completed".to_string(),
                };
                
                let mut history = self.execution_history.write().await;
                history.insert(correlation_id.to_string(), execution);
                
                self.metrics.increment_counter(&format!("activity.{}.completed", activity_type));
                info!("æ´»åŠ¨æ‰§è¡ŒæˆåŠŸ");
            },
            Err(e) => {
                // è®°å½•å¤±è´¥æ‰§è¡Œ
                let execution = ActivityExecution {
                    activity_type: activity_type.to_string(),
                    activity_version: latest_version,
                    input,
                    output: serde_json::json!({ "error": e.to_string() }),
                    started_at: start_time,
                    completed_at: end_time,
                    status: "failed".to_string(),
                };
                
                let mut history = self.execution_history.write().await;
                history.insert(correlation_id.to_string(), execution);
                
                self.metrics.increment_counter(&format!("activity.{}.failed", activity_type));
                error!(error = %e, "æ´»åŠ¨æ‰§è¡Œå¤±è´¥");
            }
        }
        
        timer.observe_duration();
        result
    }
    
    #[instrument(skip(self), fields(correlation_id = %correlation_id))]
    async fn get_activity_execution(&self, correlation_id: &str) -> Result<ActivityExecution, ActivityError> {
        let history = self.execution_history.read().await;
        
        history.get(correlation_id)
            .cloned()
            .ok_or_else(|| ActivityError::InternalError(format!("æœªæ‰¾åˆ°æ´»åŠ¨æ‰§è¡Œè®°å½•: {}", correlation_id)))
    }
}

/// ç‰ˆæœ¬æ¯”è¾ƒå‡½æ•°
fn version_compare(a: &str, b: &str) -> std::cmp::Ordering {
    let parse_version = |v: &str| -> Vec<u32> {
        v.split('.')
            .filter_map(|s| s.parse::<u32>().ok())
            .collect()
    };
    
    let va = parse_version(a);
    let vb = parse_version(b);
    
    for (a_num, b_num) in va.iter().zip(vb.iter()) {
        match a_num.cmp(b_num) {
            std::cmp::Ordering::Equal => continue,
            other => return other,
        }
    }
    
    va.len().cmp(&vb.len())
}
```

## 8 å…«ã€å·¥ä½œæµå¼•æ“å®ç°è·¯çº¿å›¾

ä¸ºäº†ç¡®ä¿å·¥ä½œæµå¼•æ“çš„æˆåŠŸå®ç°,æˆ‘å»ºè®®é‡‡ç”¨ä»¥ä¸‹é˜¶æ®µæ€§è·¯çº¿å›¾:

### 8.1 é˜¶æ®µä¸€ åŸå‹ä¸åŸºç¡€æ¡†æ¶ (4-6å‘¨)

1. **ç†è®ºä¸æ¶æ„è®¾è®¡**
   - ç¡®å®šæ ¸å¿ƒæ•°æ®æ¨¡å‹ä¸æ¥å£
   - è®¾è®¡äº‹ä»¶æº¯æºå­˜å‚¨æ¶æ„
   - å®šä¹‰é”™è¯¯å¤„ç†ç­–ç•¥

2. **æ ¸å¿ƒç»„ä»¶åŸå‹**
   - å®ç°åŸºæœ¬çŠ¶æ€æœºæ¨¡å‹
   - å¼€å‘äº‹ä»¶å­˜å‚¨æ¥å£åŠç®€å•å®ç°
   - æ„å»ºå·¥ä½œæµå¼•æ“åŸºç¡€åŠŸèƒ½

3. **å•å…ƒæµ‹è¯•ä¸éªŒè¯**
   - ä¸ºæ ¸å¿ƒç»„ä»¶ç¼–å†™æµ‹è¯•ç”¨ä¾‹
   - éªŒè¯åŸºæœ¬çŠ¶æ€è½¬æ¢é€»è¾‘
   - åˆ†ææ€§èƒ½ç‰¹å¾

### 8.2 é˜¶æ®µäºŒ åŠŸèƒ½å®Œå–„ä¸é›†æˆ (4-6å‘¨)

1. **æ´»åŠ¨æ‰§è¡Œç³»ç»Ÿ**
   - å®ç°æ´»åŠ¨å®šä¹‰ä¸æ‰§è¡Œå™¨
   - æ·»åŠ é‡è¯•ä¸é”™è¯¯å¤„ç†æœºåˆ¶
   - å¼€å‘åŸºç¡€æ´»åŠ¨ç±»å‹(HTTPã€è„šæœ¬ç­‰)

1. **æŒä¹…åŒ–ä¸æ¢å¤æœºåˆ¶**
   - å¼ºåŒ–äº‹ä»¶å­˜å‚¨å®ç°
   - æ·»åŠ å¿«ç…§ä¸çŠ¶æ€æ¢å¤åŠŸèƒ½
   - å®ç°å¹¶å‘æ§åˆ¶ä¸é”™è¯¯å¤„ç†

1. **APIæ¥å£ä¸é›†æˆç‚¹**
   - æ„å»ºREST/gRPCæ¥å£
   - å¼€å‘SDKå®¢æˆ·ç«¯
   - é›†æˆç›‘æ§ä¸è¿½è¸ªèƒ½åŠ›

### 8.3 é˜¶æ®µä¸‰ é«˜çº§åŠŸèƒ½ä¸ä¼˜åŒ– (6-8å‘¨)

1. **é«˜çº§å·¥ä½œæµåŠŸèƒ½**
   - å®ç°å­å·¥ä½œæµæ”¯æŒ
   - æ·»åŠ å®šæ—¶å’Œå‘¨æœŸæ€§å·¥ä½œæµ
   - å¼€å‘åŠ¨æ€åˆ†æ”¯å’Œå¹¶è¡Œæ‰§è¡Œ
   - å®ç°å·¥ä½œæµç‰ˆæœ¬ç®¡ç†ä¸è¿ç§»

1. **æ€§èƒ½ä¼˜åŒ–**
   - å®ç°ç¼“å­˜ç­–ç•¥
   - ä¼˜åŒ–æŒä¹…åŒ–å±‚æ€§èƒ½
   - æ·»åŠ æ‰¹é‡æ“ä½œæ”¯æŒ
   - å®ç°è¯»å†™åˆ†ç¦»

1. **æ“ä½œä¸ç®¡ç†åŠŸèƒ½**
   - å¼€å‘ç®¡ç†æ§åˆ¶å°
   - å®ç°å·¥ä½œæµæœç´¢ä¸æŸ¥è¯¢
   - æ·»åŠ ç»Ÿè®¡å’Œå†å²åˆ†æ
   - å¼€å‘å·¥ä½œæµå¯è§†åŒ–å·¥å…·

### 8.4 é˜¶æ®µå›› æ‰©å±•ä¸æˆç†Ÿ (6-8å‘¨)

1. **æ‰©å±•åŠŸèƒ½**
    - å®ç°åˆ†å¸ƒå¼æ‰§è¡Œå¼•æ“
    - æ·»åŠ æ’ä»¶ç³»ç»Ÿ
    - å¼€å‘é«˜çº§è°ƒåº¦å’Œèµ„æºç®¡ç†
    - å®ç°è·¨å·¥ä½œæµé€šä¿¡

1. **å®‰å…¨ä¸å¯é æ€§å¢å¼º**
    - æ·»åŠ èº«ä»½éªŒè¯ä¸æˆæƒ
    - å®ç°æ•°æ®åŠ å¯†
    - å¢å¼ºæ•…éšœæ¢å¤æœºåˆ¶
    - å¼€å‘ç¾éš¾æ¢å¤è§£å†³æ–¹æ¡ˆ

1. **å®Œæ•´ç”Ÿæ€ç³»ç»Ÿ**
    - å®Œå–„æ–‡æ¡£å’Œç¤ºä¾‹
    - å¼€å‘æµ‹è¯•å’Œæ¨¡æ‹Ÿå·¥å…·
    - æ„å»ºæ¨¡æ¿åº“
    - è´¡çŒ®Rustç”Ÿæ€ç³»ç»Ÿ

## 9 ä¹ã€æ‰©å±•æ€§ä¸æœªæ¥å‘å±•æ–¹å‘

### 9.1 åˆ†å¸ƒå¼å·¥ä½œæµå¼•æ“

å°†å½“å‰è®¾è®¡æ‰©å±•ä¸ºå®Œå…¨åˆ†å¸ƒå¼çš„å·¥ä½œæµå¼•æ“:

```rust
/// åˆ†å¸ƒå¼å·¥ä½œæµå¼•æ“
pub struct DistributedWorkflowEngine<S: WorkflowState, E: WorkflowEvent> {
    /// æœ¬åœ°å·¥ä½œæµå¼•æ“
    local_engine: Arc<WorkflowEngine<S, E>>,
    
    /// å·¥ä½œæµåˆ†ç‰‡åè°ƒå™¨
    shard_coordinator: Arc<ShardCoordinator>,
    
    /// åˆ†å¸ƒå¼é”æœåŠ¡
    lock_service: Arc<dyn DistributedLockService>,
    
    /// å·¥ä½œæµè°ƒåº¦å™¨
    scheduler: Arc<WorkflowScheduler<S, E>>,
    
    /// é›†ç¾¤èŠ‚ç‚¹ç®¡ç†å™¨
    node_manager: Arc<ClusterNodeManager>,
}

impl<S, E> DistributedWorkflowEngine<S, E> 
where 
    S: WorkflowState + for<'de> Deserialize<'de> + Serialize,
    E: WorkflowEvent + for<'de> Deserialize<'de> + Serialize,
{
    pub async fn start_node(&self) -> Result<(), EngineError> {
        // 1. æ³¨å†ŒèŠ‚ç‚¹
        let node_id = self.node_manager.register_node().await?;
        
        // 2. è·å–åˆ†ç‰‡åˆ†é…
        let shards = self.shard_coordinator.get_assigned_shards(node_id).await?;
        
        // 3. ä¸ºæ¯ä¸ªåˆ†ç‰‡å¯åŠ¨å·¥ä½œæµå¤„ç†å™¨
        for shard_id in shards {
            self.start_shard_processor(shard_id).await?;
        }
        
        // 4. å¯åŠ¨åˆ†ç‰‡åˆ†é…ç›‘å¬å™¨
        self.start_shard_assignment_listener(node_id).await?;
        
        // 5. å¯åŠ¨å¿ƒè·³å‘é€
        self.start_heartbeat_sender(node_id).await?;
        
        Ok(())
    }
    
    async fn start_shard_processor(&self, shard_id: String) -> Result<(), EngineError> {
        // å¯åŠ¨ç‰¹å®šåˆ†ç‰‡çš„å¤„ç†å¾ªç¯
        let engine = self.local_engine.clone();
        let lock_service = self.lock_service.clone();
        let scheduler = self.scheduler.clone();
        
        tokio::spawn(async move {
            let mut interval = tokio::time::interval(Duration::from_millis(100));
            
            loop {
                interval.tick().await;
                
                // å°è¯•è·å–åˆ†ç‰‡é”
                let lock = match lock_service.try_lock(&format!("shard:{}", shard_id), Duration::from_secs(30)).await {
                    Ok(lock) => lock,
                    Err(_) => continue, // æ— æ³•è·å–é”,ç¨åé‡è¯•
                };
                
                // å¤„ç†åˆ†ç‰‡ä¸­çš„å·¥ä½œæµä»»åŠ¡
                match scheduler.get_tasks_for_shard(&shard_id, 10).await {
                    Ok(tasks) => {
                        for task in tasks {
                            match task {
                                WorkflowTask::ProcessEvent { workflow_id, event } => {
                                    if let Err(e) = engine.trigger_event(&workflow_id, event).await {
                                        error!(workflow_id = %workflow_id, error = %e, "å¤„ç†å·¥ä½œæµäº‹ä»¶å¤±è´¥");
                                        
                                        // è®°å½•å¤±è´¥å¹¶å¯èƒ½é‡æ–°è°ƒåº¦
                                        if let Err(e) = scheduler.record_task_failure(&workflow_id, &e.to_string()).await {
                                            error!(workflow_id = %workflow_id, error = %e, "è®°å½•ä»»åŠ¡å¤±è´¥çŠ¶æ€å¤±è´¥");
                                        }
                                    }
                                },
                                // å¤„ç†å…¶ä»–ç±»å‹çš„ä»»åŠ¡...
                            }
                        }
                    },
                    Err(e) => {
                        error!(shard_id = %shard_id, error = %e, "è·å–åˆ†ç‰‡ä»»åŠ¡å¤±è´¥");
                    }
                }
                
                // é‡Šæ”¾åˆ†ç‰‡é”
                if let Err(e) = lock_service.unlock(lock).await {
                    error!(shard_id = %shard_id, error = %e, "é‡Šæ”¾åˆ†ç‰‡é”å¤±è´¥");
                }
            }
        });
        
        Ok(())
    }
    
    async fn start_shard_assignment_listener(&self, node_id: String) -> Result<(), EngineError> {
        let shard_coordinator = self.shard_coordinator.clone();
        let engine = self.clone();
        
        tokio::spawn(async move {
            let mut receiver = shard_coordinator.watch_shard_assignments(node_id.clone()).await
                .expect("å¯åŠ¨åˆ†ç‰‡åˆ†é…ç›‘å¬å™¨å¤±è´¥");
                
            while let Some(assignments) = receiver.recv().await {
                // å¤„ç†åˆ†ç‰‡åˆ†é…å˜æ›´
                let current_shards = shard_coordinator.get_assigned_shards(&node_id).await
                    .expect("è·å–å½“å‰åˆ†ç‰‡åˆ†é…å¤±è´¥");
                    
                // æ‰¾å‡ºæ–°åˆ†é…çš„åˆ†ç‰‡
                for shard_id in assignments {
                    if !current_shards.contains(&shard_id) {
                        if let Err(e) = engine.start_shard_processor(shard_id.clone()).await {
                            error!(shard_id = %shard_id, error = %e, "å¯åŠ¨åˆ†ç‰‡å¤„ç†å™¨å¤±è´¥");
                        }
                    }
                }
                
                // å¤„ç†å·²ç»ç§»é™¤çš„åˆ†ç‰‡
                // æ³¨æ„:åˆ†ç‰‡å¤„ç†å™¨ä¼šåœ¨æ— æ³•è·å–é”æ—¶è‡ªåŠ¨é€€å‡º
            }
        });
        
        Ok(())
    }
    
    async fn start_heartbeat_sender(&self, node_id: String) -> Result<(), EngineError> {
        let node_manager = self.node_manager.clone();
        
        tokio::spawn(async move {
            let mut interval = tokio::time::interval(Duration::from_secs(5));
            
            loop {
                interval.tick().await;
                
                if let Err(e) = node_manager.send_heartbeat(&node_id).await {
                    error!(node_id = %node_id, error = %e, "å‘é€å¿ƒè·³å¤±è´¥");
                }
            }
        });
        
        Ok(())
    }
}
```

### 9.2 å·¥ä½œæµå®šä¹‰DSL

åˆ›å»ºä¸€ä¸ªå£°æ˜å¼çš„å·¥ä½œæµå®šä¹‰è¯­è¨€:

```rust
/// å·¥ä½œæµDSLè§£æå™¨
pub struct WorkflowDslParser<S: WorkflowState, E: WorkflowEvent> {
    /// çŠ¶æ€å·¥å‚
    state_factory: Arc<dyn StateFactory<S>>,
    
    /// äº‹ä»¶å·¥å‚
    event_factory: Arc<dyn EventFactory<E>>,
    
    /// æ´»åŠ¨æ³¨å†Œè¡¨
    activity_registry: Arc<dyn ActivityRegistry>,
}

impl<S, E> WorkflowDslParser<S, E>
where 
    S: WorkflowState + for<'de> Deserialize<'de> + Serialize,
    E: WorkflowEvent + for<'de> Deserialize<'de> + Serialize,
{
    /// ä»DSLæ–‡ä»¶è§£æå·¥ä½œæµå®šä¹‰
    pub fn parse_from_file(&self, file_path: &str) -> Result<WorkflowDefinition<S, E>, DslError> {
        let content = std::fs::read_to_string(file_path)
            .map_err(|e| DslError::IoError(e.to_string()))?;
            
        self.parse(&content)
    }
    
    /// è§£æDSLå†…å®¹
    pub fn parse(&self, dsl_content: &str) -> Result<WorkflowDefinition<S, E>, DslError> {
        // è§£æDSLå†…å®¹ä¸ºå·¥ä½œæµå®šä¹‰
        let dsl: WorkflowDsl = serde_yaml::from_str(dsl_content)
            .map_err(|e| DslError::ParseError(e.to_string()))?;
            
        // éªŒè¯DSLå®šä¹‰
        self.validate_dsl(&dsl)?;
        
        // åˆ›å»ºåˆå§‹çŠ¶æ€
        let initial_state = self.state_factory.create_state(&dsl.initial_state)
            .map_err(|e| DslError::StateCreationError(e.to_string()))?;
            
        // åˆ›å»ºè½¬æ¢å®šä¹‰
        let mut transitions = Vec::new();
        
        for transition_def in dsl.transitions {
            let event_type = transition_def.event;
            let from_state = transition_def.from;
            let to_state = transition_def.to;
            
            // åˆ›å»ºæ¡ä»¶
            let condition = if let Some(condition_expr) = transition_def.condition {
                Some(self.create_condition_function(&condition_expr)?)
            } else {
                None
            };
            
            // åˆ›å»ºåŠ¨ä½œ
            let pre_action = if let Some(actions) = transition_def.pre_actions {
                Some(self.create_action_function(&actions, "pre")?)
            } else {
                None
            };
            
            let post_action = if let Some(actions) = transition_def.post_actions {
                Some(self.create_action_function(&actions, "post")?)
            } else {
                None
            };
            
            // æ·»åŠ è½¬æ¢
            transitions.push(WorkflowTransition {
                from_state,
                to_state,
                event_type,
                condition,
                pre_action,
                post_action,
            });
        }
        
        // åˆ›å»ºå·¥ä½œæµå®šä¹‰
        let definition = WorkflowDefinition {
            workflow_type: dsl.name,
            version: dsl.version,
            initial_state,
            transitions,
            timeout_config: self.parse_timeout_config(&dsl.timeouts),
            retry_policy: self.parse_retry_policy(&dsl.retry_policy),
        };
        
        Ok(definition)
    }
    
    // éªŒè¯DSLå®šä¹‰
    fn validate_dsl(&self, dsl: &WorkflowDsl) -> Result<(), DslError> {
        // éªŒè¯å·¥ä½œæµåç§°å’Œç‰ˆæœ¬
        if dsl.name.is_empty() {
            return Err(DslError::ValidationError("å·¥ä½œæµåç§°ä¸èƒ½ä¸ºç©º".to_string()));
        }
        
        if dsl.version.is_empty() {
            return Err(DslError::ValidationError("å·¥ä½œæµç‰ˆæœ¬ä¸èƒ½ä¸ºç©º".to_string()));
        }
        
        // éªŒè¯åˆå§‹çŠ¶æ€
        if dsl.initial_state.is_empty() {
            return Err(DslError::ValidationError("åˆå§‹çŠ¶æ€ä¸èƒ½ä¸ºç©º".to_string()));
        }
        
        // éªŒè¯è½¬æ¢å®šä¹‰
        if dsl.transitions.is_empty() {
            return Err(DslError::ValidationError("è‡³å°‘éœ€è¦ä¸€ä¸ªçŠ¶æ€è½¬æ¢".to_string()));
        }
        
        for (i, transition) in dsl.transitions.iter().enumerate() {
            if transition.from.is_empty() {
                return Err(DslError::ValidationError(format!("è½¬æ¢ #{} çš„æºçŠ¶æ€ä¸èƒ½ä¸ºç©º", i)));
            }
            
            if transition.to.is_empty() {
                return Err(DslError::ValidationError(format!("è½¬æ¢ #{} çš„ç›®æ ‡çŠ¶æ€ä¸èƒ½ä¸ºç©º", i)));
            }
            
            if transition.event.is_empty() {
                return Err(DslError::ValidationError(format!("è½¬æ¢ #{} çš„äº‹ä»¶ç±»å‹ä¸èƒ½ä¸ºç©º", i)));
            }
        }
        
        Ok(())
    }
    
    // åˆ›å»ºæ¡ä»¶å‡½æ•°
    fn create_condition_function(
        &self,
        condition_expr: &str,
    ) -> Result<Box<dyn Fn(&S, &E, &WorkflowContext) -> bool + Send + Sync>, DslError> {
        // å®ç°æ¡ä»¶è¡¨è¾¾å¼è§£æå’Œæ‰§è¡Œ
        // è¿™é‡Œéœ€è¦ä¸€ä¸ªè¡¨è¾¾å¼å¼•æ“æ¥è¯„ä¼°æ¡ä»¶
        // ç®€åŒ–ç¤ºä¾‹:è¿”å›ä¸€ä¸ªå§‹ç»ˆä¸ºçœŸçš„æ¡ä»¶
        Ok(Box::new(move |_, _, _| true))
    }
    
    // åˆ›å»ºåŠ¨ä½œå‡½æ•°
    fn create_action_function(
        &self,
        actions: &[ActionDef],
        action_type: &str,
    ) -> Result<Box<dyn Fn(&S, &E, &mut WorkflowContext) -> BoxFuture<'static, Result<(), WorkflowError>> + Send + Sync>, DslError> {
        // åˆ›å»ºåŠ¨ä½œæ‰§è¡Œå™¨
        let action_executor = self.activity_registry.clone();
        let actions = actions.to_vec();
        
        Ok(Box::new(move |state, event, context| {
            let actions = actions.clone();
            let action_executor = action_executor.clone();
            
            Box::pin(async move {
                for action in &actions {
                    match action.action_type.as_str() {
                        "activity" => {
                            // æ‰§è¡Œæ´»åŠ¨
                            let input = self.prepare_activity_input(&action.parameters, state, event, context)?;
                            
                            let result = action_executor.execute_activity(&action.name, input).await
                                .map_err(|e| WorkflowError::ActivityError(e.to_string()))?;
                                
                            // å¤„ç†ç»“æœ
                            if let Some(result_var) = &action.result_variable {
                                context.set_variable(result_var, result);
                            }
                        },
                        "set_variable" => {
                            // è®¾ç½®å˜é‡
                            let variable_name = action.parameters.get("name")
                                .ok_or_else(|| WorkflowError::ValidationError("å˜é‡åç§°ç¼ºå¤±".to_string()))?;
                                
                            let variable_value = action.parameters.get("value")
                                .ok_or_else(|| WorkflowError::ValidationError("å˜é‡å€¼ç¼ºå¤±".to_string()))?;
                                
                            context.set_variable(
                                variable_name.as_str().unwrap_or(""),
                                variable_value.clone(),
                            );
                        },
                        // å…¶ä»–åŠ¨ä½œç±»å‹...
                        _ => {
                            return Err(WorkflowError::ValidationError(
                                format!("ä¸æ”¯æŒçš„åŠ¨ä½œç±»å‹: {}", action.action_type)
                            ));
                        }
                    }
                }
                
                Ok(())
            })
        }))
    }
    
    // å‡†å¤‡æ´»åŠ¨è¾“å…¥
    fn prepare_activity_input(
        &self,
        parameters: &serde_json::Map<String, serde_json::Value>,
        state: &S,
        event: &E,
        context: &WorkflowContext,
    ) -> Result<serde_json::Value, WorkflowError> {
        let mut input = serde_json::Map::new();
        
        for (key, value) in parameters {
            if let serde_json::Value::String(s) = value {
                if s.starts_with("${") && s.ends_with("}") {
                    // è§£æè¡¨è¾¾å¼
                    let expr = &s[2..s.len()-1];
                    let resolved = self.resolve_expression(expr, state, event, context)?;
                    input.insert(key.clone(), resolved);
                } else {
                    input.insert(key.clone(), value.clone());
                }
            } else {
                input.insert(key.clone(), value.clone());
            }
        }
        
        Ok(serde_json::Value::Object(input))
    }
    
    // è§£æè¡¨è¾¾å¼
    fn resolve_expression(
        &self,
        expr: &str,
        state: &S,
        event: &E,
        context: &WorkflowContext,
    ) -> Result<serde_json::Value, WorkflowError> {
        if expr.starts_with("context.") {
            let var_name = &expr["context.".len()..];
            context.get_variable(var_name)
                .cloned()
                .ok_or_else(|| WorkflowError::ValidationError(format!("å˜é‡æœªæ‰¾åˆ°: {}", var_name)))
        } else if expr == "event" {
            event.payload().clone()
        } else if expr == "state" {
            state.to_json().map_err(|e| WorkflowError::SerializationError(e.to_string()))?
        } else {
            // æ›´å¤æ‚çš„è¡¨è¾¾å¼è¯„ä¼°...
            Err(WorkflowError::ValidationError(format!("æ— æ³•è§£æè¡¨è¾¾å¼: {}", expr)))
        }
    }
    
    // è§£æè¶…æ—¶é…ç½®
    fn parse_timeout_config(&self, timeouts: &Option<TimeoutsDef>) -> Option<WorkflowTimeoutConfig> {
        timeouts.as_ref().map(|t| {
            let workflow_timeout = t.workflow.map(|secs| chrono::Duration::seconds(secs as i64));
            
            let mut state_timeouts = None;
            if let Some(states) = &t.states {
                let mut map = HashMap::new();
                for (state, secs) in states {
                    map.insert(state.clone(), chrono::Duration::seconds(*secs as i64));
                }
                if !map.is_empty() {
                    state_timeouts = Some(map);
                }
            }
            
            let activity_timeout = t.activity.map(|secs| chrono::Duration::seconds(secs as i64));
            
            WorkflowTimeoutConfig {
                workflow_timeout,
                state_timeouts,
                activity_timeout,
            }
        })
    }
    
    // è§£æé‡è¯•ç­–ç•¥
    fn parse_retry_policy(&self, retry: &Option<RetryPolicyDef>) -> Option<RetryPolicy> {
        retry.as_ref().map(|r| {
            RetryPolicy {
                max_attempts: r.max_attempts,
                initial_interval: Duration::from_secs(r.initial_interval_seconds),
                max_interval: Duration::from_secs(r.max_interval_seconds),
                backoff_coefficient: r.backoff_coefficient,
                non_retryable_errors: r.non_retryable_errors.clone(),
            }
        })
    }
}

/// å·¥ä½œæµDSLç»“æ„
#[derive(Debug, Serialize, Deserialize)]
struct WorkflowDsl {
    name: String,
    version: String,
    description: Option<String>,
    initial_state: String,
    states: Vec<StateDef>,
    transitions: Vec<TransitionDef>,
    timeouts: Option<TimeoutsDef>,
    retry_policy: Option<RetryPolicyDef>,
}

#[derive(Debug, Serialize, Deserialize)]
struct StateDef {
    name: String,
    description: Option<String>,
    is_terminal: bool,
    metadata: Option<serde_json::Map<String, serde_json::Value>>,
}

#[derive(Debug, Serialize, Deserialize)]
struct TransitionDef {
    from: String,
    to: String,
    event: String,
    description: Option<String>,
    condition: Option<String>,
    pre_actions: Option<Vec<ActionDef>>,
    post_actions: Option<Vec<ActionDef>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct ActionDef {
    name: String,
    action_type: String,
    description: Option<String>,
    parameters: serde_json::Map<String, serde_json::Value>,
    result_variable: Option<String>,
}

#[derive(Debug, Serialize, Deserialize)]
struct TimeoutsDef {
    workflow: Option<u64>,
    states: Option<HashMap<String, u64>>,
    activity: Option<u64>,
}

#[derive(Debug, Serialize, Deserialize)]
struct RetryPolicyDef {
    max_attempts: u32,
    initial_interval_seconds: u64,
    max_interval_seconds: u64,
    backoff_coefficient: f64,
    non_retryable_errors: Vec<String>,
}

/// DSLè§£æé”™è¯¯
#[derive(Debug, thiserror::Error)]
pub enum DslError {
    #[error("è§£æé”™è¯¯: {0}")]
    ParseError(String),
    
    #[error("éªŒè¯é”™è¯¯: {0}")]
    ValidationError(String),
    
    #[error("çŠ¶æ€åˆ›å»ºé”™è¯¯: {0}")]
    StateCreationError(String),
    
    #[error("äº‹ä»¶åˆ›å»ºé”™è¯¯: {0}")]
    EventCreationError(String),
    
    #[error("IOé”™è¯¯: {0}")]
    IoError(String),
    
    #[error("è¡¨è¾¾å¼è§£æé”™è¯¯: {0}")]
    ExpressionError(String),
}
```

### 9.3 å·¥ä½œæµå¯è§†åŒ–å’Œç›‘æ§

å¼€å‘å·¥ä½œæµçŠ¶æ€å’Œè¿›åº¦å¯è§†åŒ–ç³»ç»Ÿ:

```rust
/// å·¥ä½œæµç›‘æ§æœåŠ¡
pub struct WorkflowMonitoringService<S: WorkflowState, E: WorkflowEvent> {
    /// å·¥ä½œæµå¼•æ“
    workflow_engine: Arc<WorkflowEngine<S, E>>,
    
    /// åº¦é‡æ”¶é›†å™¨
    metrics: Arc<Metrics>,
    
    /// å·¥ä½œæµç»Ÿè®¡æ•°æ®
    stats_repository: Arc<dyn WorkflowStatsRepository>,
    
    /// æ´»åŠ¨å®æ—¶ç›‘æ§
    activity_monitor: Arc<dyn ActivityMonitor>,
}

impl<S, E> WorkflowMonitoringService<S, E>
where 
    S: WorkflowState + for<'de> Deserialize<'de> + Serialize,
    E: WorkflowEvent + for<'de> Deserialize<'de> + Serialize,
{
    /// è·å–å·¥ä½œæµçŠ¶æ€åˆ†å¸ƒç»Ÿè®¡
    pub async fn get_workflow_state_stats(&self, workflow_type: &str) -> Result<WorkflowStateStats, MonitoringError> {
        self.stats_repository.get_state_distribution(workflow_type).await
    }
    
    /// è·å–æ´»åŠ¨æ‰§è¡Œç»Ÿè®¡
    pub async fn get_activity_stats(&self, activity_type: &str, time_range: TimeRange) -> Result<ActivityStats, MonitoringError> {
        self.stats_repository.get_activity_stats(activity_type, time_range).await
    }
    
    /// è·å–å·¥ä½œæµæ‰§è¡Œæ—¶é—´ç»Ÿè®¡
    pub async fn get_workflow_duration_stats(&self, workflow_type: &str, time_range: TimeRange) -> Result<DurationStats, MonitoringError> {
        self.stats_repository.get_workflow_duration_stats(workflow_type, time_range).await
    }
    
    /// è·å–å½“å‰æ´»è·ƒå·¥ä½œæµå®ä¾‹
    pub async fn get_active_workflow_instances(&self, workflow_type: &str, page: usize, page_size: usize) -> Result<PaginatedResult<WorkflowInstanceSummary>, MonitoringError> {
        self.stats_repository.get_active_instances(workflow_type, page, page_size).await
    }
    
    /// è·å–å·¥ä½œæµå†å²è¶‹åŠ¿
    pub async fn get_workflow_trend(&self, workflow_type: &str, time_range: TimeRange, interval: TimeInterval) -> Result<WorkflowTrendStats, MonitoringError> {
        self.stats_repository.get_workflow_trend(workflow_type, time_range, interval).await
    }
    
    /// è®¢é˜…å·¥ä½œæµäº‹ä»¶
    pub fn subscribe_to_workflow_events(&self, workflow_id: &str) -> mpsc::Receiver<WorkflowEventNotification> {
        self.activity_monitor.subscribe_to_workflow(workflow_id)
    }
    
    /// è·å–å·¥ä½œæµDAGå¯è§†åŒ–æ•°æ®
    pub async fn get_workflow_visualization_data(&self, workflow_type: &str, version: Option<String>) -> Result<WorkflowVisualizationData, MonitoringError> {
        // 1. è·å–å·¥ä½œæµå®šä¹‰
        let workflow_def = match version {
            Some(v) => self.workflow_engine.get_definition_by_version(workflow_type, &v).await?,
            None => self.workflow_engine.get_latest_definition(workflow_type).await?,
        };
        
        // 2. æ„å»ºèŠ‚ç‚¹åˆ—è¡¨
        let mut nodes = Vec::new();
        let mut edges = Vec::new();
        
        // æ·»åŠ åˆå§‹çŠ¶æ€èŠ‚ç‚¹
        let initial_state = workflow_def.initial_state.state_type();
        nodes.push(VisNode {
            id: initial_state.to_string(),
            label: initial_state.to_string(),
            node_type: "state".to_string(),
            properties: serde_json::json!({
                "isInitial": true,
                "isTerminal": workflow_def.initial_state.is_terminal(),
            }),
        });
        
        // å¤„ç†è½¬æ¢,æå–æ‰€æœ‰çŠ¶æ€å’Œè¾¹
        let mut all_states = HashSet::new();
        all_states.insert(initial_state.to_string());
        
        for transition in &workflow_def.transitions {
            all_states.insert(transition.from_state.clone());
            all_states.insert(transition.to_state.clone());
            
            // æ·»åŠ è¾¹
            edges.push(VisEdge {
                id: format!("{}-{}-{}", transition.from_state, transition.event_type, transition.to_state),
                source: transition.from_state.clone(),
                target: transition.to_state.clone(),
                label: transition.event_type.clone(),
                properties: serde_json::json!({
                    "hasCondition": transition.condition.is_some(),
                    "hasActions": transition.pre_action.is_some() || transition.post_action.is_some(),
                }),
            });
        }
        
        // æ·»åŠ æ‰€æœ‰çŠ¶æ€èŠ‚ç‚¹
        for state in all_states {
            if state != initial_state {
                // åˆ¤æ–­æ˜¯å¦ä¸ºç»ˆæ€
                let is_terminal = workflow_def.transitions.iter()
                    .filter(|t| t.from_state == state)
                    .count() == 0;
                    
                nodes.push(VisNode {
                    id: state.clone(),
                    label: state.clone(),
                    node_type: "state".to_string(),
                    properties: serde_json::json!({
                        "isInitial": false,
                        "isTerminal": is_terminal,
                    }),
                });
            }
        }
        
        Ok(WorkflowVisualizationData {
            workflow_type: workflow_type.to_string(),
            version: workflow_def.version,
            nodes,
            edges,
        })
    }
    
    /// è·å–å·¥ä½œæµçƒ­ç‚¹è·¯å¾„åˆ†æ
    pub async fn get_workflow_hotpath_analysis(&self, workflow_type: &str, time_range: TimeRange) -> Result<WorkflowHotpathAnalysis, MonitoringError> {
        self.stats_repository.get_hotpath_analysis(workflow_type, time_range).await
    }
    
    /// å¯åŠ¨ç»Ÿè®¡æ”¶é›†å™¨
    pub async fn start_stats_collector(&self, interval: Duration) -> tokio::task::JoinHandle<()> {
        let stats_repository = self.stats_repository.clone();
        let workflow_engine = self.workflow_engine.clone();
        
        tokio::spawn(async move {
            let mut collection_interval = tokio::time::interval(interval);
            
            loop {
                collection_interval.tick().await;
                
                // æ”¶é›†å·¥ä½œæµç»Ÿè®¡æ•°æ®
                if let Err(e) = stats_repository.collect_current_stats().await {
                    error!("æ”¶é›†å·¥ä½œæµç»Ÿè®¡æ•°æ®å¤±è´¥: {:?}", e);
                }
            }
        })
    }
}

/// å¯è§†åŒ–èŠ‚ç‚¹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VisNode {
    pub id: String,
    pub label: String,
    pub node_type: String,
    pub properties: serde_json::Value,
}

/// å¯è§†åŒ–è¾¹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VisEdge {
    pub id: String,
    pub source: String,
    pub target: String,
    pub label: String,
    pub properties: serde_json::Value,
}

/// å·¥ä½œæµå¯è§†åŒ–æ•°æ®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowVisualizationData {
    pub workflow_type: String,
    pub version: String,
    pub nodes: Vec<VisNode>,
    pub edges: Vec<VisEdge>,
}
```

## 10 åã€æ€»ç»“ä¸å»ºè®®

### 10.1 æ€»ä½“æ¶æ„è¯„ä¼°

åŸºäºæˆ‘ä»¬çš„åˆ†æ,è‡ªå»ºå·¥ä½œæµå¼•æ“çš„å…³é”®ä¼˜åŠ¿å’ŒæŒ‘æˆ˜å¦‚ä¸‹:

#### 1.1.1 ä¼˜åŠ¿

1. **ç±»å‹å®‰å…¨**: åˆ©ç”¨Rustçš„ç±»å‹ç³»ç»Ÿ,ç‰¹åˆ«æ˜¯ç±»å‹çŠ¶æ€æ¨¡å¼,å¯ä»¥åœ¨ç¼–è¯‘æ—¶ä¿è¯å·¥ä½œæµçŠ¶æ€è½¬æ¢çš„å®‰å…¨æ€§,è¿™æ˜¯ç°æœ‰è®¸å¤šå·¥ä½œæµå¼•æ“æ— æ³•æä¾›çš„åŠŸèƒ½ã€‚

2. **æ€§èƒ½ä¼˜åŠ¿**: ä½å†…å­˜å ç”¨å’Œé«˜ååé‡ä½¿å¾—å®ƒç‰¹åˆ«é€‚åˆå¤„ç†é«˜è´Ÿè½½åœºæ™¯,ä¸åŸºäºJVMçš„é€‰é¡¹ç›¸æ¯”æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

3. **å®šåˆ¶æ€§**: å¯ä»¥æ ¹æ®å…·ä½“ä¸šåŠ¡éœ€æ±‚å®šåˆ¶å·¥ä½œæµè¡Œä¸º,è€Œä¸å—ç¬¬ä¸‰æ–¹å·¥ä½œæµäº§å“çš„é™åˆ¶ã€‚

4. **åµŒå…¥èƒ½åŠ›**: å¯ä»¥ä½œä¸ºåº“ç›´æ¥åµŒå…¥åˆ°åº”ç”¨ç¨‹åºä¸­,å‡å°‘éƒ¨ç½²å¤æ‚æ€§ã€‚

5. **é›¶ä¾èµ–é€‰é¡¹**: å¯ä»¥å®ç°ä¸ä¾èµ–å¤–éƒ¨æœåŠ¡çš„ç‹¬ç«‹è¿è¡Œæ¨¡å¼,é€‚åˆå¯¹å¯é æ€§æœ‰æé«˜è¦æ±‚çš„åœºæ™¯ã€‚

#### 1.1.2 æŒ‘æˆ˜

1. **å¼€å‘æˆæœ¬**: å®Œæ•´å®ç°å·¥ä½œæµå¼•æ“éœ€è¦æŠ•å…¥å¤§é‡å¼€å‘å’Œæµ‹è¯•èµ„æº,åˆå§‹æˆæœ¬è¾ƒé«˜ã€‚

2. **ç”Ÿæ€ç³»ç»Ÿ**: ä¸æˆç†Ÿäº§å“å¦‚Temporalå’ŒCadenceç›¸æ¯”,ç¼ºä¹ç°æˆçš„å·¥å…·å’Œé›†æˆã€‚

3. **æ“ä½œå¤æ‚åº¦**: è‡ªå»ºè§£å†³æ–¹æ¡ˆéœ€è¦è‡ªè¡Œè§£å†³ç›‘æ§ã€æ‰©å±•å’Œæ•…éšœæ¢å¤ç­‰è¿ç»´é—®é¢˜ã€‚

4. **åŠŸèƒ½å®Œå¤‡åº¦**: åˆæœŸç‰ˆæœ¬åŠŸèƒ½å¯èƒ½ä¸å¦‚æˆç†Ÿäº§å“ä¸°å¯Œ,éœ€è¦é€æ­¥å®Œå–„ã€‚

### 10.2 å®æ–½å»ºè®®

æ ¹æ®é¡¹ç›®è§„æ¨¡å’Œèµ„æºæƒ…å†µ,æˆ‘æ¨èä»¥ä¸‹å®æ–½è·¯å¾„:

#### 2.2.1 å¯¹äºå°å‹é¡¹ç›®æˆ–MVPé˜¶æ®µ

1. **ç®€åŒ–ç‰ˆå¼•æ“**: é¦–å…ˆå®ç°ä¸€ä¸ªæ ¸å¿ƒåŠŸèƒ½å®Œå¤‡ä½†ä¸åŒ…å«åˆ†å¸ƒå¼ç‰¹æ€§çš„å·¥ä½œæµå¼•æ“:
   - åªæ”¯æŒåŸºæœ¬çŠ¶æ€è½¬æ¢å’Œäº‹ä»¶é©±åŠ¨
   - ä½¿ç”¨å•ä¸€å­˜å‚¨åº“å®ç°(å¦‚PostgreSQL)
   - ä»…æ”¯æŒå¿…è¦çš„æ´»åŠ¨ç±»å‹

2. **å¢é‡æ‰©å±•**: éšç€éœ€æ±‚éªŒè¯,é€æ­¥æ·»åŠ æ›´å¤æ‚åŠŸèƒ½:
   - å­å·¥ä½œæµæ”¯æŒ
   - æ›´ä¸°å¯Œçš„é”™è¯¯å¤„ç†
   - æ›´å¤šæ´»åŠ¨ç±»å‹

3. **å·¥å…·ä¼˜å…ˆçº§**: ä¼˜å…ˆå¼€å‘å¯¹å¼€å‘æ•ˆç‡å½±å“æœ€å¤§çš„å·¥å…·:
   - å·¥ä½œæµå®šä¹‰éªŒè¯å·¥å…·
   - è°ƒè¯•å’Œæ—¥å¿—å¯è§†åŒ–å·¥å…·
   - ç®€å•çš„çŠ¶æ€æ£€æŸ¥API

#### 2.2.2 å¯¹äºå¤§å‹ä¼ä¸šåº”ç”¨

1. **åˆ†é˜¶æ®µè®¡åˆ’**:
   - ç¬¬ä¸€é˜¶æ®µ: æ ¸å¿ƒå¼•æ“å’Œå…³é”®ä¸šåŠ¡æµç¨‹(3-4ä¸ªæœˆ)
   - ç¬¬äºŒé˜¶æ®µ: åˆ†å¸ƒå¼æ‰§è¡Œå’Œé«˜å¯ç”¨æ€§(2-3ä¸ªæœˆ)
   - ç¬¬ä¸‰é˜¶æ®µ: ç”Ÿæ€ç³»ç»Ÿå’Œå·¥å…·é“¾(2-3ä¸ªæœˆ)

2. **å›¢é˜Ÿé…ç½®**:
   - æ ¸å¿ƒå¼•æ“å›¢é˜Ÿ: 2-3åèµ„æ·±Rustå¼€å‘è€…
   - é›†æˆå’ŒAPIå›¢é˜Ÿ: 1-2åå¼€å‘è€…
   - æµ‹è¯•å’Œå¯é æ€§å›¢é˜Ÿ: 1-2åQAå·¥ç¨‹å¸ˆ

3. **é£é™©ç¼“è§£**:
   - ä¸ç°æœ‰å·¥ä½œæµè§£å†³æ–¹æ¡ˆå¹¶è¡Œè¿è¡Œä»¥éªŒè¯ä¸€è‡´æ€§
   - å…ˆå®ç°éå…³é”®ä¸šåŠ¡æµç¨‹
   - å»ºç«‹å…¨é¢çš„ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ

### 10.3 å¯è¡Œæ€§è¯„åˆ†

æ ¹æ®Rustç”Ÿæ€ç³»ç»Ÿç°çŠ¶å’ŒæŠ€æœ¯éš¾åº¦,ä»¥ä¸‹æ˜¯å„ç»„ä»¶çš„å¯è¡Œæ€§è¯„åˆ†(1-5åˆ†):

| ç»„ä»¶ | å¯è¡Œæ€§ | å¼€å‘éš¾åº¦ | å¤‡æ³¨ |
|-----|-------|--------|------|
| æ ¸å¿ƒçŠ¶æ€æœº | 5 | ä¸­ | Rustç±»å‹ç³»ç»Ÿéå¸¸é€‚åˆçŠ¶æ€æœºå®ç° |
| äº‹ä»¶å­˜å‚¨ | 5 | ä½ | ä½¿ç”¨sqlxå’ŒPostgreSQLå¯é å®ç° |
| æ´»åŠ¨æ‰§è¡Œå™¨ | 4 | ä¸­ | éœ€å¤„ç†å¤æ‚çš„é”™è¯¯åœºæ™¯ |
| åˆ†å¸ƒå¼åè°ƒ | 3 | é«˜ | éœ€å®ç°åˆ†ç‰‡ã€æ•…éšœè½¬ç§»ç­‰å¤æ‚é€»è¾‘ |
| å¯è§†åŒ–å·¥å…· | 4 | ä¸­ | å¯åˆ©ç”¨ç°æœ‰Rust Webæ¡†æ¶ |
| DSLè§£æå™¨ | 4 | ä¸­ | Rustæœ‰æˆç†Ÿçš„è§£æå·¥å…·å¦‚nom |

### 10.4 ä¸å¼€æºæ–¹æ¡ˆæ¯”è¾ƒ

| ç‰¹æ€§ | è‡ªå»ºå·¥ä½œæµå¼•æ“ | Temporal | Cadence |
|-----|--------------|----------|---------|
| ç±»å‹å®‰å…¨ | é«˜ (ç¼–è¯‘æ—¶) | ä¸­ (è¿è¡Œæ—¶) | ä¸­ (è¿è¡Œæ—¶) |
| æ€§èƒ½ | æé«˜ | é«˜ | é«˜ |
| æˆç†Ÿåº¦ | ä½ | é«˜ | é«˜ |
| ç”Ÿæ€ç³»ç»Ÿ | éœ€æ„å»º | ä¸°å¯Œ | ä¸°å¯Œ |
| å¼€å‘æˆæœ¬ | é«˜ | ä½ | ä½ |
| å®šåˆ¶çµæ´»æ€§ | æé«˜ | ä¸­ | ä¸­ |
| è¿ç»´å¤æ‚åº¦ | é«˜ | ä¸­ | ä¸­ |

### 10.5 æœ€ç»ˆå»ºè®®

1. **æ··åˆæ–¹æ¡ˆ**: è€ƒè™‘ç»“åˆè‡ªå»ºç»„ä»¶å’Œå¼€æºå·¥å…·:
   - ä½¿ç”¨è‡ªå»ºæ ¸å¿ƒçŠ¶æ€æœºå’Œå·¥ä½œæµé€»è¾‘
   - è€ƒè™‘Temporalæˆ–å…¶ä»–å·¥å…·ä½œä¸ºæ´»åŠ¨æ‰§è¡Œå¼•æ“
   - åˆ©ç”¨PostgreSQLçš„äº‹ä»¶æº¯æºåŠŸèƒ½è€Œä¸æ˜¯é‡æ–°å®ç°

2. **æ¸è¿›å¼å®ç°**:
   - ç¬¬ä¸€é˜¶æ®µ: å®ç°å¸¦äº‹ä»¶æº¯æºçš„æ ¸å¿ƒçŠ¶æ€æœº
   - ç¬¬äºŒé˜¶æ®µ: æ·»åŠ å·¥ä½œæµç¼–æ’å’Œæ´»åŠ¨æ‰§è¡Œ
   - ç¬¬ä¸‰é˜¶æ®µ: å®ç°åˆ†å¸ƒå¼ç‰¹æ€§(å¦‚æœéœ€è¦)

3. **å¼€æºè´¡çŒ®è€ƒè™‘**:
   - è€ƒè™‘å°†å·¥ä½œæµå¼•æ“ä½œä¸ºç‹¬ç«‹é¡¹ç›®å¼€æº
   - æ¨åŠ¨Rustå·¥ä½œæµç”Ÿæ€ç³»ç»Ÿå‘å±•
   - å¸å¼•ç¤¾åŒºå…±åŒæ”¹è¿›å’Œç»´æŠ¤

## 11 åä¸€ã€ç¤ºä¾‹å·¥ä½œæµå®šä¹‰å®ç°

ä¸ºäº†è¿›ä¸€æ­¥è¯´æ˜å·¥ä½œæµå¼•æ“çš„å®é™…åº”ç”¨,ä»¥ä¸‹æ˜¯ä¸€ä¸ªåŸºäºå‰è¿°è®¾è®¡çš„è®¢å•å¤„ç†å·¥ä½œæµç¤ºä¾‹:

### 11.1 è®¢å•å·¥ä½œæµçŠ¶æ€å®šä¹‰

```rust
/// è®¢å•å·¥ä½œæµçŠ¶æ€
#[derive(Clone, Debug, Serialize, Deserialize)]
pub enum OrderState {
    Created {
        order_id: String,
        created_at: DateTime<Utc>,
    },
    
    Validated {
        order_id: String,
        validated_at: DateTime<Utc>,
    },
    
    PaymentPending {
        order_id: String,
        payment_id: Option<String>,
        amount: f64,
        currency: String,
        started_at: DateTime<Utc>,
    },
    
    PaymentFailed {
        order_id: String,
        payment_id: Option<String>,
        reason: String,
        failed_at: DateTime<Utc>,
        attempt_count: u32,
    },
    
    PaymentCompleted {
        order_id: String,
        payment_id: String,
        transaction_id: String,
        completed_at: DateTime<Utc>,
    },
    
    InventoryAllocated {
        order_id: String,
        allocation_id: String,
        allocated_at: DateTime<Utc>,
    },
    
    Shipped {
        order_id: String,
        shipment_id: String,
        tracking_number: Option<String>,
        carrier: String,
        shipped_at: DateTime<Utc>,
    },
    
    Delivered {
        order_id: String,
        shipment_id: String,
        delivered_at: DateTime<Utc>,
    },
    
    Cancelled {
        order_id: String,
        reason: String,
        cancelled_at: DateTime<Utc>,
    },
    
    Refunded {
        order_id: String,
        refund_id: String,
        amount: f64,
        refunded_at: DateTime<Utc>,
    },
}

impl WorkflowState for OrderState {
    fn state_type(&self) -> &'static str {
        match self {
            OrderState::Created { .. } => "created",
            OrderState::Validated { .. } => "validated",
            OrderState::PaymentPending { .. } => "payment_pending",
            OrderState::PaymentFailed { .. } => "payment_failed",
            OrderState::PaymentCompleted { .. } => "payment_completed",
            OrderState::InventoryAllocated { .. } => "inventory_allocated",
            OrderState::Shipped { .. } => "shipped",
            OrderState::Delivered { .. } => "delivered",
            OrderState::Cancelled { .. } => "cancelled",
            OrderState::Refunded { .. } => "refunded",
        }
    }
    
    fn is_terminal(&self) -> bool {
        matches!(self, OrderState::Delivered { .. } | OrderState::Cancelled { .. } | OrderState::Refunded { .. })
    }
    
    fn to_json(&self) -> Result<serde_json::Value, serde_json::Error> {
        serde_json::to_value(self)
    }
    
    fn from_json(json: &serde_json::Value) -> Result<Self, serde_json::Error> {
        serde_json::from_value(json.clone())
    }
}
```

### 11.2 è®¢å•å·¥ä½œæµäº‹ä»¶å®šä¹‰

```rust
/// è®¢å•å·¥ä½œæµäº‹ä»¶
#[derive(Clone, Debug, Serialize, Deserialize)]
pub enum OrderEvent {
    OrderCreated {
        event_id: Uuid,
        order_id: String,
        customer_id: String,
        items: Vec<OrderItem>,
        total_amount: f64,
        currency: String,
        shipping_address: Address,
        timestamp: DateTime<Utc>,
    },
    
    OrderValidated {
        event_id: Uuid,
        order_id: String,
        timestamp: DateTime<Utc>,
    },
    
    PaymentInitiated {
        event_id: Uuid,
        order_id: String,
        payment_id: Option<String>,
        amount: f64,
        currency: String,
        payment_method: PaymentMethod,
        timestamp: DateTime<Utc>,
    },
    
    PaymentFailed {
        event_id: Uuid,
        order_id: String,
        payment_id: Option<String>,
        reason: String,
        attempt_count: u32,
        timestamp: DateTime<Utc>,
    },
    
    PaymentCompleted {
        event_id: Uuid,
        order_id: String,
        payment_id: String,
        transaction_id: String,
        timestamp: DateTime<Utc>,
    },
    
    InventoryAllocated {
        event_id: Uuid,
        order_id: String,
        allocation_id: String,
        items: Vec<AllocatedItem>,
        timestamp: DateTime<Utc>,
    },
    
    OrderShipped {
        event_id: Uuid,
        order_id: String,
        shipment_id: String,
        tracking_number: Option<String>,
        carrier: String,
        timestamp: DateTime<Utc>,
    },
    
    OrderDelivered {
        event_id: Uuid,
        order_id: String,
        shipment_id: String,
        timestamp: DateTime<Utc>,
    },
    
    OrderCancelled {
        event_id: Uuid,
        order_id: String,
        reason: String,
        timestamp: DateTime<Utc>,
    },
    
    RefundProcessed {
        event_id: Uuid,
        order_id: String,
        refund_id: String,
        amount: f64,
        timestamp: DateTime<Utc>,
    },
    
    RetryPayment {
        event_id: Uuid,
        order_id: String,
        timestamp: DateTime<Utc>,
    },
}

impl WorkflowEvent for OrderEvent {
    fn event_type(&self) -> &'static str {
        match self {
            OrderEvent::OrderCreated { .. } => "order_created",
            OrderEvent::OrderValidated { .. } => "order_validated",
            OrderEvent::PaymentInitiated { .. } => "payment_initiated",
            OrderEvent::PaymentFailed { .. } => "payment_failed",
            OrderEvent::PaymentCompleted { .. } => "payment_completed",
            OrderEvent::InventoryAllocated { .. } => "inventory_allocated",
            OrderEvent::OrderShipped { .. } => "order_shipped",
            OrderEvent::OrderDelivered { .. } => "order_delivered",
            OrderEvent::OrderCancelled { .. } => "order_cancelled",
            OrderEvent::RefundProcessed { .. } => "refund_processed",
            OrderEvent::RetryPayment { .. } => "retry_payment",
        }
    }
    
    fn payload(&self) -> &serde_json::Value {
        &serde_json::json!({})  // å®é™…å®ç°ä¸­ä¼šè¿”å›äº‹ä»¶æ•°æ®
    }
    
    fn to_json(&self) -> Result<serde_json::Value, serde_json::Error> {
        serde_json::to_value(self)
    }
    
    fn from_json(json: &serde_json::Value) -> Result<Self, serde_json::Error> {
        serde_json::from_value(json.clone())
    }
}
```

### 11.3 è®¢å•å·¥ä½œæµå®šä¹‰

```rust
/// åˆ›å»ºè®¢å•å·¥ä½œæµå®šä¹‰
pub fn create_order_workflow_definition() -> WorkflowDefinition<OrderState, OrderEvent> {
    let mut transitions = Vec::new();
    
    // 1. Created -> Validated (è®¢å•éªŒè¯)
    transitions.push(WorkflowTransition {
        from_state: "created".to_string(),
        to_state: "validated".to_string(),
        event_type: "order_validated".to_string(),
        condition: None,
        pre_action: Some(Box::new(|state, event, context| {
            Box::pin(async move {
                // éªŒè¯è®¢å•æ´»åŠ¨
                let order_id = match state {
                    OrderState::Created { order_id, .. } => order_id.clone(),
                    _ => return Err(WorkflowError::InternalError("çŠ¶æ€ç±»å‹é”™è¯¯".to_string())),
                };
                
                // æ„å»ºéªŒè¯è¯·æ±‚
                let validate_input = serde_json::json!({
                    "order_id": order_id,
                });
                
                // è·å–æ´»åŠ¨æ‰§è¡Œå™¨å¹¶æ‰§è¡ŒéªŒè¯
                if let Some(activity_executor) = context.get_transient("activity_executor") {
                    if let Some(executor) = activity_executor.as_object() {
                        // å®é™…åº”ç”¨ä¸­ä¼šé€šè¿‡ä¾èµ–æ³¨å…¥æä¾›æ´»åŠ¨æ‰§è¡Œå™¨
                        // æ­¤å¤„çœç•¥å®é™…å®ç°...
                    }
                }
                
                Ok(())
            })
        })),
        post_action: None,
    });
    
    // 2. Validated -> PaymentPending (å‘èµ·æ”¯ä»˜)
    transitions.push(WorkflowTransition {
        from_state: "validated".to_string(),
        to_state: "payment_pending".to_string(),
        event_type: "payment_initiated".to_string(),
        condition: None,
        pre_action: Some(Box::new(|state, event, context| {
            Box::pin(async move {
                // å‘èµ·æ”¯ä»˜æ´»åŠ¨
                let order_id = match state {
                    OrderState::Validated { order_id, .. } => order_id.clone(),
                    _ => return Err(WorkflowError::InternalError("çŠ¶æ€ç±»å‹é”™è¯¯".to_string())),
                };
                
                // ä»ä¸Šä¸‹æ–‡ä¸­è·å–æ”¯ä»˜ä¿¡æ¯
                let amount = context.get_variable("total_amount")
                    .and_then(|v| v.as_f64())
                    .ok_or_else(|| WorkflowError::ValidationError("ç¼ºå°‘æ€»é‡‘é¢".to_string()))?;
                    
                let currency = context.get_variable("currency")
                    .and_then(|v| v.as_str())
                    .ok_or_else(|| WorkflowError::ValidationError("ç¼ºå°‘å¸ç§".to_string()))?;
                    
                // æ„å»ºæ”¯ä»˜è¯·æ±‚...
                
                Ok(())
            })
        })),
        post_action: None,
    });
    
    // 3. PaymentPending -> PaymentFailed (æ”¯ä»˜å¤±è´¥)
    transitions.push(WorkflowTransition {
        from_state: "payment_pending".to_string(),
        to_state: "payment_failed".to_string(),
        event_type: "payment_failed".to_string(),
        condition: None,
        pre_action: None,
        post_action: Some(Box::new(|state, event, context| {
            Box::pin(async move {
                // è®°å½•æ”¯ä»˜å¤±è´¥åŸå› 
                if let OrderEvent::PaymentFailed { reason, attempt_count, .. } = event {
                    context.set_variable("payment_failure_reason", serde_json::Value::String(reason.clone()));
                    context.set_variable("payment_attempts", serde_json::json!(attempt_count));
                }
                
                Ok(())
            })
        })),
    });
    
    // 4. PaymentFailed -> PaymentPending (é‡è¯•æ”¯ä»˜)
    transitions.push(WorkflowTransition {
        from_state: "payment_failed".to_string(),
        to_state: "payment_pending".to_string(),
        event_type: "retry_payment".to_string(),
        condition: Some(Box::new(|state, _, context| {
            // æ£€æŸ¥é‡è¯•æ¬¡æ•°æ˜¯å¦è¶…è¿‡é™åˆ¶
            if let OrderState::PaymentFailed { attempt_count, .. } = state {
                return *attempt_count < 3; // æœ€å¤šé‡è¯•3æ¬¡
            }
            false
        })),
        pre_action: None,
        post_action: None,
    });
    
    // 5. PaymentFailed -> Cancelled (æ”¾å¼ƒé‡è¯•,å–æ¶ˆè®¢å•)
    transitions.push(WorkflowTransition {
        from_state: "payment_failed".to_string(),
        to_state: "cancelled".to_string(),
        event_type: "order_cancelled".to_string(),
        condition: Some(Box::new(|state, _, _| {
            // é‡è¯•æ¬¡æ•°è¾¾åˆ°ä¸Šé™æ—¶å…è®¸å–æ¶ˆ
            if let OrderState::PaymentFailed { attempt_count, .. } = state {
                return *attempt_count >= 3;
            }
            false
        })),
        pre_action: None,
        post_action: None,
    });
    
    // 6. PaymentPending -> PaymentCompleted (æ”¯ä»˜æˆåŠŸ)
    transitions.push(WorkflowTransition {
        from_state: "payment_pending".to_string(),
        to_state: "payment_completed".to_string(),
        event_type: "payment_completed".to_string(),
        condition: None,
        pre_action: None,
        post_action: None,
    });
    
    // 7. PaymentCompleted -> InventoryAllocated (åˆ†é…åº“å­˜)
    transitions.push(WorkflowTransition {
        from_state: "payment_completed".to_string(),
        to_state: "inventory_allocated".to_string(),
        event_type: "inventory_allocated".to_string(),
        condition: None,
        pre_action: Some(Box::new(|state, event, context| {
            Box::pin(async move {
                // åˆ†é…åº“å­˜æ´»åŠ¨
                let order_id = match state {
                    OrderState::PaymentCompleted { order_id, .. } => order_id.clone(),
                    _ => return Err(WorkflowError::InternalError("çŠ¶æ€ç±»å‹é”™è¯¯".to_string())),
                };
                
                // ä»ä¸Šä¸‹æ–‡ä¸­è·å–è®¢å•é¡¹
                let items = context.get_variable("items")
                    .ok_or_else(|| WorkflowError::ValidationError("ç¼ºå°‘è®¢å•é¡¹".to_string()))?;
                    
                // æ„å»ºåº“å­˜åˆ†é…è¯·æ±‚...
                
                Ok(())
            })
        })),
        post_action: None,
    });
    
    // 8. InventoryAllocated -> Shipped (è®¢å•å‘è´§)
    transitions.push(WorkflowTransition {
        from_state: "inventory_allocated".to_string(),
        to_state: "shipped".to_string(),
        event_type: "order_shipped".to_string(),
        condition: None,
        pre_action: Some(Box::new(|state, event, context| {
            Box::pin(async move {
                // åˆ›å»ºå‘è´§å•æ´»åŠ¨
                let order_id = match state {
                    OrderState::InventoryAllocated { order_id, .. } => order_id.clone(),
                    _ => return Err(WorkflowError::InternalError("çŠ¶æ€ç±»å‹é”™è¯¯".to_string())),
                };
                
                // æ„å»ºå‘è´§è¯·æ±‚...
                
                Ok(())
            })
        })),
        post_action: Some(Box::new(|_, event, context| {
            Box::pin(async move {
                // å‘é€å‘è´§é€šçŸ¥
                if let OrderEvent::OrderShipped { order_id, tracking_number, carrier, .. } = event {
                    // å‡†å¤‡é€šçŸ¥æ•°æ®
                    let notification_data = serde_json::json!({
                        "order_id": order_id,
                        "tracking_number": tracking_number,
                        "carrier": carrier,
                        "type": "shipping_notification"
                    });
                    
                    // å‘é€é€šçŸ¥...
                    context.set_variable("notification_sent", serde_json::json!(true));
                }
                
                Ok(())
            })
        })),
    });
    
    // 9. Shipped -> Delivered (è®¢å•äº¤ä»˜)
    transitions.push(WorkflowTransition {
        from_state: "shipped".to_string(),
        to_state: "delivered".to_string(),
        event_type: "order_delivered".to_string(),
        condition: None,
        pre_action: None,
        post_action: Some(Box::new(|_, event, context| {
            Box::pin(async move {
                // å‘é€äº¤ä»˜é€šçŸ¥
                if let OrderEvent::OrderDelivered { order_id, .. } = event {
                    // å‡†å¤‡é€šçŸ¥æ•°æ®
                    let notification_data = serde_json::json!({
                        "order_id": order_id,
                        "type": "delivery_notification"
                    });
                    
                    // å‘é€é€šçŸ¥...
                    context.set_variable("delivery_notification_sent", serde_json::json!(true));
                }
                
                Ok(())
            })
        })),
    });
    
    // 10. ä»»ä½•éç»ˆæ€ -> Cancelled (è®¢å•å–æ¶ˆ)
    // ä»Createdåˆ°Shippedçš„ä»»ä½•çŠ¶æ€éƒ½å¯ä»¥å–æ¶ˆ
    for state in &["created", "validated", "payment_pending", "payment_completed", "inventory_allocated", "shipped"] {
        transitions.push(WorkflowTransition {
            from_state: state.to_string(),
            to_state: "cancelled".to_string(),
            event_type: "order_cancelled".to_string(),
            condition: None,
            pre_action: None,
            post_action: Some(Box::new(|state, event, context| {
                Box::pin(async move {
                    // å¤„ç†å–æ¶ˆåçš„æ¸…ç†æ“ä½œ
                    if let OrderEvent::OrderCancelled { order_id, reason, .. } = event {
                        context.set_variable("cancellation_reason", serde_json::Value::String(reason.clone()));
                        
                        // æ ¹æ®å½“å‰çŠ¶æ€æ‰§è¡Œä¸åŒçš„è¡¥å¿æ“ä½œ
                        match state {
                            OrderState::PaymentCompleted { .. } => {
                                // å‘èµ·é€€æ¬¾æµç¨‹
                                // ...
                            },
                            OrderState::InventoryAllocated { allocation_id, .. } => {
                                // é‡Šæ”¾åº“å­˜
                                // ...
                            },
                            _ => {} // å…¶ä»–çŠ¶æ€æ— éœ€ç‰¹æ®Šå¤„ç†
                        }
                    }
                    
                    Ok(())
                })
            })),
        });
    }
    
    // 11. PaymentCompleted/InventoryAllocated/Shipped/Cancelled -> Refunded (é€€æ¬¾å¤„ç†)
    for state in &["payment_completed", "inventory_allocated", "shipped", "cancelled"] {
        transitions.push(WorkflowTransition {
            from_state: state.to_string(),
            to_state: "refunded".to_string(),
            event_type: "refund_processed".to_string(),
            condition: None,
            pre_action: Some(Box::new(|state, _, context| {
                Box::pin(async move {
                    // å‘èµ·é€€æ¬¾æ“ä½œ
                    let (order_id, payment_id) = match state {
                        OrderState::PaymentCompleted { order_id, payment_id, .. } => 
                            (order_id.clone(), Some(payment_id.clone())),
                        OrderState::InventoryAllocated { order_id, .. } =>
                            (order_id.clone(), context.get_variable("payment_id").and_then(|v| v.as_str().map(String::from))),
                        OrderState::Shipped { order_id, .. } =>
                            (order_id.clone(), context.get_variable("payment_id").and_then(|v| v.as_str().map(String::from))),
                        OrderState::Cancelled { order_id, .. } =>
                            (order_id.clone(), context.get_variable("payment_id").and_then(|v| v.as_str().map(String::from))),
                        _ => return Err(WorkflowError::InternalError("çŠ¶æ€ç±»å‹é”™è¯¯".to_string())),
                    };
                    
                    if let Some(payment_id) = payment_id {
                        // æ„å»ºé€€æ¬¾è¯·æ±‚...
                    } else {
                        return Err(WorkflowError::ValidationError("æ‰¾ä¸åˆ°æ”¯ä»˜ID,æ— æ³•å‘èµ·é€€æ¬¾".to_string()));
                    }
                    
                    Ok(())
                })
            })),
            post_action: Some(Box::new(|_, event, context| {
                Box::pin(async move {
                    // å‘é€é€€æ¬¾é€šçŸ¥
                    if let OrderEvent::RefundProcessed { order_id, refund_id, amount, .. } = event {
                        // å‡†å¤‡é€šçŸ¥æ•°æ®
                        let notification_data = serde_json::json!({
                            "order_id": order_id,
                            "refund_id": refund_id,
                            "amount": amount,
                            "type": "refund_notification"
                        });
                        
                        // å‘é€é€šçŸ¥...
                        context.set_variable("refund_notification_sent", serde_json::json!(true));
                    }
                    
                    Ok(())
                })
            })),
        });
    }
    
    // åˆ›å»ºå·¥ä½œæµå®šä¹‰
    let initial_state = OrderState::Created { 
        order_id: "placeholder".to_string(), 
        created_at: Utc::now() 
    };
    
    // è®¾ç½®è¶…æ—¶é…ç½®
    let mut state_timeouts = HashMap::new();
    state_timeouts.insert("payment_pending".to_string(), chrono::Duration::hours(2)); // æ”¯ä»˜æœ‰2å°æ—¶è¶…æ—¶
    state_timeouts.insert("shipped".to_string(), chrono::Duration::days(14)); // å‘è´§å14å¤©é€è¾¾è¶…æ—¶
    
    let timeout_config = Some(WorkflowTimeoutConfig {
        workflow_timeout: Some(chrono::Duration::days(30)), // æ•´ä¸ªè®¢å•æµç¨‹30å¤©è¶…æ—¶
        state_timeouts: Some(state_timeouts),
        activity_timeout: Some(chrono::Duration::minutes(5)), // æ´»åŠ¨é»˜è®¤5åˆ†é’Ÿè¶…æ—¶
    });
    
    // è®¾ç½®é‡è¯•ç­–ç•¥
    let retry_policy = Some(RetryPolicy {
        max_attempts: 3,
        initial_interval: Duration::from_secs(1),
        max_interval: Duration::from_secs(60),
        backoff_coefficient: 2.0,
        non_retryable_errors: vec!["ValidationError".to_string(), "BusinessRuleViolation".to_string()],
    });
    
    WorkflowDefinition {
        workflow_type: "order_processing".to_string(),
        version: "1.0.0".to_string(),
        initial_state,
        transitions,
        timeout_config,
        retry_policy,
    }
}
```

é€šè¿‡ä»¥ä¸Šç¤ºä¾‹,æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å·¥ä½œæµå¼•æ“å¦‚ä½•åº”ç”¨äºå®é™…ä¸šåŠ¡åœºæ™¯ã€‚è¿™ç§è®¾è®¡å°†ä¸šåŠ¡é€»è¾‘å’ŒçŠ¶æ€è½¬æ¢è§„åˆ™æ¸…æ™°åœ°åˆ†ç¦»,å¹¶åˆ©ç”¨Rustçš„ç±»å‹ç³»ç»Ÿç¡®ä¿çŠ¶æ€è½¬æ¢çš„å®‰å…¨æ€§ã€‚é€šè¿‡äº‹ä»¶æº¯æº,ç³»ç»Ÿå¯ä»¥ç¡®ä¿æ‰€æœ‰ä¸šåŠ¡æ“ä½œéƒ½è¢«è®°å½•å’Œå¯å®¡è®¡,åŒæ—¶æä¾›é«˜æ•ˆçš„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶ã€‚
