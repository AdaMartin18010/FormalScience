# å·¥ä½œæµæ¨¡å¼ä¸åˆ†å¸ƒå¼è®¾è®¡æ¨¡å¼çš„ç»¼åˆå®è·µ

```text
<think>
æˆ‘éœ€è¦åˆ›å»ºä¸€ä¸ªç»¼åˆç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•å°†21ç§å·¥ä½œæµæ¨¡å¼ä¸åˆ†å¸ƒå¼è®¾è®¡æ¨¡å¼ç»“åˆèµ·æ¥ï¼Œå¹¶ä½¿ç”¨Rustçš„å¼€æºåº“å®ç°ã€‚

è¿™ä¸ªç¤ºä¾‹åº”è¯¥:
1. æ¶µç›–21ç§å·¥ä½œæµæ¨¡å¼
2. æ•´åˆåˆ†å¸ƒå¼è®¾è®¡æ¨¡å¼
3. ä½¿ç”¨Rustçš„çŸ¥åå¼€æºåº“
4. é€šè¿‡ä¸€ä¸ªå®é™…åœºæ™¯å±•ç¤ºè¿™äº›æ¨¡å¼çš„ç»“åˆ

å…ˆåˆ—å‡ºç›¸å…³çš„å·¥ä½œæµæ¨¡å¼å’Œåˆ†å¸ƒå¼è®¾è®¡æ¨¡å¼:

**å·¥ä½œæµæ¨¡å¼:**
- é¡ºåºå·¥ä½œæµ
- å¹¶è¡Œå·¥ä½œæµ
- çŠ¶æ€æœº
- äº‹ä»¶é©±åŠ¨
- äººå·¥ä»»åŠ¡
- ä¸šåŠ¡è§„åˆ™
- æµç¨‹ç¼–æ’
- å­æµç¨‹
- å®šæ—¶è§¦å‘
- å¼‚å¸¸å¤„ç†
- è¡¥å¿äº‹åŠ¡
- æ¶ˆæ¯ä¸­é—´ä»¶é›†æˆ
- æœåŠ¡ç¼–æ’
- æœåŠ¡ç¼–æ’ä¸åè°ƒ
- åŠ¨æ€å·¥ä½œæµ
- é•¿æ—¶é—´è¿è¡Œçš„å·¥ä½œæµ
- å¤šå®ä¾‹æ¨¡å¼
- æ¡ä»¶è·¯ç”±
- å¹¶è¡Œæ‹†åˆ†ä¸åˆå¹¶
- é‡Œç¨‹ç¢‘ä¸é˜¶æ®µ
- ç‰ˆæœ¬æ§åˆ¶

**åˆ†å¸ƒå¼è®¾è®¡æ¨¡å¼:**
- å®¹é”™æ¨¡å¼(ç†”æ–­å™¨ã€èˆ±å£æ¨¡å¼ã€è¶…æ—¶ä¸é‡è¯•ã€èƒŒå‹)
- äº‹åŠ¡æ¨¡å¼(ä¸¤é˜¶æ®µæäº¤ã€SAGAã€TCC)
- ç¼“å­˜æ¨¡å¼(æœ¬åœ°ç¼“å­˜ã€åˆ†å¸ƒå¼ç¼“å­˜ã€ç¼“å­˜é˜²å¾¡)
- æœåŠ¡å‘ç°ä¸é…ç½®(æœåŠ¡æ³¨å†Œä¸å‘ç°ã€é…ç½®ä¸­å¿ƒã€è¾¹è½¦æ¨¡å¼)
- è°ƒåº¦ä¸è´Ÿè½½å‡è¡¡(è´Ÿè½½å‡è¡¡ã€æœåŠ¡ç½‘æ ¼ã€ä»»åŠ¡è°ƒåº¦)

**å¯ä»¥ä½¿ç”¨çš„Rustå¼€æºåº“:**
- Tokio (å¼‚æ­¥è¿è¡Œæ—¶)
- Actix (Actoræ¡†æ¶)
- Reqwest (HTTPå®¢æˆ·ç«¯)
- Serde (åºåˆ—åŒ–/ååºåˆ—åŒ–)
- Diesel (ORM)
- Rusoto (AWS SDK)
- Redis-rs (Rediså®¢æˆ·ç«¯)
- Kafka-rust (Kafkaå®¢æˆ·ç«¯)
- Hyper (HTTP)
- Tonic (gRPC)
- Lapin (RabbitMQ)
- Raft-rs (åˆ†å¸ƒå¼ä¸€è‡´æ€§)

**å®ä¾‹é€‰æ‹©:**
æˆ‘å°†åˆ›å»ºä¸€ä¸ªç”µå­å•†åŠ¡è®¢å•å¤„ç†ç³»ç»Ÿï¼Œæ¶µç›–ä»ä¸‹å•åˆ°é…é€çš„å®Œæ•´æµç¨‹ï¼Œè¿™æ ·å¯ä»¥è‡ªç„¶åœ°èåˆå¤šç§å·¥ä½œæµæ¨¡å¼å’Œåˆ†å¸ƒå¼è®¾è®¡æ¨¡å¼ã€‚
</think>
```

## ğŸ“‹ ç›®å½•

- [1 ç”µå­å•†åŠ¡å¹³å°è®¢å•å¤„ç†ç³»ç»Ÿ](#1-ç”µå­å•†åŠ¡å¹³å°è®¢å•å¤„ç†ç³»ç»Ÿ)
  - [1.1 ç³»ç»Ÿæ¶æ„ä¸æ ¸å¿ƒç»„ä»¶](#11-ç³»ç»Ÿæ¶æ„ä¸æ ¸å¿ƒç»„ä»¶)
  - [1.2 å·¥ä½œæµå¼•æ“å®ç°](#12-å·¥ä½œæµå¼•æ“å®ç°)
  - [1.3 åˆ†å¸ƒå¼è®¾è®¡æ¨¡å¼å®ç°](#13-åˆ†å¸ƒå¼è®¾è®¡æ¨¡å¼å®ç°)
  - [1.4 æœåŠ¡æ³¨å†Œä¸å‘ç°å®ç°](#14-æœåŠ¡æ³¨å†Œä¸å‘ç°å®ç°)
  - [1.5 è®¢å•å¤„ç†å·¥ä½œæµå®ç°](#15-è®¢å•å¤„ç†å·¥ä½œæµå®ç°)
  - [1.6 æœåŠ¡ç½‘æ ¼é›†æˆå®ç°](#16-æœåŠ¡ç½‘æ ¼é›†æˆå®ç°)
  - [1.7 å®Œæ•´ç¤ºä¾‹æµç¨‹å±•ç¤º](#17-å®Œæ•´ç¤ºä¾‹æµç¨‹å±•ç¤º)

---

## 1 ç”µå­å•†åŠ¡å¹³å°è®¢å•å¤„ç†ç³»ç»Ÿ

ä¸‹é¢æˆ‘å°†é€šè¿‡ä¸€ä¸ªç”µå­å•†åŠ¡è®¢å•å¤„ç†ç³»ç»Ÿï¼Œå±•ç¤ºå¦‚ä½•ç»“åˆå·¥ä½œæµæ¨¡å¼ä¸åˆ†å¸ƒå¼è®¾è®¡æ¨¡å¼ï¼Œå¹¶ä½¿ç”¨Rustçš„å¼€æºåº“æ¥å®ç°ã€‚

```rust
// ä¾èµ–åº“
use tokio::{self, sync::{mpsc, oneshot, Mutex, RwLock}};
use async_trait::async_trait;
use futures::{stream, StreamExt};
use serde::{Serialize, Deserialize};
use redis::{Client as RedisClient, AsyncCommands};
use lapin::{Connection, ConnectionProperties, options::*, types::FieldTable};
use sqlx::{Pool, Postgres, postgres::PgPoolOptions};
use uuid::Uuid;
use dashmap::DashMap;
use tower::Service;
use tracing::{info, error, warn, instrument};
use reqwest::Client as HttpClient;
```

### 1.1 ç³»ç»Ÿæ¶æ„ä¸æ ¸å¿ƒç»„ä»¶

```rust
/// ç³»ç»Ÿæ¶æ„ï¼š
/// - è®¢å•æœåŠ¡: å¤„ç†è®¢å•åˆ›å»ºå’ŒçŠ¶æ€ç®¡ç†
/// - æ”¯ä»˜æœåŠ¡: å¤„ç†æ”¯ä»˜æµç¨‹
/// - åº“å­˜æœåŠ¡: ç®¡ç†äº§å“åº“å­˜
/// - ç‰©æµæœåŠ¡: å¤„ç†é…é€æµç¨‹
/// - é€šçŸ¥æœåŠ¡: å‘ç”¨æˆ·å‘é€é€šçŸ¥

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct Order {
    id: String,
    user_id: String,
    items: Vec<OrderItem>,
    total_amount: f64,
    status: OrderStatus,
    created_at: chrono::DateTime<chrono::Utc>,
    updated_at: chrono::DateTime<chrono::Utc>,
}

#[derive(Clone, Debug, Serialize, Deserialize, PartialEq)]
pub enum OrderStatus {
    Created,
    PaymentPending,
    PaymentCompleted,
    PaymentFailed,
    InventoryChecked,
    InventoryReserved,
    Processing,
    Shipped,
    Delivered,
    Cancelled,
    Refunded,
}
```

### 1.2 å·¥ä½œæµå¼•æ“å®ç°

```rust
/// å·¥ä½œæµå¼•æ“ - ç»“åˆé¡ºåºå·¥ä½œæµã€çŠ¶æ€æœºã€äº‹ä»¶é©±åŠ¨å’ŒåŠ¨æ€å·¥ä½œæµæ¨¡å¼
pub struct WorkflowEngine {
    workflow_definitions: DashMap<String, WorkflowDefinition>,
    execution_store: WorkflowExecutionStore,
    event_bus: Arc<EventBus>,
    saga_coordinator: Arc<SagaCoordinator>,
    circuit_breaker: Arc<CircuitBreaker>,
}

#[derive(Clone)]
pub struct WorkflowDefinition {
    id: String,
    name: String,
    version: u32,
    states: HashMap<String, WorkflowState>,
    initial_state: String,
    final_states: HashSet<String>,
}

#[derive(Clone)]
pub struct WorkflowState {
    id: String,
    name: String,
    actions: Vec<Arc<dyn WorkflowAction>>,
    transitions: Vec<Transition>,
    is_compensable: bool,
    compensation_action: Option<Arc<dyn WorkflowAction>>,
}

#[derive(Clone)]
pub struct Transition {
    from: String,
    to: String,
    condition: Arc<dyn TransitionCondition>,
}

impl WorkflowEngine {
    #[instrument(skip(self))]
    pub async fn start_workflow(&self, definition_id: &str, input: Value) -> Result<String, WorkflowError> {
        // ä½¿ç”¨ç†”æ–­å™¨æ¨¡å¼é˜²æ­¢æœåŠ¡è¿‡è½½
        self.circuit_breaker.execute(|| async {
            let definition = self.workflow_definitions.get(definition_id)
                .ok_or(WorkflowError::DefinitionNotFound)?;
                
            let execution_id = Uuid::new_v4().to_string();
            
            // åˆ›å»ºå·¥ä½œæµå®ä¾‹
            let initial_state = definition.initial_state.clone();
            let execution = WorkflowExecution {
                id: execution_id.clone(),
                definition_id: definition_id.to_string(),
                current_state: initial_state.clone(),
                status: ExecutionStatus::Running,
                context: HashMap::new(),
                created_at: chrono::Utc::now(),
                updated_at: chrono::Utc::now(),
            };
            
            // å­˜å‚¨å·¥ä½œæµå®ä¾‹
            self.execution_store.save_execution(&execution).await?;
            
            // å‘å¸ƒå·¥ä½œæµå¯åŠ¨äº‹ä»¶
            self.event_bus.publish(Event::new(
                "workflow.started",
                json!({
                    "execution_id": execution_id,
                    "definition_id": definition_id,
                })
            )).await?;
            
            // æ‰§è¡Œåˆå§‹çŠ¶æ€çš„åŠ¨ä½œ
            self.execute_state_actions(&execution_id, &initial_state, &input).await?;
            
            Ok(execution_id)
        }).await
    }
    
    #[instrument(skip(self))]
    async fn execute_state_actions(&self, execution_id: &str, state_id: &str, input: &Value) -> Result<(), WorkflowError> {
        let execution = self.execution_store.get_execution(execution_id).await?;
        let definition = self.workflow_definitions.get(&execution.definition_id)
            .ok_or(WorkflowError::DefinitionNotFound)?;
            
        let state = definition.states.get(state_id)
            .ok_or(WorkflowError::StateNotFound)?;
            
        // ä½¿ç”¨SAGAæ¨¡å¼è¿›è¡Œæµç¨‹ç¼–æ’
        let saga = self.saga_coordinator.create_saga(execution_id);
        
        for action in &state.actions {
            // æ·»åŠ æ“ä½œå’Œè¡¥å¿
            if state.is_compensable {
                saga.add_step(
                    |ctx| action.execute(ctx),
                    |ctx| {
                        if let Some(comp) = &state.compensation_action {
                            comp.execute(ctx)
                        } else {
                            futures::future::ok(Value::Null).boxed()
                        }
                    }
                ).await;
            } else {
                // éè¡¥å¿æ€§åŠ¨ä½œ
                let result = action.execute(input).await?;
                
                // æ›´æ–°å·¥ä½œæµä¸Šä¸‹æ–‡
                let mut execution = self.execution_store.get_execution(execution_id).await?;
                execution.context.insert(action.id().to_string(), result);
                self.execution_store.save_execution(&execution).await?;
            }
        }
        
        // æ‰§è¡ŒSAGA
        saga.execute().await?;
        
        // æ›´æ–°å·¥ä½œæµçŠ¶æ€
        self.process_transitions(execution_id).await?;
        
        Ok(())
    }
    
    #[instrument(skip(self))]
    async fn process_transitions(&self, execution_id: &str) -> Result<(), WorkflowError> {
        let execution = self.execution_store.get_execution(execution_id).await?;
        let definition = self.workflow_definitions.get(&execution.definition_id)
            .ok_or(WorkflowError::DefinitionNotFound)?;
            
        let current_state = definition.states.get(&execution.current_state)
            .ok_or(WorkflowError::StateNotFound)?;
            
        // è¯„ä¼°è½¬æ¢æ¡ä»¶
        for transition in &current_state.transitions {
            if transition.condition.evaluate(&execution.context).await? {
                // æ›´æ–°çŠ¶æ€
                let mut updated = execution.clone();
                updated.current_state = transition.to.clone();
                updated.updated_at = chrono::Utc::now();
                
                self.execution_store.save_execution(&updated).await?;
                
                // å¦‚æœä¸æ˜¯æœ€ç»ˆçŠ¶æ€ï¼Œåˆ™ç»§ç»­æ‰§è¡ŒåŠ¨ä½œ
                if !definition.final_states.contains(&transition.to) {
                    let context = json!(execution.context);
                    self.execute_state_actions(execution_id, &transition.to, &context).await?;
                } else {
                    // å·¥ä½œæµå®Œæˆ
                    let mut completed = updated.clone();
                    completed.status = ExecutionStatus::Completed;
                    self.execution_store.save_execution(&completed).await?;
                    
                    self.event_bus.publish(Event::new(
                        "workflow.completed",
                        json!({
                            "execution_id": execution_id,
                            "definition_id": execution.definition_id,
                        })
                    )).await?;
                }
                
                break;
            }
        }
        
        Ok(())
    }
}
```

### 1.3 åˆ†å¸ƒå¼è®¾è®¡æ¨¡å¼å®ç°

```rust
/// ç†”æ–­å™¨æ¨¡å¼å®ç° - ä½¿ç”¨ Failsafe-rs åº“
pub struct CircuitBreaker {
    breakers: DashMap<String, failsafe::CircuitBreaker>,
    config: CircuitBreakerConfig,
}

impl CircuitBreaker {
    pub fn new(config: CircuitBreakerConfig) -> Self {
        Self {
            breakers: DashMap::new(),
            config,
        }
    }
    
    pub async fn execute<F, Fut, T, E>(&self, operation: F) -> Result<T, E>
    where
        F: FnOnce() -> Fut,
        Fut: Future<Output = Result<T, E>>,
        E: std::error::Error + 'static,
    {
        let service_name = std::any::type_name::<F>();
        let breaker = self.breakers.entry(service_name.to_string()).or_insert_with(|| {
            failsafe::CircuitBreaker::builder()
                .failure_rate_threshold(self.config.failure_threshold)
                .wait_interval(self.config.reset_timeout)
                .build()
        });
        
        breaker.call(operation).await
    }
}

/// SAGA æ¨¡å¼å®ç° - åˆ†å¸ƒå¼äº‹åŠ¡åè°ƒ
pub struct SagaCoordinator {
    store: Arc<SagaStore>,
    event_bus: Arc<EventBus>,
}

pub struct Saga {
    id: String,
    steps: Vec<SagaStep>,
    coordinator: Arc<SagaCoordinator>,
}

impl Saga {
    pub async fn add_step<E, C>(&mut self, 
        execute: E, 
        compensate: C
    ) -> &mut Self
    where
        E: Fn(&Value) -> BoxFuture<'static, Result<Value, SagaError>> + Send + Sync + 'static,
        C: Fn(&Value) -> BoxFuture<'static, Result<Value, SagaError>> + Send + Sync + 'static,
    {
        self.steps.push(SagaStep {
            id: format!("step-{}", self.steps.len() + 1),
            execute: Arc::new(execute),
            compensate: Arc::new(compensate),
            executed: false,
        });
        
        self
    }
    
    pub async fn execute(&mut self) -> Result<Value, SagaError> {
        let mut context = json!({});
        let mut completed_steps = Vec::new();
        
        // æ‰§è¡Œäº‹åŠ¡æ­¥éª¤
        for step in &mut self.steps {
            match (step.execute)(&context).await {
                Ok(result) => {
                    // è®°å½•æ­¥éª¤æ‰§è¡ŒæˆåŠŸ
                    step.executed = true;
                    completed_steps.push(step.id.clone());
                    
                    // åˆå¹¶ç»“æœåˆ°ä¸Šä¸‹æ–‡
                    if let Some(obj) = result.as_object() {
                        for (k, v) in obj {
                            if let Some(obj_mut) = context.as_object_mut() {
                                obj_mut.insert(k.clone(), v.clone());
                            }
                        }
                    }
                }
                Err(e) => {
                    // æ‰§è¡Œè¡¥å¿æ“ä½œ
                    self.compensate(&completed_steps, &context).await?;
                    return Err(e);
                }
            }
        }
        
        // æ‰€æœ‰æ­¥éª¤æ‰§è¡ŒæˆåŠŸ
        Ok(context)
    }
    
    async fn compensate(&self, completed_steps: &[String], context: &Value) -> Result<(), SagaError> {
        // æŒ‰ç…§ç›¸åçš„é¡ºåºæ‰§è¡Œè¡¥å¿
        for step_id in completed_steps.iter().rev() {
            if let Some(step) = self.steps.iter().find(|s| &s.id == step_id) {
                // æ‰§è¡Œè¡¥å¿æ“ä½œ
                (step.compensate)(context).await?;
            }
        }
        
        Ok(())
    }
}

/// åˆ†å¸ƒå¼ç¼“å­˜å®ç° - ç»“åˆæœ¬åœ°ç¼“å­˜å’ŒRedis
pub struct DistributedCache {
    local_cache: moka::future::Cache<String, Vec<u8>>,
    redis_client: Arc<RedisClient>,
    bloom_filter: Arc<BloomFilter>,
}

impl DistributedCache {
    pub async fn get<T: for<'de> Deserialize<'de>>(&self, key: &str) -> Option<T> {
        // æ£€æŸ¥å¸ƒéš†è¿‡æ»¤å™¨ï¼Œé˜²æ­¢ç¼“å­˜ç©¿é€
        if !self.bloom_filter.might_contain(key) {
            return None;
        }
        
        // å…ˆæŸ¥æœ¬åœ°ç¼“å­˜
        if let Some(data) = self.local_cache.get(key).await {
            return serde_json::from_slice(&data).ok();
        }
        
        // æŸ¥è¯¢Redis
        let mut conn = self.redis_client.get_async_connection().await.ok()?;
        let data: Option<Vec<u8>> = conn.get(key).await.ok()?;
        
        if let Some(data) = data {
            // æ›´æ–°æœ¬åœ°ç¼“å­˜
            let data_clone = data.clone();
            self.local_cache.insert(key.to_string(), data_clone).await;
            
            return serde_json::from_slice(&data).ok();
        }
        
        None
    }
    
    pub async fn put<T: Serialize>(&self, key: &str, value: &T, ttl_secs: u64) -> Result<(), CacheError> {
        let serialized = serde_json::to_vec(value)?;
        
        // æ›´æ–°æœ¬åœ°ç¼“å­˜
        self.local_cache.insert(key.to_string(), serialized.clone()).await;
        
        // æ›´æ–°Redis
        let mut conn = self.redis_client.get_async_connection().await?;
        conn.set_ex(key, serialized, ttl_secs as usize).await?;
        
        // æ›´æ–°å¸ƒéš†è¿‡æ»¤å™¨
        self.bloom_filter.insert(key);
        
        Ok(())
    }
}
```

### 1.4 æœåŠ¡æ³¨å†Œä¸å‘ç°å®ç°

```rust
/// æœåŠ¡æ³¨å†Œä¸å‘ç° - ä½¿ç”¨Consul
pub struct ServiceRegistry {
    consul_client: ConsulClient,
    service_cache: RwLock<HashMap<String, Vec<ServiceInstance>>>,
    refresh_interval: Duration,
}

impl ServiceRegistry {
    pub async fn new(consul_url: &str, refresh_interval: Duration) -> Result<Self, Error> {
        let client = ConsulClient::new(consul_url)?;
        let registry = Self {
            consul_client: client,
            service_cache: RwLock::new(HashMap::new()),
            refresh_interval,
        };
        
        // å¯åŠ¨åå°åˆ·æ–°ä»»åŠ¡
        registry.start_refresh_task();
        
        Ok(registry)
    }
    
    pub async fn register_service(&self, service: Service) -> Result<(), Error> {
        self.consul_client.register_service(&service).await
    }
    
    pub async fn deregister_service(&self, service_id: &str) -> Result<(), Error> {
        self.consul_client.deregister_service(service_id).await
    }
    
    pub async fn discover_service(&self, service_name: &str) -> Result<Vec<ServiceInstance>, Error> {
        // å…ˆä»ç¼“å­˜è·å–
        let cache = self.service_cache.read().await;
        if let Some(instances) = cache.get(service_name) {
            return Ok(instances.clone());
        }
        
        // ç¼“å­˜æœªå‘½ä¸­ï¼Œä»Consulè·å–
        let instances = self.consul_client.get_service(service_name).await?;
        
        // æ›´æ–°ç¼“å­˜
        drop(cache);
        let mut cache = self.service_cache.write().await;
        cache.insert(service_name.to_string(), instances.clone());
        
        Ok(instances)
    }
    
    fn start_refresh_task(&self) {
        let client = self.consul_client.clone();
        let cache = self.service_cache.clone();
        let interval = self.refresh_interval;
        
        tokio::spawn(async move {
            let mut timer = tokio::time::interval(interval);
            
            loop {
                timer.tick().await;
                
                // è·å–æ‰€æœ‰æœåŠ¡
                match client.get_services().await {
                    Ok(services) => {
                        let mut new_cache = HashMap::new();
                        
                        // è·å–æ¯ä¸ªæœåŠ¡çš„å®ä¾‹
                        for service_name in services {
                            if let Ok(instances) = client.get_service(&service_name).await {
                                new_cache.insert(service_name, instances);
                            }
                        }
                        
                        // æ›´æ–°ç¼“å­˜
                        let mut cache_write = cache.write().await;
                        *cache_write = new_cache;
                    }
                    Err(e) => {
                        error!("Failed to refresh service registry: {}", e);
                    }
                }
            }
        });
    }
}
```

### 1.5 è®¢å•å¤„ç†å·¥ä½œæµå®ç°

```rust
/// è®¢å•å¤„ç†å·¥ä½œæµ - ç»“åˆå¤šç§æ¨¡å¼
pub fn create_order_workflow() -> WorkflowDefinition {
    let mut workflow = WorkflowDefinition {
        id: "order-processing".to_string(),
        name: "Order Processing Workflow".to_string(),
        version: 1,
        states: HashMap::new(),
        initial_state: "order_created".to_string(),
        final_states: HashSet::from([
            "order_delivered".to_string(),
            "order_cancelled".to_string(),
        ]),
    };
    
    // åˆ›å»ºè®¢å•çŠ¶æ€
    workflow.states.insert("order_created".to_string(), WorkflowState {
        id: "order_created".to_string(),
        name: "Order Created".to_string(),
        actions: vec![
            Arc::new(ValidateOrderAction {}),
            Arc::new(ReserveInventoryAction {}),
        ],
        transitions: vec![
            Transition {
                from: "order_created".to_string(),
                to: "payment_pending".to_string(),
                condition: Arc::new(AlwaysTrue {}),
            }
        ],
        is_compensable: true,
        compensation_action: Some(Arc::new(ReleaseInventoryAction {})),
    });
    
    // æ”¯ä»˜å¤„ç†çŠ¶æ€
    workflow.states.insert("payment_pending".to_string(), WorkflowState {
        id: "payment_pending".to_string(),
        name: "Payment Pending".to_string(),
        actions: vec![
            Arc::new(ProcessPaymentAction {}),
        ],
        transitions: vec![
            Transition {
                from: "payment_pending".to_string(),
                to: "payment_completed".to_string(),
                condition: Arc::new(PaymentSuccessful {}),
            },
            Transition {
                from: "payment_pending".to_string(),
                to: "order_cancelled".to_string(),
                condition: Arc::new(PaymentFailed {}),
            }
        ],
        is_compensable: true,
        compensation_action: Some(Arc::new(RefundPaymentAction {})),
    });
    
    // å…¶ä»–çŠ¶æ€å®šä¹‰...
    
    workflow
}

// å·¥ä½œæµæ“ä½œå®šä¹‰
struct ValidateOrderAction {}

#[async_trait]
impl WorkflowAction for ValidateOrderAction {
    fn id(&self) -> &str {
        "validate_order"
    }
    
    async fn execute(&self, input: &Value) -> Result<Value, WorkflowError> {
        // å®ç°è®¢å•éªŒè¯é€»è¾‘
        // ...
        Ok(json!({ "validation": "success" }))
    }
}

struct ReserveInventoryAction {}

#[async_trait]
impl WorkflowAction for ReserveInventoryAction {
    fn id(&self) -> &str {
        "reserve_inventory"
    }
    
    async fn execute(&self, input: &Value) -> Result<Value, WorkflowError> {
        // è°ƒç”¨åº“å­˜æœåŠ¡ï¼Œä½¿ç”¨æ–­è·¯å™¨æ¨¡å¼
        let circuit_breaker = get_circuit_breaker();
        let inventory_client = get_inventory_client();
        
        circuit_breaker.execute(|| async {
            // æå–è®¢å•é¡¹
            let order: Order = serde_json::from_value(input.clone())?;
            let items = order.items.clone();
            
            // è°ƒç”¨åº“å­˜æœåŠ¡
            inventory_client.reserve_items(&order.id, &items).await
        }).await.map_err(|e| WorkflowError::ActionFailed(e.to_string()))
    }
}

// æ”¯ä»˜å¤„ç†æ“ä½œ
struct ProcessPaymentAction {}

#[async_trait]
impl WorkflowAction for ProcessPaymentAction {
    fn id(&self) -> &str {
        "process_payment"
    }
    
    async fn execute(&self, input: &Value) -> Result<Value, WorkflowError> {
        // å®ç°æ”¯ä»˜å¤„ç†é€»è¾‘ï¼Œä½¿ç”¨é‡è¯•æ¨¡å¼
        let retry_policy = get_retry_policy();
        let payment_client = get_payment_client();
        
        retry_policy.execute(|| async {
            let order: Order = serde_json::from_value(input.clone())?;
            
            // è°ƒç”¨æ”¯ä»˜æœåŠ¡
            payment_client.process_payment(&order.id, order.total_amount).await
        }).await.map_err(|e| WorkflowError::ActionFailed(e.to_string()))
    }
}
```

### 1.6 æœåŠ¡ç½‘æ ¼é›†æˆå®ç°

```rust
/// æœåŠ¡ç½‘æ ¼é›†æˆ - ä½¿ç”¨Linkerdæˆ–è‡ªå®šä¹‰å®ç°
pub struct ServiceMesh {
    proxies: HashMap<String, ServiceProxy>,
    config: ServiceMeshConfig,
    metric_collector: Arc<MetricCollector>,
}

impl ServiceMesh {
    pub fn new(config: ServiceMeshConfig) -> Self {
        Self {
            proxies: HashMap::new(),
            config,
            metric_collector: Arc::new(MetricCollector::new()),
        }
    }
    
    pub async fn register_service(&mut self, service_id: &str, routes: Vec<RouteConfig>) -> Result<(), Error> {
        let proxy = ServiceProxy::new(service_id, routes, self.config.clone());
        self.proxies.insert(service_id.to_string(), proxy);
        Ok(())
    }
    
    pub async fn handle_request(&self, service_id: &str, request: Request) -> Result<Response, Error> {
        let proxy = self.proxies.get(service_id)
            .ok_or(Error::ServiceNotFound)?;
            
        // æ”¶é›†è¯·æ±‚æŒ‡æ ‡
        self.metric_collector.record_request(service_id, &request).await;
        
        // å¤„ç†è¯·æ±‚
        let start = std::time::Instant::now();
        let result = proxy.handle_request(request).await;
        let duration = start.elapsed();
        
        // æ”¶é›†å“åº”æŒ‡æ ‡
        self.metric_collector.record_response(service_id, &result, duration).await;
        
        result
    }
}

pub struct ServiceProxy {
    service_id: String,
    routes: Vec<RouteConfig>,
    circuit_breaker: CircuitBreaker,
    rate_limiter: RateLimiter,
    retry_policy: RetryPolicy,
}

impl ServiceProxy {
    pub fn new(service_id: &str, routes: Vec<RouteConfig>, config: ServiceMeshConfig) -> Self {
        Self {
            service_id: service_id.to_string(),
            routes,
            circuit_breaker: CircuitBreaker::new(config.circuit_breaker),
            rate_limiter: RateLimiter::new(config.rate_limit),
            retry_policy: RetryPolicy::new(config.retry),
        }
    }
    
    pub async fn handle_request(&self, request: Request) -> Result<Response, Error> {
        // åº”ç”¨é™æµ
        if !self.rate_limiter.allow().await? {
            return Err(Error::RateLimitExceeded);
        }
        
        // æŸ¥æ‰¾è·¯ç”±
        let route = self.find_route(&request)
            .ok_or(Error::RouteNotFound)?;
            
        // ä½¿ç”¨ç†”æ–­å™¨å’Œé‡è¯•æ¨¡å¼
        self.circuit_breaker.execute(|| {
            self.retry_policy.execute(|| async {
                self.forward_request(&request, &route).await
            })
        }).await
    }
    
    async fn forward_request(&self, request: &Request, route: &RouteConfig) -> Result<Response, Error> {
        // æŸ¥æ‰¾ç›®æ ‡æœåŠ¡
        let service_registry = get_service_registry();
        let instances = service_registry.discover_service(&route.target_service).await?;
        
        // è´Ÿè½½å‡è¡¡
        let load_balancer = get_load_balancer();
        let instance = load_balancer.select_instance(&instances).await?;
        
        // æ„å»ºè¯·æ±‚URL
        let url = format!("http://{}:{}{}", 
            instance.address, 
            instance.port, 
            request.path);
            
        // å‘é€è¯·æ±‚
        let client = reqwest::Client::new();
        let response = client.request(request.method.clone(), &url)
            .headers(request.headers.clone())
            .body(request.body.clone())
            .send()
            .await?;
            
        // è½¬æ¢å“åº”
        Ok(Response {
            status: response.status().as_u16(),
            headers: response.headers().clone(),
            body: response.bytes().await?.to_vec(),
        })
    }
}
```

### 1.7 å®Œæ•´ç¤ºä¾‹æµç¨‹å±•ç¤º

è¿™ä¸ªå®ä¾‹é€šè¿‡ç»“åˆå¤šç§å·¥ä½œæµæ¨¡å¼å’Œåˆ†å¸ƒå¼è®¾è®¡æ¨¡å¼ï¼Œè§£å†³äº†ç”µå­å•†åŠ¡ç³»ç»Ÿä¸­çš„å…³é”®æŒ‘æˆ˜ï¼š

1. **å·¥ä½œæµæ¨¡å¼åº”ç”¨**:
   - é¡ºåºå’Œå¹¶è¡Œå·¥ä½œæµ: è®¢å•å¤„ç†çš„å„ä¸ªé˜¶æ®µ
   - çŠ¶æ€æœº: è®¢å•çŠ¶æ€è½¬æ¢
   - äº‹ä»¶é©±åŠ¨: é€šè¿‡EventBuså¤„ç†å¼‚æ­¥æ¶ˆæ¯
   - è¡¥å¿äº‹åŠ¡: ä½¿ç”¨SAGAæ¨¡å¼å¤„ç†åˆ†å¸ƒå¼äº‹åŠ¡

2. **åˆ†å¸ƒå¼è®¾è®¡æ¨¡å¼åº”ç”¨**:
   - ç†”æ–­å™¨: é˜²æ­¢çº§è”æ•…éšœ
   - é‡è¯•ç­–ç•¥: å¢å¼ºæœåŠ¡è°ƒç”¨å¯é æ€§
   - åˆ†å¸ƒå¼ç¼“å­˜: æé«˜ç³»ç»Ÿæ€§èƒ½
   - æœåŠ¡æ³¨å†Œå‘ç°: åŠ¨æ€æœåŠ¡ç®¡ç†
   - è´Ÿè½½å‡è¡¡: åˆ†æ•£ç³»ç»Ÿè´Ÿè½½

3. **ä½¿ç”¨çš„ä¸»è¦Ruståº“**:
   - tokio: å¼‚æ­¥è¿è¡Œæ—¶
   - async-trait: å¼‚æ­¥traitæ”¯æŒ
   - serde: åºåˆ—åŒ–/ååºåˆ—åŒ–
   - reqwest: HTTPå®¢æˆ·ç«¯
   - lapin: RabbitMQå®¢æˆ·ç«¯
   - redis-rs: Rediså®¢æˆ·ç«¯
   - sqlx: æ•°æ®åº“æ“ä½œ

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•å°†å·¥ä½œæµæ¨¡å¼ä¸åˆ†å¸ƒå¼è®¾è®¡æ¨¡å¼æœ‰æœºç»“åˆï¼Œåˆ›å»ºä¸€ä¸ªå¥å£®ã€å¯é çš„ç”µå­å•†åŠ¡è®¢å•å¤„ç†ç³»ç»Ÿï¼ŒåŒæ—¶é€šè¿‡ä½¿ç”¨Rustçš„å¼€æºåº“ç®€åŒ–å®ç°å¤æ‚åº¦ã€‚
