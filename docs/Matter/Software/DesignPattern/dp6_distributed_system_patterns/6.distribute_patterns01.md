# Rustå®ç°åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡æ¨¡å¼

```text
<think>
This is a comprehensive request asking to explain and implement all the distributed system design patterns listed in the markdown snippet using Rust's async, generic, and multithreading mechanisms. I'll need to be detailed and provide code examples for each pattern.

I'll focus on:
1. Explaining each pattern briefly
2. Showing how to implement it in Rust using async programming, generics, and multithreading
3. Providing practical, runnable code examples
4. Highlighting Rust-specific features that make these implementations robust

Since there are many patterns listed (around 30 total across 8 categories), I should be concise but comprehensive for each pattern.
</think>
```

## ğŸ“‹ ç›®å½•

- [1 é€šä¿¡æ¨¡å¼](#1-é€šä¿¡æ¨¡å¼)
  - [1.1 è¯·æ±‚-å“åº”æ¨¡å¼](#11-è¯·æ±‚-å“åº”æ¨¡å¼)
  - [1.2 å‘å¸ƒ-è®¢é˜…æ¨¡å¼](#12-å‘å¸ƒ-è®¢é˜…æ¨¡å¼)
  - [1.3 æ¶ˆæ¯é˜Ÿåˆ—æ¨¡å¼](#13-æ¶ˆæ¯é˜Ÿåˆ—æ¨¡å¼)
  - [1.4 RPCæ¨¡å¼](#14-rpcæ¨¡å¼)
  - [1.5 æµå¤„ç†æ¨¡å¼](#15-æµå¤„ç†æ¨¡å¼)
- [2 ä¸€è‡´æ€§ä¸å¤åˆ¶æ¨¡å¼](#2-ä¸€è‡´æ€§ä¸å¤åˆ¶æ¨¡å¼)
  - [2.1 ä¸»ä»å¤åˆ¶](#21-ä¸»ä»å¤åˆ¶)
  - [2.2 å¤šä¸»å¤åˆ¶](#22-å¤šä¸»å¤åˆ¶)
  - [2.3 æ— ä¸»å¤åˆ¶](#23-æ— ä¸»å¤åˆ¶)
  - [2.4 åˆ†å¸ƒå¼å…±è¯†Raft](#24-åˆ†å¸ƒå¼å…±è¯†raft)
  - [2.5 æœ€ç»ˆä¸€è‡´æ€§](#25-æœ€ç»ˆä¸€è‡´æ€§)
- [3 åˆ†åŒºæ¨¡å¼](#3-åˆ†åŒºæ¨¡å¼)
  - [3.1 åˆ†ç‰‡](#31-åˆ†ç‰‡)
  - [3.2 ä¸€è‡´æ€§å“ˆå¸Œ](#32-ä¸€è‡´æ€§å“ˆå¸Œ)
  - [3.3 å‰¯æœ¬åˆ†å¸ƒ](#33-å‰¯æœ¬åˆ†å¸ƒ)
- [4 å®¹é”™æ¨¡å¼](#4-å®¹é”™æ¨¡å¼)
  - [4.1 ç†”æ–­å™¨](#41-ç†”æ–­å™¨)
  - [4.2 èˆ±å£æ¨¡å¼](#42-èˆ±å£æ¨¡å¼)
  - [4.3 è¶…æ—¶ä¸é‡è¯•](#43-è¶…æ—¶ä¸é‡è¯•)
  - [4.4 èƒŒå‹](#44-èƒŒå‹)
- [5 äº‹åŠ¡æ¨¡å¼](#5-äº‹åŠ¡æ¨¡å¼)
  - [5.1 ä¸¤é˜¶æ®µæäº¤](#51-ä¸¤é˜¶æ®µæäº¤)
  - [5.2 Sagaæ¨¡å¼](#52-sagaæ¨¡å¼)
- [6 ç¼“å­˜æ¨¡å¼](#6-ç¼“å­˜æ¨¡å¼)
  - [6.1 ç¼“å­˜ä»£ç†](#61-ç¼“å­˜ä»£ç†)
  - [6.2 å†™é€ä¸åå†™ç¼“å­˜](#62-å†™é€ä¸åå†™ç¼“å­˜)
  - [6.3 ç¼“å­˜ä¸€è‡´æ€§](#63-ç¼“å­˜ä¸€è‡´æ€§)
- [7 ç»“è®º](#7-ç»“è®º)
- [8 æ¶ˆæ¯ä¼ é€’æ¨¡å¼](#8-æ¶ˆæ¯ä¼ é€’æ¨¡å¼)
  - [8.1 å‘å¸ƒ-è®¢é˜…](#81-å‘å¸ƒ-è®¢é˜…)
  - [8.2 æ¶ˆæ¯é˜Ÿåˆ—](#82-æ¶ˆæ¯é˜Ÿåˆ—)
  - [8.3 è¯·æ±‚-å“åº”](#83-è¯·æ±‚-å“åº”)
- [9 ç¨³å®šæ€§æ¨¡å¼](#9-ç¨³å®šæ€§æ¨¡å¼)
  - [9.1 é™æµå™¨](#91-é™æµå™¨)
  - [9.2 æ–­è·¯å™¨](#92-æ–­è·¯å™¨)
  - [9.3 éš”æ¿æ¨¡å¼](#93-éš”æ¿æ¨¡å¼)
- [10 åˆ†å¸ƒå¼åè°ƒæ¨¡å¼](#10-åˆ†å¸ƒå¼åè°ƒæ¨¡å¼)
  - [10.1 é¢†å¯¼è€…é€‰ä¸¾](#101-é¢†å¯¼è€…é€‰ä¸¾)
  - [10.2 åˆ†å¸ƒå¼é”](#102-åˆ†å¸ƒå¼é”)
  - [10.3 åˆ†å¸ƒå¼ä¿¡å·é‡](#103-åˆ†å¸ƒå¼ä¿¡å·é‡)
- [11 å¯æ‰©å±•æ€§æ¨¡å¼](#11-å¯æ‰©å±•æ€§æ¨¡å¼)
  - [11.1 åˆ†ç‰‡æ¨¡å¼](#111-åˆ†ç‰‡æ¨¡å¼)
  - [11.2 å¤åˆ¶æ¨¡å¼](#112-å¤åˆ¶æ¨¡å¼)
  - [11.3 ç¼“å­˜æ¨¡å¼](#113-ç¼“å­˜æ¨¡å¼)
- [12 æ€»ç»“](#12-æ€»ç»“)
- [13 è¿›é˜¶æŠ€å·§ä¸æœ€ä½³å®è·µ](#13-è¿›é˜¶æŠ€å·§ä¸æœ€ä½³å®è·µ)
  - [13.1 æ¨¡å¼ç»„åˆ](#131-æ¨¡å¼ç»„åˆ)
  - [13.2 æ€§èƒ½è€ƒé‡](#132-æ€§èƒ½è€ƒé‡)
  - [13.3 å¸¸è§é™·é˜±ä¸è§£å†³æ–¹æ¡ˆ](#133-å¸¸è§é™·é˜±ä¸è§£å†³æ–¹æ¡ˆ)
  - [13.4 è®¾è®¡æ¨¡å¼é€‰æ‹©æŒ‡å—](#134-è®¾è®¡æ¨¡å¼é€‰æ‹©æŒ‡å—)
- [14 ç»“è¯­](#14-ç»“è¯­)

---

## 1 é€šä¿¡æ¨¡å¼

### 1.1 è¯·æ±‚-å“åº”æ¨¡å¼

è¯·æ±‚-å“åº”æ¨¡å¼æ˜¯æœ€åŸºæœ¬çš„é€šä¿¡æ¨¡å¼ï¼Œå®¢æˆ·ç«¯å‘é€è¯·æ±‚ï¼ŒæœåŠ¡ç«¯å¤„ç†åè¿”å›å“åº”ã€‚

```rust
use std::future::Future;
use std::pin::Pin;
use tokio::sync::mpsc;
use serde::{Serialize, Deserialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
struct Request<T> {
    id: String,
    payload: T,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct Response<R> {
    request_id: String,
    payload: R,
}

struct RequestResponseService<T, R, F, Fut>
where
    T: Send + 'static,
    R: Send + 'static,
    F: Fn(Request<T>) -> Fut + Send + Sync + 'static,
    Fut: Future<Output = Response<R>> + Send,
{
    handler: F,
    request_rx: mpsc::Receiver<(Request<T>, mpsc::Sender<Response<R>>)>,
}

impl<T, R, F, Fut> RequestResponseService<T, R, F, Fut>
where
    T: Send + 'static,
    R: Send + 'static,
    F: Fn(Request<T>) -> Fut + Send + Sync + 'static,
    Fut: Future<Output = Response<R>> + Send,
{
    fn new(handler: F) -> (Self, mpsc::Sender<(Request<T>, mpsc::Sender<Response<R>>)>) {
        let (tx, rx) = mpsc::channel(100);
        (Self { handler, request_rx: rx }, tx)
    }

    async fn run(&mut self) {
        while let Some((request, response_tx)) = self.request_rx.recv().await {
            let handler = &self.handler;
            let response = handler(request).await;
            let _ = response_tx.send(response).await;
        }
    }
}

// å®¢æˆ·ç«¯å®ç°
struct Client<T, R> {
    request_tx: mpsc::Sender<(Request<T>, mpsc::Sender<Response<R>>)>,
}

impl<T, R> Client<T, R>
where
    T: Send + 'static,
    R: Send + 'static,
{
    fn new(request_tx: mpsc::Sender<(Request<T>, mpsc::Sender<Response<R>>)>) -> Self {
        Self { request_tx }
    }

    async fn send_request(&self, request: Request<T>) -> Result<Response<R>, String> {
        let (response_tx, mut response_rx) = mpsc::channel(1);
        
        if self.request_tx.send((request, response_tx)).await.is_err() {
            return Err("æœåŠ¡å·²å…³é—­".to_string());
        }
        
        response_rx.recv().await.ok_or_else(|| "æ— æ³•è·å–å“åº”".to_string())
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºæœåŠ¡
    let handler = |req: Request<String>| async move {
        println!("å¤„ç†è¯·æ±‚: {:?}", req);
        Response {
            request_id: req.id,
            payload: format!("å·²å¤„ç†: {}", req.payload),
        }
    };
    
    let (mut service, request_tx) = RequestResponseService::new(handler);
    
    // å¯åŠ¨æœåŠ¡
    tokio::spawn(async move {
        service.run().await;
    });
    
    // åˆ›å»ºå®¢æˆ·ç«¯
    let client = Client::new(request_tx);
    
    // å‘é€è¯·æ±‚
    let request = Request {
        id: "req-1".to_string(),
        payload: "Hello, Service!".to_string(),
    };
    
    let response = client.send_request(request).await.unwrap();
    println!("æ”¶åˆ°å“åº”: {:?}", response);
}
```

### 1.2 å‘å¸ƒ-è®¢é˜…æ¨¡å¼

å‘å¸ƒ-è®¢é˜…æ¨¡å¼ä¸­ï¼Œæ¶ˆæ¯å‘é€è€…ï¼ˆå‘å¸ƒè€…ï¼‰ä¸ç›´æ¥å°†æ¶ˆæ¯å‘é€ç»™ç‰¹å®šçš„æ¥æ”¶è€…ï¼Œè€Œæ˜¯å°†æ¶ˆæ¯åˆ†ç±»ä¸ºä¸åŒçš„ä¸»é¢˜ã€‚
è®¢é˜…è€…å¯ä»¥è¡¨è¾¾å¯¹ä¸€ä¸ªæˆ–å¤šä¸ªä¸»é¢˜çš„å…´è¶£ï¼Œåªæ¥æ”¶æ„Ÿå…´è¶£çš„æ¶ˆæ¯ã€‚

```rust
use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use tokio::sync::broadcast;
use tokio::sync::mpsc;
use serde::{Serialize, Deserialize};
use futures::StreamExt;

#[derive(Clone, Debug, Serialize, Deserialize)]
struct Message<T> {
    topic: String,
    payload: T,
}

struct PubSubBroker<T: Clone + Send + 'static> {
    topics: Arc<Mutex<HashMap<String, broadcast::Sender<Message<T>>>>>,
    max_capacity: usize,
}

impl<T: Clone + Send + 'static> PubSubBroker<T> {
    fn new(max_capacity: usize) -> Self {
        Self {
            topics: Arc::new(Mutex::new(HashMap::new())),
            max_capacity,
        }
    }
    
    async fn publish(&self, message: Message<T>) -> Result<(), String> {
        let topic = message.topic.clone();
        let sender = {
            let mut topics = self.topics.lock().unwrap();
            if !topics.contains_key(&topic) {
                let (tx, _) = broadcast::channel(self.max_capacity);
                topics.insert(topic.clone(), tx);
            }
            topics.get(&topic).unwrap().clone()
        };
        
        sender.send(message).map_err(|e| format!("å‘å¸ƒå¤±è´¥: {}", e))
    }
    
    async fn subscribe(&self, topic: String) -> broadcast::Receiver<Message<T>> {
        let mut topics = self.topics.lock().unwrap();
        if !topics.contains_key(&topic) {
            let (tx, _) = broadcast::channel(self.max_capacity);
            topics.insert(topic.clone(), tx);
        }
        topics.get(&topic).unwrap().subscribe()
    }
    
    async fn subscribe_multiple(&self, topics: Vec<String>) -> mpsc::Receiver<Message<T>> {
        let (tx, rx) = mpsc::channel(100);
        
        for topic in topics {
            let mut receiver = self.subscribe(topic).await;
            let tx_clone = tx.clone();
            
            tokio::spawn(async move {
                while let Ok(message) = receiver.recv().await {
                    if tx_clone.send(message).await.is_err() {
                        break;
                    }
                }
            });
        }
        
        rx
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    let broker: PubSubBroker<String> = PubSubBroker::new(100);
    
    // åˆ›å»ºè®¢é˜…è€…
    let mut weather_subscriber = broker.subscribe("weather".to_string()).await;
    let mut news_subscriber = broker.subscribe("news".to_string()).await;
    let mut multi_subscriber = broker.subscribe_multiple(vec![
        "weather".to_string(), 
        "news".to_string()
    ]).await;
    
    // å‘å¸ƒæ¶ˆæ¯
    tokio::spawn(async move {
        let weather_msg = Message {
            topic: "weather".to_string(),
            payload: "å¤©æ°”æ™´æœ—ï¼Œæ¸©åº¦25Â°C".to_string(),
        };
        
        let news_msg = Message {
            topic: "news".to_string(),
            payload: "ä»Šæ—¥å¤´æ¡ï¼šRust 2023å‘å¸ƒäº†!".to_string(),
        };
        
        broker.publish(weather_msg).await.unwrap();
        tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
        broker.publish(news_msg).await.unwrap();
    });
    
    // å¤„ç†è®¢é˜…æ¶ˆæ¯
    tokio::spawn(async move {
        if let Ok(msg) = weather_subscriber.recv().await {
            println!("å¤©æ°”è®¢é˜…è€…: {:?}", msg);
        }
    });
    
    tokio::spawn(async move {
        if let Ok(msg) = news_subscriber.recv().await {
            println!("æ–°é—»è®¢é˜…è€…: {:?}", msg);
        }
    });
    
    tokio::spawn(async move {
        while let Some(msg) = multi_subscriber.recv().await {
            println!("å¤šä¸»é¢˜è®¢é˜…è€…: {:?}", msg);
        }
    });
    
    // ç­‰å¾…è¶³å¤Ÿæ—¶é—´è®©æ¶ˆæ¯å¤„ç†å®Œæˆ
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
}
```

### 1.3 æ¶ˆæ¯é˜Ÿåˆ—æ¨¡å¼

æ¶ˆæ¯é˜Ÿåˆ—æ¨¡å¼æ˜¯å‘å¸ƒ-è®¢é˜…æ¨¡å¼çš„å˜ä½“ï¼Œå…¶ä¸­æ¶ˆæ¯è¢«ä¿å­˜åœ¨é˜Ÿåˆ—ä¸­ï¼Œç›´åˆ°è¢«æ¶ˆè´¹è€…å¤„ç†ã€‚è¿™ç§æ¨¡å¼å…è®¸å¼‚æ­¥é€šä¿¡å’Œè§£è€¦ã€‚

```rust
use std::collections::VecDeque;
use std::sync::{Arc, Mutex};
use tokio::sync::{mpsc, Semaphore};
use serde::{Serialize, Deserialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
struct Message<T> {
    id: String,
    queue: String,
    payload: T,
}

struct MessageQueue<T: Clone + Send + 'static> {
    queues: Arc<Mutex<HashMap<String, VecDeque<Message<T>>>>>,
    semaphores: Arc<Mutex<HashMap<String, Arc<Semaphore>>>>,
}

impl<T: Clone + Send + 'static> MessageQueue<T> {
    fn new() -> Self {
        Self {
            queues: Arc::new(Mutex::new(HashMap::new())),
            semaphores: Arc::new(Mutex::new(HashMap::new())),
        }
    }
    
    async fn send(&self, message: Message<T>) {
        let queue_name = message.queue.clone();
        
        // è·å–å¯¹åº”é˜Ÿåˆ—çš„ä¿¡å·é‡
        let semaphore = {
            let mut semaphores = self.semaphores.lock().unwrap();
            if !semaphores.contains_key(&queue_name) {
                semaphores.insert(queue_name.clone(), Arc::new(Semaphore::new(0)));
            }
            semaphores.get(&queue_name).unwrap().clone()
        };
        
        // å°†æ¶ˆæ¯æ·»åŠ åˆ°é˜Ÿåˆ—
        {
            let mut queues = self.queues.lock().unwrap();
            queues.entry(queue_name).or_insert_with(VecDeque::new).push_back(message);
        }
        
        // é‡Šæ”¾ä¸€ä¸ªä¿¡å·é‡ï¼Œé€šçŸ¥å¯èƒ½çš„æ¶ˆè´¹è€…
        semaphore.add_permits(1);
    }
    
    async fn receive(&self, queue_name: &str) -> Option<Message<T>> {
        // è·å–å¯¹åº”é˜Ÿåˆ—çš„ä¿¡å·é‡
        let semaphore = {
            let mut semaphores = self.semaphores.lock().unwrap();
            if !semaphores.contains_key(queue_name) {
                semaphores.insert(queue_name.to_string(), Arc::new(Semaphore::new(0)));
            }
            semaphores.get(queue_name).unwrap().clone()
        };
        
        // ç­‰å¾…æ¶ˆæ¯å¯ç”¨
        let _permit = semaphore.acquire().await.ok()?;
        
        // ä»é˜Ÿåˆ—å–å‡ºæ¶ˆæ¯
        let mut queues = self.queues.lock().unwrap();
        if let Some(queue) = queues.get_mut(queue_name) {
            queue.pop_front()
        } else {
            None
        }
    }
    
    async fn create_consumer(&self, queue_name: String) -> mpsc::Receiver<Message<T>> {
        let (tx, rx) = mpsc::channel(100);
        let queue_clone = Arc::new(self.clone());
        
        tokio::spawn(async move {
            loop {
                match queue_clone.receive(&queue_name).await {
                    Some(message) => {
                        if tx.send(message).await.is_err() {
                            // é€šé“å…³é—­ï¼Œæ¶ˆè´¹è€…å¯èƒ½å·²ç»ç¦»å¼€
                            break;
                        }
                    },
                    None => break,
                }
            }
        });
        
        rx
    }
    
    fn clone(&self) -> Self {
        Self {
            queues: self.queues.clone(),
            semaphores: self.semaphores.clone(),
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    let queue = MessageQueue::<String>::new();
    
    // åˆ›å»ºæ¶ˆè´¹è€…
    let mut consumer1 = queue.create_consumer("tasks".to_string()).await;
    let mut consumer2 = queue.create_consumer("tasks".to_string()).await;
    
    // å‘é€æ¶ˆæ¯
    for i in 0..10 {
        let message = Message {
            id: format!("msg-{}", i),
            queue: "tasks".to_string(),
            payload: format!("è¿™æ˜¯ä»»åŠ¡ #{}", i),
        };
        
        queue.send(message).await;
    }
    
    // å¤„ç†æ¶ˆæ¯
    tokio::spawn(async move {
        while let Some(msg) = consumer1.recv().await {
            println!("æ¶ˆè´¹è€…1æ”¶åˆ°: {:?}", msg);
            tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
        }
    });
    
    tokio::spawn(async move {
        while let Some(msg) = consumer2.recv().await {
            println!("æ¶ˆè´¹è€…2æ”¶åˆ°: {:?}", msg);
            tokio::time::sleep(tokio::time::Duration::from_millis(150)).await;
        }
    });
    
    // ç­‰å¾…è¶³å¤Ÿæ—¶é—´è®©æ¶ˆæ¯å¤„ç†å®Œæˆ
    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;
}
```

### 1.4 RPCæ¨¡å¼

RPCï¼ˆè¿œç¨‹è¿‡ç¨‹è°ƒç”¨ï¼‰å…è®¸å®¢æˆ·ç«¯è°ƒç”¨æœåŠ¡å™¨ä¸Šçš„å‡½æ•°ï¼Œå°±åƒè°ƒç”¨æœ¬åœ°å‡½æ•°ä¸€æ ·ã€‚

```rust
use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use tokio::sync::oneshot;
use serde::{Serialize, Deserialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
struct RpcRequest<P> {
    id: String,
    method: String,
    params: P,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct RpcResponse<R> {
    id: String,
    result: Result<R, String>,
}

struct RpcServer<P, R> {
    handlers: HashMap<String, Box<dyn Fn(P) -> R + Send + Sync>>,
}

impl<P, R> RpcServer<P, R>
where
    P: Send + 'static,
    R: Send + 'static,
{
    fn new() -> Self {
        Self {
            handlers: HashMap::new(),
        }
    }
    
    fn register<F>(&mut self, method: &str, handler: F)
    where
        F: Fn(P) -> R + Send + Sync + 'static,
    {
        self.handlers.insert(method.to_string(), Box::new(handler));
    }
    
    fn handle(&self, request: RpcRequest<P>) -> RpcResponse<R> {
        let handler = self.handlers.get(&request.method);
        
        match handler {
            Some(handler) => {
                let result = handler(request.params);
                RpcResponse {
                    id: request.id,
                    result: Ok(result),
                }
            },
            None => RpcResponse {
                id: request.id,
                result: Err(format!("æœªçŸ¥æ–¹æ³•: {}", request.method)),
            },
        }
    }
}

struct RpcClient<P, R> {
    server: Arc<RpcServer<P, R>>,
}

impl<P, R> RpcClient<P, R>
where
    P: Clone + Send + 'static,
    R: Clone + Send + 'static,
{
    fn new(server: Arc<RpcServer<P, R>>) -> Self {
        Self { server }
    }
    
    async fn call(&self, method: &str, params: P) -> Result<R, String> {
        let request = RpcRequest {
            id: format!("req-{}", uuid::Uuid::new_v4()),
            method: method.to_string(),
            params,
        };
        
        let response = self.server.handle(request);
        response.result
    }
}

// ä½¿ç”¨è¿œç¨‹å®ç°
use tokio::sync::mpsc;

struct RemoteRpcClient<P, R>
where
    P: Serialize + Send + 'static,
    R: for<'de> Deserialize<'de> + Send + 'static,
{
    request_tx: mpsc::Sender<(String, Vec<u8>, oneshot::Sender<Vec<u8>>)>,
}

impl<P, R> RemoteRpcClient<P, R>
where
    P: Serialize + Send + 'static,
    R: for<'de> Deserialize<'de> + Send + 'static,
{
    fn new(request_tx: mpsc::Sender<(String, Vec<u8>, oneshot::Sender<Vec<u8>>)>) -> Self {
        Self { request_tx }
    }
    
    async fn call(&self, method: &str, params: P) -> Result<R, String> {
        let request_id = format!("req-{}", uuid::Uuid::new_v4());
        
        // åºåˆ—åŒ–è¯·æ±‚
        let request = RpcRequest {
            id: request_id.clone(),
            method: method.to_string(),
            params,
        };
        
        let serialized_request = serde_json::to_vec(&request)
            .map_err(|e| format!("åºåˆ—åŒ–è¯·æ±‚å¤±è´¥: {}", e))?;
        
        // åˆ›å»ºå“åº”é€šé“
        let (response_tx, response_rx) = oneshot::channel();
        
        // å‘é€è¯·æ±‚
        self.request_tx.send((request_id, serialized_request, response_tx)).await
            .map_err(|_| "RPCæœåŠ¡å·²å…³é—­".to_string())?;
        
        // ç­‰å¾…å“åº”
        let serialized_response = response_rx.await
            .map_err(|_| "è·å–å“åº”å¤±è´¥".to_string())?;
        
        // ååºåˆ—åŒ–å“åº”
        let response: RpcResponse<R> = serde_json::from_slice(&serialized_response)
            .map_err(|e| format!("ååºåˆ—åŒ–å“åº”å¤±è´¥: {}", e))?;
        
        response.result
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºRPCæœåŠ¡å™¨
    let mut server = RpcServer::<String, String>::new();
    
    // æ³¨å†Œå¤„ç†å™¨
    server.register("echo", |message| {
        message
    });
    
    server.register("reverse", |message| {
        message.chars().rev().collect()
    });
    
    let server_arc = Arc::new(server);
    
    // åˆ›å»ºå®¢æˆ·ç«¯
    let client = RpcClient::new(server_arc);
    
    // è°ƒç”¨RPCæ–¹æ³•
    let echo_result = client.call("echo", "Hello, RPC!".to_string()).await.unwrap();
    println!("Echoç»“æœ: {}", echo_result);
    
    let reverse_result = client.call("reverse", "Hello, RPC!".to_string()).await.unwrap();
    println!("Reverseç»“æœ: {}", reverse_result);
}
```

### 1.5 æµå¤„ç†æ¨¡å¼

æµå¤„ç†æ¨¡å¼å¤„ç†è¿ç»­çš„æ•°æ®æµï¼Œé€šå¸¸é€šè¿‡ä¸€ç³»åˆ—è½¬æ¢æ“ä½œã€‚

```rust
use futures::{Stream, StreamExt};
use std::pin::Pin;
use std::task::{Context, Poll};
use tokio::sync::mpsc;

type BoxStream<T> = Pin<Box<dyn Stream<Item = T> + Send>>;

trait StreamProcessor<In, Out> {
    fn process(&self, input: In) -> Out;
    
    fn process_stream<S>(&self, stream: S) -> BoxStream<Out>
    where
        S: Stream<Item = In> + Send + 'static,
        In: 'static,
        Out: 'static,
        Self: 'static + Sync + Send,
    {
        let processor = self.clone();
        Box::pin(stream.map(move |item| processor.process(item)))
    }
    
    fn clone(&self) -> Box<dyn StreamProcessor<In, Out> + Send + Sync>;
}

struct MapProcessor<In, Out, F>
where
    F: Fn(In) -> Out + Send + Sync + Clone,
{
    func: F,
    _phantom: std::marker::PhantomData<(In, Out)>,
}

impl<In, Out, F> MapProcessor<In, Out, F>
where
    F: Fn(In) -> Out + Send + Sync + Clone,
{
    fn new(func: F) -> Self {
        Self {
            func,
            _phantom: std::marker::PhantomData,
        }
    }
}

impl<In, Out, F> StreamProcessor<In, Out> for MapProcessor<In, Out, F>
where
    F: Fn(In) -> Out + Send + Sync + Clone + 'static,
    In: 'static,
    Out: 'static,
{
    fn process(&self, input: In) -> Out {
        (self.func)(input)
    }
    
    fn clone(&self) -> Box<dyn StreamProcessor<In, Out> + Send + Sync> {
        Box::new(Self {
            func: self.func.clone(),
            _phantom: std::marker::PhantomData,
        })
    }
}

struct FilterProcessor<T, F>
where
    F: Fn(&T) -> bool + Send + Sync + Clone,
{
    predicate: F,
    _phantom: std::marker::PhantomData<T>,
}

impl<T, F> FilterProcessor<T, F>
where
    F: Fn(&T) -> bool + Send + Sync + Clone,
{
    fn new(predicate: F) -> Self {
        Self {
            predicate,
            _phantom: std::marker::PhantomData,
        }
    }
}

impl<T, F> StreamProcessor<T, Option<T>> for FilterProcessor<T, F>
where
    F: Fn(&T) -> bool + Send + Sync + Clone + 'static,
    T: 'static + Clone,
{
    fn process(&self, input: T) -> Option<T> {
        if (self.predicate)(&input) {
            Some(input)
        } else {
            None
        }
    }
    
    fn clone(&self) -> Box<dyn StreamProcessor<T, Option<T>> + Send + Sync> {
        Box::new(Self {
            predicate: self.predicate.clone(),
            _phantom: std::marker::PhantomData,
        })
    }
    
    fn process_stream<S>(&self, stream: S) -> BoxStream<Option<T>>
    where
        S: Stream<Item = T> + Send + 'static,
        T: 'static,
        Self: 'static + Sync + Send,
    {
        let processor = self.clone();
        Box::pin(stream.map(move |item| processor.process(item)))
    }
}

// ç»„åˆå¤„ç†å™¨
struct StreamPipeline<T> {
    input_tx: Option<mpsc::Sender<T>>,
    output_rx: Option<BoxStream<T>>,
}

impl<T: Clone + Send + 'static> StreamPipeline<T> {
    fn new<S: Stream<Item = T> + Send + 'static>(source: S) -> Self {
        Self {
            input_tx: None,
            output_rx: Some(Box::pin(source)),
        }
    }
    
    fn from_channel(capacity: usize) -> Self {
        let (tx, rx) = mpsc::channel(capacity);
        Self {
            input_tx: Some(tx),
            output_rx: Some(Box::pin(rx)),
        }
    }
    
    fn map<R, F>(self, func: F) -> StreamPipeline<R>
    where
        F: Fn(T) -> R + Send + Sync + Clone + 'static,
        R: Send + 'static,
    {
        let processor = MapProcessor::new(func);
        
        match self.output_rx {
            Some(stream) => {
                let output_stream = processor.process_stream(stream);
                StreamPipeline {
                    input_tx: None,
                    output_rx: Some(output_stream),
                }
            },
            None => panic!("æµå·²è¢«æ¶ˆè´¹"),
        }
    }
    
    fn filter<F>(self, predicate: F) -> StreamPipeline<T>
    where
        F: Fn(&T) -> bool + Send + Sync + Clone + 'static,
    {
        let processor = FilterProcessor::new(predicate);
        
        match self.output_rx {
            Some(stream) => {
                let filtered_stream = processor.process_stream(stream);
                let non_none_stream = Box::pin(filtered_stream.filter_map(futures::future::ready));
                
                StreamPipeline {
                    input_tx: None,
                    output_rx: Some(non_none_stream),
                }
            },
            None => panic!("æµå·²è¢«æ¶ˆè´¹"),
        }
    }
    
    fn get_sender(&self) -> Option<mpsc::Sender<T>> {
        self.input_tx.clone()
    }
    
    fn into_stream(self) -> BoxStream<T> {
        self.output_rx.expect("æµå·²è¢«æ¶ˆè´¹")
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºä¸€ä¸ªæºé€šé“
    let pipeline = StreamPipeline::<i32>::from_channel(100);
    let producer = pipeline.get_sender().unwrap();
    
    // åˆ›å»ºå¤„ç†æµæ°´çº¿
    let processed_stream = pipeline
        .map(|x| x * 2)
        .filter(|x| *x > 10)
        .map(|x| format!("å¤„ç†åçš„å€¼: {}", x))
        .into_stream();
    
    // ç”Ÿäº§æ•°æ®
    tokio::spawn(async move {
        for i in 1..=10 {
            producer.send(i).await.unwrap();
        }
    });
    
    // æ¶ˆè´¹å¤„ç†åçš„æ•°æ®
    tokio::pin!(processed_stream);
    while let Some(item) = processed_stream.next().await {
        println!("{}", item);
    }
}
```

## 2 ä¸€è‡´æ€§ä¸å¤åˆ¶æ¨¡å¼

### 2.1 ä¸»ä»å¤åˆ¶

ä¸»ä»å¤åˆ¶æ¨¡å¼ä¸­ï¼Œä¸€ä¸ªèŠ‚ç‚¹ï¼ˆä¸»èŠ‚ç‚¹ï¼‰æ¥æ”¶æ‰€æœ‰å†™å…¥ï¼Œç„¶åå¤åˆ¶åˆ°å¤šä¸ªä»èŠ‚ç‚¹ã€‚

```rust
use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use tokio::sync::{broadcast, mpsc, RwLock};
use tokio::time::Duration;
use serde::{Serialize, Deserialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
enum Operation<K, V> {
    Put(K, V),
    Delete(K),
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct ReplicationLog<K, V> {
    seq_no: u64,
    operation: Operation<K, V>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
enum ReplicaMessage<K, V> {
    Sync(Vec<ReplicationLog<K, V>>),
    SyncRequest { from_seq: u64 },
    Heartbeat { seq_no: u64 },
}

struct MasterNode<K, V>
where
    K: Clone + Eq + std::hash::Hash + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    data: Arc<RwLock<HashMap<K, V>>>,
    log: Arc<Mutex<Vec<ReplicationLog<K, V>>>>,
    next_seq_no: Arc<Mutex<u64>>,
    replica_tx: broadcast::Sender<ReplicaMessage<K, V>>,
}

impl<K, V> MasterNode<K, V>
where
    K: Clone + Eq + std::hash::Hash + Send + Sync + 'static + Serialize + for<'de> Deserialize<'de>,
    V: Clone + Send + Sync + 'static + Serialize + for<'de> Deserialize<'de>,
{
    fn new(capacity: usize) -> Self {
        let (tx, _) = broadcast::channel(capacity);
        
        Self {
            data: Arc::new(RwLock::new(HashMap::new())),
            log: Arc::new(Mutex::new(Vec::new())),
            next_seq_no: Arc::new(Mutex::new(0)),
            replica_tx: tx,
        }
    }
    
    async fn put(&self, key: K, value: V) {
        // æ›´æ–°æ•°æ®
        {
            let mut data = self.data.write().await;
            data.insert(key.clone(), value.clone());
        }
        
        // è®°å½•å¹¶å¤åˆ¶æ“ä½œ
        let operation = Operation::Put(key, value);
        self.replicate_operation(operation).await;
    }
    
    async fn delete(&self, key: K) {
        // æ›´æ–°æ•°æ®
        {
            let mut data = self.data.write().await;
            data.remove(&key);
        }
        
        // è®°å½•å¹¶å¤åˆ¶æ“ä½œ
        let operation = Operation::Delete(key);
        self.replicate_operation(operation).await;
    }
    
    async fn get(&self, key: &K) -> Option<V> {
        let data = self.data.read().await;
        data.get(key).cloned()
    }
    
    async fn replicate_operation(&self, operation: Operation<K, V>) {
        let seq_no = {
            let mut next_seq = self.next_seq_no.lock().unwrap();
            let seq = *next_seq;
            *next_seq += 1;
            seq
        };
        
        let log_entry = ReplicationLog {
            seq_no,
            operation,
        };
        
        // æ·»åŠ åˆ°æ—¥å¿—
        {
            let mut log = self.log.lock().unwrap();
            log.push(log_entry.clone());
        }
        
        // å¹¿æ’­ç»™ä»èŠ‚ç‚¹
        let message = ReplicaMessage::Sync(vec![log_entry]);
        let _ = self.replica_tx.send(message);
    }
    
    fn get_subscriber(&self) -> broadcast::Receiver<ReplicaMessage<K, V>> {
        self.replica_tx.subscribe()
    }
    
    async fn handle_sync_request(&self, from_seq: u64) -> Vec<ReplicationLog<K, V>> {
        let log = self.log.lock().unwrap();
        log.iter()
            .filter(|entry| entry.seq_no >= from_seq)
            .cloned()
            .collect()
    }
    
    async fn start_heartbeat(&self, interval: Duration) {
        let replica_tx = self.replica_tx.clone();
        let next_seq_no = self.next_seq_no.clone();
        
        tokio::spawn(async move {
            let mut interval = tokio::time::interval(interval);
            
            loop {
                interval.tick().await;
                let seq_no = {
                    let seq = next_seq_no.lock().unwrap();
                    *seq
                };
                
                let heartbeat = ReplicaMessage::Heartbeat { seq_no };
                let _ = replica_tx.send(heartbeat);
            }
        });
    }
}

struct ReplicaNode<K, V>
where
    K: Clone + Eq + std::hash::Hash + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    data: Arc<RwLock<HashMap<K, V>>>,
    last_seq_no: Arc<Mutex<u64>>,
    master_tx: mpsc::Sender<ReplicaMessage<K, V>>,
    master_rx: broadcast::Receiver<ReplicaMessage<K, V>>,
}

impl<K, V> ReplicaNode<K, V>
where
    K: Clone + Eq + std::hash::Hash + Send + Sync + 'static + Serialize + for<'de> Deserialize<'de>,
    V: Clone + Send + Sync + 'static + Serialize + for<'de> Deserialize<'de>,
{
    fn new(
        master_tx: mpsc::Sender<ReplicaMessage<K, V>>,
        master_rx: broadcast::Receiver<ReplicaMessage<K, V>>,
    ) -> Self {
        Self {
            data: Arc::new(RwLock::new(HashMap::new())),
            last_seq_no: Arc::new(Mutex::new(0)),
            master_tx,
            master_rx,
        }
    }
    
    async fn get(&self, key: &K) -> Option<V> {
        let data = self.data.read().await;
        data.get(key).cloned()
    }
    
    async fn apply_log(&self, log_entry: &ReplicationLog<K, V>) {
        match &log_entry.operation {
            Operation::Put(key, value) => {
                let mut data = self.data.write().await;
                data.insert(key.clone(), value.clone());
            },
            Operation::Delete(key) => {
                let mut data = self.data.write().await;
                data.remove(key);
            },
        }
        
        // æ›´æ–°åºåˆ—å·
        {
            let mut last_seq = self.last_seq_no.lock().unwrap();
            *last_seq = log_entry.seq_no;
        }
    }
    
    async fn start(&mut self) {
        let data_clone = self.data.clone();
        let last_seq_no_clone = self.last_seq_no.clone();
        let master_tx_clone = self.master_tx.clone();
        
        // åˆå§‹è¯·æ±‚åŒæ­¥
        self.request_sync().await;
        
        // å¤„ç†æ¥è‡ªä¸»èŠ‚ç‚¹çš„æ¶ˆæ¯
        while let Ok(message) = self.master_rx.recv().await {
            match message {
                ReplicaMessage::Sync(logs) => {
                    for log in logs {
                        if log.seq_no >= {
                            let seq = last_seq_no_clone.lock().unwrap();
                            *seq
                        } {
                            self.apply_log(&log).await;
                        }
                    }
                },
                ReplicaMessage::Heartbeat { seq_no } => {
                    let current_seq = {
                        let seq = last_seq_no_clone.lock().unwrap();
                        *seq
                    };
                    
                    if seq_no > current_seq {
                        // å‘ç°è‡ªå·±æœ‰æ—¥å¿—ç¼ºå¤±ï¼Œè¯·æ±‚åŒæ­¥
                        self.request_sync().await;
                    }
                },
                _ => {},
            }
        }
    }
    
    async fn request_sync(&self) {
        let from_seq = {
            let seq = self.last_seq_no.lock().unwrap();
            *seq
        };
        
        let request = ReplicaMessage::SyncRequest { from_seq };
        let _ = self.master_tx.send(request).await;
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºä¸»èŠ‚ç‚¹
    let master = Arc::new(MasterNode::<String, String>::new(100));
    
    // è®¾ç½®ä¸»èŠ‚ç‚¹å¤„ç†åŒæ­¥è¯·æ±‚
    let master_clone = master.clone();
    let (request_tx, mut request_rx) = mpsc::channel(100);
    
    tokio::spawn(async move {
        while let Some(message) = request_rx.recv().await {
            match message {
                ReplicaMessage::SyncRequest { from_seq } => {
                    let logs = master_clone.handle_sync_request(from_seq).await;
                    let sync_message = ReplicaMessage::Sync(logs);
                    let _ = master_clone.replica_tx.send(sync_message);
                },
                _ => {},
            }
        }
    });
    
    // å¯åŠ¨ä¸»èŠ‚ç‚¹å¿ƒè·³
    master.start_heartbeat(Duration::from_secs(1)).await;
    
    // åˆ›å»ºä»èŠ‚ç‚¹
    let master_rx = master.get_subscriber();
    let mut replica = ReplicaNode::new(request_tx.clone(), master_rx);
    
    // å¯åŠ¨ä»èŠ‚ç‚¹
    tokio::spawn(async move {
        replica.start().await;
    });
    
    // æµ‹è¯•ä¸»ä»å¤åˆ¶
    master.put("key1".to_string(), "value1".to_string()).await;

/*
<think>
æˆ‘éœ€è¦ç»§ç»­å®Œæˆå…³äºåˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡æ¨¡å¼çš„Rustå®ç°ç¤ºä¾‹ã€‚
æˆ‘å°†ç»§ç»­ä¹‹å‰è¢«æˆªæ–­çš„ä¸»ä»å¤åˆ¶ç¤ºä¾‹ä»£ç ï¼Œç„¶åç»§ç»­ä»‹ç»å…¶ä»–æ¨¡å¼ã€‚
</think>
*/

    master.put("key2".to_string(), "value2".to_string()).await;
    tokio::time::sleep(Duration::from_millis(500)).await;
    
    let value = master.get(&"key1".to_string()).await;
    println!("ä¸»èŠ‚ç‚¹è·å–key1: {:?}", value);
    
    // åˆ é™¤ä¸€ä¸ªé”®ï¼Œè¿™åº”è¯¥ä¹Ÿä¼šå¤åˆ¶åˆ°ä»èŠ‚ç‚¹
    master.delete("key1".to_string()).await;
    tokio::time::sleep(Duration::from_millis(500)).await;
    
    // ç­‰å¾…è¶³å¤Ÿçš„æ—¶é—´è®©å¤åˆ¶å®Œæˆ
    tokio::time::sleep(Duration::from_secs(2)).await;
}
```

### 2.2 å¤šä¸»å¤åˆ¶

å¤šä¸»å¤åˆ¶å…è®¸å¤šä¸ªèŠ‚ç‚¹æ¥å—å†™å…¥æ“ä½œï¼Œå½¼æ­¤ä¹‹é—´ç›¸äº’å¤åˆ¶ã€‚è¿™ç§æ¨¡å¼å¢åŠ äº†å¤æ‚æ€§ä½†æé«˜äº†å†™å…¥å¯ç”¨æ€§ã€‚

```rust
use std::collections::{HashMap, HashSet};
use std::sync::{Arc, Mutex};
use tokio::sync::{broadcast, mpsc, RwLock};
use serde::{Serialize, Deserialize};
use uuid::Uuid;

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
struct VersionVector {
    node_id: String,
    counter: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct Operation<K, V> {
    id: String,
    key: K,
    value: Option<V>,
    vector_clock: HashMap<String, u64>,
    timestamp: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
enum NodeMessage<K, V> {
    Replicate(Operation<K, V>),
    SyncRequest { node_id: String, vector_clock: HashMap<String, u64> },
    SyncResponse { operations: Vec<Operation<K, V>> },
}

struct MultiMasterNode<K, V>
where
    K: Clone + Eq + std::hash::Hash + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    node_id: String,
    data: Arc<RwLock<HashMap<K, (V, HashMap<String, u64>)>>>,
    operations: Arc<Mutex<Vec<Operation<K, V>>>>,
    vector_clock: Arc<Mutex<HashMap<String, u64>>>,
    applied_ops: Arc<Mutex<HashSet<String>>>,
    node_tx: broadcast::Sender<NodeMessage<K, V>>,
    peers: Vec<mpsc::Sender<NodeMessage<K, V>>>,
}

impl<K, V> MultiMasterNode<K, V>
where
    K: Clone + Eq + std::hash::Hash + Send + Sync + 'static + Serialize + for<'de> Deserialize<'de>,
    V: Clone + Send + Sync + 'static + Serialize + for<'de> Deserialize<'de>,
{
    fn new(node_id: &str, capacity: usize) -> Self {
        let (tx, _) = broadcast::channel(capacity);
        let mut vector_clock = HashMap::new();
        vector_clock.insert(node_id.to_string(), 0);
        
        Self {
            node_id: node_id.to_string(),
            data: Arc::new(RwLock::new(HashMap::new())),
            operations: Arc::new(Mutex::new(Vec::new())),
            vector_clock: Arc::new(Mutex::new(vector_clock)),
            applied_ops: Arc::new(Mutex::new(HashSet::new())),
            node_tx: tx,
            peers: Vec::new(),
        }
    }
    
    fn add_peer(&mut self, peer_tx: mpsc::Sender<NodeMessage<K, V>>) {
        self.peers.push(peer_tx);
    }
    
    async fn put(&self, key: K, value: V) {
        // æ›´æ–°æœ¬åœ°å‘é‡æ—¶é’Ÿ
        let op_id = Uuid::new_v4().to_string();
        let vector_clock = {
            let mut vc = self.vector_clock.lock().unwrap();
            *vc.get_mut(&self.node_id).unwrap() += 1;
            vc.clone()
        };
        
        // åˆ›å»ºæ“ä½œ
        let timestamp = chrono::Utc::now().timestamp_millis() as u64;
        let operation = Operation {
            id: op_id.clone(),
            key: key.clone(),
            value: Some(value.clone()),
            vector_clock: vector_clock.clone(),
            timestamp,
        };
        
        // åº”ç”¨åˆ°æœ¬åœ°
        self.apply_operation(operation.clone()).await;
        
        // å¤åˆ¶åˆ°å…¶ä»–èŠ‚ç‚¹
        let message = NodeMessage::Replicate(operation);
        for peer in &self.peers {
            let _ = peer.send(message.clone()).await;
        }
    }
    
    async fn delete(&self, key: K) {
        // æ›´æ–°æœ¬åœ°å‘é‡æ—¶é’Ÿ
        let op_id = Uuid::new_v4().to_string();
        let vector_clock = {
            let mut vc = self.vector_clock.lock().unwrap();
            *vc.get_mut(&self.node_id).unwrap() += 1;
            vc.clone()
        };
        
        // åˆ›å»ºæ“ä½œ
        let timestamp = chrono::Utc::now().timestamp_millis() as u64;
        let operation = Operation {
            id: op_id.clone(),
            key: key.clone(),
            value: None,
            vector_clock: vector_clock.clone(),
            timestamp,
        };
        
        // åº”ç”¨åˆ°æœ¬åœ°
        self.apply_operation(operation.clone()).await;
        
        // å¤åˆ¶åˆ°å…¶ä»–èŠ‚ç‚¹
        let message = NodeMessage::Replicate(operation);
        for peer in &self.peers {
            let _ = peer.send(message.clone()).await;
        }
    }
    
    async fn get(&self, key: &K) -> Option<V> {
        let data = self.data.read().await;
        data.get(key).map(|(value, _)| value.clone())
    }
    
    async fn apply_operation(&self, operation: Operation<K, V>) {
        // æ£€æŸ¥æ“ä½œæ˜¯å¦å·²åº”ç”¨
        {
            let applied = self.applied_ops.lock().unwrap();
            if applied.contains(&operation.id) {
                return;
            }
        }
        
        // åº”ç”¨æ“ä½œåˆ°æ•°æ®
        {
            let mut data = self.data.write().await;
            
            match operation.value {
                Some(value) => {
                    data.insert(operation.key.clone(), (value, operation.vector_clock.clone()));
                },
                None => {
                    data.remove(&operation.key);
                }
            }
        }
        
        // æ›´æ–°å‘é‡æ—¶é’Ÿ
        {
            let mut vc = self.vector_clock.lock().unwrap();
            for (node, counter) in &operation.vector_clock {
                let entry = vc.entry(node.clone()).or_insert(0);
                *entry = std::cmp::max(*entry, *counter);
            }
        }
        
        // è®°å½•æ“ä½œå¹¶æ ‡è®°ä¸ºå·²åº”ç”¨
        {
            let mut ops = self.operations.lock().unwrap();
            ops.push(operation.clone());
            
            let mut applied = self.applied_ops.lock().unwrap();
            applied.insert(operation.id);
        }
    }
    
    fn get_subscriber(&self) -> broadcast::Receiver<NodeMessage<K, V>> {
        self.node_tx.subscribe()
    }
    
    async fn handle_sync_request(&self, node_id: String, remote_vc: HashMap<String, u64>) -> Vec<Operation<K, V>> {
        let ops = {
            let ops = self.operations.lock().unwrap();
            ops.clone()
        };
        
        // æ‰¾å‡ºè¿œç¨‹èŠ‚ç‚¹ç¼ºå°‘çš„æ“ä½œ
        ops.iter()
            .filter(|op| {
                for (node, counter) in &op.vector_clock {
                    if let Some(remote_counter) = remote_vc.get(node) {
                        if counter > remote_counter {
                            return true;
                        }
                    } else {
                        return true; // è¿œç¨‹æ²¡æœ‰è¿™ä¸ªèŠ‚ç‚¹çš„å‘é‡
                    }
                }
                false
            })
            .cloned()
            .collect()
    }
    
    async fn request_sync_from_peers(&self) {
        let node_id = self.node_id.clone();
        let vector_clock = {
            let vc = self.vector_clock.lock().unwrap();
            vc.clone()
        };
        
        let message = NodeMessage::SyncRequest { node_id, vector_clock };
        
        for peer in &self.peers {
            let _ = peer.send(message.clone()).await;
        }
    }
    
    async fn start_background_sync(&self, interval: tokio::time::Duration) {
        let self_clone = self.clone();
        
        tokio::spawn(async move {
            let mut interval = tokio::time::interval(interval);
            
            loop {
                interval.tick().await;
                self_clone.request_sync_from_peers().await;
            }
        });
    }
    
    fn clone(&self) -> Self {
        Self {
            node_id: self.node_id.clone(),
            data: self.data.clone(),
            operations: self.operations.clone(),
            vector_clock: self.vector_clock.clone(),
            applied_ops: self.applied_ops.clone(),
            node_tx: self.node_tx.clone(),
            peers: self.peers.clone(),
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºä¸¤ä¸ªä¸»èŠ‚ç‚¹
    let mut node1 = MultiMasterNode::<String, String>::new("node1", 100);
    let mut node2 = MultiMasterNode::<String, String>::new("node2", 100);
    
    // è®¾ç½®èŠ‚ç‚¹é—´é€šä¿¡
    let (node1_tx, mut node1_rx) = mpsc::channel(100);
    let (node2_tx, mut node2_rx) = mpsc::channel(100);
    
    node1.add_peer(node2_tx);
    node2.add_peer(node1_tx);
    
    // å¯åŠ¨èŠ‚ç‚¹1çš„æ¶ˆæ¯å¤„ç†å¾ªç¯
    let node1_clone = node1.clone();
    tokio::spawn(async move {
        while let Some(message) = node1_rx.recv().await {
            match message {
                NodeMessage::Replicate(op) => {
                    node1_clone.apply_operation(op).await;
                },
                NodeMessage::SyncRequest { node_id, vector_clock } => {
                    let ops = node1_clone.handle_sync_request(node_id, vector_clock).await;
                    let sync_message = NodeMessage::SyncResponse { operations: ops };
                    // å‘é€å›è¯·æ±‚çš„èŠ‚ç‚¹ - åœ¨å®é™…ç³»ç»Ÿä¸­ä¼šæœ‰æ›´å¤æ‚çš„è·¯ç”±
                },
                NodeMessage::SyncResponse { operations } => {
                    for op in operations {
                        node1_clone.apply_operation(op).await;
                    }
                }
            }
        }
    });
    
    // å¯åŠ¨èŠ‚ç‚¹2çš„æ¶ˆæ¯å¤„ç†å¾ªç¯
    let node2_clone = node2.clone();
    tokio::spawn(async move {
        while let Some(message) = node2_rx.recv().await {
            match message {
                NodeMessage::Replicate(op) => {
                    node2_clone.apply_operation(op).await;
                },
                NodeMessage::SyncRequest { node_id, vector_clock } => {
                    let ops = node2_clone.handle_sync_request(node_id, vector_clock).await;
                    let sync_message = NodeMessage::SyncResponse { operations: ops };
                    // å‘é€å›è¯·æ±‚çš„èŠ‚ç‚¹
                },
                NodeMessage::SyncResponse { operations } => {
                    for op in operations {
                        node2_clone.apply_operation(op).await;
                    }
                }
            }
        }
    });
    
    // å¯åŠ¨å®šæœŸåŒæ­¥
    node1.start_background_sync(tokio::time::Duration::from_secs(5)).await;
    node2.start_background_sync(tokio::time::Duration::from_secs(5)).await;
    
    // åœ¨ä¸¤ä¸ªèŠ‚ç‚¹ä¸Šæ‰§è¡Œå†™å…¥æ“ä½œ
    node1.put("key1".to_string(), "value1-from-node1".to_string()).await;
    node2.put("key2".to_string(), "value2-from-node2".to_string()).await;
    
    // ç­‰å¾…åŒæ­¥
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
    
    // æ£€æŸ¥ä¸¤ä¸ªèŠ‚ç‚¹æ˜¯å¦æœ‰ç›¸åŒçš„æ•°æ®
    let value1_from_node1 = node1.get(&"key1".to_string()).await;
    let value1_from_node2 = node2.get(&"key1".to_string()).await;
    
    let value2_from_node1 = node1.get(&"key2".to_string()).await;
    let value2_from_node2 = node2.get(&"key2".to_string()).await;
    
    println!("èŠ‚ç‚¹1ä¸Šçš„key1: {:?}", value1_from_node1);
    println!("èŠ‚ç‚¹2ä¸Šçš„key1: {:?}", value1_from_node2);
    println!("èŠ‚ç‚¹1ä¸Šçš„key2: {:?}", value2_from_node1);
    println!("èŠ‚ç‚¹2ä¸Šçš„key2: {:?}", value2_from_node2);
}
```

### 2.3 æ— ä¸»å¤åˆ¶

æ— ä¸»å¤åˆ¶ä¸æŒ‡å®šä»»ä½•èŠ‚ç‚¹ä¸ºä¸»èŠ‚ç‚¹ï¼Œä»»ä½•èŠ‚ç‚¹éƒ½å¯ä»¥å¤„ç†è¯»å†™è¯·æ±‚ã€‚

```rust
use std::collections::{HashMap, HashSet};
use std::sync::{Arc, Mutex};
use tokio::sync::{mpsc, RwLock};
use tokio::time::Duration;
use serde::{Serialize, Deserialize};
use uuid::Uuid;
use std::time::{SystemTime, UNIX_EPOCH};

#[derive(Debug, Clone, Serialize, Deserialize)]
struct DataItem<V> {
    value: V,
    timestamp: u64,
    node_id: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
enum NodeMessage<K, V> {
    Write { key: K, value: V, timestamp: u64, node_id: String },
    ReadRepair { key: K, value: V, timestamp: u64, node_id: String },
    ReadRequest { key: K, request_id: String, reply_to: String },
    ReadResponse { key: K, value: Option<DataItem<V>>, request_id: String },
}

struct PeerlessNode<K, V>
where
    K: Clone + Eq + std::hash::Hash + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    node_id: String,
    data: Arc<RwLock<HashMap<K, DataItem<V>>>>,
    peers: Vec<mpsc::Sender<NodeMessage<K, V>>>,
    read_quorum: usize,
    write_quorum: usize,
    pending_reads: Arc<Mutex<HashMap<String, Vec<DataItem<V>>>>>,
}

impl<K, V> PeerlessNode<K, V>
where
    K: Clone + Eq + std::hash::Hash + Send + Sync + 'static + Serialize + for<'de> Deserialize<'de>,
    V: Clone + Send + Sync + 'static + PartialEq + Serialize + for<'de> Deserialize<'de>,
{
    fn new(node_id: &str, n_replicas: usize) -> Self {
        // è®¾ç½®è¯»å†™ä»²è£å€¼
        // é€šå¸¸ R + W > N ä»¥ç¡®ä¿ä¸€è‡´æ€§
        let write_quorum = (n_replicas / 2) + 1;
        let read_quorum = (n_replicas / 2) + 1;
        
        Self {
            node_id: node_id.to_string(),
            data: Arc::new(RwLock::new(HashMap::new())),
            peers: Vec::new(),
            read_quorum,
            write_quorum,
            pending_reads: Arc::new(Mutex::new(HashMap::new())),
        }
    }
    
    fn add_peer(&mut self, peer_tx: mpsc::Sender<NodeMessage<K, V>>) {
        self.peers.push(peer_tx);
    }
    
    async fn write(&self, key: K, value: V) -> Result<(), String> {
        let timestamp = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_millis() as u64;
        
        // æ›´æ–°æœ¬åœ°å­˜å‚¨
        {
            let mut data = self.data.write().await;
            data.insert(key.clone(), DataItem {
                value: value.clone(),
                timestamp,
                node_id: self.node_id.clone(),
            });
        }
        
        // æ„å»ºå†™å…¥æ¶ˆæ¯
        let write_message = NodeMessage::Write {
            key: key.clone(),
            value: value.clone(),
            timestamp,
            node_id: self.node_id.clone(),
        };
        
        // å‘æ‰€æœ‰å¯¹ç­‰èŠ‚ç‚¹å‘é€å†™å…¥æ¶ˆæ¯
        let mut successful_writes = 1; // æœ¬åœ°å†™å…¥å·²æˆåŠŸ
        
        let mut handles = Vec::new();
        for peer in &self.peers {
            let peer_clone = peer.clone();
            let message_clone = write_message.clone();
            
            let handle = tokio::spawn(async move {
                peer_clone.send(message_clone).await.is_ok()
            });
            
            handles.push(handle);
        }
        
        for handle in handles {
            if handle.await.unwrap_or(false) {
                successful_writes += 1;
            }
        }
        
        // æ£€æŸ¥æ˜¯å¦è¾¾åˆ°å†™å…¥ä»²è£
        if successful_writes >= self.write_quorum {
            Ok(())
        } else {
            Err(format!("å†™å…¥å¤±è´¥: ä»…æœ‰ {} èŠ‚ç‚¹ç¡®è®¤ï¼Œéœ€è¦ {}", successful_writes, self.write_quorum))
        }
    }
    
    async fn read(&self, key: K) -> Result<Option<V>, String> {
        let request_id = Uuid::new_v4().to_string();
        
        // ä»æœ¬åœ°è¯»å–æ•°æ®
        let local_value = {
            let data = self.data.read().await;
            data.get(&key).cloned()
        };
        
        // åˆå§‹åŒ–æŒ‚èµ·çš„è¯»å–
        {
            let mut pending = self.pending_reads.lock().unwrap();
            let values = Vec::new();
            pending.insert(request_id.clone(), values);
        }
        
        // å¦‚æœæœ¬åœ°æœ‰å€¼ï¼Œæ·»åŠ åˆ°æŒ‚èµ·çš„è¯»å–ä¸­
        if let Some(value) = local_value {
            let mut pending = self.pending_reads.lock().unwrap();
            if let Some(values) = pending.get_mut(&request_id) {
                values.push(value);
            }
        }
        
        // ä»æ‰€æœ‰å¯¹ç­‰èŠ‚ç‚¹è¯·æ±‚è¯»å–
        let read_message = NodeMessage::ReadRequest {
            key: key.clone(),
            request_id: request_id.clone(),
            reply_to: self.node_id.clone(),
        };
        
        for peer in &self.peers {
            let _ = peer.send(read_message.clone()).await;
        }
        
        // ç­‰å¾…è¶³å¤Ÿçš„å“åº”
        let mut received_responses = if local_value.is_some() { 1 } else { 0 };
        let timeout = Duration::from_millis(100);
        
        let start = SystemTime::now();
        while received_responses < self.read_quorum && 
              SystemTime::now().duration_since(start).unwrap() < timeout {
            let responses = {
                let pending = self.pending_reads.lock().unwrap();
                pending.get(&request_id).map(|v| v.len()).unwrap_or(0)
            };
            
            received_responses = responses;
            
            if received_responses < self.read_quorum {
                tokio::time::sleep(Duration::from_millis(10)).await;
            }
        }
        
        // æ£€æŸ¥æ˜¯å¦è¾¾åˆ°è¯»å–ä»²è£
        if received_responses < self.read_quorum {
            // æ¸…ç†æŒ‚èµ·çš„è¯»å–
            let mut pending = self.pending_reads.lock().unwrap();
            pending.remove(&request_id);
            
            return Err(format!("è¯»å–å¤±è´¥: ä»…æœ‰ {} èŠ‚ç‚¹å“åº”ï¼Œéœ€è¦ {}", received_responses, self.read_quorum));
        }
        
        // å¤„ç†æ‰€æœ‰æ”¶åˆ°çš„å€¼
        let responses = {
            let mut pending = self.pending_reads.lock().unwrap();
            pending.remove(&request_id).unwrap_or_default()
        };
        
        if responses.is_empty() {
            return Ok(None);
        }
        
        // æ‰¾åˆ°æœ€æ–°çš„å€¼
        let latest = responses.iter()
            .max_by_key(|item| item.timestamp)
            .cloned();
        
        // æ£€æŸ¥æ˜¯å¦éœ€è¦è¯»ä¿®å¤
        for response in &responses {
            if response.timestamp < latest.as_ref().unwrap().timestamp {
                // æ‰¾åˆ°é™ˆæ—§ç‰ˆæœ¬ï¼Œæ‰§è¡Œè¯»ä¿®å¤
                let repair_message = NodeMessage::ReadRepair {
                    key: key.clone(),
                    value: latest.as_ref().unwrap().value.clone(),
                    timestamp: latest.as_ref().unwrap().timestamp,
                    node_id: latest.as_ref().unwrap().node_id.clone(),
                };
                
                for peer in &self.peers {
                    let _ = peer.send(repair_message.clone()).await;
                }
                
                // æ›´æ–°æœ¬åœ°å­˜å‚¨
                let mut data = self.data.write().await;
                data.insert(key.clone(), latest.as_ref().unwrap().clone());
                
                break;
            }
        }
        
        Ok(latest.map(|item| item.value))
    }
    
    async fn handle_message(&self, message: NodeMessage<K, V>) {
        match message {
            NodeMessage::Write { key, value, timestamp, node_id } => {
                let mut data = self.data.write().await;
                let current = data.get(&key);
                
                let should_update = match current {
                    Some(existing) => existing.timestamp < timestamp,
                    None => true,
                };
                
                if should_update {
                    data.insert(key, DataItem {
                        value,
                        timestamp,
                        node_id,
                    });
                }
            },
            NodeMessage::ReadRepair { key, value, timestamp, node_id } => {
                let mut data = self.data.write().await;
                let current = data.get(&key);
                
                let should_update = match current {
                    Some(existing) => existing.timestamp < timestamp,
                    None => true,
                };
                
                if should_update {
                    data.insert(key, DataItem {
                        value,
                        timestamp,
                        node_id,
                    });
                }
            },
            NodeMessage::ReadRequest { key, request_id, reply_to } => {
                let value = {
                    let data = self.data.read().await;
                    data.get(&key).cloned()
                };
                
                // æ‰¾åˆ°ç›®æ ‡èŠ‚ç‚¹å¹¶å›å¤
                for peer in &self.peers {
                    let response = NodeMessage::ReadResponse {
                        key: key.clone(),
                        value,
                        request_id,
                    };
                    
                    // åœ¨å®é™…ç³»ç»Ÿä¸­ï¼Œä¼šæœ‰æ›´å¤æ‚çš„è·¯ç”±æœºåˆ¶
                    let _ = peer.send(response).await;
                }
            },
            NodeMessage::ReadResponse { key, value, request_id } => {
                if let Some(value) = value {
                    let mut pending = self.pending_reads.lock().unwrap();
                    if let Some(values) = pending.get_mut(&request_id) {
                        values.push(value);
                    }
                }
            }
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºä¸‰ä¸ªæ— ä¸»èŠ‚ç‚¹
    let mut node1 = PeerlessNode::<String, String>::new("node1", 3);
    let mut node2 = PeerlessNode::<String, String>::new("node2", 3);
    let mut node3 = PeerlessNode::<String, String>::new("node3", 3);
    
    // è®¾ç½®èŠ‚ç‚¹é—´é€šä¿¡
    let (node1_tx, mut node1_rx) = mpsc::channel(100);
    let (node2_tx, mut node2_rx) = mpsc::channel(100);
    let (node3_tx, mut node3_rx) = mpsc::channel(100);
    
    node1.add_peer(node2_tx.clone());
    node1.add_peer(node3_tx.clone());
    
    node2.add_peer(node1_tx.clone());
    node2.add_peer(node3_tx.clone());
    
    node3.add_peer(node1_tx.clone());
    node3.add_peer(node2_tx.clone());
    
    // å¯åŠ¨æ¶ˆæ¯å¤„ç†å¾ªç¯
    let node1_clone = Arc::new(node1);
    let node2_clone = Arc::new(node2);
    let node3_clone = Arc::new(node3);
    
    let node1_handle = {
        let node = node1_clone.clone();
        tokio::spawn(async move {
            while let Some(message) = node1_rx.recv().await {
                node.handle_message(message).await;
            }
        })
    };
    
    let node2_handle = {
        let node = node2_clone.clone();
        tokio::spawn(async move {
            while let Some(message) = node2_rx.recv().await {
                node.handle_message(message).await;
            }
        })
    };
    
    let node3_handle = {
        let node = node3_clone.clone();
        tokio::spawn(async move {
            while let Some(message) = node3_rx.recv().await {
                node.handle_message(message).await;
            }
        })
    };
    
    // ä»node1å†™å…¥æ•°æ®
    node1_clone.write("key1".to_string(), "value1".to_string()).await.unwrap();
    
    // ç­‰å¾…æ•°æ®å¤åˆ¶
    tokio::time::sleep(Duration::from_millis(500)).await;
    
    // ä»å„ä¸ªèŠ‚ç‚¹è¯»å–æ•°æ®
    let result1 = node1_clone.read("key1".to_string()).await.unwrap();
    let result2 = node2_clone.read("key1".to_string()).await.unwrap();
    let result3 = node3_clone.read("key1".to_string()).await.unwrap();
    
    println!("Node1è¯»å–ç»“æœ: {:?}", result1);
    println!("Node2è¯»å–ç»“æœ: {:?}", result2);
    println!("Node3è¯»å–ç»“æœ: {:?}", result3);
    
    // ä»node2å†™å…¥æ›´æ–°çš„æ•°æ®
    node2_clone.write("key1".to_string(), "value1-updated".to_string()).await.unwrap();
    
    // ç­‰å¾…æ•°æ®å¤åˆ¶
    tokio::time::sleep(Duration::from_millis(500)).await;
    
    // å†æ¬¡ä»å„ä¸ªèŠ‚ç‚¹è¯»å–æ•°æ®
    let result1 = node1_clone.read("key1".to_string()).await.unwrap();
    let result2 = node2_clone.read("key1".to_string()).await.unwrap();
    let result3 = node3_clone.read("key1".to_string()).await.unwrap();
    
    println!("æ›´æ–°åNode1è¯»å–ç»“æœ: {:?}", result1);
    println!("æ›´æ–°åNode2è¯»å–ç»“æœ: {:?}", result2);
    println!("æ›´æ–°åNode3è¯»å–ç»“æœ: {:?}", result3);
}
```

### 2.4 åˆ†å¸ƒå¼å…±è¯†Raft

åˆ†å¸ƒå¼å…±è¯†ç®—æ³•å¦‚Raftå…è®¸ä¸€ç»„èŠ‚ç‚¹å°±å€¼è¾¾æˆä¸€è‡´ï¼Œå³ä½¿åœ¨èŠ‚ç‚¹æ•…éšœçš„æƒ…å†µä¸‹ä¹Ÿèƒ½ä¿æŒç³»ç»Ÿçš„ä¸€è‡´æ€§ã€‚

```rust
use std::collections::{HashMap, HashSet};
use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant};
use tokio::sync::{mpsc, RwLock};
use rand::Rng;
use serde::{Serialize, Deserialize};

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
enum NodeState {
    Follower,
    Candidate,
    Leader,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct LogEntry {
    term: u64,
    command: Vec<u8>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
enum RaftMessage {
    // é€‰ä¸¾ç›¸å…³æ¶ˆæ¯
    RequestVote {
        term: u64,
        candidate_id: u64,
        last_log_index: u64,
        last_log_term: u64,
    },
    VoteResponse {
        term: u64,
        vote_granted: bool,
    },
    
    // æ—¥å¿—å¤åˆ¶ç›¸å…³æ¶ˆæ¯
    AppendEntries {
        term: u64,
        leader_id: u64,
        prev_log_index: u64,
        prev_log_term: u64,
        entries: Vec<LogEntry>,
        leader_commit: u64,
    },
    AppendResponse {
        term: u64,
        success: bool,
        last_index: u64,
    },
    
    // å®¢æˆ·ç«¯è¯·æ±‚
    ClientRequest {
        command: Vec<u8>,
        response_tx: mpsc::Sender<ClientResponse>,
    },
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct ClientResponse {
    success: bool,
    result: Vec<u8>,
}

struct RaftNode {
    // èŠ‚ç‚¹æ ‡è¯†
    id: u64,
    peers: Vec<u64>,
    
    // èŠ‚ç‚¹çŠ¶æ€
    state: Arc<Mutex<NodeState>>,
    current_term: Arc<Mutex<u64>>,
    voted_for: Arc<Mutex<Option<u64>>>,
    
    // æ—¥å¿—å’ŒçŠ¶æ€æœº
    log: Arc<Mutex<Vec<LogEntry>>>,
    commit_index: Arc<Mutex<u64>>,
    last_applied: Arc<Mutex<u64>>,
    state_machine: Arc<RwLock<HashMap<Vec<u8>, Vec<u8>>>>,
    
    // é¢†å¯¼è€…çŠ¶æ€
    next_index: Arc<Mutex<HashMap<u64, u64>>>,
    match_index: Arc<Mutex<HashMap<u64, u64>>>,
    
    // æ¶ˆæ¯ä¼ é€’
    message_tx: HashMap<u64, mpsc::Sender<RaftMessage>>,
    message_rx: mpsc::Receiver<RaftMessage>,
    
    // å®šæ—¶å™¨
    last_heartbeat: Arc<Mutex<Instant>>,
    election_timeout: Duration,
    heartbeat_interval: Duration,
}

impl RaftNode {
    fn new(
        id: u64,
        peers: Vec<u64>,
        message_tx: HashMap<u64, mpsc::Sender<RaftMessage>>,
        message_rx: mpsc::Receiver<RaftMessage>,
    ) -> Self {
        // éšæœºåŒ–é€‰ä¸¾è¶…æ—¶
        let mut rng = rand::thread_rng();
        let election_timeout = Duration::from_millis(rng.gen_range(150..300));
        let heartbeat_interval = Duration::from_millis(50);
        
        Self {
            id,
            peers,
            state: Arc::new(Mutex::new(NodeState::Follower)),
            current_term: Arc::new(Mutex::new(0)),
            voted_for: Arc::new(Mutex::new(None)),
            log: Arc::new(Mutex::new(Vec::new())),
            commit_index: Arc::new(Mutex::new(0)),
            last_applied: Arc::new(Mutex::new(0)),
            state_machine: Arc::new(RwLock::new(HashMap::new())),
            next_index: Arc::new(Mutex::new(HashMap::new())),
            match_index: Arc::new(Mutex::new(HashMap::new())),
            message_tx,
            message_rx,
            last_heartbeat: Arc::new(Mutex::new(Instant::now())),
            election_timeout,
            heartbeat_interval,
        }
    }
    
    async fn run(&mut self) {
        // å¯åŠ¨é€‰ä¸¾å®šæ—¶å™¨æ£€æŸ¥ä»»åŠ¡
        self.start_election_timer();
        
        // ä¸»æ¶ˆæ¯å¤„ç†å¾ªç¯
        while let Some(message) = self.message_rx.recv().await {
            match message {
                RaftMessage::RequestVote { term, candidate_id, last_log_index, last_log_term } => {
                    self.handle_vote_request(term, candidate_id, last_log_index, last_log_term).await;
                },
                RaftMessage::VoteResponse { term, vote_granted } => {
                    self.handle_vote_response(term, vote_granted).await;
                },
                RaftMessage::AppendEntries { term, leader_id, prev_log_index, prev_log_term, entries, leader_commit } => {
                    self.handle_append_entries(term, leader_id, prev_log_index, prev_log_term, entries, leader_commit).await;
                },
                RaftMessage::AppendResponse { term, success, last_index } => {
                    self.handle_append_response(term, success, last_index).await;
                },
                RaftMessage::ClientRequest { command, response_tx } => {
                    self.handle_client_request(command, response_tx).await;
                }
            }
        }
    }
    
    fn start_election_timer(&self) {
        let id = self.id;
        let state = self.state.clone();
        let current_term = self.current_term.clone();
        let voted_for = self.voted_for.clone();
        let last_heartbeat = self.last_heartbeat.clone();
        let election_timeout = self.election_timeout;
        let peers = self.peers.clone();
        let message_tx = self.message_tx.clone();
        let log = self.log.clone();
        
        tokio::spawn(async move {
            let mut interval = tokio::time::interval(Duration::from_millis(10));
            
            loop {
                interval.tick().await;
                
                // æ£€æŸ¥æ˜¯å¦éœ€è¦å¼€å§‹é€‰ä¸¾
                let should_start_election = {
                    let current_state = *state.lock().unwrap();
                    let last_hb = *last_heartbeat.lock().unwrap();
                    
                    current_state != NodeState::Leader && 
                    last_hb.elapsed() > election_timeout
                };
                
                if should_start_election {
                    // å˜æˆå€™é€‰äºº
                    {
                        let mut state_guard = state.lock().unwrap();
                        *state_guard = NodeState::Candidate;
                    }
                    
                    // å¢åŠ å½“å‰ä»»æœŸ
                    let term = {
                        let mut term_guard = current_term.lock().unwrap();
                        *term_guard += 1;
                        *term_guard
                    };
                    
                    // æŠ•ç¥¨ç»™è‡ªå·±
                    {
                        let mut voted_guard = voted_for.lock().unwrap();
                        *voted_guard = Some(id);
                    }
                    
                    // é‡ç½®å¿ƒè·³æ—¶é—´
                    {
                        let mut hb_guard = last_heartbeat.lock().unwrap();
                        *hb_guard = Instant::now();
                    }
                    
                    // è·å–æœ€åä¸€ä¸ªæ—¥å¿—æ¡ç›®çš„ç´¢å¼•å’Œä»»æœŸ
                    let (last_log_index, last_log_term) = {
                        let log_guard = log.lock().unwrap();
                        let idx = log_guard.len() as u64;
                        let term = if idx > 0 { log_guard[idx as usize - 1].term } else { 0 };
                        (idx, term)
                    };
                    
                    // å‘æ‰€æœ‰å¯¹ç­‰èŠ‚ç‚¹å‘é€æŠ•ç¥¨è¯·æ±‚
                    for &peer_id in &peers {
                        if let Some(tx) = message_tx.get(&peer_id) {
                            let vote_request = RaftMessage::RequestVote {
                                term,
                                candidate_id: id,
                                last_log_index,
                                last_log_term,
                            };
                            
                            let _ = tx.send(vote_request).await;
                        }
                    }
                }
            }
        });
    }
    
    async fn handle_vote_request(
        &self,
        term: u64,
        candidate_id: u64,
        last_log_index: u64,
        last_log_term: u64,
    ) {
        let mut vote_granted = false;
        
        // å¦‚æœæ¥æ”¶åˆ°çš„ä»»æœŸå¤§äºå½“å‰ä»»æœŸï¼Œè½¬æ¢ä¸ºè·Ÿéšè€…
        {
            let mut current_term_guard = self.current_term.lock().unwrap();
            let mut state_guard = self.state.lock().unwrap();

/*
<think>
I need to continue where I left off, which is in the `handle_vote_request` method of the Raft implementation. 
Let me finish that method and continue with the rest of the Raft implementation and other distributed system patterns.
</think>
*/

            let mut voted_for_guard = self.voted_for.lock().unwrap();
            
            if term > *current_term_guard {
                *current_term_guard = term;
                *state_guard = NodeState::Follower;
                *voted_for_guard = None;
            }
            
            // æ£€æŸ¥æŠ•ç¥¨æ¡ä»¶
            // 1. æŠ•ç¥¨è€…çš„ä»»æœŸå¤§äºç­‰äºå½“å‰ä»»æœŸ
            // 2. è¿˜æœªæŠ•ç¥¨ç»™ä»»ä½•äººæˆ–å·²ç»æŠ•ç¥¨ç»™candidate_id
            // 3. å€™é€‰äººçš„æ—¥å¿—è‡³å°‘å’Œæˆ‘ä»¬çš„ä¸€æ ·æ–°
            let log_guard = self.log.lock().unwrap();
            let my_last_idx = log_guard.len() as u64;
            let my_last_term = if my_last_idx > 0 { log_guard[my_last_idx as usize - 1].term } else { 0 };
            
            let log_is_up_to_date = 
                last_log_term > my_last_term || 
                (last_log_term == my_last_term && last_log_index >= my_last_idx);
            
            if term >= *current_term_guard && 
               (voted_for_guard.is_none() || *voted_for_guard == Some(candidate_id)) &&
               log_is_up_to_date 
            {
                *voted_for_guard = Some(candidate_id);
                vote_granted = true;
                
                // é‡ç½®é€‰ä¸¾è¶…æ—¶
                let mut last_hb = self.last_heartbeat.lock().unwrap();
                *last_hb = Instant::now();
            }
        }
        
        // å‘é€æŠ•ç¥¨å“åº”
        if let Some(tx) = self.message_tx.get(&candidate_id) {
            let current_term = *self.current_term.lock().unwrap();
            let vote_response = RaftMessage::VoteResponse {
                term: current_term,
                vote_granted,
            };
            
            let _ = tx.send(vote_response).await;
        }
    }
    
    async fn handle_append_entries(
        &self,
        term: u64,
        leader_id: u64,
        prev_log_index: u64,
        prev_log_term: u64,
        entries: Vec<LogEntry>,
        leader_commit: u64,
    ) {
        let mut success = false;
        let mut last_index = 0;
        
        // å¦‚æœé¢†å¯¼è€…çš„ä»»æœŸå°äºå½“å‰ä»»æœŸï¼Œæ‹’ç»è¯·æ±‚
        {
            let mut current_term_guard = self.current_term.lock().unwrap();
            if term < *current_term_guard {
                // å‘é€å¤±è´¥å“åº”
                if let Some(tx) = self.message_tx.get(&leader_id) {
                    let append_response = RaftMessage::AppendResponse {
                        term: *current_term_guard,
                        success: false,
                        last_index: 0,
                    };
                    
                    let _ = tx.send(append_response).await;
                }
                return;
            }
            
            // å¦‚æœæ¥æ”¶åˆ°æ›´é«˜ä»»æœŸï¼Œæ›´æ–°å½“å‰ä»»æœŸå¹¶è½¬æ¢ä¸ºè·Ÿéšè€…
            if term > *current_term_guard {
                *current_term_guard = term;
                let mut state_guard = self.state.lock().unwrap();
                *state_guard = NodeState::Follower;
                let mut voted_for_guard = self.voted_for.lock().unwrap();
                *voted_for_guard = None;
            }
            
            // é‡ç½®é€‰ä¸¾è¶…æ—¶ï¼ˆæ¥æ”¶åˆ°æœ‰æ•ˆçš„é™„åŠ æ¡ç›®è¯·æ±‚ï¼‰
            let mut last_hb = self.last_heartbeat.lock().unwrap();
            *last_hb = Instant::now();
            
            // å¤„ç†æ—¥å¿—æ¡ç›®
            let mut log_guard = self.log.lock().unwrap();
            
            // æ£€æŸ¥å‰ä¸€ä¸ªæ—¥å¿—æ¡ç›®æ˜¯å¦åŒ¹é…
            if prev_log_index > 0 {
                if log_guard.len() < prev_log_index as usize ||
                   log_guard[prev_log_index as usize - 1].term != prev_log_term {
                    // æ—¥å¿—ä¸åŒ¹é…
                    success = false;
                    last_index = log_guard.len() as u64;
                } else {
                    // æ—¥å¿—åŒ¹é…ï¼Œæ·»åŠ æ–°æ¡ç›®
                    success = true;
                    
                    // åˆ é™¤å†²çªçš„æ¡ç›®
                    if prev_log_index < log_guard.len() as u64 {
                        log_guard.truncate(prev_log_index as usize);
                    }
                    
                    // æ·»åŠ æ–°æ¡ç›®
                    for entry in &entries {
                        log_guard.push(entry.clone());
                    }
                    
                    last_index = (prev_log_index + entries.len() as u64) as u64;
                }
            } else {
                // å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªæ¡ç›®
                success = true;
                log_guard.clear();
                for entry in &entries {
                    log_guard.push(entry.clone());
                }
                last_index = entries.len() as u64;
            }
            
            // å¦‚æœé¢†å¯¼è€…æäº¤ç´¢å¼•å¤§äºå½“å‰æäº¤ç´¢å¼•ï¼Œæ›´æ–°æäº¤ç´¢å¼•
            if success && leader_commit > *self.commit_index.lock().unwrap() {
                let mut commit_guard = self.commit_index.lock().unwrap();
                *commit_guard = std::cmp::min(leader_commit, last_index);
                
                // åº”ç”¨æäº¤çš„æ¡ç›®åˆ°çŠ¶æ€æœº
                self.apply_committed_entries().await;
            }
        }
        
        // å‘é€å“åº”
        if let Some(tx) = self.message_tx.get(&leader_id) {
            let current_term = *self.current_term.lock().unwrap();
            let append_response = RaftMessage::AppendResponse {
                term: current_term,
                success,
                last_index,
            };
            
            let _ = tx.send(append_response).await;
        }
    }
    
    async fn apply_committed_entries(&self) {
        let commit_index = *self.commit_index.lock().unwrap();
        let mut last_applied = self.last_applied.lock().unwrap();
        
        if commit_index > *last_applied {
            let log_entries = {
                let log_guard = self.log.lock().unwrap();
                log_guard[(last_applied as usize)..=(commit_index as usize - 1)].to_vec()
            };
            
            for entry in log_entries {
                // ç®€åŒ–çš„å‘½ä»¤æ‰§è¡Œ - å‡è®¾å‘½ä»¤æ˜¯é”®å€¼å¯¹
                if let Ok((key, value)) = bincode::deserialize::<(Vec<u8>, Vec<u8>)>(&entry.command) {
                    let mut state_machine = self.state_machine.write().await;
                    state_machine.insert(key, value);
                }
                
                *last_applied += 1;
            }
        }
    }
    
    async fn start_leader_heartbeat(&self) {
        let state = self.state.clone();
        let id = self.id;
        let peers = self.peers.clone();
        let message_tx = self.message_tx.clone();
        let current_term = self.current_term.clone();
        let log = self.log.clone();
        let commit_index = self.commit_index.clone();
        let next_index = self.next_index.clone();
        let match_index = self.match_index.clone();
        
        tokio::spawn(async move {
            let mut interval = tokio::time::interval(Duration::from_millis(100));
            
            loop {
                interval.tick().await;
                
                // åªæœ‰é¢†å¯¼è€…å‘é€å¿ƒè·³
                let is_leader = {
                    let state_guard = state.lock().unwrap();
                    *state_guard == NodeState::Leader
                };
                
                if !is_leader {
                    continue;
                }
                
                let term = *current_term.lock().unwrap();
                
                // ä¸ºæ¯ä¸ªå¯¹ç­‰èŠ‚ç‚¹å‘é€é™„åŠ æ¡ç›®è¯·æ±‚ï¼ˆå¿ƒè·³ï¼‰
                for &peer_id in &peers {
                    let next_idx = {
                        let next_idx_guard = next_index.lock().unwrap();
                        *next_idx_guard.get(&peer_id).unwrap_or(&1)
                    };
                    
                    let prev_log_index = next_idx - 1;
                    let prev_log_term = if prev_log_index > 0 {
                        let log_guard = log.lock().unwrap();
                        if prev_log_index as usize <= log_guard.len() {
                            log_guard[prev_log_index as usize - 1].term
                        } else { 0 }
                    } else { 0 };
                    
                    // æ„å»ºè¦å‘é€çš„æ¡ç›®
                    let entries = {
                        let log_guard = log.lock().unwrap();
                        if next_idx as usize <= log_guard.len() {
                            log_guard[(next_idx as usize - 1)..].to_vec()
                        } else {
                            Vec::new() // ç©ºæ¡ç›® = å¿ƒè·³
                        }
                    };
                    
                    let leader_commit = *commit_index.lock().unwrap();
                    
                    // å‘é€é™„åŠ æ¡ç›®è¯·æ±‚
                    if let Some(tx) = message_tx.get(&peer_id) {
                        let append_request = RaftMessage::AppendEntries {
                            term,
                            leader_id: id,
                            prev_log_index,
                            prev_log_term,
                            entries,
                            leader_commit,
                        };
                        
                        let _ = tx.send(append_request).await;
                    }
                }
            }
        });
    }
    
    async fn handle_client_request(&self, command: Vec<u8>, response_tx: mpsc::Sender<ClientResponse>) {
        // æ£€æŸ¥æ˜¯å¦æ˜¯é¢†å¯¼è€…
        let is_leader = {
            let state_guard = self.state.lock().unwrap();
            *state_guard == NodeState::Leader
        };
        
        if !is_leader {
            let _ = response_tx.send(ClientResponse {
                success: false,
                result: b"not leader".to_vec(),
            }).await;
            return;
        }
        
        // æ·»åŠ åˆ°æ—¥å¿—
        let term = *self.current_term.lock().unwrap();
        let log_entry = LogEntry {
            term,
            command: command.clone(),
        };
        
        let log_index = {
            let mut log_guard = self.log.lock().unwrap();
            log_guard.push(log_entry);
            log_guard.len() as u64
        };
        
        // ç­‰å¾…æ—¥å¿—æäº¤
        let commit_future = async {
            loop {
                let commit_index = *self.commit_index.lock().unwrap();
                if commit_index >= log_index {
                    break;
                }
                tokio::time::sleep(Duration::from_millis(10)).await;
            }
        };
        
        // è®¾ç½®è¶…æ—¶
        let timeout = tokio::time::sleep(Duration::from_secs(5));
        
        tokio::select! {
            _ = commit_future => {
                // æ—¥å¿—å·²æäº¤ï¼Œè·å–ç»“æœ
                let state_machine = self.state_machine.read().await;
                
                // ç®€åŒ–ç‰ˆ - å‡è®¾å‘½ä»¤æ˜¯è·å–æ“ä½œ
                if let Ok((op, key)) = bincode::deserialize::<(String, Vec<u8>)>(&command) {
                    if op == "get" {
                        let result = state_machine.get(&key).cloned().unwrap_or_default();
                        let _ = response_tx.send(ClientResponse {
                            success: true,
                            result,
                        }).await;
                    }
                } else {
                    let _ = response_tx.send(ClientResponse {
                        success: true,
                        result: b"command executed".to_vec(),
                    }).await;
                }
            }
            _ = timeout => {
                let _ = response_tx.send(ClientResponse {
                    success: false,
                    result: b"timeout".to_vec(),
                }).await;
            }
        }
    }
    
    async fn handle_message(&self, message: RaftMessage) {
        match message {
            RaftMessage::RequestVote { term, candidate_id, last_log_index, last_log_term } => {
                self.handle_vote_request(term, candidate_id, last_log_index, last_log_term).await;
            },
            RaftMessage::VoteResponse { term, vote_granted } => {
                // å¦‚æœæ”¶åˆ°çš„ä»»æœŸå¤§äºå½“å‰ä»»æœŸï¼Œè½¬ä¸ºè·Ÿéšè€…
                {
                    let mut current_term_guard = self.current_term.lock().unwrap();
                    if term > *current_term_guard {
                        *current_term_guard = term;
                        let mut state_guard = self.state.lock().unwrap();
                        *state_guard = NodeState::Follower;
                        let mut voted_for_guard = self.voted_for.lock().unwrap();
                        *voted_for_guard = None;
                        return;
                    }
                }
                
                // å¦‚æœä¸æ˜¯å€™é€‰äººï¼Œå¿½ç•¥
                {
                    let state_guard = self.state.lock().unwrap();
                    if *state_guard != NodeState::Candidate {
                        return;
                    }
                }
                
                // è®¡ç¥¨
                if vote_granted {
                    let mut votes = self.votes_received.lock().unwrap();
                    votes.insert(term);
                    
                    // æ£€æŸ¥æ˜¯å¦è·å¾—å¤šæ•°ç¥¨
                    let majority = (self.peers.len() + 1) / 2 + 1;
                    if votes.len() >= majority {
                        // æˆä¸ºé¢†å¯¼è€…
                        let mut state_guard = self.state.lock().unwrap();
                        *state_guard = NodeState::Leader;
                        
                        // åˆå§‹åŒ–leaderçŠ¶æ€
                        let log_length = self.log.lock().unwrap().len() as u64 + 1;
                        let mut next_idx = self.next_index.lock().unwrap();
                        let mut match_idx = self.match_index.lock().unwrap();
                        
                        for &peer_id in &self.peers {
                            next_idx.insert(peer_id, log_length);
                            match_idx.insert(peer_id, 0);
                        }
                        
                        // å¼€å§‹å‘é€å¿ƒè·³
                        self.start_leader_heartbeat().await;
                    }
                }
            },
            RaftMessage::AppendEntries { term, leader_id, prev_log_index, prev_log_term, entries, leader_commit } => {
                self.handle_append_entries(term, leader_id, prev_log_index, prev_log_term, entries, leader_commit).await;
            },
            RaftMessage::AppendResponse { term, success, last_index } => {
                // å¦‚æœæ”¶åˆ°çš„ä»»æœŸå¤§äºå½“å‰ä»»æœŸï¼Œè½¬ä¸ºè·Ÿéšè€…
                {
                    let mut current_term_guard = self.current_term.lock().unwrap();
                    if term > *current_term_guard {
                        *current_term_guard = term;
                        let mut state_guard = self.state.lock().unwrap();
                        *state_guard = NodeState::Follower;
                        let mut voted_for_guard = self.voted_for.lock().unwrap();
                        *voted_for_guard = None;
                        return;
                    }
                }
                
                // å¦‚æœä¸æ˜¯é¢†å¯¼è€…ï¼Œå¿½ç•¥
                {
                    let state_guard = self.state.lock().unwrap();
                    if *state_guard != NodeState::Leader {
                        return;
                    }
                }
                
                // å¤„ç†å¤åˆ¶å“åº”
                if success {
                    // æ›´æ–°matchIndexå’ŒnextIndex
                    {
                        let mut next_idx = self.next_index.lock().unwrap();
                        let mut match_idx = self.match_index.lock().unwrap();
                        
                        match_idx.insert(last_index, last_index);
                        next_idx.insert(last_index, last_index + 1);
                    }
                    
                    // æ£€æŸ¥æ˜¯å¦å¯ä»¥æäº¤æ›´å¤šæ¡ç›®
                    self.update_commit_index().await;
                } else {
                    // å¦‚æœå¤åˆ¶å¤±è´¥ï¼Œå‡å°‘nextIndexå¹¶é‡è¯•
                    let mut next_idx = self.next_index.lock().unwrap();
                    if let Some(idx) = next_idx.get_mut(&last_index) {
                        *idx = std::cmp::max(1, last_index);
                    }
                }
            },
            RaftMessage::ClientRequest { command, response_tx } => {
                self.handle_client_request(command, response_tx).await;
            }
        }
    }
    
    async fn update_commit_index(&self) {
        let current_term = *self.current_term.lock().unwrap();
        let log_len = self.log.lock().unwrap().len() as u64;
        
        for n in (*self.commit_index.lock().unwrap() + 1)..=log_len {
            let mut count = 1; // åŒ…æ‹¬è‡ªå·±
            
            // æ£€æŸ¥æ˜¯å¦æœ‰å¤šæ•°èŠ‚ç‚¹åŒ¹é…æ­¤ç´¢å¼•
            for &peer_id in &self.peers {
                let match_idx = {
                    let match_idx_guard = self.match_index.lock().unwrap();
                    *match_idx_guard.get(&peer_id).unwrap_or(&0)
                };
                
                if match_idx >= n {
                    count += 1;
                }
            }
            
            // å¤šæ•°èŠ‚ç‚¹åŒ¹é…ä¸”æ˜¯å½“å‰ä»»æœŸçš„æ¡ç›®
            let is_current_term = {
                let log_guard = self.log.lock().unwrap();
                n > 0 && n <= log_guard.len() as u64 && log_guard[n as usize - 1].term == current_term
            };
            
            if count > self.peers.len() / 2 && is_current_term {
                let mut commit_guard = self.commit_index.lock().unwrap();
                *commit_guard = n;
                
                // åº”ç”¨å·²æäº¤çš„æ¡ç›®
                self.apply_committed_entries().await;
            }
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºä¸‰ä¸ªRaftèŠ‚ç‚¹
    let node1_id = 1;
    let node2_id = 2;
    let node3_id = 3;
    
    let peers = vec![node1_id, node2_id, node3_id];
    
    // è®¾ç½®é€šä¿¡é€šé“
    let (node1_tx, mut node1_rx) = mpsc::channel(100);
    let (node2_tx, mut node2_rx) = mpsc::channel(100);
    let (node3_tx, mut node3_rx) = mpsc::channel(100);
    
    let mut message_channels = HashMap::new();
    message_channels.insert(node1_id, node1_tx);
    message_channels.insert(node2_id, node2_tx);
    message_channels.insert(node3_id, node3_tx);
    
    // åˆ›å»ºèŠ‚ç‚¹
    let node1 = Arc::new(RaftNode::new(node1_id, peers.clone(), message_channels.clone()));
    let node2 = Arc::new(RaftNode::new(node2_id, peers.clone(), message_channels.clone()));
    let node3 = Arc::new(RaftNode::new(node3_id, peers.clone(), message_channels.clone()));
    
    // å¯åŠ¨èŠ‚ç‚¹æ¶ˆæ¯å¤„ç†
    let node1_clone = node1.clone();
    tokio::spawn(async move {
        while let Some(message) = node1_rx.recv().await {
            node1_clone.handle_message(message).await;
        }
    });
    
    let node2_clone = node2.clone();
    tokio::spawn(async move {
        while let Some(message) = node2_rx.recv().await {
            node2_clone.handle_message(message).await;
        }
    });
    
    let node3_clone = node3.clone();
    tokio::spawn(async move {
        while let Some(message) = node3_rx.recv().await {
            node3_clone.handle_message(message).await;
        }
    });
    
    // å¯åŠ¨é€‰ä¸¾è¶…æ—¶
    node1.start_election_timeout().await;
    node2.start_election_timeout().await;
    node3.start_election_timeout().await;
    
    // ç­‰å¾…ä¸€æ®µæ—¶é—´è®©é€‰ä¸¾å®Œæˆ
    tokio::time::sleep(Duration::from_secs(2)).await;
    
    // æ‰¾å‡ºé¢†å¯¼è€…
    let leader = if *node1.state.lock().unwrap() == NodeState::Leader {
        node1.clone()
    } else if *node2.state.lock().unwrap() == NodeState::Leader {
        node2.clone()
    } else {
        node3.clone()
    };
    
    println!("é¢†å¯¼è€…æ˜¯èŠ‚ç‚¹ {}", leader.id);
    
    // å‘é€å®¢æˆ·ç«¯è¯·æ±‚
    let (response_tx, mut response_rx) = mpsc::channel(1);
    
    // è®¾ç½®é”®å€¼å¯¹
    let set_command = bincode::serialize(&("set".to_string(), b"mykey".to_vec(), b"myvalue".to_vec())).unwrap();
    leader.handle_message(RaftMessage::ClientRequest {
        command: set_command,
        response_tx: response_tx.clone(),
    }).await;
    
    // ç­‰å¾…å“åº”
    let response = response_rx.recv().await.unwrap();
    println!("è®¾ç½®é”®å€¼å¯¹å“åº”: {:?}", response);
    
    // ç­‰å¾…å¤åˆ¶å®Œæˆ
    tokio::time::sleep(Duration::from_secs(1)).await;
    
    // è·å–é”®å€¼
    let get_command = bincode::serialize(&("get".to_string(), b"mykey".to_vec())).unwrap();
    leader.handle_message(RaftMessage::ClientRequest {
        command: get_command,
        response_tx,
    }).await;
    
    // ç­‰å¾…å“åº”
    let response = response_rx.recv().await.unwrap();
    println!("è·å–é”®å€¼å¯¹å“åº”: {:?}", response);
    
    // æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹çš„çŠ¶æ€æœºæ˜¯å¦ä¸€è‡´
    let value1 = node1.state_machine.read().await.get(&b"mykey".to_vec()).cloned();
    let value2 = node2.state_machine.read().await.get(&b"mykey".to_vec()).cloned();
    let value3 = node3.state_machine.read().await.get(&b"mykey".to_vec()).cloned();
    
    println!("èŠ‚ç‚¹1ä¸­çš„å€¼: {:?}", value1);
    println!("èŠ‚ç‚¹2ä¸­çš„å€¼: {:?}", value2);
    println!("èŠ‚ç‚¹3ä¸­çš„å€¼: {:?}", value3);
}
```

### 2.5 æœ€ç»ˆä¸€è‡´æ€§

æœ€ç»ˆä¸€è‡´æ€§æ¨¡å¼ä¿è¯åœ¨æ²¡æœ‰æ–°çš„æ›´æ–°çš„æƒ…å†µä¸‹ï¼Œæœ€ç»ˆæ‰€æœ‰å‰¯æœ¬å°†æ”¶æ•›åˆ°ç›¸åŒçš„å€¼ã€‚

```rust
use std::collections::{HashMap, HashSet, VecDeque};
use std::sync::{Arc, Mutex};
use tokio::sync::{mpsc, RwLock};
use tokio::time::Duration;
use serde::{Serialize, Deserialize};
use uuid::Uuid;

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
struct VersionVector {
    node_id: String,
    counter: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct Operation<K, V> {
    op_id: String,
    key: K,
    value: Option<V>,
    timestamp: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct DataItem<K, V> {
    key: K,
    value: V,
    version_vector: HashMap<String, u64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
enum EventualMessage<K, V> {
    Update { item: DataItem<K, V> },
    Sync { version_vector: HashMap<String, u64> },
    SyncResponse { items: Vec<DataItem<K, V>> },
}

struct EventualConsistencyNode<K, V>
where
    K: Clone + Eq + std::hash::Hash + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    node_id: String,
    data: Arc<RwLock<HashMap<K, DataItem<K, V>>>>,
    version_vector: Arc<Mutex<HashMap<String, u64>>>,
    applied_ops: Arc<Mutex<HashSet<String>>>,
    peers: Vec<mpsc::Sender<EventualMessage<K, V>>>,
    anti_entropy_interval: Duration,
}

impl<K, V> EventualConsistencyNode<K, V>
where
    K: Clone + Eq + std::hash::Hash + Send + Sync + 'static + Serialize + for<'de> Deserialize<'de>,
    V: Clone + Send + Sync + 'static + Serialize + for<'de> Deserialize<'de>,
{
    fn new(node_id: &str, anti_entropy_interval: Duration) -> Self {
        let mut version_vector = HashMap::new();
        version_vector.insert(node_id.to_string(), 0);
        
        Self {
            node_id: node_id.to_string(),
            data: Arc::new(RwLock::new(HashMap::new())),
            version_vector: Arc::new(Mutex::new(version_vector)),
            applied_ops: Arc::new(Mutex::new(HashSet::new())),
            peers: Vec::new(),
            anti_entropy_interval,
        }
    }
    
    fn add_peer(&mut self, peer_tx: mpsc::Sender<EventualMessage<K, V>>) {
        self.peers.push(peer_tx);
    }
    
    async fn put(&self, key: K, value: V) {
        // æ›´æ–°ç‰ˆæœ¬å‘é‡
        let version_vector = {
            let mut vv = self.version_vector.lock().unwrap();
            let counter = vv.entry(self.node_id.clone()).or_insert(0);
            *counter += 1;
            vv.clone()
        };
        
        // åˆ›å»ºæ•°æ®é¡¹
        let item = DataItem {
            key: key.clone(),
            value: value.clone(),
            version_vector: version_vector.clone(),
        };
        
        // æ›´æ–°æœ¬åœ°å­˜å‚¨
        {
            let mut data = self.data.write().await;
            data.insert(key, item.clone());
        }
        
        // å‘é€æ›´æ–°åˆ°æ‰€æœ‰å¯¹ç­‰èŠ‚ç‚¹
        let update_message = EventualMessage::Update { item };
        for peer in &self.peers {
            let _ = peer.send(update_message.clone()).await;
        }
    }
    
    async fn get(&self, key: &K) -> Option<V> {
        let data = self.data.read().await;
        data.get(key).map(|item| item.value.clone())
    }
    
    async fn start_anti_entropy(&self) {
        let node_id = self.node_id.clone();
        let version_vector = self.version_vector.clone();
        let peers = self.peers.clone();
        let interval = self.anti_entropy_interval;
        
        tokio::spawn(async move {
            let mut interval_timer = tokio::time::interval(interval);
            
            loop {
                interval_timer.tick().await;
                
                // å‘é€åŒæ­¥è¯·æ±‚ç»™æ‰€æœ‰å¯¹ç­‰èŠ‚ç‚¹
                let vv = {
                    let vv_guard = version_vector.lock().unwrap();
                    vv_guard.clone()
                };
                
                let sync_message = EventualMessage::Sync { version_vector: vv };
                for peer in &peers {
                    let _ = peer.send(sync_message.clone()).await;
                }
                
                // ç­‰å¾…ä¸‹ä¸€æ¬¡é—´éš”
                tokio::time::sleep(Duration::from_millis(100)).await;
            }
        });
    }
    
    async fn handle_message(&self, message: EventualMessage<K, V>) {
        match message {
            EventualMessage::Update { item } => {
                self.merge_item(item).await;
            },
            EventualMessage::Sync { version_vector } => {
                // æ¯”è¾ƒç‰ˆæœ¬å‘é‡ï¼Œæ‰¾å‡ºå¯¹æ–¹ç¼ºå°‘çš„é¡¹
                let items_to_send = self.find_newer_items(&version_vector).await;
                
                // æ„å»ºåŒæ­¥å“åº”
                let sync_response = EventualMessage::SyncResponse { items: items_to_send };
                
                // åœ¨å®é™…å®ç°ä¸­ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“å¦‚ä½•å°†å“åº”è·¯ç”±å›è¯·æ±‚è€…
                // è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå‡è®¾æ‰€æœ‰å¯¹ç­‰æ–¹éƒ½æ¥æ”¶å“åº”
                for peer in &self.peers {
                    let _ = peer.send(sync_response.clone()).await;
                }
            },
            EventualMessage::SyncResponse { items } => {
                // åˆå¹¶æ”¶åˆ°çš„æ‰€æœ‰é¡¹
                for item in items {
                    self.merge_item(item).await;
                }
            }
        }
    }
    
    async fn merge_item(&self, item: DataItem<K, V>) {
        let should_update = {
            let data = self.data.read().await;
            if let Some(existing_item) = data.get(&item.key) {
                // æ¯”è¾ƒç‰ˆæœ¬å‘é‡
                self.is_newer_than(&item.version_vector, &existing_item.version_vector)
            } else {
                // æ–°é¡¹ç›®
                true
            }
        };
        
        if should_update {
            // æ›´æ–°æœ¬åœ°æ•°æ®
            let mut data = self.data.write().await;
            data.insert(item.key.clone(), item.clone());
            
            // æ›´æ–°ç‰ˆæœ¬å‘é‡
            let mut vv = self.version_vector.lock().unwrap();
            for (node, counter) in &item.version_vector {
                let local_counter = vv.entry(node.clone()).or_insert(0);
                *local_counter = std::cmp::max(*local_counter, *counter);
            }
        }
    }
    
    fn is_newer_than(&self, vv1: &HashMap<String, u64>, vv2: &HashMap<String, u64>) -> bool {
        let mut is_strictly_newer = false;
        
        // å¯¹äºvv1ä¸­çš„æ¯ä¸ªæ¡ç›®
        for (node, counter1) in vv1 {
            let counter2 = vv2.get(node).copied().unwrap_or(0);
            
            if *counter1 < counter2 {
                // vv1æ¯”vv2æ—§
                return false;
            } else if *counter1 > counter2 {
                // vv1è‡³å°‘åœ¨ä¸€ä¸ªèŠ‚ç‚¹ä¸Šæ¯”vv2æ–°
                is_strictly_newer = true;
            }
        }
        
        // å¯¹äºvv2ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹ï¼Œæ£€æŸ¥vv1æ˜¯å¦æœ‰è¯¥èŠ‚ç‚¹çš„è®¡æ•°å™¨
        for (node, counter2) in vv2 {
            if !vv1.contains_key(node) && *counter2 > 0 {
                // vv2æœ‰vv1æ²¡æœ‰çš„èŠ‚ç‚¹ä¿¡æ¯
                return false;
            }
        }
        
        is_strictly_newer
    }
    
    async fn find_newer_items(&self, remote_vv: &HashMap<String, u64>) -> Vec<DataItem<K, V>> {
        let mut newer_items = Vec::new();
        let data = self.data.read().await;
        
        for item in data.values() {
            if self.is_newer_than(&item.version_vector, remote_vv) {
                newer_items.push(item.clone());
            }
        }
        
        newer_items
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºä¸‰ä¸ªèŠ‚ç‚¹
    let mut node1 = EventualConsistencyNode::<String, String>::new(
        "node1", 
        Duration::from_secs(5)
    );
    
    let mut node2 = EventualConsistencyNode::<String, String>::new(
        "node2", 
        Duration::from_secs(5)
    );
    
    let mut node3 = EventualConsistencyNode::<String, String>::new(
        "node3", 
        Duration::from_secs(5)
    );
    
    // è®¾ç½®é€šä¿¡é€šé“
    let (node1_tx, mut node1_rx) = mpsc::channel(100);
    let (node2_tx, mut node2_rx) = mpsc::channel(100);
    let (node3_tx, mut node3_rx) = mpsc::channel(100);
    
    node1.add_peer(node2_tx.clone());
    node1.add_peer(node3_tx.clone());
    
    node2.add_peer(node1_tx.clone());
    node2.add_peer(node3_tx.clone());
    
    node3.add_peer(node1_tx.clone());
    node3.add_peer(node2_tx.clone());
    
    // å¯åŠ¨æ¶ˆæ¯å¤„ç†
    let node1_clone = Arc::new(node1);
    let node1_handle = {
        let node = node1_clone.clone();
        tokio::spawn(async move {
            while let Some(message) = node1_rx.recv().await {
                node.handle_message(message).await;
            }
        })
    };
    
    let node2_clone = Arc::new(node2);
    let node2_handle = {
        let node = node2_clone.clone();
        tokio::spawn(async move {
            while let Some(message) = node2_rx.recv().await {
                node.handle_message(message).await;
            }
        })
    };
    
    let node3_clone = Arc::new(node3);
    let node3_handle = {
        let node = node3_clone.clone();
        tokio::spawn(async move {
            while let Some(message) = node3_rx.recv().await {
                node.handle_message(message).await;
            }
        })
    };
    
    // å¯åŠ¨åç†µ
    node1_clone.start_anti_entropy().await;
    node2_clone.start_anti_entropy().await;
    node3_clone.start_anti_entropy().await;
    
    // æ¨¡æ‹Ÿç½‘ç»œåˆ†åŒº
    // èŠ‚ç‚¹1å’ŒèŠ‚ç‚¹2ä¸èŠ‚ç‚¹3æ–­å¼€è¿æ¥
    // åœ¨èŠ‚ç‚¹1å’ŒèŠ‚ç‚¹2ä¸Šå†™å…¥æ•°æ®
    node1_clone.put("key1".to_string(), "value1-from-node1".to_string()).await;
    node2_clone.put("key2".to_string(), "value2-from-node2".to_string()).await;
    
    // åœ¨èŠ‚ç‚¹3ä¸Šå†™å…¥ä¸åŒçš„æ•°æ®
    node3_clone.put("key3".to_string(), "value3-from-node3".to_string()).await;
    
    // ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œç„¶åæ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹
    tokio::time::sleep(Duration::from_secs(10)).await;
    
    // æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹æ˜¯å¦æœ€ç»ˆä¸€è‡´
    let value1_from_node1 = node1_clone.get(&"key1".to_string()).await;
    let value1_from_node2 = node2_clone.get(&"key1".to_string()).await;
    let value1_from_node3 = node3_clone.get(&"key1".to_string()).await;
    
    let value2_from_node1 = node1_clone.get(&"key2".to_string()).await;
    let value2_from_node2 = node2_clone.get(&"key2".to_string()).await;
    let value2_from_node3 = node3_clone.get(&"key2".to_string()).await;
    
    let value3_from_node1 = node1_clone.get(&"key3".to_string()).await;
    let value3_from_node2 = node2_clone.get(&"key3".to_string()).await;
    let value3_from_node3 = node3_clone.get(&"key3".to_string()).await;
    
    println!("Node1 - key1: {:?}, key2: {:?}, key3: {:?}", 
             value1_from_node1, value2_from_node1, value3_from_node1);
    println!("Node2 - key1: {:?}, key2: {:?}, key3: {:?}", 
             value1_from_node2, value2_from_node2, value3_from_node2);
    println!("Node3 - key1: {:?}, key2: {:?}, key3: {:?}", 
             value1_from_node3, value2_from_node3, value3_from_node3);
}
```

```text
<think>
æˆ‘éœ€è¦ç»§ç»­æä¾›å…³äºåˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡æ¨¡å¼çš„Rustå®ç°ã€‚æ ¹æ®åŸå§‹æ–‡æ¡£ï¼Œæˆ‘è¿˜éœ€è¦æ¶µç›–ä»¥ä¸‹éƒ¨åˆ†ï¼š

3. åˆ†åŒºæ¨¡å¼
   - åˆ†ç‰‡
   - ä¸€è‡´æ€§å“ˆå¸Œ
   - å‰¯æœ¬åˆ†å¸ƒ

æˆ‘å°†é¦–å…ˆå®ç°è¿™äº›åˆ†åŒºæ¨¡å¼ï¼Œç„¶åç»§ç»­å®ç°åç»­å„éƒ¨åˆ†ã€‚
</think>
```

## 3 åˆ†åŒºæ¨¡å¼

### 3.1 åˆ†ç‰‡

åˆ†ç‰‡æ˜¯å°†æ•°æ®æ°´å¹³åˆ†åŒºåˆ°å¤šä¸ªèŠ‚ç‚¹çš„æŠ€æœ¯ï¼Œæ¯ä¸ªèŠ‚ç‚¹è´Ÿè´£æ•°æ®çš„ä¸€ä¸ªå­é›†ã€‚

```rust
use std::collections::HashMap;
use std::hash::{Hash, Hasher};
use std::sync::{Arc, Mutex};
use tokio::sync::{mpsc, RwLock};
use serde::{Serialize, Deserialize};

// åˆ†ç‰‡å‡½æ•°ç‰¹å¾
trait ShardingFunction<K> {
    fn shard(&self, key: &K) -> usize;
}

// ç®€å•çš„å–æ¨¡åˆ†ç‰‡å‡½æ•°
struct ModuloSharding {
    shard_count: usize,
}

impl<K> ShardingFunction<K> for ModuloSharding
where
    K: Hash,
{
    fn shard(&self, key: &K) -> usize {
        let mut hasher = std::collections::hash_map::DefaultHasher::new();
        key.hash(&mut hasher);
        (hasher.finish() as usize) % self.shard_count
    }
}

// èŒƒå›´åˆ†ç‰‡å‡½æ•°
struct RangeSharding<K> {
    boundaries: Vec<K>,
}

impl<K> ShardingFunction<K> for RangeSharding<K>
where
    K: Ord + Clone,
{
    fn shard(&self, key: &K) -> usize {
        match self.boundaries.binary_search(key) {
            Ok(exact) => exact,
            Err(insertion_point) => insertion_point,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
enum ShardMessage<K, V> {
    Get { key: K, respond_to: String },
    GetResponse { key: K, value: Option<V> },
    Put { key: K, value: V },
    Delete { key: K },
}

struct ShardNode<K, V> {
    id: String,
    data: Arc<RwLock<HashMap<K, V>>>,
    peers: HashMap<usize, mpsc::Sender<ShardMessage<K, V>>>,
    shard_function: Box<dyn ShardingFunction<K> + Send + Sync>,
}

impl<K, V> ShardNode<K, V>
where
    K: Clone + Eq + Hash + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    fn new<F>(id: &str, shard_function: F) -> Self
    where
        F: ShardingFunction<K> + Send + Sync + 'static,
    {
        Self {
            id: id.to_string(),
            data: Arc::new(RwLock::new(HashMap::new())),
            peers: HashMap::new(),
            shard_function: Box::new(shard_function),
        }
    }
    
    fn add_peer(&mut self, shard_id: usize, tx: mpsc::Sender<ShardMessage<K, V>>) {
        self.peers.insert(shard_id, tx);
    }
    
    // æœ¬åœ°å­˜å‚¨é”®å€¼å¯¹
    async fn local_put(&self, key: K, value: V) {
        let mut data = self.data.write().await;
        data.insert(key, value);
    }
    
    // æœ¬åœ°è·å–å€¼
    async fn local_get(&self, key: &K) -> Option<V> {
        let data = self.data.read().await;
        data.get(key).cloned()
    }
    
    // æœ¬åœ°åˆ é™¤é”®
    async fn local_delete(&self, key: &K) {
        let mut data = self.data.write().await;
        data.remove(key);
    }
    
    // æ ¹æ®é”®ç¡®å®šåˆ†ç‰‡å¹¶æ‰§è¡Œæ“ä½œ
    async fn get(&self, key: K) -> Option<V> 
    where
        K: Serialize + for<'de> Deserialize<'de>,
        V: Serialize + for<'de> Deserialize<'de>,
    {
        let shard_id = self.shard_function.shard(&key);
        
        if let Some(tx) = self.peers.get(&shard_id) {
            // é”®å±äºå¦ä¸€ä¸ªåˆ†ç‰‡
            let (response_tx, mut response_rx) = mpsc::channel(1);
            
            // å‘é€è·å–è¯·æ±‚
            let message = ShardMessage::Get { 
                key: key.clone(), 
                respond_to: self.id.clone() 
            };
            
            if tx.send(message).await.is_err() {
                return None; // å‘é€å¤±è´¥
            }
            
            // ç­‰å¾…å“åº”
            if let Some(response) = response_rx.recv().await {
                match response {
                    ShardMessage::GetResponse { key: _, value } => value,
                    _ => None,
                }
            } else {
                None
            }
        } else {
            // é”®å±äºå½“å‰åˆ†ç‰‡
            self.local_get(&key).await
        }
    }
    
    async fn put(&self, key: K, value: V) 
    where
        K: Serialize + for<'de> Deserialize<'de>,
        V: Serialize + for<'de> Deserialize<'de>,
    {
        let shard_id = self.shard_function.shard(&key);
        
        if let Some(tx) = self.peers.get(&shard_id) {
            // é”®å±äºå¦ä¸€ä¸ªåˆ†ç‰‡
            let message = ShardMessage::Put { 
                key, 
                value 
            };
            
            let _ = tx.send(message).await;
        } else {
            // é”®å±äºå½“å‰åˆ†ç‰‡
            self.local_put(key, value).await;
        }
    }
    
    async fn delete(&self, key: K) 
    where
        K: Serialize + for<'de> Deserialize<'de>,
    {
        let shard_id = self.shard_function.shard(&key);
        
        if let Some(tx) = self.peers.get(&shard_id) {
            // é”®å±äºå¦ä¸€ä¸ªåˆ†ç‰‡
            let message = ShardMessage::Delete { key };
            
            let _ = tx.send(message).await;
        } else {
            // é”®å±äºå½“å‰åˆ†ç‰‡
            self.local_delete(&key).await;
        }
    }
    
    async fn handle_message(&self, message: ShardMessage<K, V>)
    where
        K: Serialize + for<'de> Deserialize<'de>,
        V: Serialize + for<'de> Deserialize<'de>,
    {
        match message {
            ShardMessage::Get { key, respond_to } => {
                let value = self.local_get(&key).await;
                
                if let Some(tx) = self.peers.get(&self.shard_function.shard(&respond_to)) {
                    let response = ShardMessage::GetResponse {
                        key,
                        value,
                    };
                    
                    let _ = tx.send(response).await;
                }
            },
            ShardMessage::Put { key, value } => {
                self.local_put(key, value).await;
            },
            ShardMessage::Delete { key } => {
                self.local_delete(&key).await;
            },
            _ => {}, // å¿½ç•¥å…¶ä»–æ¶ˆæ¯ç±»å‹
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºä¸€ä¸ª3åˆ†ç‰‡çš„ç³»ç»Ÿ
    let shard_count = 3;
    let sharding_function = ModuloSharding { shard_count };
    
    let mut node1 = ShardNode::<String, String>::new("node1", sharding_function.clone());
    let mut node2 = ShardNode::<String, String>::new("node2", sharding_function.clone());
    let mut node3 = ShardNode::<String, String>::new("node3", sharding_function);
    
    // è®¾ç½®é€šä¿¡é€šé“
    let (node1_tx, mut node1_rx) = mpsc::channel(100);
    let (node2_tx, mut node2_rx) = mpsc::channel(100);
    let (node3_tx, mut node3_rx) = mpsc::channel(100);
    
    node1.add_peer(0, node1_tx.clone());
    node1.add_peer(1, node2_tx.clone());
    node1.add_peer(2, node3_tx.clone());
    
    node2.add_peer(0, node1_tx.clone());
    node2.add_peer(1, node2_tx.clone());
    node2.add_peer(2, node3_tx.clone());
    
    node3.add_peer(0, node1_tx);
    node3.add_peer(1, node2_tx);
    node3.add_peer(2, node3_tx);
    
    // å¯åŠ¨æ¶ˆæ¯å¤„ç†
    let node1_clone = Arc::new(node1);
    tokio::spawn(async move {
        while let Some(message) = node1_rx.recv().await {
            node1_clone.handle_message(message).await;
        }
    });
    
    let node2_clone = Arc::new(node2);
    tokio::spawn(async move {
        while let Some(message) = node2_rx.recv().await {
            node2_clone.handle_message(message).await;
        }
    });
    
    let node3_clone = Arc::new(node3);
    tokio::spawn(async move {
        while let Some(message) = node3_rx.recv().await {
            node3_clone.handle_message(message).await;
        }
    });
    
    // é€šè¿‡node1å†™å…¥ä¸€äº›æ•°æ®
    for i in 0..10 {
        let key = format!("key{}", i);
        let value = format!("value{}", i);
        node1_clone.put(key, value).await;
    }
    
    // ç­‰å¾…æ•°æ®åˆ†å‘
    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
    
    // ä»æ‰€æœ‰èŠ‚ç‚¹è¯»å–æ•°æ®
    for i in 0..10 {
        let key = format!("key{}", i);
        let value1 = node1_clone.get(key.clone()).await;
        let value2 = node2_clone.get(key.clone()).await;
        let value3 = node3_clone.get(key.clone()).await;
        
        println!("Key: {}, Node1: {:?}, Node2: {:?}, Node3: {:?}", 
                 key, value1, value2, value3);
    }
    
    // æŸ¥çœ‹æ¯ä¸ªèŠ‚ç‚¹å®é™…å­˜å‚¨çš„æ•°æ®
    let data1 = node1_clone.data.read().await;
    let data2 = node2_clone.data.read().await;
    let data3 = node3_clone.data.read().await;
    
    println!("Node1æ•°æ®: {:?}", data1);
    println!("Node2æ•°æ®: {:?}", data2);
    println!("Node3æ•°æ®: {:?}", data3);
}
```

### 3.2 ä¸€è‡´æ€§å“ˆå¸Œ

ä¸€è‡´æ€§å“ˆå¸Œæ˜¯ä¸€ç§ç‰¹æ®Šçš„å“ˆå¸Œç®—æ³•ï¼Œå®ƒæœ€å°åŒ–åœ¨æ·»åŠ æˆ–åˆ é™¤èŠ‚ç‚¹æ—¶éœ€è¦é‡æ–°æ˜ å°„çš„é”®æ•°é‡ã€‚

```rust
use std::collections::{BTreeMap, HashMap};
use std::hash::{Hash, Hasher};
use std::sync::Arc;
use tokio::sync::{mpsc, RwLock};
use rand::Rng;

struct ConsistentHash<T> {
    ring: BTreeMap<u64, T>,
    virtual_nodes: usize,
}

impl<T: Clone> ConsistentHash<T> {
    fn new(virtual_nodes: usize) -> Self {
        Self {
            ring: BTreeMap::new(),
            virtual_nodes,
        }
    }
    
    fn add_node(&mut self, node: T, node_id: &str) {
        for i in 0..self.virtual_nodes {
            let key = format!("{}:{}", node_id, i);
            let hash = self.hash(&key);
            self.ring.insert(hash, node.clone());
        }
    }
    
    fn remove_node(&mut self, node_id: &str) {
        for i in 0..self.virtual_nodes {
            let key = format!("{}:{}", node_id, i);
            let hash = self.hash(&key);
            self.ring.remove(&hash);
        }
    }
    
    fn get_node<K: Hash>(&self, key: &K) -> Option<&T> {
        if self.ring.is_empty() {
            return None;
        }
        
        let hash = self.hash(key);
        
        // æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¤§äºç­‰äºhashçš„èŠ‚ç‚¹
        match self.ring.range(hash..).next() {
            Some((_, node)) => Some(node),
            None => {
                // å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°±è¿”å›ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼ˆç¯ç»•ï¼‰
                self.ring.values().next()
            }
        }
    }
    
    fn hash<K: Hash>(&self, key: &K) -> u64 {
        let mut hasher = std::collections::hash_map::DefaultHasher::new();
        key.hash(&mut hasher);
        hasher.finish()
    }
}

#[derive(Debug, Clone)]
struct NodeInfo {
    id: String,
    address: String,
}

struct ConsistentHashRing {
    hash_ring: Arc<RwLock<ConsistentHash<NodeInfo>>>,
    node_connections: Arc<RwLock<HashMap<String, mpsc::Sender<Message>>>>,
}

#[derive(Debug, Clone)]
enum Message {
    Get { key: String, response_tx: mpsc::Sender<Option<String>> },
    Put { key: String, value: String },
    Delete { key: String },
}

impl ConsistentHashRing {
    fn new(virtual_nodes: usize) -> Self {
        Self {
            hash_ring: Arc::new(RwLock::new(ConsistentHash::new(virtual_nodes))),
            node_connections: Arc::new(RwLock::new(HashMap::new())),
        }
    }
    
    async fn add_node(&self, node: NodeInfo, connection: mpsc::Sender<Message>) {
        let mut hash_ring = self.hash_ring.write().await;
        let mut connections = self.node_connections.write().await;
        
        hash_ring.add_node(node.clone(), &node.id);
        connections.insert(node.id.clone(), connection);
    }
    
    async fn remove_node(&self, node_id: &str) {
        let mut hash_ring = self.hash_ring.write().await;
        let mut connections = self.node_connections.write().await;
        
        hash_ring.remove_node(node_id);
        connections.remove(node_id);
    }
    
    async fn get(&self, key: &str) -> Option<String> {
        let hash_ring = self.hash_ring.read().await;
        let connections = self.node_connections.read().await;
        
        if let Some(node) = hash_ring.get_node(&key) {
            if let Some(tx) = connections.get(&node.id) {
                let (response_tx, mut response_rx) = mpsc::channel(1);
                
                let message = Message::Get {
                    key: key.to_string(),
                    response_tx,
                };
                
                if tx.send(message).await.is_ok() {
                    return response_rx.recv().await.flatten();
                }
            }
        }
        
        None
    }
    
    async fn put(&self, key: &str, value: &str) -> bool {
        let hash_ring = self.hash_ring.read().await;
        let connections = self.node_connections.read().await;
        
        if let Some(node) = hash_ring.get_node(&key) {
            if let Some(tx) = connections.get(&node.id) {
                let message = Message::Put {
                    key: key.to_string(),
                    value: value.to_string(),
                };
                
                return tx.send(message).await.is_ok();
            }
        }
        
        false
    }
    
    async fn delete(&self, key: &str) -> bool {
        let hash_ring = self.hash_ring.read().await;
        let connections = self.node_connections.read().await;
        
        if let Some(node) = hash_ring.get_node(&key) {
            if let Some(tx) = connections.get(&node.id) {
                let message = Message::Delete {
                    key: key.to_string(),
                };
                
                return tx.send(message).await.is_ok();
            }
        }
        
        false
    }
}

struct StorageNode {
    id: String,
    data: Arc<RwLock<HashMap<String, String>>>,
}

impl StorageNode {
    fn new(id: &str) -> Self {
        Self {
            id: id.to_string(),
            data: Arc::new(RwLock::new(HashMap::new())),
        }
    }
    
    async fn start(&self) -> mpsc::Sender<Message> {
        let (tx, mut rx) = mpsc::channel(100);
        
        let data = self.data.clone();
        tokio::spawn(async move {
            while let Some(message) = rx.recv().await {
                match message {
                    Message::Get { key, response_tx } => {
                        let value = {
                            let data_guard = data.read().await;
                            data_guard.get(&key).cloned()
                        };
                        
                        let _ = response_tx.send(value).await;
                    },
                    Message::Put { key, value } => {
                        let mut data_guard = data.write().await;
                        data_guard.insert(key, value);
                    },
                    Message::Delete { key } => {
                        let mut data_guard = data.write().await;
                        data_guard.remove(&key);
                    },
                }
            }
        });
        
        tx
    }
    
    async fn get_data_size(&self) -> usize {
        let data = self.data.read().await;
        data.len()
    }
    
    async fn get_data(&self) -> HashMap<String, String> {
        let data = self.data.read().await;
        data.clone()
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºä¸€è‡´æ€§å“ˆå¸Œç¯
    let ring = ConsistentHashRing::new(10); // æ¯ä¸ªèŠ‚ç‚¹10ä¸ªè™šæ‹ŸèŠ‚ç‚¹
    
    // åˆ›å»ºå­˜å‚¨èŠ‚ç‚¹
    let node1 = StorageNode::new("node1");
    let node2 = StorageNode::new("node2");
    let node3 = StorageNode::new("node3");
    
    // å¯åŠ¨èŠ‚ç‚¹å¹¶è·å–é€šä¿¡é€šé“
    let node1_tx = node1.start().await;
    let node2_tx = node2.start().await;
    let node3_tx = node3.start().await;
    
    // å°†èŠ‚ç‚¹æ·»åŠ åˆ°å“ˆå¸Œç¯
    ring.add_node(
        NodeInfo { id: "node1".to_string(), address: "127.0.0.1:8081".to_string() }, 
        node1_tx
    ).await;
    
    ring.add_node(
        NodeInfo { id: "node2".to_string(), address: "127.0.0.1:8082".to_string() }, 
        node2_tx
    ).await;
    
    ring.add_node(
        NodeInfo { id: "node3".to_string(), address: "127.0.0.1:8083".to_string() }, 
        node3_tx
    ).await;
    
    // å†™å…¥ä¸€äº›æ•°æ®
    let keys: Vec<String> = (0..100).map(|i| format!("key{}", i)).collect();
    
    for key in &keys {
        let value = format!("value-{}", key);
        ring.put(key, &value).await;
    }
    
    // æ£€æŸ¥æ•°æ®åˆ†å¸ƒ
    let node1_size = node1.get_data_size().await;
    let node2_size = node2.get_data_size().await;
    let node3_size = node3.get_data_size().await;
    
    println!("åˆå§‹æ•°æ®åˆ†å¸ƒ:");
    println!("Node1: {} é¡¹", node1_size);
    println!("Node2: {} é¡¹", node2_size);
    println!("Node3: {} é¡¹", node3_size);
    
    // è¯»å–ä¸€äº›æ•°æ®
    for i in 0..10 {
        let key = &keys[i];
        let value = ring.get(key).await;
        println!("Key: {}, Value: {:?}", key, value);
    }
    
    // æ·»åŠ ä¸€ä¸ªæ–°èŠ‚ç‚¹
    let node4 = StorageNode::new("node4");
    let node4_tx = node4.start().await;
    
    ring.add_node(
        NodeInfo { id: "node4".to_string(), address: "127.0.0.1:8084".to_string() }, 
        node4_tx
    ).await;
    
    // é‡æ–°åˆ†é…æ•°æ® - åœ¨å®é™…ç³»ç»Ÿä¸­ï¼Œå¯èƒ½éœ€è¦ä¸€ä¸ªé‡æ–°å¹³è¡¡çš„è¿‡ç¨‹
    // è¿™é‡Œæˆ‘ä»¬ç®€å•åœ°é‡æ–°å†™å…¥ç›¸åŒçš„æ•°æ®
    for key in &keys {
        let value = format!("value-{}", key);
        ring.put(key, &value).await;
    }
    
    // æ£€æŸ¥æ·»åŠ èŠ‚ç‚¹åçš„æ•°æ®åˆ†å¸ƒ
    let node1_size = node1.get_data_size().await;
    let node2_size = node2.get_data_size().await;
    let node3_size = node3.get_data_size().await;
    let node4_size = node4.get_data_size().await;
    
    println!("\næ·»åŠ èŠ‚ç‚¹åçš„æ•°æ®åˆ†å¸ƒ:");
    println!("Node1: {} é¡¹", node1_size);
    println!("Node2: {} é¡¹", node2_size);
    println!("Node3: {} é¡¹", node3_size);
    println!("Node4: {} é¡¹", node4_size);
    
    // ç§»é™¤ä¸€ä¸ªèŠ‚ç‚¹
    ring.remove_node("node1").await;
    
    // å†æ¬¡é‡æ–°åˆ†é…æ•°æ®
    for key in &keys {
        let value = format!("value-{}", key);
        ring.put(key, &value).await;
    }
    
    // æ£€æŸ¥ç§»é™¤èŠ‚ç‚¹åçš„æ•°æ®åˆ†å¸ƒ
    let node2_size = node2.get_data_size().await;
    let node3_size = node3.get_data_size().await;
    let node4_size = node4.get_data_size().await;
    
    println!("\nç§»é™¤èŠ‚ç‚¹åçš„æ•°æ®åˆ†å¸ƒ:");
    println!("Node2: {} é¡¹", node2_size);
    println!("Node3: {} é¡¹", node3_size);
    println!("Node4: {} é¡¹", node4_size);
    
    // æŸ¥çœ‹æ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„éƒ¨åˆ†æ•°æ®
    let node2_data = node2.get_data().await;
    let node3_data = node3.get_data().await;
    let node4_data = node4.get_data().await;
    
    println!("\næ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„å‰5é¡¹æ•°æ®:");
    println!("Node2: {:?}", node2_data.iter().take(5).collect::<Vec<_>>());
    println!("Node3: {:?}", node3_data.iter().take(5).collect::<Vec<_>>());
    println!("Node4: {:?}", node4_data.iter().take(5).collect::<Vec<_>>());
}
```

### 3.3 å‰¯æœ¬åˆ†å¸ƒ

å‰¯æœ¬åˆ†å¸ƒæ¨¡å¼æ§åˆ¶æ•°æ®å‰¯æœ¬åœ¨å„èŠ‚ç‚¹ä¸­çš„åˆ†å¸ƒï¼Œæé«˜æ•°æ®å¯ç”¨æ€§å’Œè¯»å–æ€§èƒ½ã€‚

```rust
use std::collections::{HashMap, HashSet};
use std::hash::{Hash, Hasher};
use std::sync::Arc;
use tokio::sync::{mpsc, RwLock};
use rand::{thread_rng, Rng};
use serde::{Serialize, Deserialize};

enum ReplicaPlacementStrategy {
    // ç®€å•ç­–ç•¥ï¼šæ•°æ®æ”¾åœ¨Nä¸ªè¿ç»­çš„èŠ‚ç‚¹ä¸Š
    Adjacent { replica_count: usize },
    
    // éšæœºç­–ç•¥ï¼šæ•°æ®æ”¾åœ¨éšæœºé€‰æ‹©çš„Nä¸ªèŠ‚ç‚¹ä¸Š
    Random { replica_count: usize },
}

struct ReplicaDistributor<T, N> {
    nodes: Vec<N>,
    placement_strategy: ReplicaPlacementStrategy,
    node_for_key: HashMap<T, Vec<usize>>,
}

impl<T, N> ReplicaDistributor<T, N>
where
    T: Eq + Hash + Clone,
    N: Clone,
{
    fn new(nodes: Vec<N>, strategy: ReplicaPlacementStrategy) -> Self {
        Self {
            nodes,
            placement_strategy,
            node_for_key: HashMap::new(),
        }
    }
    
    fn get_replica_nodes(&mut self, key: &T) -> Vec<N> {
        let node_indices = self.calculate_replica_indices(key);
        self.node_for_key.insert(key.clone(), node_indices.clone());
        
        node_indices.into_iter()
            .map(|idx| self.nodes[idx].clone())
            .collect()
    }
    
    fn calculate_replica_indices(&self, key: &T) -> Vec<usize> {
        match &self.placement_strategy {
            ReplicaPlacementStrategy::Adjacent { replica_count } => {
                let mut hasher = std::collections::hash_map::DefaultHasher::new();
                key.hash(&mut hasher);
                let hash = hasher.finish();
                
                let start_idx = (hash as usize) % self.nodes.len();
                let mut indices = Vec::with_capacity(*replica_count);
                
                for i in 0..*replica_count {
                    indices.push((start_idx + i) % self.nodes.len());
                }
                
                indices
            },
            ReplicaPlacementStrategy::Random { replica_count } => {
                let mut rng = thread_rng();
                let mut indices = HashSet::new();
                
                while indices.len() < *replica_count {
                    let idx = rng.gen_range(0..self.nodes.len());
                    indices.insert(idx);
                }
                
                indices.into_iter().collect()
            }
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
enum ReplicaMessage<K, V> {
    Put { key: K, value: V },
    Get { key: K, response_tx: mpsc::Sender<Option<V>> },
    Delete { key: K },
}

struct ReplicaNode<K, V> {
    id: String,
    data: Arc<RwLock<HashMap<K, V>>>,
}

impl<K, V> ReplicaNode<K, V>
where
    K: Clone + Eq + Hash + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    fn new(id: &str) -> Self {
        Self {
            id: id.to_string(),
            data: Arc::new(RwLock::new(HashMap::new())),
        }
    }
    
    async fn start(&self) -> mpsc::Sender<ReplicaMessage<K, V>> {
        let (tx, mut rx) = mpsc::channel(100);
        
        let data = self.data.clone();
        tokio::spawn(async move {
            while let Some(message) = rx.recv().await {
                match message {
                    ReplicaMessage::Put { key, value } => {
                        let mut data_guard = data.write().await;
                        data_guard.insert(key, value);
                    },
                    ReplicaMessage::Get { key, response_tx } => {
                        let value = {
                            let data_guard = data.read().await;
                            data_guard.get(&key).cloned()
                        };
                        
                        let _ = response_tx.send(value).await;
                    },
                    ReplicaMessage::Delete { key } => {
                        let mut data_guard = data.write().await;
                        data_guard.remove(&key);
                    },
                }
            }
        });
        
        tx
    }
    
    async fn get_data_size(&self) -> usize {
        let data = self.data.read().await;
        data.len()
    }
}

struct ReplicatedStorage<K, V> {
    replica_distributor: ReplicaDistributor<K, mpsc::Sender<ReplicaMessage<K, V>>>,
}

impl<K, V> ReplicatedStorage<K, V>
where
    K: Clone + Eq + Hash + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    fn new(
        node_channels: Vec<mpsc::Sender<ReplicaMessage<K, V>>>,
        strategy: ReplicaPlacementStrategy,
    ) -> Self {
        Self {
            replica_distributor: ReplicaDistributor::new(node_channels, strategy),
        }
    }
    
    async fn put(&mut self, key: K, value: V) {
        let replica_nodes = self.replica_distributor.get_replica_nodes(&key);
        
        for node_tx in replica_nodes {
            let message = ReplicaMessage::Put {
                key: key.clone(),
                value: value.clone(),
            };
            
            let _ = node_tx.send(message).await;
        }
    }
    
    async fn get(&mut self, key: K) -> Option<V> {
        let replica_nodes = self.replica_distributor.get_replica_nodes(&key);
        
        if replica_nodes.is_empty() {
            return None;
        }
        
        // ä»ç¬¬ä¸€ä¸ªå¯ç”¨å‰¯æœ¬è·å–
        let (response_tx, mut response_rx) = mpsc::channel(1);
        
        let message = ReplicaMessage::Get {
            key,
            response_tx,
        };
        
        // å°è¯•ä»ç¬¬ä¸€ä¸ªå‰¯æœ¬è¯»å–
        if replica_nodes[0].send(message).await.is_ok() {
            if let Some(value) = response_rx.recv().await {
                return value;
            }
        }
        
        None
    }
    
    async fn delete(&mut self, key: K) {
        let replica_nodes = self.replica_distributor.get_replica_nodes(&key);
        
        for node_tx in replica_nodes {
            let message = ReplicaMessage::Delete {
                key: key.clone(),
            };
            
            let _ = node_tx.send(message).await;
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºå¤šä¸ªå­˜å‚¨èŠ‚ç‚¹
    let node_count = 5;
    let mut nodes = Vec::with_capacity(node_count);
    let mut node_channels = Vec::with_capacity(node_count);
    
    for i in 0..node_count {
        let node = ReplicaNode::<String, String>::new(&format!("node{}", i));
        let channel = node.start().await;
        
        nodes.push(node);
        node_channels.push(channel);
    }
    
    // åˆ›å»ºå…·æœ‰ç›¸é‚»å‰¯æœ¬ç­–ç•¥çš„å­˜å‚¨
    let mut adjacent_storage = ReplicatedStorage::new(
        node_channels.clone(),
        ReplicaPlacementStrategy::Adjacent { replica_count: 3 },
    );
    
    // å†™å…¥ä¸€äº›æ•°æ®
    for i in 0..20 {
        let key = format!("key{}", i);
        let value = format!("value{}", i);
        adjacent_storage.put(key, value).await;
    }
    
    // æ£€æŸ¥æ•°æ®åˆ†å¸ƒ
    println!("ç›¸é‚»å‰¯æœ¬ç­–ç•¥çš„æ•°æ®åˆ†å¸ƒ:");
    for (i, node) in nodes.iter().enumerate() {
        println!("Node{}: {} é¡¹", i, node.get_data_size().await);
    }
    
    // åˆ›å»ºå…·æœ‰éšæœºå‰¯æœ¬ç­–ç•¥çš„å­˜å‚¨
    let mut random_storage = ReplicatedStorage::new(
        node_channels.clone(),
        ReplicaPlacementStrategy::Random { replica_count: 3 },
    );
    
    // æ¸…ç©ºèŠ‚ç‚¹æ•°æ®
    for channel in &node_channels {
        for i in 0..20 {
            let message = ReplicaMessage::Delete {
                key: format!("key{}", i),
            };
            let _ = channel.send(message).await;
        }
    }
    
    // ä½¿ç”¨éšæœºç­–ç•¥å†™å…¥æ•°æ®
    for i in 0..20 {
        let key = format!("key{}", i);
        let value = format!("value{}", i);
        random_storage.put(key, value).await;
    }
    
    // æ£€æŸ¥éšæœºç­–ç•¥çš„æ•°æ®åˆ†å¸ƒ
    println!("\néšæœºå‰¯æœ¬ç­–ç•¥çš„æ•°æ®åˆ†å¸ƒ:");
    for (i, node) in nodes.iter().enumerate() {
        println!("Node{}: {} é¡¹", i, node.get_data_size().await);
    }
    
    // è¯»å–æ•°æ®
    for i in 0..5 {
        let key = format!("key{}", i);
        let value = random_storage.get(key.clone()).await;
        println!("è¯»å– {}: {:?}", key, value);
    }
    
    // åˆ é™¤ä¸€ä¸ªèŠ‚ç‚¹å¹¶è§‚å¯Ÿå½±å“
    println!("\næ¨¡æ‹ŸèŠ‚ç‚¹0å¤±æ•ˆ:");
    // æˆ‘ä»¬ä¸ä¼šçœŸçš„åˆ é™¤èŠ‚ç‚¹ï¼Œè€Œæ˜¯è®©å®ƒä¸å†æ¥æ”¶æ–°çš„è¯·æ±‚
    
    // è¯»å–æ‰€æœ‰é”®ï¼Œçœ‹çœ‹å“ªäº›å—åˆ°å½±å“
    for i in 0..20 {
        let key = format!("key{}", i);
        let value = random_storage.get(key.clone()).await;
        println!("è¯»å– {}: {}", key, if value.is_some() { "æˆåŠŸ" } else { "å¤±è´¥" });
    }
}
```

## 4 å®¹é”™æ¨¡å¼

### 4.1 ç†”æ–­å™¨

ç†”æ–­å™¨æ¨¡å¼ç”¨äºé˜²æ­¢å¤±è´¥çš„æ“ä½œé‡å¤æ‰§è¡Œï¼Œç‰¹åˆ«æ˜¯åœ¨è¿œç¨‹æœåŠ¡ä¸å¯ç”¨æ—¶ã€‚

```rust
use std::sync::atomic::{AtomicU64, AtomicUsize, Ordering};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::RwLock;
use tokio::time::sleep;
use std::future::Future;
use std::pin::Pin;
use async_trait::async_trait;

#[derive(Debug, Clone, Copy, PartialEq)]
enum CircuitState {
    Closed,    // æ­£å¸¸çŠ¶æ€
    Open,      // ç†”æ–­çŠ¶æ€
    HalfOpen,  // æ¢æµ‹çŠ¶æ€
}

struct CircuitBreakerStats {
    success_count: AtomicUsize,
    failure_count: AtomicUsize,
    total_count: AtomicUsize,
    last_failure_time: AtomicU64,
}

impl CircuitBreakerStats {
    fn new() -> Self {
        Self {
            success_count: AtomicUsize::new(0),
            failure_count: AtomicUsize::new(0),
            total_count: AtomicUsize::new(0),
            last_failure_time: AtomicU64::new(0),
        }
    }
    
    fn record_success(&self) {
        self.success_count.fetch_add(1, Ordering::SeqCst);
        self.total_count.fetch_add(1, Ordering::SeqCst);
    }
    
    fn record_failure(&self) {
        self.failure_count.fetch_add(1, Ordering::SeqCst);
        self.total_count.fetch_add(1, Ordering::SeqCst);
        self.last_failure_time.store(
            Instant::now().elapsed().as_secs(),
            Ordering::SeqCst,
        );
    }
    
    fn reset(&self) {
        self.success_count.store(0, Ordering::SeqCst);
        self.failure_count.store(0, Ordering::SeqCst);
    }
    
    fn failure_rate(&self) -> f64 {
        let failures = self.failure_count.load(Ordering::SeqCst);
        let total = self.total_count.load(Ordering::SeqCst);
        
        if total == 0 {
            return 0.0;
        }
        
        failures as f64 / total as f64
    }
}

struct CircuitBreaker {
    state: RwLock<CircuitState>,
    stats: CircuitBreakerStats,
    failure_threshold: f64,
    reset_timeout: Duration,
    half_open_allowed_calls: usize,
}

impl CircuitBreaker {
    fn new(
        failure_threshold: f64,
        reset_timeout: Duration,
        half_open_allowed_calls: usize,
    ) -> Arc<Self> {
        Arc::new(Self {
            state: RwLock::new(CircuitState::Closed),
            stats: CircuitBreakerStats::new(),
            failure_threshold,
            reset_timeout,
            half_open_allowed_calls,
        })
    }

/*    
<think>
æˆ‘å°†ç»§ç»­ä»CircuitBreakerçš„å®ç°å¼€å§‹ï¼Œæ¥ç€å®Œæˆå‰©ä½™çš„å®¹é”™æ¨¡å¼éƒ¨åˆ†ã€‚
</think>
*/


    async fn current_state(&self) -> CircuitState {
        *self.state.read().await
    }
    
    async fn trip(&self) {
        let mut state = self.state.write().await;
        if *state == CircuitState::Closed {
            *state = CircuitState::Open;
            println!("ç†”æ–­å™¨çŠ¶æ€å˜æ›´: å…³é—­ -> æ‰“å¼€");
        }
    }
    
    async fn reset(&self) {
        let mut state = self.state.write().await;
        *state = CircuitState::Closed;
        self.stats.reset();
        println!("ç†”æ–­å™¨çŠ¶æ€å˜æ›´: æ‰“å¼€/åŠå¼€ -> å…³é—­");
    }
    
    async fn half_open(&self) {
        let mut state = self.state.write().await;
        if *state == CircuitState::Open {
            *state = CircuitState::HalfOpen;
            self.stats.reset();
            println!("ç†”æ–­å™¨çŠ¶æ€å˜æ›´: æ‰“å¼€ -> åŠå¼€");
        }
    }
    
    async fn check_state(&self) {
        match self.current_state().await {
            CircuitState::Closed => {
                // æ£€æŸ¥å¤±è´¥ç‡æ˜¯å¦è¶…è¿‡é˜ˆå€¼
                if self.stats.failure_rate() >= self.failure_threshold {
                    self.trip().await;
                }
            },
            CircuitState::Open => {
                // æ£€æŸ¥æ˜¯å¦ç»è¿‡äº†è¶³å¤Ÿçš„æ—¶é—´æ¥å°è¯•åŠå¼€
                let last_failure = self.stats.last_failure_time.load(Ordering::SeqCst);
                let now = Instant::now().elapsed().as_secs();
                
                if now - last_failure >= self.reset_timeout.as_secs() {
                    self.half_open().await;
                }
            },
            CircuitState::HalfOpen => {
                // åœ¨åŠå¼€çŠ¶æ€ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æˆåŠŸè¯·æ±‚æ¥å…³é—­æ–­è·¯å™¨
                let success_count = self.stats.success_count.load(Ordering::SeqCst);
                
                if success_count >= self.half_open_allowed_calls {
                    self.reset().await;
                } else if self.stats.failure_count.load(Ordering::SeqCst) > 0 {
                    // å¦‚æœæœ‰ä»»ä½•å¤±è´¥ï¼Œç«‹å³å›åˆ°æ‰“å¼€çŠ¶æ€
                    self.trip().await;
                }
            },
        }
    }
    
    async fn execute<F, Fut, T, E>(&self, f: F) -> Result<T, E>
    where
        F: FnOnce() -> Fut,
        Fut: Future<Output = Result<T, E>>,
    {
        // æ£€æŸ¥çŠ¶æ€
        match self.current_state().await {
            CircuitState::Open => {
                println!("ç†”æ–­å™¨æ‰“å¼€ï¼Œå¿«é€Ÿå¤±è´¥");
                return Err(std::any::type_name::<E>().parse().unwrap());
            },
            CircuitState::HalfOpen => {
                let total = self.stats.total_count.load(Ordering::SeqCst);
                if total >= self.half_open_allowed_calls {
                    println!("åŠå¼€çŠ¶æ€è¯·æ±‚æ•°é‡å·²è¾¾ä¸Šé™ï¼Œå¿«é€Ÿå¤±è´¥");
                    return Err(std::any::type_name::<E>().parse().unwrap());
                }
            },
            CircuitState::Closed => {}
        }
        
        // æ‰§è¡Œå‡½æ•°
        match f().await {
            Ok(result) => {
                self.stats.record_success();
                self.check_state().await;
                Ok(result)
            },
            Err(err) => {
                self.stats.record_failure();
                self.check_state().await;
                Err(err)
            }
        }
    }
}

#[async_trait]
trait RemoteService {
    async fn call(&self) -> Result<String, String>;
}

struct UnreliableService {
    failure_rate: f64,
}

#[async_trait]
impl RemoteService for UnreliableService {
    async fn call(&self) -> Result<String, String> {
        // æ¨¡æ‹Ÿéšæœºå¤±è´¥
        if rand::random::<f64>() < self.failure_rate {
            sleep(Duration::from_millis(100)).await; // æ¨¡æ‹Ÿå»¶è¿Ÿ
            Err("æœåŠ¡è°ƒç”¨å¤±è´¥".to_string())
        } else {
            sleep(Duration::from_millis(50)).await; // æ¨¡æ‹Ÿå»¶è¿Ÿ
            Ok("æœåŠ¡è°ƒç”¨æˆåŠŸ".to_string())
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºä¸€ä¸ªä¸å¯é çš„æœåŠ¡
    let service = UnreliableService { failure_rate: 0.7 }; // 70%å¤±è´¥ç‡
    
    // åˆ›å»ºä¸€ä¸ªç†”æ–­å™¨
    let breaker = CircuitBreaker::new(
        0.5, // 50%å¤±è´¥ç‡é˜ˆå€¼
        Duration::from_secs(5), // 5ç§’é‡ç½®æ—¶é—´
        3, // åŠå¼€çŠ¶æ€å…è®¸çš„è°ƒç”¨æ¬¡æ•°
    );
    
    // æ‰§è¡Œä¸€ç³»åˆ—è°ƒç”¨
    for i in 0..30 {
        println!("å°è¯• #{}", i);
        
        let result = breaker.execute(|| async {
            service.call().await
        }).await;
        
        match result {
            Ok(msg) => println!("æˆåŠŸ: {}", msg),
            Err(err) => println!("å¤±è´¥: {}", err),
        }
        
        sleep(Duration::from_millis(300)).await;
    }
}
```

### 4.2 èˆ±å£æ¨¡å¼

èˆ±å£æ¨¡å¼é€šè¿‡éš”ç¦»èµ„æºï¼Œé˜²æ­¢æ•…éšœåœ¨ç³»ç»Ÿä¸­æ‰©æ•£ã€‚ä¾‹å¦‚ï¼Œä¸ºä¸åŒçš„æœåŠ¡æˆ–å®¢æˆ·ç«¯åˆ†é…ç‹¬ç«‹çš„èµ„æºæ± ã€‚

```rust
use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant};
use tokio::sync::{mpsc, Semaphore};
use tokio::time::sleep;
use futures::future::join_all;

#[derive(Debug, Clone)]
struct BulkheadConfig {
    max_concurrent_calls: usize,
    max_queue_size: usize,
    call_timeout: Duration,
}

// èˆ±å£å®ç° - é™åˆ¶å¹¶å‘è°ƒç”¨æ•°é‡å’Œæ’é˜Ÿè¯·æ±‚æ•°
struct Bulkhead {
    name: String,
    semaphore: Arc<Semaphore>,
    queue_channel: mpsc::Sender<()>,
    call_timeout: Duration,
}

impl Bulkhead {
    fn new(name: &str, config: BulkheadConfig) -> Self {
        let (queue_tx, mut queue_rx) = mpsc::channel(config.max_queue_size);
        
        // å‡†å¤‡ä¿¡å·é‡ç”¨äºæ§åˆ¶å¹¶å‘
        let semaphore = Arc::new(Semaphore::new(config.max_concurrent_calls));
        
        Self {
            name: name.to_string(),
            semaphore,
            queue_channel: queue_tx,
            call_timeout: config.call_timeout,
        }
    }
    
    async fn execute<F, Fut, T>(&self, f: F) -> Result<T, String>
    where
        F: FnOnce() -> Fut,
        Fut: std::future::Future<Output = T>,
    {
        // å°è¯•è¿›å…¥é˜Ÿåˆ—
        match self.queue_channel.try_send(()) {
            Ok(_) => {},
            Err(_) => return Err(format!("é˜Ÿåˆ—å·²æ»¡ - {}", self.name)),
        };
        
        // è·å–ä¿¡å·é‡è®¸å¯
        let permit = match tokio::time::timeout(
            self.call_timeout,
            self.semaphore.acquire(),
        ).await {
            Ok(permit_result) => match permit_result {
                Ok(permit) => permit,
                Err(_) => return Err(format!("è·å–è®¸å¯å¤±è´¥ - {}", self.name)),
            },
            Err(_) => return Err(format!("ç­‰å¾…è®¸å¯è¶…æ—¶ - {}", self.name)),
        };
        
        // æ‰§è¡Œå‡½æ•°ï¼Œç¡®ä¿é‡Šæ”¾èµ„æº
        let start = Instant::now();
        let result = f().await;
        let elapsed = start.elapsed();
        
        // é‡Šæ”¾è®¸å¯å’Œé˜Ÿåˆ—ä½ç½®
        drop(permit);
        
        Ok(result)
    }
}

// ä½¿ç”¨èˆ±å£éš”ç¦»ä¸åŒæœåŠ¡çš„èµ„æº
struct BulkheadRegistry {
    bulkheads: Mutex<HashMap<String, Arc<Bulkhead>>>,
    default_config: BulkheadConfig,
}

impl BulkheadRegistry {
    fn new(default_config: BulkheadConfig) -> Self {
        Self {
            bulkheads: Mutex::new(HashMap::new()),
            default_config,
        }
    }
    
    fn get_or_create(&self, name: &str) -> Arc<Bulkhead> {
        let mut bulkheads = self.bulkheads.lock().unwrap();
        
        if let Some(bulkhead) = bulkheads.get(name) {
            return bulkhead.clone();
        }
        
        let bulkhead = Arc::new(Bulkhead::new(name, self.default_config.clone()));
        bulkheads.insert(name.to_string(), bulkhead.clone());
        bulkhead
    }
    
    fn get_or_create_with_config(&self, name: &str, config: BulkheadConfig) -> Arc<Bulkhead> {
        let mut bulkheads = self.bulkheads.lock().unwrap();
        
        if let Some(bulkhead) = bulkheads.get(name) {
            return bulkhead.clone();
        }
        
        let bulkhead = Arc::new(Bulkhead::new(name, config));
        bulkheads.insert(name.to_string(), bulkhead.clone());
        bulkhead
    }
}

async fn slow_service_call(service_name: &str, duration_ms: u64) -> String {
    sleep(Duration::from_millis(duration_ms)).await;
    format!("æ¥è‡ª {} çš„å“åº”", service_name)
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºèˆ±å£æ³¨å†Œè¡¨
    let registry = Arc::new(BulkheadRegistry::new(BulkheadConfig {
        max_concurrent_calls: 10,
        max_queue_size: 20,
        call_timeout: Duration::from_secs(2),
    }));
    
    // ä¸ºæ•°æ®åº“æœåŠ¡åˆ›å»ºé™åˆ¶æ›´ä¸¥æ ¼çš„èˆ±å£
    let db_config = BulkheadConfig {
        max_concurrent_calls: 3,
        max_queue_size: 5,
        call_timeout: Duration::from_secs(1),
    };
    
    registry.get_or_create_with_config("database", db_config);
    
    // æ¨¡æ‹Ÿå¯¹ä¸åŒæœåŠ¡çš„å¤§é‡å¹¶å‘è°ƒç”¨
    let mut api_handles = Vec::new();
    let mut db_handles = Vec::new();
    
    // APIè°ƒç”¨ - ä½å»¶è¿Ÿ
    for i in 0..15 {
        let registry = registry.clone();
        api_handles.push(tokio::spawn(async move {
            let bulkhead = registry.get_or_create("api");
            let result = bulkhead.execute(|| async move {
                slow_service_call("api", 200).await
            }).await;
            
            println!("APIè°ƒç”¨ #{}: {:?}", i, result);
            result
        }));
    }
    
    // æ•°æ®åº“è°ƒç”¨ - é«˜å»¶è¿Ÿ
    for i in 0..15 {
        let registry = registry.clone();
        db_handles.push(tokio::spawn(async move {
            let bulkhead = registry.get_or_create("database");
            let result = bulkhead.execute(|| async move {
                slow_service_call("database", 500).await
            }).await;
            
            println!("æ•°æ®åº“è°ƒç”¨ #{}: {:?}", i, result);
            result
        }));
    }
    
    // ç­‰å¾…æ‰€æœ‰è°ƒç”¨å®Œæˆ
    let api_results = join_all(api_handles).await;
    let db_results = join_all(db_handles).await;
    
    // è®¡ç®—æˆåŠŸç‡
    let api_success = api_results.iter()
        .filter(|r| match r {
            Ok(Ok(_)) => true,
            _ => false,
        })
        .count();
    
    let db_success = db_results.iter()
        .filter(|r| match r {
            Ok(Ok(_)) => true,
            _ => false,
        })
        .count();
    
    println!("APIè°ƒç”¨æˆåŠŸç‡: {}/{}", api_success, api_handles.len());
    println!("æ•°æ®åº“è°ƒç”¨æˆåŠŸç‡: {}/{}", db_success, db_handles.len());
}
```

### 4.3 è¶…æ—¶ä¸é‡è¯•

è¶…æ—¶ä¸é‡è¯•æ¨¡å¼é€šè¿‡é™åˆ¶ç­‰å¾…æ—¶é—´å’Œåœ¨å¤±è´¥æ—¶é‡æ–°å°è¯•æ“ä½œï¼Œæé«˜ç³»ç»Ÿçš„å¼¹æ€§ã€‚

```rust
use std::future::Future;
use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::Arc;
use std::time::Duration;
use tokio::time::timeout;
use rand::prelude::*;
use backoff::{backoff::Backoff, ExponentialBackoff};

// é‡è¯•ç­–ç•¥ç‰¹å¾
trait RetryStrategy {
    fn should_retry(&mut self, attempts: usize, error: &str) -> bool;
    fn next_backoff(&mut self, attempts: usize) -> Option<Duration>;
}

// æŒ‡æ•°é€€é¿ç­–ç•¥
struct ExponentialRetryStrategy {
    max_attempts: usize,
    backoff: ExponentialBackoff,
}

impl ExponentialRetryStrategy {
    fn new(max_attempts: usize, initial_interval: Duration, max_interval: Duration) -> Self {
        let mut backoff = ExponentialBackoff::default();
        backoff.initial_interval = initial_interval;
        backoff.max_interval = max_interval;
        backoff.multiplier = 2.0;
        backoff.randomization_factor = 0.2;
        
        Self {
            max_attempts,
            backoff,
        }
    }
}

impl RetryStrategy for ExponentialRetryStrategy {
    fn should_retry(&mut self, attempts: usize, _error: &str) -> bool {
        attempts < self.max_attempts
    }
    
    fn next_backoff(&mut self, _attempts: usize) -> Option<Duration> {
        self.backoff.next_backoff()
    }
}

// å›ºå®šé—´éš”é‡è¯•ç­–ç•¥
struct FixedRetryStrategy {
    max_attempts: usize,
    interval: Duration,
}

impl FixedRetryStrategy {
    fn new(max_attempts: usize, interval: Duration) -> Self {
        Self {
            max_attempts,
            interval,
        }
    }
}

impl RetryStrategy for FixedRetryStrategy {
    fn should_retry(&mut self, attempts: usize, _error: &str) -> bool {
        attempts < self.max_attempts
    }
    
    fn next_backoff(&mut self, _attempts: usize) -> Option<Duration> {
        Some(self.interval)
    }
}

// é‡è¯•æ‰§è¡Œå™¨
struct RetryExecutor<S: RetryStrategy> {
    strategy: S,
    timeout_duration: Duration,
}

impl<S: RetryStrategy> RetryExecutor<S> {
    fn new(strategy: S, timeout_duration: Duration) -> Self {
        Self {
            strategy,
            timeout_duration,
        }
    }
    
    async fn execute<F, Fut, T, E>(&mut self, operation: F) -> Result<T, String>
    where
        F: Fn() -> Fut,
        Fut: Future<Output = Result<T, E>>,
        E: std::fmt::Display,
    {
        let mut attempts = 0;
        
        loop {
            attempts += 1;
            
            // ä½¿ç”¨è¶…æ—¶åŒ…è£…æ“ä½œ
            let result = match timeout(self.timeout_duration, operation()).await {
                Ok(inner_result) => match inner_result {
                    Ok(value) => return Ok(value),
                    Err(err) => Err(err.to_string()),
                },
                Err(_) => Err(format!("æ“ä½œè¶…æ—¶ (å°è¯• #{})", attempts)),
            };
            
            // å¤„ç†é”™è¯¯å’Œé‡è¯•é€»è¾‘
            if let Err(err) = result {
                if !self.strategy.should_retry(attempts, &err) {
                    return Err(format!("æœ€ç»ˆå¤±è´¥ ({}æ¬¡å°è¯•): {}", attempts, err));
                }
                
                if let Some(delay) = self.strategy.next_backoff(attempts) {
                    println!("å°è¯• #{} å¤±è´¥: {}. ç­‰å¾… {:?} åé‡è¯•...", attempts, err, delay);
                    tokio::time::sleep(delay).await;
                } else {
                    return Err(format!("é‡è¯•ç­–ç•¥å†³å®šåœæ­¢é‡è¯•: {}", err));
                }
            }
        }
    }
}

// æ¨¡æ‹Ÿä¸å¯é çš„è¿œç¨‹æœåŠ¡
struct UnreliableService {
    failure_rate: f64,
    delay_ms: u64,
    call_count: AtomicUsize,
}

impl UnreliableService {
    fn new(failure_rate: f64, delay_ms: u64) -> Self {
        Self {
            failure_rate: failure_rate,
            delay_ms,
            call_count: AtomicUsize::new(0),
        }
    }
    
    async fn call(&self) -> Result<String, String> {
        let count = self.call_count.fetch_add(1, Ordering::SeqCst);
        
        // æ¨¡æ‹Ÿå»¶è¿Ÿ
        tokio::time::sleep(Duration::from_millis(self.delay_ms)).await;
        
        // æ¨¡æ‹Ÿéšæœºå¤±è´¥
        let mut rng = rand::thread_rng();
        if rng.gen::<f64>() < self.failure_rate {
            Err(format!("æœåŠ¡è°ƒç”¨ #{} å¤±è´¥", count))
        } else {
            Ok(format!("æ¥è‡ªè°ƒç”¨ #{} çš„æˆåŠŸå“åº”", count))
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºæœåŠ¡å®ä¾‹
    let service = Arc::new(UnreliableService::new(0.7, 200)); // 70%å¤±è´¥ç‡ï¼Œ200mså»¶è¿Ÿ
    
    println!("ä½¿ç”¨å›ºå®šé—´éš”é‡è¯•ç­–ç•¥:");
    {
        let service_clone = service.clone();
        let strategy = FixedRetryStrategy::new(3, Duration::from_millis(500));
        let mut executor = RetryExecutor::new(strategy, Duration::from_millis(300));
        
        let result = executor.execute(|| async move {
            service_clone.call().await
        }).await;
        
        println!("ç»“æœ: {:?}", result);
    }
    
    println!("\nä½¿ç”¨æŒ‡æ•°é€€é¿é‡è¯•ç­–ç•¥:");
    {
        let service_clone = service.clone();
        let strategy = ExponentialRetryStrategy::new(
            5,
            Duration::from_millis(100),
            Duration::from_millis(1000)
        );
        let mut executor = RetryExecutor::new(strategy, Duration::from_millis(300));
        
        let result = executor.execute(|| async move {
            service_clone.call().await
        }).await;
        
        println!("ç»“æœ: {:?}", result);
    }
    
    println!("\nä½¿ç”¨è¶…çŸ­è¶…æ—¶è§¦å‘è¶…æ—¶é”™è¯¯:");
    {
        let service_clone = service.clone();
        let strategy = ExponentialRetryStrategy::new(
            3,
            Duration::from_millis(100),
            Duration::from_millis(1000)
        );
        // è¶…æ—¶è®¾ç½®ä¸º50msï¼Œå°äºæœåŠ¡å»¶è¿Ÿ
        let mut executor = RetryExecutor::new(strategy, Duration::from_millis(50));
        
        let result = executor.execute(|| async move {
            service_clone.call().await
        }).await;
        
        println!("ç»“æœ: {:?}", result);
    }
}
```

### 4.4 èƒŒå‹

èƒŒå‹æœºåˆ¶åœ¨ä¸‹æ¸¸ç»„ä»¶å¤„ç†ä¸è¿‡æ¥æ—¶ï¼Œèƒ½å¤Ÿå‘ä¸Šæ¸¸ç»„ä»¶ä¼ é€’ä¿¡å·ï¼Œå‡ç¼“æ•°æ®å‘é€é€Ÿç‡ã€‚

```rust
use std::sync::Arc;
use tokio::sync::{mpsc, Semaphore};
use tokio::time::{sleep, Duration};
use rand::{thread_rng, Rng};
use futures::stream::{self, StreamExt};

// æµå¤„ç†ç±»å‹ï¼Œå…·æœ‰èƒŒå‹èƒ½åŠ›
struct BackpressuredProcessor<T> {
    name: String,
    capacity: usize,
    semaphore: Arc<Semaphore>,
    input_tx: Option<mpsc::Sender<T>>,
    output_rx: Option<mpsc::Receiver<T>>,
    processing_time_ms: u64,
}

impl<T: Send + 'static> BackpressuredProcessor<T> {
    fn new(name: &str, capacity: usize, processing_time_ms: u64) -> Self {
        let semaphore = Arc::new(Semaphore::new(capacity));
        
        Self {
            name: name.to_string(),
            capacity,
            semaphore,
            input_tx: None,
            output_rx: None,
            processing_time_ms,
        }
    }
    
    // åˆå§‹åŒ–å¤„ç†å™¨çš„é€šé“
    async fn init(&mut self) {
        let (input_tx, mut input_rx) = mpsc::channel(self.capacity);
        let (output_tx, output_rx) = mpsc::channel(self.capacity);
        
        self.input_tx = Some(input_tx);
        self.output_rx = Some(output_rx);
        
        let semaphore = self.semaphore.clone();
        let name = self.name.clone();
        let processing_time = self.processing_time_ms;
        
        // å¯åŠ¨å¤„ç†å™¨ä»»åŠ¡
        tokio::spawn(async move {
            while let Some(item) = input_rx.recv().await {
                // è·å–ä¿¡å·é‡è®¸å¯ï¼Œå®ç°èƒŒå‹
                let permit = semaphore.acquire().await.unwrap();
                
                // å¤„ç†é¡¹ç›®
                println!("[{}] æ­£åœ¨å¤„ç†é¡¹ç›®...", name);
                sleep(Duration::from_millis(processing_time)).await;
                
                // å‘é€åˆ°è¾“å‡º
                let _ = output_tx.send(item).await;
                
                // é‡Šæ”¾è®¸å¯
                drop(permit);
            }
        });
    }
    
    // è·å–è¾“å…¥å‘é€å™¨
    fn get_sender(&self) -> Option<mpsc::Sender<T>> {
        self.input_tx.clone()
    }
    
    // è·å–è¾“å‡ºæ¥æ”¶å™¨
    fn take_receiver(&mut self) -> Option<mpsc::Receiver<T>> {
        self.output_rx.take()
    }
}

// èƒŒå‹ç®¡é“ï¼Œè¿æ¥å¤šä¸ªå¤„ç†å™¨
struct ProcessingPipeline<T> {
    stages: Vec<BackpressuredProcessor<T>>,
    initialized: bool,
}

impl<T: Send + Clone + std::fmt::Debug + 'static> ProcessingPipeline<T> {
    fn new() -> Self {
        Self {
            stages: Vec::new(),
            initialized: false,
        }
    }
    
    // æ·»åŠ å¤„ç†é˜¶æ®µ
    fn add_stage(&mut self, processor: BackpressuredProcessor<T>) {
        if self.initialized {
            panic!("ç®¡é“å·²åˆå§‹åŒ–ï¼Œä¸èƒ½æ·»åŠ æ›´å¤šé˜¶æ®µ");
        }
        self.stages.push(processor);
    }
    
    // åˆå§‹åŒ–ç®¡é“ï¼Œè¿æ¥æ‰€æœ‰é˜¶æ®µ
    async fn init(&mut self) {
        if self.initialized {
            return;
        }
        
        // åˆå§‹åŒ–æ¯ä¸ªé˜¶æ®µ
        for stage in &mut self.stages {
            stage.init().await;
        }
        
        self.initialized = true;
    }
    
    // è·å–è¾“å…¥å‘é€å™¨
    fn get_input_sender(&self) -> Option<mpsc::Sender<T>> {
        if !self.initialized || self.stages.is_empty() {
            return None;
        }
        
        self.stages[0].get_sender()
    }
    
    // è·å–æœ€ç»ˆè¾“å‡ºæ¥æ”¶å™¨
    fn take_output_receiver(&mut self) -> Option<mpsc::Receiver<T>> {
        if !self.initialized || self.stages.is_empty() {
            return None;
        }
        
        let last_index = self.stages.len() - 1;
        self.stages[last_index].take_receiver()
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºä¸€ä¸ªä¸‰é˜¶æ®µçš„å¤„ç†ç®¡é“
    let mut pipeline = ProcessingPipeline::<u32>::new();
    
    // æ·»åŠ å¤„ç†é˜¶æ®µï¼Œæ¨¡æ‹Ÿä¸åŒé€Ÿç‡çš„å¤„ç†å™¨
    pipeline.add_stage(BackpressuredProcessor::new("é˜¶æ®µ1", 10, 50));  // å¿«é€Ÿ
    pipeline.add_stage(BackpressuredProcessor::new("é˜¶æ®µ2", 5, 200));  // è¾ƒæ…¢
    pipeline.add_stage(BackpressuredProcessor::new("é˜¶æ®µ3", 3, 100));  // ä¸­ç­‰
    
    // åˆå§‹åŒ–ç®¡é“
    pipeline.init().await;
    
    // è·å–è¾“å…¥å‘é€å™¨å’Œè¾“å‡ºæ¥æ”¶å™¨
    let input_sender = pipeline.get_input_sender().unwrap();
    let mut output_receiver = pipeline.take_output_receiver().unwrap();
    
    // å¯åŠ¨æ¶ˆè´¹è€…
    tokio::spawn(async move {
        while let Some(item) = output_receiver.recv().await {
            println!("æœ€ç»ˆè¾“å‡º: {:?}", item);
            sleep(Duration::from_millis(300)).await;  // æ¨¡æ‹Ÿæ¶ˆè´¹è€…å¤„ç†æ—¶é—´
        }
    });
    
    // ç”Ÿæˆæ•°æ®ï¼Œè§‚å¯ŸèƒŒå‹æ•ˆæœ
    let mut rng = thread_rng();
    
    for i in 0..50 {
        // å°è¯•å‘é€æ•°æ®
        match input_sender.try_send(i) {
            Ok(_) => println!("å‘é€é¡¹ç›® {} æˆåŠŸ", i),
            Err(e) => println!("å‘é€é¡¹ç›® {} å¤±è´¥: {:?}", i, e),
        }
        
        // éšæœºé—´éš”ç”Ÿæˆæ•°æ®
        let delay = rng.gen_range(10..100);
        sleep(Duration::from_millis(delay)).await;
    }
    
    // ç­‰å¾…å¤„ç†å®Œæˆ
    sleep(Duration::from_secs(5)).await;
}
```

## 5 äº‹åŠ¡æ¨¡å¼

### 5.1 ä¸¤é˜¶æ®µæäº¤

ä¸¤é˜¶æ®µæäº¤åè®®æ˜¯åˆ†å¸ƒå¼äº‹åŠ¡çš„åŸºæœ¬å®ç°ï¼Œåˆ†ä¸ºå‡†å¤‡é˜¶æ®µå’Œæäº¤é˜¶æ®µã€‚

```rust
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::{mpsc, Mutex, RwLock};
use tokio::time::timeout;
use std::time::Duration;
use uuid::Uuid;
use serde::{Serialize, Deserialize};

// äº‹åŠ¡çŠ¶æ€
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
enum TransactionState {
    Pending,
    Prepared,
    Committed,
    Aborted,
}

// äº‹åŠ¡ç®¡ç†å™¨æ¶ˆæ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
enum TwoPhaseMessage {
    // ç¬¬ä¸€é˜¶æ®µï¼šå‡†å¤‡
    Prepare { tx_id: String },
    PrepareResponse { tx_id: String, prepared: bool },
    
    // ç¬¬äºŒé˜¶æ®µï¼šæäº¤æˆ–ä¸­æ­¢
    Commit { tx_id: String },
    Abort { tx_id: String },
    
    // å®Œæˆç¡®è®¤
    Ack { tx_id: String, success: bool },
}

// å‚ä¸è€…
struct Participant {
    id: String,
    data: Arc<RwLock<HashMap<String, String>>>,
    pending_changes: Arc<RwLock<HashMap<String, HashMap<String, String>>>>,
    tx_states: Arc<RwLock<HashMap<String, TransactionState>>>,
}

impl Participant {
    fn new(id: &str) -> Self {
        Self {
            id: id.to_string(),
            data: Arc::new(RwLock::new(HashMap::new())),
            pending_changes: Arc::new(RwLock::new(HashMap::new())),
            tx_states: Arc::new(RwLock::new(HashMap::new())),
        }
    }
    
    // å¯åŠ¨å‚ä¸è€…å¹¶è¿”å›é€šä¿¡é€šé“
    async fn start(&self) -> mpsc::Sender<TwoPhaseMessage> {
        let (tx, mut rx) = mpsc::channel(100);
        
        let id = self.id.clone();
        let data = self.data.clone();
        let pending_changes = self.pending_changes.clone();
        let tx_states = self.tx_states.clone();
        
        tokio::spawn(async move {
            while let Some(message) = rx.recv().await {
                match message {
                    TwoPhaseMessage::Prepare { tx_id } => {
                        let can_prepare = {
...(about 25 lines omitted)...
                }
            }
        });
        
        tx
    }
    
    // åœ¨äº‹åŠ¡ä¸­è®¾ç½®å€¼ï¼ˆé˜¶æ®µ1ï¼‰
    async fn set_value(&self, tx_id: &str, key: &str, value: &str) -> Result<(), String> {
        let mut pending = self.pending_changes.write().await;
        
        let tx_changes = pending.entry(tx_id.to_string())
            .or_insert_with(HashMap::new);
        
        tx_changes.insert(key.to_string(), value.to_string());
        
        Ok(())
    }
    
    // å¤„ç†å‡†å¤‡è¯·æ±‚
    async fn handle_prepare(&self, tx_id: &str) -> bool {
        // æ£€æŸ¥æ˜¯å¦æœ‰èµ„æºå†²çª
        // åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™å¯èƒ½æ¶‰åŠé”å®šèµ„æºå’Œæ›´å¤æ‚çš„éªŒè¯
        
        // æ›´æ–°äº‹åŠ¡çŠ¶æ€
        let mut tx_states = self.tx_states.write().await;
        tx_states.insert(tx_id.to_string(), TransactionState::Prepared);
        
        true
    }
    
    // å¤„ç†æäº¤è¯·æ±‚
    async fn handle_commit(&self, tx_id: &str) -> bool {
        // æ£€æŸ¥äº‹åŠ¡çŠ¶æ€
        let state = {
            let tx_states = self.tx_states.read().await;
            tx_states.get(tx_id).cloned().unwrap_or(TransactionState::Pending)
        };
        
        if state != TransactionState::Prepared {
            return false;
        }
        
        // åº”ç”¨æŒ‚èµ·çš„æ›´æ”¹
        let changes = {
            let mut pending = self.pending_changes.write().await;
            pending.remove(tx_id).unwrap_or_default()
        };
        
        let mut data = self.data.write().await;
        for (key, value) in changes {
            data.insert(key, value);
        }
        
        // æ›´æ–°äº‹åŠ¡çŠ¶æ€
        let mut tx_states = self.tx_states.write().await;
        tx_states.insert(tx_id.to_string(), TransactionState::Committed);
        
        true
    }
    
    // å¤„ç†ä¸­æ­¢è¯·æ±‚
    async fn handle_abort(&self, tx_id: &str) -> bool {
        // æ¸…é™¤æŒ‚èµ·çš„æ›´æ”¹
        let mut pending = self.pending_changes.write().await;
        pending.remove(tx_id);
        
        // æ›´æ–°äº‹åŠ¡çŠ¶æ€
        let mut tx_states = self.tx_states.write().await;
        tx_states.insert(tx_id.to_string(), TransactionState::Aborted);
        
        true
    }
}
```

```text
<think>
I'll continue the implementation of the Two-Phase Commit pattern,
and then move on to the other remaining patterns in the list.

The next part of the code should include:
1. Finishing the Transaction Coordinator for the Two-Phase Commit pattern
2. An example showing the Two-Phase Commit in action
3. Then move on to implement the Saga pattern

After that, I'll continue with the remaining patterns from the list such as service discovery patterns, load balancing patterns, etc.
</think>
```

```rust
// åè°ƒè€…
struct TransactionCoordinator {
    participants: HashMap<String, mpsc::Sender<TwoPhaseMessage>>,
    active_transactions: Arc<Mutex<HashMap<String, TransactionState>>>,
    timeout_duration: Duration,
}

impl TransactionCoordinator {
    fn new(timeout_duration: Duration) -> Self {
        Self {
            participants: HashMap::new(),
            active_transactions: Arc::new(Mutex::new(HashMap::new())),
            timeout_duration,
        }
    }
    
    // æ·»åŠ å‚ä¸è€…
    fn add_participant(&mut self, id: &str, channel: mpsc::Sender<TwoPhaseMessage>) {
        self.participants.insert(id.to_string(), channel);
    }
    
    // å¼€å§‹æ–°äº‹åŠ¡
    async fn begin_transaction(&self) -> String {
        let tx_id = Uuid::new_v4().to_string();
        
        let mut transactions = self.active_transactions.lock().await;
        transactions.insert(tx_id.clone(), TransactionState::Pending);
        
        tx_id
    }
    
    // æäº¤äº‹åŠ¡ (ä¸¤é˜¶æ®µ)
    async fn commit(&self, tx_id: &str) -> Result<(), String> {
        // ç¬¬ä¸€é˜¶æ®µ: å‡†å¤‡
        println!("å¼€å§‹ç¬¬ä¸€é˜¶æ®µ: å‡†å¤‡");
        let prepare_results = self.prepare_phase(tx_id).await?;
        
        // æ£€æŸ¥æ‰€æœ‰å‚ä¸è€…æ˜¯å¦å‡†å¤‡å¥½
        let all_prepared = prepare_results.iter().all(|(_, prepared)| *prepared);
        
        if all_prepared {
            // ç¬¬äºŒé˜¶æ®µ: æäº¤
            println!("æ‰€æœ‰å‚ä¸è€…å·²å‡†å¤‡å¥½ï¼Œå¼€å§‹ç¬¬äºŒé˜¶æ®µ: æäº¤");
            self.commit_phase(tx_id).await?;
            
            // æ›´æ–°äº‹åŠ¡çŠ¶æ€
            let mut transactions = self.active_transactions.lock().await;
            transactions.insert(tx_id.to_string(), TransactionState::Committed);
            
            Ok(())
        } else {
            // æœ‰å‚ä¸è€…æœªå‡†å¤‡å¥½ï¼Œä¸­æ­¢äº‹åŠ¡
            println!("éƒ¨åˆ†å‚ä¸è€…æœªå‡†å¤‡å¥½ï¼Œä¸­æ­¢äº‹åŠ¡");
            self.abort_phase(tx_id).await?;
            
            // æ›´æ–°äº‹åŠ¡çŠ¶æ€
            let mut transactions = self.active_transactions.lock().await;
            transactions.insert(tx_id.to_string(), TransactionState::Aborted);
            
            Err("æœ‰å‚ä¸è€…æœªå‡†å¤‡å¥½ï¼Œäº‹åŠ¡å·²ä¸­æ­¢".to_string())
        }
    }
    
    // å‡†å¤‡é˜¶æ®µ (ç¬¬ä¸€é˜¶æ®µ)
    async fn prepare_phase(&self, tx_id: &str) -> Result<HashMap<String, bool>, String> {
        let mut prepare_responses = HashMap::new();
        let (response_tx, mut response_rx) = mpsc::channel(self.participants.len());
        
        // å‘æ‰€æœ‰å‚ä¸è€…å‘é€å‡†å¤‡æ¶ˆæ¯
        for (participant_id, participant_tx) in &self.participants {
            let message = TwoPhaseMessage::Prepare {
                tx_id: tx_id.to_string(),
            };
            
            let participant_id = participant_id.clone();
            let response_tx = response_tx.clone();
            let participant_tx = participant_tx.clone();
            
            tokio::spawn(async move {
                if let Err(e) = participant_tx.send(message).await {
                    println!("å‘å‚ä¸è€… {} å‘é€å‡†å¤‡æ¶ˆæ¯å¤±è´¥: {}", participant_id, e);
                    let _ = response_tx.send((participant_id, false)).await;
                    return;
                }
                
                // ç­‰å¾…å“åº”æˆ–è¶…æ—¶
                // åœ¨å®é™…ç³»ç»Ÿä¸­ï¼Œæˆ‘ä»¬ä¼šæœ‰ä¸“é—¨çš„å“åº”é€šé“
                let _ = response_tx.send((participant_id, true)).await;
            });
        }
        
        // ç­‰å¾…æ‰€æœ‰å“åº”
        for _ in 0..self.participants.len() {
            match timeout(self.timeout_duration, response_rx.recv()).await {
                Ok(Some((participant_id, prepared))) => {
                    prepare_responses.insert(participant_id, prepared);
                },
                _ => {
                    // è¶…æ—¶æˆ–é€šé“å…³é—­
                    return Err("å‡†å¤‡é˜¶æ®µè¶…æ—¶æˆ–é€šé“å…³é—­".to_string());
                }
            }
        }
        
        Ok(prepare_responses)
    }
    
    // æäº¤é˜¶æ®µ (ç¬¬äºŒé˜¶æ®µ)
    async fn commit_phase(&self, tx_id: &str) -> Result<(), String> {
        let mut commit_futures = Vec::new();
        
        // å‘æ‰€æœ‰å‚ä¸è€…å‘é€æäº¤æ¶ˆæ¯
        for (participant_id, participant_tx) in &self.participants {
            let message = TwoPhaseMessage::Commit {
                tx_id: tx_id.to_string(),
            };
            
            let participant_id = participant_id.clone();
            let participant_tx = participant_tx.clone();
            
            let commit_future = async move {
                match participant_tx.send(message).await {
                    Ok(_) => Ok(participant_id),
                    Err(e) => Err(format!("å‘å‚ä¸è€… {} å‘é€æäº¤æ¶ˆæ¯å¤±è´¥: {}", participant_id, e)),
                }
            };
            
            commit_futures.push(commit_future);
        }
        
        // ç­‰å¾…æ‰€æœ‰æäº¤å®Œæˆ
        for result in futures::future::join_all(commit_futures).await {
            if let Err(e) = result {
                println!("è­¦å‘Š: {}", e);
                // åœ¨å®é™…ç³»ç»Ÿä¸­ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦é‡è¯•æˆ–è¿›è¡Œè¡¥å¿å¤„ç†
            }
        }
        
        Ok(())
    }
    
    // ä¸­æ­¢é˜¶æ®µ
    async fn abort_phase(&self, tx_id: &str) -> Result<(), String> {
        let mut abort_futures = Vec::new();
        
        // å‘æ‰€æœ‰å‚ä¸è€…å‘é€ä¸­æ­¢æ¶ˆæ¯
        for (participant_id, participant_tx) in &self.participants {
            let message = TwoPhaseMessage::Abort {
                tx_id: tx_id.to_string(),
            };
            
            let participant_id = participant_id.clone();
            let participant_tx = participant_tx.clone();
            
            let abort_future = async move {
                match participant_tx.send(message).await {
                    Ok(_) => Ok(participant_id),
                    Err(e) => Err(format!("å‘å‚ä¸è€… {} å‘é€ä¸­æ­¢æ¶ˆæ¯å¤±è´¥: {}", participant_id, e)),
                }
            };
            
            abort_futures.push(abort_future);
        }
        
        // ç­‰å¾…æ‰€æœ‰ä¸­æ­¢å®Œæˆ
        for result in futures::future::join_all(abort_futures).await {
            if let Err(e) = result {
                println!("è­¦å‘Š: {}", e);
            }
        }
        
        Ok(())
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºå‚ä¸è€…
    let participant1 = Arc::new(Participant::new("node1"));
    let participant2 = Arc::new(Participant::new("node2"));
    let participant3 = Arc::new(Participant::new("node3"));
    
    // å¯åŠ¨å‚ä¸è€…
    let channel1 = participant1.start().await;
    let channel2 = participant2.start().await;
    let channel3 = participant3.start().await;
    
    // åˆ›å»ºåè°ƒè€…
    let mut coordinator = TransactionCoordinator::new(Duration::from_secs(5));
    coordinator.add_participant("node1", channel1);
    coordinator.add_participant("node2", channel2);
    coordinator.add_participant("node3", channel3);
    
    // å¼€å§‹äº‹åŠ¡
    let tx_id = coordinator.begin_transaction().await;
    println!("å¼€å§‹äº‹åŠ¡: {}", tx_id);
    
    // åœ¨å„å‚ä¸è€…ä¸Šè®¾ç½®å€¼
    participant1.set_value(&tx_id, "key1", "value1").await.unwrap();
    participant2.set_value(&tx_id, "key2", "value2").await.unwrap();
    participant3.set_value(&tx_id, "key3", "value3").await.unwrap();
    
    // æäº¤äº‹åŠ¡
    match coordinator.commit(&tx_id).await {
        Ok(_) => println!("äº‹åŠ¡ {} æˆåŠŸæäº¤", tx_id),
        Err(e) => println!("äº‹åŠ¡ {} æäº¤å¤±è´¥: {}", tx_id, e),
    }
    
    // æ£€æŸ¥æ¯ä¸ªå‚ä¸è€…çš„æ•°æ®
    tokio::time::sleep(Duration::from_millis(500)).await;
    
    let data1 = participant1.data.read().await;
    let data2 = participant2.data.read().await;
    let data3 = participant3.data.read().await;
    
    println!("å‚ä¸è€…1æ•°æ®: {:?}", data1);
    println!("å‚ä¸è€…2æ•°æ®: {:?}", data2);
    println!("å‚ä¸è€…3æ•°æ®: {:?}", data3);
    
    // æ¨¡æ‹Ÿå¤±è´¥åœºæ™¯
    let tx_id_fail = coordinator.begin_transaction().await;
    println!("\nå¼€å§‹å¯èƒ½å¤±è´¥çš„äº‹åŠ¡: {}", tx_id_fail);
    
    participant1.set_value(&tx_id_fail, "key4", "value4").await.unwrap();
    participant2.set_value(&tx_id_fail, "key5", "value5").await.unwrap();
    
    // ç¬¬ä¸‰ä¸ªå‚ä¸è€…æ— æ³•å‡†å¤‡ (æ¨¡æ‹Ÿ)
    {
        let mut tx_states = participant3.tx_states.write().await;
        tx_states.insert(tx_id_fail.clone(), TransactionState::Aborted);
    }
    
    // å°è¯•æäº¤äº‹åŠ¡
    match coordinator.commit(&tx_id_fail).await {
        Ok(_) => println!("äº‹åŠ¡ {} æˆåŠŸæäº¤", tx_id_fail),
        Err(e) => println!("äº‹åŠ¡ {} æäº¤å¤±è´¥: {}", tx_id_fail, e),
    }
    
    // æ£€æŸ¥æ¯ä¸ªå‚ä¸è€…çš„æ•°æ® (åº”è¯¥æ²¡æœ‰å˜åŒ–)
    tokio::time::sleep(Duration::from_millis(500)).await;
    
    let data1 = participant1.data.read().await;
    let data2 = participant2.data.read().await;
    let data3 = participant3.data.read().await;
    
    println!("å‚ä¸è€…1æ•°æ®: {:?}", data1);
    println!("å‚ä¸è€…2æ•°æ®: {:?}", data2);
    println!("å‚ä¸è€…3æ•°æ®: {:?}", data3);
}
```

### 5.2 Sagaæ¨¡å¼

Sagaæ¨¡å¼æ˜¯ä¸€ç§é•¿äº‹åŠ¡çš„è§£å†³æ–¹æ¡ˆï¼Œå®ƒå°†ä¸€ä¸ªåˆ†å¸ƒå¼äº‹åŠ¡åˆ†è§£ä¸ºå¤šä¸ªæœ¬åœ°äº‹åŠ¡ï¼Œå¹¶å®šä¹‰å¯¹åº”çš„è¡¥å¿äº‹åŠ¡ã€‚

```rust
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::{mpsc, Mutex};
use serde::{Serialize, Deserialize};
use uuid::Uuid;

// Sagaæ­¥éª¤çŠ¶æ€
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
enum StepStatus {
    Pending,
    Succeeded,
    Failed,
    Compensated,
}

// SagaçŠ¶æ€
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
enum SagaStatus {
    Running,
    Completed,
    Compensating,
    Failed,
}

// Sagaæ­¥éª¤å®šä¹‰
#[derive(Clone)]
struct SagaStep<T> {
    name: String,
    execute: Arc<dyn Fn(T) -> T + Send + Sync>,
    compensate: Arc<dyn Fn(T) -> T + Send + Sync>,
}

// Sagaæ‰§è¡Œä¸Šä¸‹æ–‡
struct SagaContext<T> {
    saga_id: String,
    data: T,
    step_statuses: HashMap<String, StepStatus>,
    status: SagaStatus,
}

// Sagaåè°ƒå™¨
struct SagaCoordinator<T: Clone + Send + 'static> {
    steps: Vec<SagaStep<T>>,
    active_sagas: Arc<Mutex<HashMap<String, SagaContext<T>>>>,
}

impl<T: Clone + Send + 'static> SagaCoordinator<T> {
    fn new() -> Self {
        Self {
            steps: Vec::new(),
            active_sagas: Arc::new(Mutex::new(HashMap::new())),
        }
    }
    
    // æ·»åŠ Sagaæ­¥éª¤
    fn add_step<E, C>(&mut self, name: &str, execute: E, compensate: C)
    where
        E: Fn(T) -> T + Send + Sync + 'static,
        C: Fn(T) -> T + Send + Sync + 'static,
    {
        let step = SagaStep {
            name: name.to_string(),
            execute: Arc::new(execute),
            compensate: Arc::new(compensate),
        };
        
        self.steps.push(step);
    }
    
    // å¼€å§‹æ–°çš„Saga
    async fn start(&self, initial_data: T) -> String {
        let saga_id = Uuid::new_v4().to_string();
        
        let context = SagaContext {
            saga_id: saga_id.clone(),
            data: initial_data,
            step_statuses: HashMap::new(),
            status: SagaStatus::Running,
        };
        
        let mut active_sagas = self.active_sagas.lock().await;
        active_sagas.insert(saga_id.clone(), context);
        
        saga_id
    }
    
    // æ‰§è¡ŒSaga
    async fn execute(&self, saga_id: &str) -> Result<T, String> {
        // è·å–Sagaä¸Šä¸‹æ–‡
        let mut context = {
            let mut active_sagas = self.active_sagas.lock().await;
            
            active_sagas.get_mut(saga_id)
                .ok_or_else(|| format!("æ‰¾ä¸åˆ°Saga: {}", saga_id))?
                .clone()
        };
        
        // æ‰§è¡Œæ‰€æœ‰æ­¥éª¤
        for (i, step) in self.steps.iter().enumerate() {
            println!("æ‰§è¡Œæ­¥éª¤ {}: {}", i, step.name);
            
            // æ›´æ–°æ­¥éª¤çŠ¶æ€
            context.step_statuses.insert(step.name.clone(), StepStatus::Pending);
            
            // æ‰§è¡Œæ­¥éª¤
            let result = {
                let execute = step.execute.clone();
                let data = context.data.clone();
                
                // åœ¨å®é™…ç¯å¢ƒä¸­ï¼Œè¿™é‡Œå¯èƒ½æ˜¯å¯¹è¿œç¨‹æœåŠ¡çš„å¼‚æ­¥è°ƒç”¨
                execute(data)
            };
            
            // æ›´æ–°ä¸Šä¸‹æ–‡
            context.data = result.clone();
            
            // å¦‚æœæ­¥éª¤å¤±è´¥ (å–å†³äºé¢†åŸŸé€»è¾‘å¦‚ä½•åˆ¤æ–­å¤±è´¥)
            let step_failed = false; // è¿™é‡Œåº”è¯¥æœ‰åˆ¤æ–­é€»è¾‘
            
            if step_failed {
                context.step_statuses.insert(step.name.clone(), StepStatus::Failed);
                context.status = SagaStatus::Compensating;
                
                // æ‰§è¡Œè¡¥å¿
                let compensation_result = self.compensate(&mut context, i).await;
                
                // æ›´æ–°æ´»åŠ¨Saga
                {
                    let mut active_sagas = self.active_sagas.lock().await;
                    if let Some(ctx) = active_sagas.get_mut(saga_id) {
                        *ctx = context.clone();
                    }
                }
                
                return Err(format!("Sagaæ­¥éª¤ {} å¤±è´¥ï¼Œå·²æ‰§è¡Œè¡¥å¿", step.name));
            }
            
            // æ›´æ–°æ­¥éª¤çŠ¶æ€ä¸ºæˆåŠŸ
            context.step_statuses.insert(step.name.clone(), StepStatus::Succeeded);
        }
        
        // æ‰€æœ‰æ­¥éª¤æˆåŠŸå®Œæˆ
        context.status = SagaStatus::Completed;
        
        // æ›´æ–°æ´»åŠ¨Saga
        {
            let mut active_sagas = self.active_sagas.lock().await;
            if let Some(ctx) = active_sagas.get_mut(saga_id) {
                *ctx = context.clone();
            }
        }
        
        Ok(context.data)
    }
    
    // æ‰§è¡Œè¡¥å¿
    async fn compensate(&self, context: &mut SagaContext<T>, failed_step_index: usize) -> Result<(), String> {
        println!("å¼€å§‹è¡¥å¿...");
        
        // åå‘æ‰§è¡Œè¡¥å¿æ“ä½œ
        for i in (0..=failed_step_index).rev() {
            let step = &self.steps[i];
            let step_status = context.step_statuses.get(&step.name).copied().unwrap_or(StepStatus::Pending);
            
            // åªè¡¥å¿æˆåŠŸçš„æ­¥éª¤
            if step_status == StepStatus::Succeeded {
                println!("è¡¥å¿æ­¥éª¤ {}: {}", i, step.name);
                
                // æ‰§è¡Œè¡¥å¿æ“ä½œ
                let compensate = step.compensate.clone();
                context.data = compensate(context.data.clone());
                
                // æ›´æ–°æ­¥éª¤çŠ¶æ€
                context.step_statuses.insert(step.name.clone(), StepStatus::Compensated);
            }
        }
        
        // æ›´æ–°SagaçŠ¶æ€
        context.status = SagaStatus::Failed;
        
        Ok(())
    }
}

// ä½¿ç”¨ç¤ºä¾‹ - æ¨¡æ‹Ÿè®¢å•å¤„ç†
#[derive(Debug, Clone, Serialize, Deserialize)]
struct OrderData {
    order_id: String,
    customer_id: String,
    amount: f64,
    payment_completed: bool,
    inventory_reserved: bool,
    shipping_scheduled: bool,
}

#[tokio::main]
async fn main() {
    // åˆ›å»ºSagaåè°ƒå™¨
    let mut coordinator = SagaCoordinator::new();
    
    // æ·»åŠ Sagaæ­¥éª¤
    
    // 1. æ”¯ä»˜å¤„ç†
    coordinator.add_step(
        "payment_processing",
        |mut data: OrderData| {
            println!("å¤„ç†æ”¯ä»˜ {:.2} å…ƒ", data.amount);
            data.payment_completed = true;
            data
        },
        |mut data: OrderData| {
            println!("é€€æ¬¾ {:.2} å…ƒ", data.amount);
            data.payment_completed = false;
            data
        }
    );
    
    // 2. åº“å­˜é¢„ç•™
    coordinator.add_step(
        "inventory_reservation",
        |mut data: OrderData| {
            println!("ä¸ºè®¢å• {} é¢„ç•™åº“å­˜", data.order_id);
            data.inventory_reserved = true;
            data
        },
        |mut data: OrderData| {
            println!("é‡Šæ”¾è®¢å• {} çš„åº“å­˜é¢„ç•™", data.order_id);
            data.inventory_reserved = false;
            data
        }
    );
    
    // 3. å®‰æ’å‘è´§
    coordinator.add_step(
        "shipping_scheduling",
        |mut data: OrderData| {
            println!("ä¸ºè®¢å• {} å®‰æ’å‘è´§", data.order_id);
            data.shipping_scheduled = true;
            data
        },
        |mut data: OrderData| {
            println!("å–æ¶ˆè®¢å• {} çš„å‘è´§å®‰æ’", data.order_id);
            data.shipping_scheduled = false;
            data
        }
    );
    
    // åˆ›å»ºåˆå§‹è®¢å•æ•°æ®
    let initial_data = OrderData {
        order_id: Uuid::new_v4().to_string(),
        customer_id: "customer123".to_string(),
        amount: 99.99,
        payment_completed: false,
        inventory_reserved: false,
        shipping_scheduled: false,
    };
    
    // å¯åŠ¨Saga
    let saga_id = coordinator.start(initial_data.clone()).await;
    println!("å¼€å§‹Saga: {}", saga_id);
    
    // æ‰§è¡ŒSaga
    match coordinator.execute(&saga_id).await {
        Ok(result) => {
            println!("SagaæˆåŠŸå®Œæˆ!");
            println!("æœ€ç»ˆçŠ¶æ€: {:?}", result);
        },
        Err(e) => {
            println!("Sagaå¤±è´¥: {}", e);
        }
    }
    
    // æ¨¡æ‹Ÿå¤±è´¥åœºæ™¯
    // åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬ä¼šæœ‰ä¸€ä¸ªæœºåˆ¶æ¥æ¨¡æ‹Ÿæˆ–æ£€æµ‹æ•…éšœ
    
    // å†æ¬¡å¯åŠ¨Sagaï¼Œè¿™æ¬¡æˆ‘ä»¬å°†æ¨¡æ‹Ÿç¬¬äºŒæ­¥å¤±è´¥
    let saga_id_fail = coordinator.start(initial_data).await;
    println!("\nå¼€å§‹å¯èƒ½å¤±è´¥çš„Saga: {}", saga_id_fail);
    
    // åœ¨è¿™é‡Œæˆ‘ä»¬é€šå¸¸ä¼šæ³¨å…¥ä¸€ä¸ªå¤±è´¥ç‚¹
    // ç®€å•èµ·è§ï¼Œæˆ‘ä»¬å°†ä¾èµ–æ‰§è¡Œå‡½æ•°ä¸­çš„é€»è¾‘æ¥æ£€æµ‹å¤±è´¥
    
    match coordinator.execute(&saga_id_fail).await {
        Ok(result) => {
            println!("SagaæˆåŠŸå®Œæˆ!");
            println!("æœ€ç»ˆçŠ¶æ€: {:?}", result);
        },
        Err(e) => {
            println!("Sagaå¤±è´¥: {}", e);
            
            // æ£€æŸ¥SagaçŠ¶æ€
            let active_sagas = coordinator.active_sagas.lock().await;
            if let Some(context) = active_sagas.get(&saga_id_fail) {
                println!("æœ€ç»ˆçŠ¶æ€: {:?}", context.status);
                println!("æ­¥éª¤çŠ¶æ€: {:?}", context.step_statuses);
            }
        }
    }
}
```

## 6 ç¼“å­˜æ¨¡å¼

### 6.1 ç¼“å­˜ä»£ç†

ç¼“å­˜ä»£ç†æ¨¡å¼ä½¿ç”¨ç¼“å­˜æ¥æé«˜è¯»å–æ“ä½œçš„æ€§èƒ½ï¼Œå¹¶å‡å°‘å¯¹åŸå§‹æ•°æ®æºçš„è®¿é—®ã€‚

```rust
use std::collections::HashMap;
use std::hash::Hash;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::RwLock;
use async_trait::async_trait;

// ç¼“å­˜é¡¹ç»“æ„
struct CacheItem<V> {
    value: V,
    expiry: Option<Instant>,
}

// ç¼“å­˜æ¥å£
#[async_trait]
trait Cache<K, V> {
    async fn get(&self, key: &K) -> Option<V>;
    async fn put(&self, key: K, value: V, ttl: Option<Duration>);
    async fn remove(&self, key: &K);
    async fn clear(&self);
}

// å†…å­˜ç¼“å­˜å®ç°
struct InMemoryCache<K, V> {
    data: RwLock<HashMap<K, CacheItem<V>>>,
}

impl<K, V> InMemoryCache<K, V>
where
    K: Eq + Hash + Clone + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    fn new() -> Self {
        Self {
            data: RwLock::new(HashMap::new()),
        }
    }
    
    // æ¸…ç†è¿‡æœŸé¡¹ç›®
    async fn cleanup(&self) {
        let mut data = self.data.write().await;
        let now = Instant::now();
        
        data.retain(|_, item| {
            match item.expiry {
                Some(expiry) => expiry > now,
                None => true,
            }
        });
    }
}

#[async_trait]
impl<K, V> Cache<K, V> for InMemoryCache<K, V>
where
    K: Eq + Hash + Clone + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    async fn get(&self, key: &K) -> Option<V> {
        let data = self.data.read().await;
        
        if let Some(item) = data.get(key) {
            // æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if let Some(expiry) = item.expiry {
                if Instant::now() > expiry {
                    return None;
                }
            }
            
            Some(item.value.clone())
        } else {
            None
        }
    }
    
    async fn put(&self, key: K, value: V, ttl: Option<Duration>) {
        let expiry = ttl.map(|duration| Instant::now() + duration);
        
        let item = CacheItem {
            value,
            expiry,
        };
        
        let mut data = self.data.write().await;
        data.insert(key, item);
    }
    
    async fn remove(&self, key: &K) {
        let mut data = self.data.write().await;
        data.remove(key);
    }
    
    async fn clear(&self) {
        let mut data = self.data.write().await;
        data.clear();
    }
}

// æ•°æ®æºæ¥å£
#[async_trait]
trait DataSource<K, V> {
    async fn load(&self, key: &K) -> Option<V>;
}

// æ¨¡æ‹Ÿæ•°æ®åº“æ•°æ®æº
struct DatabaseSource {
    data: HashMap<String, String>,
    load_delay_ms: u64, // æ¨¡æ‹Ÿæ•°æ®åº“å»¶è¿Ÿ
}

impl DatabaseSource {
    fn new(load_delay_ms: u64) -> Self {
        let mut data = HashMap::new();
        data.insert("user:1".to_string(), "ç”¨æˆ·1æ•°æ®".to_string());
        data.insert("user:2".to_string(), "ç”¨æˆ·2æ•°æ®".to_string());
        data.insert("product:1".to_string(), "äº§å“1æ•°æ®".to_string());
        
        Self {
            data,
            load_delay_ms,
        }
    }
}

#[async_trait]
impl DataSource<String, String> for DatabaseSource {
    async fn load(&self, key: &String) -> Option<String> {
        // æ¨¡æ‹Ÿæ•°æ®åº“è®¿é—®å»¶è¿Ÿ
        tokio::time::sleep(Duration::from_millis(self.load_delay_ms)).await;
        
        self.data.get(key).cloned()
    }
}

// ç¼“å­˜ä»£ç†
struct CacheProxy<K, V, D, C>
where
    K: Eq + Hash + Clone + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
    D: DataSource<K, V> + Send + Sync + 'static,
    C: Cache<K, V> + Send + Sync,
{
    data_source: Arc<D>,
    cache: Arc<C>,
    default_ttl: Option<Duration>,
}

impl<K, V, D, C> CacheProxy<K, V, D, C>
where
    K: Eq + Hash + Clone + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
    D: DataSource<K, V> + Send + Sync,
    C: Cache<K, V> + Send + Sync,
{
    fn new(data_source: D, cache: C, default_ttl: Option<Duration>) -> Self {
        Self {
            data_source: Arc::new(data_source),
            cache: Arc::new(cache),
            default_ttl,
        }
    }
    
    async fn get(&self, key: K) -> Option<V> {
        // é¦–å…ˆå°è¯•ä»ç¼“å­˜è·å–
        if let Some(value) = self.cache.get(&key).await {
            println!("ç¼“å­˜å‘½ä¸­: {}", key.to_string());
            return Some(value);
        }
        
        println!("ç¼“å­˜æœªå‘½ä¸­: {}, ä»æ•°æ®æºåŠ è½½", key.to_string());
        
        // å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰ï¼Œä»æ•°æ®æºåŠ è½½
        let value = self.data_source.load(&key).await;
        
        // å¦‚æœæ•°æ®æºä¸­æœ‰å€¼ï¼Œåˆ™ç¼“å­˜å®ƒ
        if let Some(ref v) = value {
            self.cache.put(key, v.clone(), self.default_ttl).await;
        }
        
        value
    }
    
    async fn invalidate(&self, key: &K) {
        self.cache.remove(key).await;
    }
    
    async fn put(&self, key: K, value: V) {
        // æ›´æ–°ç¼“å­˜å¹¶å¯èƒ½åŒæ­¥åˆ°æ•°æ®æº
        self.cache.put(key, value, self.default_ttl).await;
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºæ•°æ®æº
    let database = DatabaseSource::new(500); // 500msåŠ è½½å»¶è¿Ÿ
    
    // åˆ›å»ºç¼“å­˜
    let cache = InMemoryCache::new();
    
    // åˆ›å»ºç¼“å­˜ä»£ç†
    let proxy = CacheProxy::new(
        database,
        cache,
        Some(Duration::from_secs(10)), // 10ç§’TTL
    );
    
    // ç¬¬ä¸€æ¬¡è®¿é—® - ç¼“å­˜æœªå‘½ä¸­ï¼Œä»æ•°æ®æºåŠ è½½
    let start = Instant::now();
    let value1 = proxy.get("user:1".to_string()).await;
    let duration1 = start.elapsed();
    println!("ç¬¬ä¸€æ¬¡è®¿é—®: {:?}, è€—æ—¶: {:?}", value1, duration1);
    
    // ç¬¬äºŒæ¬¡è®¿é—®åŒä¸€é”® - ç¼“å­˜å‘½ä¸­
    let start = Instant::now();
    let value2 = proxy.get("user:1".to_string()).await;
    let duration2 = start.elapsed();
    println!("ç¬¬äºŒæ¬¡è®¿é—®: {:?}, è€—æ—¶: {:?}", value2, duration2);
    
    // è®¿é—®å¦ä¸€ä¸ªé”®
    let start = Instant::now();
    let value3 = proxy.get("product:1".to_string()).await;
    let duration3 = start.elapsed();
    println!("è®¿é—®å…¶ä»–é”®: {:?}, è€—æ—¶: {:?}", value3, duration3);
    
    // è®¿é—®ä¸å­˜åœ¨çš„é”®
    let start = Instant::now();
    let value4 = proxy.get("not_exist".to_string()).await;
    let duration4 = start.elapsed();
    println!("è®¿é—®ä¸å­˜åœ¨é”®: {:?}, è€—æ—¶: {:?}", value4, duration4);
    
    // å†æ¬¡è®¿é—®ä¸å­˜åœ¨çš„é”® - åº”è¯¥ç›´æ¥ä»ç¼“å­˜è·å–ç©ºç»“æœ
    let start = Instant::now();
    let value5 = proxy.get("not_exist".to_string()).await;
    let duration5 = start.elapsed();
    println!("å†æ¬¡è®¿é—®ä¸å­˜åœ¨é”®: {:?}, è€—æ—¶: {:?}", value5, duration5);
    
    // å¤±æ•ˆæŸä¸ªç¼“å­˜é¡¹
    proxy.invalidate(&"user:1".to_string()).await;
    println!("ä½¿ user:1 ç¼“å­˜å¤±æ•ˆ");
    
    // å†æ¬¡è®¿é—®ï¼Œåº”è¯¥å†æ¬¡ä»æ•°æ®æºåŠ è½½
    let start = Instant::now();
    let value6 = proxy.get("user:1".to_string()).await;
    let duration6 = start.elapsed();
    println!("å¤±æ•ˆåè®¿é—®: {:?}, è€—æ—¶: {:?}", value6, duration6);
}
```

### 6.2 å†™é€ä¸åå†™ç¼“å­˜

å†™é€å’Œåå†™ç¼“å­˜æ˜¯ä¸¤ç§ä¸åŒçš„ç¼“å­˜å†™å…¥ç­–ç•¥ï¼Œå‰è€…åŒæ­¥å†™å…¥ç¼“å­˜å’Œæ•°æ®æºï¼Œåè€…å…ˆå†™å…¥ç¼“å­˜ï¼Œä¹‹åå¼‚æ­¥å†™å…¥æ•°æ®æºã€‚

```rust
use std::collections::HashMap;
use std::hash::Hash;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{mpsc, RwLock};
use tokio::time::sleep;
use async_trait::async_trait;

// ç¼“å­˜æ¥å£
#[async_trait]
trait Cache<K, V> {
    async fn get(&self, key: &K) -> Option<V>;
    async fn put(&self, key: K, value: V);
    async fn remove(&self, key: &K);
}

// æ•°æ®æºæ¥å£
#[async_trait]
trait DataSource<K, V> {
    async fn load(&self, key: &K) -> Option<V>;
    async fn store(&self, key: &K, value: &V) -> Result<(), String>;
    async fn delete(&self, key: &K) -> Result<(), String>;
}

// å†…å­˜ç¼“å­˜å®ç°
struct InMemoryCache<K, V> {
    data: RwLock<HashMap<K, V>>,
}

impl<K, V> InMemoryCache<K, V>
where
    K: Eq + Hash + Clone + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    fn new() -> Self {
        Self {
            data: RwLock::new(HashMap::new()),
        }
    }
}

#[async_trait]
impl<K, V> Cache<K, V> for InMemoryCache<K, V>
where
    K: Eq + Hash + Clone + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    async fn get(&self, key: &K) -> Option<V> {
        let data = self.data.read().await;
        data.get(key).cloned()
    }
    
    async fn put(&self, key: K, value: V) {
        let mut data = self.data.write().await;
        data.insert(key, value);
    }
    
    async fn remove(&self, key: &K) {
        let mut data = self.data.write().await;
        data.remove(key);
    }
}

// æ¨¡æ‹Ÿæ•°æ®åº“æ•°æ®æº
struct DatabaseSource {
    data: RwLock<HashMap<String, String>>,
    write_delay_ms: u64, // æ¨¡æ‹Ÿæ•°æ®åº“å†™å…¥å»¶è¿Ÿ
}

impl DatabaseSource {
    fn new(write_delay_ms: u64) -> Self {
        Self {
            data: RwLock::new(HashMap::new()),
            write_delay_ms,
        }
    }
}

#[async_trait]
impl DataSource<String, String> for DatabaseSource {
    async fn load(&self, key: &String) -> Option<String> {
        let data = self.data.read().await;
        data.get(key).cloned()
    }
    
    async fn store(&self, key: &String, value: &String) -> Result<(), String> {
        // æ¨¡æ‹Ÿå†™å…¥å»¶è¿Ÿ
        sleep(Duration::from_millis(self.write_delay_ms)).await;
        
        let mut data = self.data.write().await;
        data.insert(key.clone(), value.clone());
        Ok(())
    }
    
    async fn delete(&self, key: &String) -> Result<(), String> {
        // æ¨¡æ‹Ÿå»¶è¿Ÿ
        sleep(Duration::from_millis(self.write_delay_ms)).await;
        
        let mut data = self.data.write().await;
        data.remove(key);
        Ok(())
    }
}

// å†™é€ç¼“å­˜ç­–ç•¥
struct WriteThrough<K, V, C, D>
where
    K: Eq + Hash + Clone + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
    C: Cache<K, V> + Send + Sync,
    D: DataSource<K, V> + Send + Sync,
{
    cache: Arc<C>,
    data_source: Arc<D>,
}

impl<K, V, C, D> WriteThrough<K, V, C, D>
where
    K: Eq + Hash + Clone + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
    C: Cache<K, V> + Send + Sync,
    D: DataSource<K, V> + Send + Sync,
{
    fn new(cache: C, data_source: D) -> Self {
        Self {
            cache: Arc::new(cache),
            data_source: Arc::new(data_source),
        }
    }
    
    async fn get(&self, key: &K) -> Option<V> {
        // é¦–å…ˆå°è¯•ä»ç¼“å­˜è·å–
        if let Some(value) = self.cache.get(key).await {
            return Some(value);
        }
        
        // ç¼“å­˜ä¸­æ²¡æœ‰ï¼Œä»æ•°æ®æºåŠ è½½
        match self.data_source.load(key).await {
            Some(value) => {
                // æ›´æ–°ç¼“å­˜
                self.cache.put(key.clone(), value.clone()).await;
                Some(value)
            },
            None => None,
        }
    }
    
    async fn put(&self, key: K, value: V) -> Result<(), String> {
        // å†™é€ç­–ç•¥ï¼šåŒæ­¥å†™å…¥æ•°æ®æºå’Œç¼“å­˜
        self.data_source.store(&key, &value).await?;
        self.cache.put(key, value).await;
        Ok(())
    }
    
    async fn remove(&self, key: &K) -> Result<(), String> {
        // åŒæ­¥ä»æ•°æ®æºå’Œç¼“å­˜ä¸­åˆ é™¤
        self.data_source.delete(key).await?;
        self.cache.remove(key).await;
        Ok(())
    }
}

/*
<think>
ç»§ç»­å®Œæˆ `WriteBack` ç¼“å­˜ç­–ç•¥çš„ä»£ç ï¼Œç„¶åæä¾›ä¸€ä¸ªä½¿ç”¨ç¤ºä¾‹ã€‚
è¿™éƒ¨åˆ†ä»£ç å°†å±•ç¤ºåå†™ç¼“å­˜å¦‚ä½•å·¥ä½œï¼Œå³å…ˆæ›´æ–°ç¼“å­˜ï¼Œç„¶åå¼‚æ­¥æ›´æ–°æ•°æ®æºã€‚
</think>
*/

// åå†™ç¼“å­˜ç­–ç•¥
struct WriteBack<K, V, C, D>
where
    K: Eq + Hash + Clone + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
    C: Cache<K, V> + Send + Sync,
    D: DataSource<K, V> + Send + Sync,
{
    cache: Arc<C>,
    data_source: Arc<D>,
    dirty_queue: Arc<RwLock<HashMap<K, V>>>,
}

impl<K, V, C, D> WriteBack<K, V, C, D>
where
    K: Eq + Hash + Clone + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
    C: Cache<K, V> + Send + Sync,
    D: DataSource<K, V> + Send + Sync,
{
    fn new(cache: C, data_source: D) -> Self {
        Self {
            cache: Arc::new(cache),
            data_source: Arc::new(data_source),
            dirty_queue: Arc::new(RwLock::new(HashMap::new())),
        }
    }
    
    // å¯åŠ¨åå°å†™å…¥è¿›ç¨‹
    async fn start_background_writer(&self, interval: Duration) {
        let dirty_queue = self.dirty_queue.clone();
        let data_source = self.data_source.clone();
        
        tokio::spawn(async move {
            loop {
                sleep(interval).await;
                
                // è·å–å¹¶æ¸…ç©ºè„é˜Ÿåˆ—
                let dirty_entries = {
                    let mut queue = dirty_queue.write().await;
                    let entries = queue.clone();
                    queue.clear();
                    entries
                };
                
                // å†™å…¥æ•°æ®æº
                for (key, value) in dirty_entries {
                    match data_source.store(&key, &value).await {
                        Ok(_) => println!("åå°å†™å…¥æˆåŠŸ: {}", key.to_string()),
                        Err(e) => {
                            println!("åå°å†™å…¥å¤±è´¥: {}, é”™è¯¯: {}", key.to_string(), e);
                            
                            // é‡æ–°åŠ å…¥è„é˜Ÿåˆ—
                            let mut queue = dirty_queue.write().await;
                            queue.insert(key, value);
                        }
                    }
                }
            }
        });
    }
    
    async fn get(&self, key: &K) -> Option<V> {
        // é¦–å…ˆæ£€æŸ¥è„é˜Ÿåˆ—
        {
            let dirty = self.dirty_queue.read().await;
            if let Some(value) = dirty.get(key) {
                return Some(value.clone());
            }
        }
        
        // å…¶æ¬¡æ£€æŸ¥ç¼“å­˜
        if let Some(value) = self.cache.get(key).await {
            return Some(value);
        }
        
        // æœ€åå°è¯•ä»æ•°æ®æºåŠ è½½
        match self.data_source.load(key).await {
            Some(value) => {
                // æ›´æ–°ç¼“å­˜ï¼Œä½†ä¸æ›´æ–°è„é˜Ÿåˆ—
                self.cache.put(key.clone(), value.clone()).await;
                Some(value)
            },
            None => None,
        }
    }
    
    async fn put(&self, key: K, value: V) {
        // åå†™ç­–ç•¥ï¼šç«‹å³æ›´æ–°ç¼“å­˜ï¼Œå°†å†™å…¥åŠ å…¥è„é˜Ÿåˆ—
        self.cache.put(key.clone(), value.clone()).await;
        
        let mut dirty = self.dirty_queue.write().await;
        dirty.insert(key, value);
    }
    
    async fn remove(&self, key: &K) {
        // ç«‹å³ä»ç¼“å­˜ä¸­åˆ é™¤
        self.cache.remove(key).await;
        
        // ä»è„é˜Ÿåˆ—ä¸­åˆ é™¤
        {
            let mut dirty = self.dirty_queue.write().await;
            dirty.remove(key);
        }
        
        // å¼‚æ­¥ä»æ•°æ®æºä¸­åˆ é™¤
        let key_clone = key.clone();
        let data_source = self.data_source.clone();
        tokio::spawn(async move {
            if let Err(e) = data_source.delete(&key_clone).await {
                println!("åˆ é™¤æ“ä½œå¤±è´¥: {}, é”™è¯¯: {}", key_clone.to_string(), e);
            }
        });
    }
    
    // å¼ºåˆ¶å°†è„é˜Ÿåˆ—ä¸­çš„æ•°æ®å†™å…¥æ•°æ®æº
    async fn flush(&self) -> Result<(), String> {
        let dirty_entries = {
            let mut queue = self.dirty_queue.write().await;
            let entries = queue.clone();
            queue.clear();
            entries
        };
        
        // å†™å…¥æ‰€æœ‰è„æ•°æ®
        for (key, value) in dirty_entries {
            if let Err(e) = self.data_source.store(&key, &value).await {
                return Err(format!("åˆ·æ–°å¤±è´¥: {}", e));
            }
        }
        
        Ok(())
    }
}

// ç¼“å­˜åœºæ™¯åˆ†æå™¨ - ç”¨äºæµ‹é‡æ€§èƒ½å¹¶æä¾›å»ºè®®
struct CacheAnalyzer {
    reads: usize,
    writes: usize,
    read_hits: usize,
    read_time: Duration,
    write_time: Duration,
}

impl CacheAnalyzer {
    fn new() -> Self {
        Self {
            reads: 0,
            writes: 0,
            read_hits: 0,
            read_time: Duration::from_secs(0),
            write_time: Duration::from_secs(0),
        }
    }
    
    fn record_read(&mut self, hit: bool, time: Duration) {
        self.reads += 1;
        if hit {
            self.read_hits += 1;
        }
        self.read_time += time;
    }
    
    fn record_write(&mut self, time: Duration) {
        self.writes += 1;
        self.write_time += time;
    }
    
    fn analyze(&self) {
        println!("\n--- ç¼“å­˜æ€§èƒ½åˆ†æ ---");
        println!("è¯»å–æ¬¡æ•°: {}", self.reads);
        println!("å†™å…¥æ¬¡æ•°: {}", self.writes);
        
        if self.reads > 0 {
            let hit_rate = (self.read_hits as f64 / self.reads as f64) * 100.0;
            println!("ç¼“å­˜å‘½ä¸­ç‡: {:.2}%", hit_rate);
            println!("å¹³å‡è¯»å–æ—¶é—´: {:?}", self.read_time / self.reads as u32);
        }
        
        if self.writes > 0 {
            println!("å¹³å‡å†™å…¥æ—¶é—´: {:?}", self.write_time / self.writes as u32);
        }
        
        println!("å»ºè®®:");
        if self.reads > 0 && (self.read_hits as f64 / self.reads as f64) < 0.5 {
            println!("- ç¼“å­˜å‘½ä¸­ç‡è¾ƒä½ï¼Œè€ƒè™‘é¢„çƒ­ç¼“å­˜æˆ–å¢åŠ ç¼“å­˜é¡¹TTL");
        }
        
        let read_write_ratio = if self.writes > 0 {
            self.reads as f64 / self.writes as f64
        } else {
            f64::INFINITY
        };
        
        println!("è¯»å†™æ¯”: {:.2}", read_write_ratio);
        if read_write_ratio > 10.0 {
            println!("- ä»¥è¯»ä¸ºä¸»çš„å·¥ä½œè´Ÿè½½ï¼Œè€ƒè™‘ä½¿ç”¨ReadThrough/WriteThroughç­–ç•¥");
        } else if read_write_ratio < 1.0 {
            println!("- ä»¥å†™ä¸ºä¸»çš„å·¥ä½œè´Ÿè½½ï¼Œè€ƒè™‘ä½¿ç”¨WriteBackç­–ç•¥å‡å°‘å†™å…¥å»¶è¿Ÿ");
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºä¸€ä¸ªæ€§èƒ½åˆ†æå™¨
    let mut analyzer = CacheAnalyzer::new();
    
    println!("=== å†™é€ç¼“å­˜æµ‹è¯• ===");
    
    // åˆ›å»ºå†™é€ç¼“å­˜
    let cache1 = InMemoryCache::new();
    let db1 = DatabaseSource::new(200); // 200mså†™å…¥å»¶è¿Ÿ
    let write_through = WriteThrough::new(cache1, db1);
    
    // å†™å…¥æµ‹è¯•
    for i in 1..=5 {
        let key = format!("key{}", i);
        let value = format!("value{}", i);
        
        let start = Instant::now();
        let _ = write_through.put(key, value).await;
        analyzer.record_write(start.elapsed());
    }
    
    // è¯»å–æµ‹è¯•
    for i in 1..=7 {
        let key = format!("key{}", i);
        
        let start = Instant::now();
        let result = write_through.get(&key).await;
        let hit = result.is_some() && i <= 5;
        analyzer.record_read(hit, start.elapsed());
        
        println!("å†™é€è¯»å– {}: {:?}", key, result);
    }
    
    println!("\n=== åå†™ç¼“å­˜æµ‹è¯• ===");
    
    // åˆ›å»ºåå†™ç¼“å­˜
    let cache2 = InMemoryCache::new();
    let db2 = DatabaseSource::new(200); // 200mså†™å…¥å»¶è¿Ÿ
    let write_back = WriteBack::new(cache2, db2);
    
    // å¯åŠ¨åå°å†™å…¥è¿›ç¨‹
    write_back.start_background_writer(Duration::from_secs(1)).await;
    
    // å†™å…¥æµ‹è¯•
    for i in 1..=5 {
        let key = format!("key{}", i);
        let value = format!("value{}", i);
        
        let start = Instant::now();
        write_back.put(key, value).await;
        analyzer.record_write(start.elapsed());
    }
    
    // ç«‹å³è¯»å– - åº”è¯¥ä»ç¼“å­˜è·å–
    for i in 1..=7 {
        let key = format!("key{}", i);
        
        let start = Instant::now();
        let result = write_back.get(&key).await;
        let hit = result.is_some() && i <= 5;
        analyzer.record_read(hit, start.elapsed());
        
        println!("åå†™ç«‹å³è¯»å– {}: {:?}", key, result);
    }
    
    // ç­‰å¾…åå°å†™å…¥å®Œæˆ
    println!("\nç­‰å¾…åå°å†™å…¥...");
    sleep(Duration::from_secs(2)).await;
    
    // åˆ·æ–°å‰©ä½™çš„å†™å…¥
    write_back.flush().await.unwrap();
    
    // æ€§èƒ½åˆ†æ
    analyzer.analyze();
}
```

### 6.3 ç¼“å­˜ä¸€è‡´æ€§

ç¼“å­˜ä¸€è‡´æ€§æ¨¡å¼ç¡®ä¿ç¼“å­˜å’Œæ•°æ®æºä¸­çš„æ•°æ®ä¿æŒä¸€è‡´ï¼Œå³ä½¿åœ¨å¤šä¸ªå®ä¾‹æˆ–åˆ†å¸ƒå¼ç¯å¢ƒä¸­ã€‚

```rust
use std::collections::HashMap;
use std::hash::Hash;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{broadcast, mpsc, RwLock};
use tokio::time::sleep;
use async_trait::async_trait;
use serde::{Serialize, Deserialize};

// ç¼“å­˜äº‹ä»¶ç±»å‹
#[derive(Debug, Clone, Serialize, Deserialize)]
enum CacheEvent<K, V> {
    Put { key: K, value: V },
    Remove { key: K },
    Clear,
}

// ç¼“å­˜æ¥å£
#[async_trait]
trait Cache<K, V> {
    async fn get(&self, key: &K) -> Option<V>;
    async fn put(&self, key: K, value: V);
    async fn remove(&self, key: &K);
    async fn clear(&self);
}

// åˆ†å¸ƒå¼ç¼“å­˜æ¥å£
#[async_trait]
trait DistributedCache<K, V>: Cache<K, V> {
    // å‘å¸ƒç¼“å­˜äº‹ä»¶
    async fn publish_event(&self, event: CacheEvent<K, V>);
    
    // å¤„ç†æ¥æ”¶åˆ°çš„ç¼“å­˜äº‹ä»¶
    async fn handle_event(&self, event: CacheEvent<K, V>);
}

// å†…å­˜ç¼“å­˜å®ç°
struct InMemoryCache<K, V> {
    data: RwLock<HashMap<K, V>>,
    event_tx: Option<broadcast::Sender<CacheEvent<K, V>>>,
    instance_id: String,
}

impl<K, V> InMemoryCache<K, V>
where
    K: Eq + Hash + Clone + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    fn new(instance_id: &str) -> Self {
        Self {
            data: RwLock::new(HashMap::new()),
            event_tx: None,
            instance_id: instance_id.to_string(),
        }
    }
    
    // è®¾ç½®äº‹ä»¶å‘å¸ƒå™¨
    fn set_event_publisher(&mut self, tx: broadcast::Sender<CacheEvent<K, V>>) {
        self.event_tx = Some(tx);
    }
}

#[async_trait]
impl<K, V> Cache<K, V> for InMemoryCache<K, V>
where
    K: Eq + Hash + Clone + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    async fn get(&self, key: &K) -> Option<V> {
        let data = self.data.read().await;
        data.get(key).cloned()
    }
    
    async fn put(&self, key: K, value: V) {
        let mut data = self.data.write().await;
        data.insert(key, value);
    }
    
    async fn remove(&self, key: &K) {
        let mut data = self.data.write().await;
        data.remove(key);
    }
    
    async fn clear(&self) {
        let mut data = self.data.write().await;
        data.clear();
    }
}

#[async_trait]
impl<K, V> DistributedCache<K, V> for InMemoryCache<K, V>
where
    K: Eq + Hash + Clone + Send + Sync + 'static + Serialize + for<'de> Deserialize<'de>,
    V: Clone + Send + Sync + 'static + Serialize + for<'de> Deserialize<'de>,
{
    async fn publish_event(&self, event: CacheEvent<K, V>) {
        if let Some(tx) = &self.event_tx {
            let _ = tx.send(event);
        }
    }
    
    async fn handle_event(&self, event: CacheEvent<K, V>) {
        match event {
            CacheEvent::Put { key, value } => {
                self.put(key, value).await;
            },
            CacheEvent::Remove { key } => {
                self.remove(&key).await;
            },
            CacheEvent::Clear => {
                self.clear().await;
            },
        }
    }
}

// åˆ†å¸ƒå¼ç¼“å­˜åè°ƒå™¨
struct CacheCoordinator<K, V> {
    caches: RwLock<HashMap<String, Arc<InMemoryCache<K, V>>>>,
    event_tx: broadcast::Sender<CacheEvent<K, V>>,
}

impl<K, V> CacheCoordinator<K, V>
where
    K: Eq + Hash + Clone + Send + Sync + 'static + Serialize + for<'de> Deserialize<'de>,
    V: Clone + Send + Sync + 'static + Serialize + for<'de> Deserialize<'de>,
{
...(about 80 lines omitted)...
    // åˆ›å»ºç¼“å­˜åè°ƒå™¨
    let (event_tx, _) = broadcast::channel(100);
    let coordinator = Arc::new(CacheCoordinator::new(event_tx.clone()));
    
    // åˆ›å»ºä¸‰ä¸ªç¼“å­˜å®ä¾‹
    let cache1 = coordinator.create_cache("cache1").await;
    let cache2 = coordinator.create_cache("cache2").await;
    let cache3 = coordinator.create_cache("cache3").await;
    
    // åœ¨cache1ä¸­å†™å…¥æ•°æ®
    cache1.put("key1".to_string(), "value1".to_string()).await;
    cache1.publish_event(CacheEvent::Put {
        key: "key1".to_string(),
        value: "value1".to_string(),
    }).await;
    
    // ç­‰å¾…äº‹ä»¶ä¼ æ’­
    sleep(Duration::from_millis(100)).await;
    
    // ä»æ‰€æœ‰ç¼“å­˜å®ä¾‹è¯»å–æ•°æ®
    let value1 = cache1.get(&"key1".to_string()).await;
    let value2 = cache2.get(&"key1".to_string()).await;
    let value3 = cache3.get(&"key1".to_string()).await;
    
    println!("ç¼“å­˜1ä¸­çš„å€¼: {:?}", value1);
    println!("ç¼“å­˜2ä¸­çš„å€¼: {:?}", value2);
    println!("ç¼“å­˜3ä¸­çš„å€¼: {:?}", value3);
    
    // åœ¨cache2ä¸­åˆ é™¤æ•°æ®
    cache2.remove(&"key1".to_string()).await;
    cache2.publish_event(CacheEvent::Remove {
        key: "key1".to_string(),
    }).await;
    
    // ç­‰å¾…äº‹ä»¶ä¼ æ’­
    sleep(Duration::from_millis(100)).await;
    
    // å†æ¬¡ä»æ‰€æœ‰ç¼“å­˜å®ä¾‹è¯»å–æ•°æ®
    let value1 = cache1.get(&"key1".to_string()).await;
    let value2 = cache2.get(&"key1".to_string()).await;
    let value3 = cache3.get(&"key1".to_string()).await;
    
    println!("åˆ é™¤åï¼Œç¼“å­˜1ä¸­çš„å€¼: {:?}", value1);
    println!("åˆ é™¤åï¼Œç¼“å­˜2ä¸­çš„å€¼: {:?}", value2);
    println!("åˆ é™¤åï¼Œç¼“å­˜3ä¸­çš„å€¼: {:?}", value3);
    
    // æ¨¡æ‹Ÿå»¶è¿Ÿäº‹ä»¶ä¼ æ’­
    println!("\næ¨¡æ‹Ÿç½‘ç»œåˆ†åŒºåœºæ™¯:");
    
    // è®¾ç½®ä¸€ä¸ªæ–°å€¼ä½†ä¸å‘å¸ƒäº‹ä»¶
    cache1.put("key2".to_string(), "value2-cache1-only".to_string()).await;
    println!("åœ¨ç¼“å­˜1ä¸­è®¾ç½®äº†key2ï¼Œä½†æ²¡æœ‰å‘å¸ƒäº‹ä»¶");
    
    // æ£€æŸ¥æ‰€æœ‰ç¼“å­˜
    let value1 = cache1.get(&"key2".to_string()).await;
    let value2 = cache2.get(&"key2".to_string()).await;
    let value3 = cache3.get(&"key2".to_string()).await;
    
    println!("ç¼“å­˜1ä¸­çš„key2: {:?}", value1);
    println!("ç¼“å­˜2ä¸­çš„key2: {:?}", value2);
    println!("ç¼“å­˜3ä¸­çš„key2: {:?}", value3);
    
    // æ‰‹åŠ¨æ‰§è¡ŒåŒæ­¥
    println!("\næ‰§è¡Œæ‰‹åŠ¨åŒæ­¥:");
    coordinator.sync_all_caches().await;
    
    // ç­‰å¾…åŒæ­¥å®Œæˆ
    sleep(Duration::from_millis(100)).await;
    
    // å†æ¬¡æ£€æŸ¥æ‰€æœ‰ç¼“å­˜
    let value1 = cache1.get(&"key2".to_string()).await;
    let value2 = cache2.get(&"key2".to_string()).await;
    let value3 = cache3.get(&"key2".to_string()).await;
    
    println!("åŒæ­¥åï¼Œç¼“å­˜1ä¸­çš„key2: {:?}", value1);
    println!("åŒæ­¥åï¼Œç¼“å­˜2ä¸­çš„key2: {:?}", value2);
    println!("åŒæ­¥åï¼Œç¼“å­˜3ä¸­çš„key2: {:?}", value3);
}
```

## 7 ç»“è®º

è¿™äº›åˆ†å¸ƒå¼ç³»ç»Ÿæ¨¡å¼ä»£è¡¨äº†åº”å¯¹åˆ†å¸ƒå¼ç³»ç»ŸæŒ‘æˆ˜çš„æˆç†Ÿè§£å†³æ–¹æ¡ˆã€‚é€šè¿‡ç†è§£å’Œåº”ç”¨è¿™äº›æ¨¡å¼ï¼Œå¼€å‘è€…å¯ä»¥æ„å»ºæ›´å¯é ã€æ›´é«˜æ•ˆçš„åˆ†å¸ƒå¼ç³»ç»Ÿã€‚

æ¯ä¸ªæ¨¡å¼éƒ½æœ‰å…¶åº”ç”¨åœºæ™¯å’Œæƒè¡¡ï¼Œé€‰æ‹©åˆé€‚çš„æ¨¡å¼éœ€è¦è€ƒè™‘ç³»ç»Ÿçš„ç‰¹å®šéœ€æ±‚å’Œçº¦æŸã€‚é€šè¿‡è¿™äº›Rustç¤ºä¾‹ï¼Œæˆ‘ä»¬å¸Œæœ›ä¸ºåˆ†å¸ƒå¼ç³»ç»Ÿå¼€å‘è€…æä¾›å®ç”¨çš„å‚è€ƒå’ŒæŒ‡å¯¼ã€‚

```text
<think>
I notice that we've covered quite a few distributed system patterns already throughout the previous responses, including:

1. Replication patterns:
   - Single-master replication
   - Multi-master replication
   - Masterless replication
   - Raft consensus

2. Partitioning patterns:
   - Sharding
   - Consistent hashing
   - Replica distribution

3. Fault tolerance patterns:
   - Circuit breaker
   - Bulkhead
   - Timeout and retry
   - Backpressure

4. Transaction patterns:
   - Two-phase commit
   - Saga

5. Caching patterns:
   - Cache proxy
   - Write-through and write-back
   - Cache consistency

I'll continue with more patterns that we haven't covered yet. Some possibilities include:

1. Event-based patterns:
   - Event sourcing
   - CQRS (Command Query Responsibility Segregation)

2. Messaging patterns:
   - Publish-subscribe
   - Message queues
   - Request-response

3. Service discovery patterns

4. Concurrency patterns

Let me continue with these additional patterns to provide a more comprehensive overview of distributed systems patterns.
</think>
```

## 8 æ¶ˆæ¯ä¼ é€’æ¨¡å¼

### 8.1 å‘å¸ƒ-è®¢é˜…

å‘å¸ƒ-è®¢é˜…æ¨¡å¼å…è®¸æ¶ˆæ¯å‘é€è€…ï¼ˆå‘å¸ƒè€…ï¼‰å°†æ¶ˆæ¯å‘é€ç»™å¤šä¸ªæ¥æ”¶è€…ï¼ˆè®¢é˜…è€…ï¼‰ï¼Œè€Œä¸éœ€è¦ç›´æ¥äº†è§£å¯¹æ–¹çš„å­˜åœ¨ã€‚

```rust
use std::collections::{HashMap, HashSet};
use std::sync::{Arc, Weak};
use tokio::sync::{mpsc, RwLock};
use serde::{Serialize, Deserialize};
use uuid::Uuid;

// æ¶ˆæ¯æ¥å£
trait Message: Send + Sync + Clone {}

// ç®€å•çš„æ–‡æœ¬æ¶ˆæ¯å®ç°
#[derive(Debug, Clone, Serialize, Deserialize)]
struct TextMessage {
    id: String,
    topic: String,
    content: String,
    timestamp: u64,
}

impl Message for TextMessage {}

// æ¶ˆæ¯å¤„ç†å™¨ç‰¹å¾
#[async_trait::async_trait]
trait MessageHandler: Send + Sync {
    async fn handle(&self, message: TextMessage);
}

// è®¢é˜…è€…
struct Subscriber {
    id: String,
    name: String,
    handler: Box<dyn MessageHandler>,
}

impl Subscriber {
    fn new(name: &str, handler: Box<dyn MessageHandler>) -> Self {
        Self {
            id: Uuid::new_v4().to_string(),
            name: name.to_string(),
            handler,
        }
    }
    
    async fn receive(&self, message: TextMessage) {
        self.handler.handle(message).await;
    }
}

// ç®€å•çš„æ‰“å°æ¶ˆæ¯å¤„ç†å™¨
struct LoggingHandler {
    prefix: String,
}

#[async_trait::async_trait]
impl MessageHandler for LoggingHandler {
    async fn handle(&self, message: TextMessage) {
        println!("[{}] æ”¶åˆ°æ¶ˆæ¯: {}: {}", 
                 self.prefix, message.topic, message.content);
    }
}

// è¿‡æ»¤æ¶ˆæ¯å¤„ç†å™¨
struct FilteringHandler {
    prefix: String,
    filter_word: String,
}

#[async_trait::async_trait]
impl MessageHandler for FilteringHandler {
    async fn handle(&self, message: TextMessage) {
        if message.content.contains(&self.filter_word) {
            println!("[{}] åŒ¹é…è¿‡æ»¤è¯ '{}': {}: {}", 
                    self.prefix, self.filter_word, message.topic, message.content);
        }
    }
}

// æ¶ˆæ¯ä»£ç†
struct MessageBroker {
    topics: RwLock<HashMap<String, HashSet<String>>>,
    subscribers: RwLock<HashMap<String, Arc<Subscriber>>>,
}

impl MessageBroker {
    fn new() -> Self {
        Self {
            topics: RwLock::new(HashMap::new()),
            subscribers: RwLock::new(HashMap::new()),
        }
    }
    
    // æ³¨å†Œè®¢é˜…è€…
    async fn register(&self, subscriber: Arc<Subscriber>) {
        let mut subscribers = self.subscribers.write().await;
        subscribers.insert(subscriber.id.clone(), subscriber);
    }
    
    // å–æ¶ˆæ³¨å†Œè®¢é˜…è€…
    async fn unregister(&self, subscriber_id: &str) {
        let mut subscribers = self.subscribers.write().await;
        subscribers.remove(subscriber_id);
        
        // æ¸…ç†ä¸»é¢˜è®¢é˜…
        let mut topics = self.topics.write().await;
        for subscribers_set in topics.values_mut() {
            subscribers_set.remove(subscriber_id);
        }
    }
    
    // è®¢é˜…ä¸»é¢˜
    async fn subscribe(&self, subscriber_id: &str, topic: &str) {
        let subscribers = self.subscribers.read().await;
        if !subscribers.contains_key(subscriber_id) {
            return;
        }
        
        let mut topics = self.topics.write().await;
        let subscribers_set = topics
            .entry(topic.to_string())
            .or_insert_with(HashSet::new);
        
        subscribers_set.insert(subscriber_id.to_string());
    }
    
    // å–æ¶ˆè®¢é˜…ä¸»é¢˜
    async fn unsubscribe(&self, subscriber_id: &str, topic: &str) {
        let mut topics = self.topics.write().await;
        if let Some(subscribers_set) = topics.get_mut(topic) {
            subscribers_set.remove(subscriber_id);
        }
    }
    
    // å‘å¸ƒæ¶ˆæ¯åˆ°ä¸»é¢˜
    async fn publish(&self, message: TextMessage) {
        let topics = self.topics.read().await;
        let subscribers = self.subscribers.read().await;
        
        if let Some(subscriber_ids) = topics.get(&message.topic) {
            for subscriber_id in subscriber_ids {
                if let Some(subscriber) = subscribers.get(subscriber_id) {
                    let message_clone = message.clone();
                    let subscriber_clone = subscriber.clone();
                    
                    // å¼‚æ­¥å‘é€æ¶ˆæ¯
                    tokio::spawn(async move {
                        subscriber_clone.receive(message_clone).await;
                    });
                }
            }
        }
    }
    
    // è·å–ä¸»é¢˜è®¢é˜…è€…æ•°é‡
    async fn subscriber_count(&self, topic: &str) -> usize {
        let topics = self.topics.read().await;
        topics.get(topic).map(|set| set.len()).unwrap_or(0)
    }
    
    // è·å–æ‰€æœ‰ä¸»é¢˜
    async fn get_topics(&self) -> Vec<String> {
        let topics = self.topics.read().await;
        topics.keys().cloned().collect()
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºæ¶ˆæ¯ä»£ç†
    let broker = Arc::new(MessageBroker::new());
    
    // åˆ›å»ºè®¢é˜…è€…
    let subscriber1 = Arc::new(Subscriber::new(
        "è®¢é˜…è€…1", 
        Box::new(LoggingHandler { prefix: "è®¢é˜…è€…1".to_string() })
    ));
    
    let subscriber2 = Arc::new(Subscriber::new(
        "è®¢é˜…è€…2", 
        Box::new(LoggingHandler { prefix: "è®¢é˜…è€…2".to_string() })
    ));
    
    let subscriber3 = Arc::new(Subscriber::new(
        "è¿‡æ»¤è®¢é˜…è€…", 
        Box::new(FilteringHandler { 
            prefix: "è¿‡æ»¤å™¨".to_string(),
            filter_word: "é‡è¦".to_string()
        })
    ));
    
    // æ³¨å†Œè®¢é˜…è€…
    broker.register(subscriber1.clone()).await;
    broker.register(subscriber2.clone()).await;
    broker.register(subscriber3.clone()).await;
    
    // è®¢é˜…ä¸»é¢˜
    broker.subscribe(&subscriber1.id, "æ–°é—»").await;
    broker.subscribe(&subscriber1.id, "ä½“è‚²").await;
    broker.subscribe(&subscriber2.id, "ç§‘æŠ€").await;
    broker.subscribe(&subscriber3.id, "æ–°é—»").await;
    broker.subscribe(&subscriber3.id, "ç§‘æŠ€").await;
    
    // å‘å¸ƒæ¶ˆæ¯
    let message1 = TextMessage {
        id: Uuid::new_v4().to_string(),
        topic: "æ–°é—»".to_string(),
        content: "é‡è¦æ–°é—»ï¼šä»Šå¤©æ˜¯æ™´å¤©".to_string(),
        timestamp: chrono::Utc::now().timestamp() as u64,
    };
    
    let message2 = TextMessage {
        id: Uuid::new_v4().to_string(),
        topic: "ä½“è‚²".to_string(),
        content: "ä½“è‚²èµ›äº‹ï¼šè¶³çƒæ¯”èµ›ç»“æœ".to_string(),
        timestamp: chrono::Utc::now().timestamp() as u64,
    };
    
    let message3 = TextMessage {
        id: Uuid::new_v4().to_string(),
        topic: "ç§‘æŠ€".to_string(),
        content: "ç§‘æŠ€æ–°é—»ï¼šé‡è¦æŠ€æœ¯çªç ´".to_string(),
        timestamp: chrono::Utc::now().timestamp() as u64,
    };
    
    println!("å¼€å§‹å‘å¸ƒæ¶ˆæ¯...");
    broker.publish(message1).await;
    broker.publish(message2).await;
    broker.publish(message3).await;
    
    // ç­‰å¾…æ¶ˆæ¯å¤„ç†
    tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
    
    // æŸ¥çœ‹ä¸»é¢˜è®¢é˜…æƒ…å†µ
    let topics = broker.get_topics().await;
    for topic in &topics {
        let count = broker.subscriber_count(topic).await;
        println!("ä¸»é¢˜ '{}' æœ‰ {} ä¸ªè®¢é˜…è€…", topic, count);
    }
    
    // å–æ¶ˆè®¢é˜…
    println!("\nè®¢é˜…è€…1å–æ¶ˆè®¢é˜…'ä½“è‚²'ä¸»é¢˜");
    broker.unsubscribe(&subscriber1.id, "ä½“è‚²").await;
    
    // å†æ¬¡å‘å¸ƒæ¶ˆæ¯
    let message4 = TextMessage {
        id: Uuid::new_v4().to_string(),
        topic: "ä½“è‚²".to_string(),
        content: "æ›´å¤šä½“è‚²æ–°é—»ï¼šç¯®çƒæ¯”èµ›ç»“æœ".to_string(),
        timestamp: chrono::Utc::now().timestamp() as u64,
    };
    
    println!("\nå‘å¸ƒæ›´å¤šæ¶ˆæ¯...");
    broker.publish(message4).await;
    
    // ç­‰å¾…æ¶ˆæ¯å¤„ç†
    tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
    
    // å–æ¶ˆæ³¨å†Œè®¢é˜…è€…
    println!("\nå–æ¶ˆæ³¨å†Œè®¢é˜…è€…2");
    broker.unregister(&subscriber2.id).await;
    
    // å†æ¬¡å‘å¸ƒæ¶ˆæ¯
    let message5 = TextMessage {
        id: Uuid::new_v4().to_string(),
        topic: "ç§‘æŠ€".to_string(),
        content: "ç§‘æŠ€æ–°é—»ï¼šåˆä¸€é¡¹é‡è¦çªç ´".to_string(),
        timestamp: chrono::Utc::now().timestamp() as u64,
    };
    
    println!("\næœ€åå‘å¸ƒæ¶ˆæ¯...");
    broker.publish(message5).await;
    
    // ç­‰å¾…æ¶ˆæ¯å¤„ç†
    tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
}
```

### 8.2 æ¶ˆæ¯é˜Ÿåˆ—

æ¶ˆæ¯é˜Ÿåˆ—æ¨¡å¼æä¾›å¼‚æ­¥ç‚¹å¯¹ç‚¹é€šä¿¡ï¼Œå…è®¸ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…è§£è€¦ï¼Œå¹¶æ”¯æŒæ¶ˆæ¯ç¼“å†²ã€è´Ÿè½½å‡è¡¡å’Œå¯é ä¼ é€’ã€‚

```rust
use std::collections::{HashMap, VecDeque};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{mpsc, Mutex, RwLock};
use serde::{Serialize, Deserialize};
use uuid::Uuid;

// æ¶ˆæ¯çŠ¶æ€
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
enum MessageStatus {
    Queued,
    Processing,
    Completed,
    Failed,
}

// æ¶ˆæ¯ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize)]
struct Message {
    id: String,
    queue: String,
    payload: Vec<u8>,
    created_at: u64,
    visibility_timeout: u64,
    processing_started: Option<u64>,
    attempts: u32,
}

impl Message {
    fn new(queue: &str, payload: Vec<u8>) -> Self {
        Self {
            id: Uuid::new_v4().to_string(),
            queue: queue.to_string(),
            payload,
            created_at: chrono::Utc::now().timestamp() as u64,
            visibility_timeout: 30, // é»˜è®¤30ç§’
            processing_started: None,
            attempts: 0,
        }
    }
}

// é˜Ÿåˆ—è®¾ç½®
#[derive(Debug, Clone)]
struct QueueSettings {
    max_size: usize,
    visibility_timeout: u64,
    max_attempts: u32,
    dead_letter_queue: Option<String>,
}

impl Default for QueueSettings {
    fn default() -> Self {
        Self {
            max_size: 10000,
            visibility_timeout: 30,
            max_attempts: 3,
            dead_letter_queue: None,
        }
    }
}

// æ¶ˆæ¯é˜Ÿåˆ—ç®¡ç†å™¨
struct MessageQueue {
    queues: RwLock<HashMap<String, QueueSettings>>,
    messages: RwLock<HashMap<String, HashMap<String, Message>>>,
    in_flight: RwLock<HashMap<String, HashMap<String, Message>>>,
    timers: Mutex<HashMap<String, tokio::task::JoinHandle<()>>>,
}

impl MessageQueue {
    fn new() -> Self {
        Self {
            queues: RwLock::new(HashMap::new()),
            messages: RwLock::new(HashMap::new()),
            in_flight: RwLock::new(HashMap::new()),
            timers: Mutex::new(HashMap::new()),
        }
    }
    
    // åˆ›å»ºä¸€ä¸ªæ–°é˜Ÿåˆ—
    async fn create_queue(&self, name: &str, settings: QueueSettings) -> Result<(), String> {
        let mut queues = self.queues.write().await;
        if queues.contains_key(name) {
            return Err(format!("é˜Ÿåˆ— '{}' å·²å­˜åœ¨", name));
        }
        
        queues.insert(name.to_string(), settings);
        
        // åˆå§‹åŒ–æ¶ˆæ¯å­˜å‚¨
        let mut messages = self.messages.write().await;
        messages.insert(name.to_string(), HashMap::new());
        
        // åˆå§‹åŒ–in-flightå­˜å‚¨
        let mut in_flight = self.in_flight.write().await;
        in_flight.insert(name.to_string(), HashMap::new());
        
        // å¯åŠ¨å¯è§æ€§è¶…æ—¶æ£€æŸ¥å™¨
        self.start_visibility_checker(name).await;
        
        Ok(())
    }
    
    // å‘é€æ¶ˆæ¯åˆ°é˜Ÿåˆ—
    async fn send(&self, queue_name: &str, payload: Vec<u8>) -> Result<String, String> {
        // æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å­˜åœ¨
        let queues = self.queues.read().await;
        let settings = match queues.get(queue_name) {
            Some(settings) => settings.clone(),
            None => return Err(format!("é˜Ÿåˆ— '{}' ä¸å­˜åœ¨", queue_name)),
        };
        
        // åˆ›å»ºæ¶ˆæ¯
        let mut message = Message::new(queue_name, payload);
        message.visibility_timeout = settings.visibility_timeout;
        
        // æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å·²æ»¡
        let mut messages = self.messages.write().await;
        let queue_messages = messages.get_mut(queue_name).unwrap();
        
        if queue_messages.len() >= settings.max_size {
            return Err(format!("é˜Ÿåˆ— '{}' å·²æ»¡", queue_name));
        }
        
        // æ·»åŠ æ¶ˆæ¯åˆ°é˜Ÿåˆ—
        let message_id = message.id.clone();
        queue_messages.insert(message_id.clone(), message);
        
        Ok(message_id)
    }
    
    // æ¥æ”¶æ¶ˆæ¯
    async fn receive(&self, queue_name: &str, max_messages: usize) -> Result<Vec<Message>, String> {
        // æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å­˜åœ¨
        let queues = self.queues.read().await;
        if !queues.contains_key(queue_name) {
            return Err(format!("é˜Ÿåˆ— '{}' ä¸å­˜åœ¨", queue_name));
        }
        
        let now = chrono::Utc::now().timestamp() as u64;
        let mut result = Vec::new();
        
        // è·å–æ¶ˆæ¯
        let mut messages = self.messages.write().await;
        let mut in_flight = self.in_flight.write().await;
        
        let queue_messages = messages.get_mut(queue_name).unwrap();
        let in_flight_messages = in_flight.get_mut(queue_name).unwrap();
        
        // ç­›é€‰å¯è§çš„æ¶ˆæ¯
        let mut available_messages = Vec::new();
        for (id, message) in queue_messages.iter() {
            available_messages.push(id.clone());
            if available_messages.len() >= max_messages {
                break;
            }
        }
        
        // ç§»åŠ¨æ¶ˆæ¯åˆ°in-flightçŠ¶æ€
        for message_id in available_messages {
            if let Some(mut message) = queue_messages.remove(&message_id) {
                message.processing_started = Some(now);
                message.attempts += 1;
                
                result.push(message.clone());
                in_flight_messages.insert(message_id, message);
            }
        }
        
        Ok(result)
    }
    
    // å®Œæˆå¤„ç†æ¶ˆæ¯
    async fn complete(&self, queue_name: &str, message_id: &str) -> Result<(), String> {
        // æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å­˜åœ¨
        let queues = self.queues.read().await;
        if !queues.contains_key(queue_name) {
            return Err(format!("é˜Ÿåˆ— '{}' ä¸å­˜åœ¨", queue_name));
        }
        
        // ä»in-flightä¸­åˆ é™¤æ¶ˆæ¯
        let mut in_flight = self.in_flight.write().await;
        let in_flight_messages = in_flight.get_mut(queue_name).unwrap();
        
        if in_flight_messages.remove(message_id).is_none() {
            return Err(format!("æ¶ˆæ¯ '{}' ä¸åœ¨å¤„ç†ä¸­", message_id));
        }
        
        Ok(())
    }
    
    // æ ‡è®°æ¶ˆæ¯å¤„ç†å¤±è´¥
    async fn fail(&self, queue_name: &str, message_id: &str) -> Result<(), String> {
        // æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å­˜åœ¨
        let queues = self.queues.read().await;
        let settings = match queues.get(queue_name) {
            Some(settings) => settings.clone(),
            None => return Err(format!("é˜Ÿåˆ— '{}' ä¸å­˜åœ¨", queue_name)),
        };
        
        // ä»in-flightä¸­è·å–æ¶ˆæ¯
        let mut in_flight = self.in_flight.write().await;
        let in_flight_messages = in_flight.get_mut(queue_name).unwrap();
        
        let message = match in_flight_messages.remove(message_id) {
            Some(message) => message,
            None => return Err(format!("æ¶ˆæ¯ '{}' ä¸åœ¨å¤„ç†ä¸­", message_id)),
        };
        
        // æ£€æŸ¥é‡è¯•æ¬¡æ•°
        if message.attempts >= settings.max_attempts {
            // å¦‚æœæœ‰æ­»ä¿¡é˜Ÿåˆ—ï¼Œåˆ™ç§»åŠ¨åˆ°æ­»ä¿¡é˜Ÿåˆ—
            if let Some(dlq) = &settings.dead_letter_queue {
                if queues.contains_key(dlq) {
                    drop(queues); // é‡Šæ”¾è¯»é”
                    self.send(dlq, message.payload).await?;
                }
            }
        } else {
            // å¦åˆ™å°†æ¶ˆæ¯æ”¾å›é˜Ÿåˆ—
            let mut messages = self.messages.write().await;
            let queue_messages = messages.get_mut(queue_name).unwrap();
            queue_messages.insert(message_id.to_string(), message);
        }
        
        Ok(())
    }
    
    // å¯åŠ¨å¯è§æ€§è¶…æ—¶æ£€æŸ¥å™¨
    async fn start_visibility_checker(&self, queue_name: &str) {
        let queue_name = queue_name.to_string();
        let queue_clone = Arc::new(self.clone());
        
        let handle = tokio::spawn(async move {
            let mut interval = tokio::time::interval(Duration::from_secs(1));
            
            loop {
                interval.tick().await;
                queue_clone.check_visibility_timeouts(&queue_name).await;
            }
        });
        
        let mut timers = self.timers.lock().await;
        timers.insert(queue_name, handle);
    }
    
    // æ£€æŸ¥å¯è§æ€§è¶…æ—¶
    async fn check_visibility_timeouts(&self, queue_name: &str) {
        let now = chrono::Utc::now().timestamp() as u64;
        
        // è·å–in-flightæ¶ˆæ¯
        let mut in_flight = self.in_flight.write().await;
        let in_flight_messages = match in_flight.get_mut(queue_name) {
            Some(messages) => messages,
            None => return,
        };
        
        // æ£€æŸ¥è¶…æ—¶æ¶ˆæ¯
        let mut timed_out_messages = Vec::new();
        for (id, message) in in_flight_messages.iter() {
            if let Some(started) = message.processing_started {
                if now - started > message.visibility_timeout {
                    timed_out_messages.push(id.clone());
                }
            }
        }
        
        // å¤„ç†è¶…æ—¶æ¶ˆæ¯
        if !timed_out_messages.is_empty() {
            drop(in_flight); // é‡Šæ”¾å†™é”
            
            for message_id in timed_out_messages {
                let _ = self.fail(queue_name, &message_id).await;
            }
        }
    }
    
    // è·å–é˜Ÿåˆ—é•¿åº¦
    async fn queue_length(&self, queue_name: &str) -> Result<usize, String> {
        let messages = self.messages.read().await;
        match messages.get(queue_name) {
            Some(queue_messages) => Ok(queue_messages.len()),
            None => Err(format!("é˜Ÿåˆ— '{}' ä¸å­˜åœ¨", queue_name)),
        }
    }
    
    // è·å–æ­£åœ¨å¤„ç†çš„æ¶ˆæ¯æ•°
    async fn in_flight_count(&self, queue_name: &str) -> Result<usize, String> {
        let in_flight = self.in_flight.read().await;
        match in_flight.get(queue_name) {
            Some(in_flight_messages) => Ok(in_flight_messages.len()),
            None => Err(format!("é˜Ÿåˆ— '{}' ä¸å­˜åœ¨", queue_name)),
        }
    }
}

impl Clone for MessageQueue {
    fn clone(&self) -> Self {
        Self {
            queues: self.queues.clone(),
            messages: self.messages.clone(),
            in_flight: self.in_flight.clone(),
            timers: self.timers.clone(),
        }
    }
}

// ç”Ÿäº§è€…æ¥å£
struct Producer {
    queue: Arc<MessageQueue>,
}

impl Producer {
    fn new(queue: Arc<MessageQueue>) -> Self {
        Self { queue }
    }
    
    async fn send(&self, queue_name: &str, data: &str) -> Result<String, String> {
        self.queue.send(queue_name, data.as_bytes().to_vec()).await
    }
}

// æ¶ˆè´¹è€…æ¥å£
struct Consumer {
    queue: Arc<MessageQueue>,
    queue_name: String,
}

impl Consumer {
    fn new(queue: Arc<MessageQueue>, queue_name: &str) -> Self {
        Self {
            queue,
            queue_name: queue_name.to_string(),
        }
    }
    
    async fn receive(&self, max_messages: usize) -> Result<Vec<(String, String)>, String> {
        let messages = self.queue.receive(&self.queue_name, max_messages).await?;
        
        let mut result = Vec::new();
        for message in messages {
            let payload = String::from_utf8(message.payload.clone())
                .map_err(|e| format!("è§£ææ¶ˆæ¯å¤±è´¥: {}", e))?;
            
            result.push((message.id, payload));
        }
        
        Ok(result)
    }
    
    async fn complete(&self, message_id: &str) -> Result<(), String> {
        self.queue.complete(&self.queue_name, message_id).await
    }
    
    async fn fail(&self, message_id: &str) -> Result<(), String> {
        self.queue.fail(&self.queue_name, message_id).await
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºæ¶ˆæ¯é˜Ÿåˆ—
    let queue = Arc::new(MessageQueue::new());
    
    // åˆ›å»ºä¸»é˜Ÿåˆ—
    let main_settings = QueueSettings {
        max_size: 1000,
        visibility_timeout: 10,
        max_attempts: 3,
        dead_letter_queue: Some("dead_letter".to_string()),
    };
    
    queue.create_queue("main", main_settings).await.unwrap();
    
    // åˆ›å»ºæ­»ä¿¡é˜Ÿåˆ—
    let dlq_settings = QueueSettings {
        max_size: 1000,
        visibility_timeout: 60,
        max_attempts: 1,
        dead_letter_queue: None,
    };
    
    queue.create_queue("dead_letter", dlq_settings).await.unwrap();
    
    // åˆ›å»ºç”Ÿäº§è€…
    let producer = Producer::new(queue.clone());
    
    // åˆ›å»ºæ¶ˆè´¹è€…
    let consumer1 = Consumer::new(queue.clone(), "main");
    let consumer2 = Consumer::new(queue.clone(), "main");
    let dlq_consumer = Consumer::new(queue.clone(), "dead_letter");
    
    // ç”Ÿäº§ä¸€äº›æ¶ˆæ¯
    println!("ç”Ÿäº§æ¶ˆæ¯...");
    for i in 1..=10 {
        let message_id = producer.send("main", &format!("æ¶ˆæ¯å†…å®¹ #{}", i)).await.unwrap();
        println!("å‘é€æ¶ˆæ¯ #{}: ID = {}", i, message_id);
    }
    
    // æ£€æŸ¥é˜Ÿåˆ—é•¿åº¦
    let length = queue.queue_length("main").await.unwrap();
    println!("é˜Ÿåˆ—é•¿åº¦: {}", length);
    
    // æ¶ˆè´¹è€…1æ¶ˆè´¹ä¸€äº›æ¶ˆæ¯
    println!("\næ¶ˆè´¹è€…1æ¥æ”¶æ¶ˆæ¯...");
    let messages1 = consumer1.receive(3).await.unwrap();
    for (id, content) in &messages1 {
        println!("æ¶ˆè´¹è€…1æ”¶åˆ°: {} - {}", id, content);
    }
    
    // æ¶ˆè´¹è€…2æ¶ˆè´¹ä¸€äº›æ¶ˆæ¯
    println!("\næ¶ˆè´¹è€…2æ¥æ”¶æ¶ˆæ¯...");
    let messages2 = consumer2.receive(4).await.unwrap();
    for (id, content) in &messages2 {
        println!("æ¶ˆè´¹è€…2æ”¶åˆ°: {} - {}", id, content);
    }
    
    // æ£€æŸ¥in-flightè®¡æ•°
    let in_flight = queue.in_flight_count("main").await.unwrap();
    println!("æ­£åœ¨å¤„ç†çš„æ¶ˆæ¯æ•°: {}", in_flight);
    
    // æ¶ˆè´¹è€…1å®Œæˆä¸€äº›æ¶ˆæ¯
    println!("\næ¶ˆè´¹è€…1å®Œæˆå¤„ç†...");
    for (id, _) in messages1.iter().take(2) {
        consumer1.complete(id).await.unwrap();
        println!("æ¶ˆè´¹è€…1å®Œæˆ: {}", id);
    }
    
    // æ¶ˆè´¹è€…2å°†ä¸€äº›æ¶ˆæ¯æ ‡è®°ä¸ºå¤±è´¥
    println!("\næ¶ˆè´¹è€…2æ ‡è®°å¤±è´¥...");
    for (id, _) in messages2.iter().take(2) {
        consumer2.fail(id).await.unwrap();
        println!("æ¶ˆè´¹è€…2å¤±è´¥: {}", id);
    }
    
    // å†æ¬¡æ£€æŸ¥é˜Ÿåˆ—é•¿åº¦å’Œin-flightè®¡æ•°
    let length = queue.queue_length("main").await.unwrap();
    let in_flight = queue.in_flight_count("main").await.unwrap();
    println!("é˜Ÿåˆ—é•¿åº¦: {}, æ­£åœ¨å¤„ç†: {}", length, in_flight);
    
    // ç­‰å¾…å¯è§æ€§è¶…æ—¶
    println!("\nç­‰å¾…å¯è§æ€§è¶…æ—¶...");
    tokio::time::sleep(Duration::from_secs(11)).await;
    
    // æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€
    let length = queue.queue_length("main").await.unwrap();
    let in_flight = queue.in_flight_count("main").await.unwrap();
    let dlq_length = queue.queue_length("dead_letter").await.unwrap();
    
    println!("è¶…æ—¶å:");
    println!("  ä¸»é˜Ÿåˆ—é•¿åº¦: {}", length);
    println!("  æ­£åœ¨å¤„ç†: {}", in_flight);
    println!("  æ­»ä¿¡é˜Ÿåˆ—é•¿åº¦: {}", dlq_length);
    
    // ä»æ­»ä¿¡é˜Ÿåˆ—æ¥æ”¶æ¶ˆæ¯
    if dlq_length > 0 {
        println!("\nä»æ­»ä¿¡é˜Ÿåˆ—æ¥æ”¶æ¶ˆæ¯...");
        let dlq_messages = dlq_consumer.receive(10).await.unwrap();
        for (id, content) in &dlq_messages {
            println!("æ­»ä¿¡é˜Ÿåˆ—æ¶ˆæ¯: {} - {}", id, content);
            dlq_consumer.complete(id).await.unwrap();
        }
    }
}
```

### 8.3 è¯·æ±‚-å“åº”

è¯·æ±‚-å“åº”æ˜¯ä¸€ç§å¸¸è§çš„é€šä¿¡æ¨¡å¼ï¼Œå®¢æˆ·ç«¯å‘é€è¯·æ±‚ï¼ŒæœåŠ¡å™¨å¤„ç†å¹¶è¿”å›å“åº”ã€‚

```rust
use std::collections::HashMap;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{mpsc, oneshot, Mutex, RwLock};
use serde::{Serialize, Deserialize};
use uuid::Uuid;

// è¯·æ±‚å’Œå“åº”ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize)]
struct Request {
    id: String,
    service: String,
    method: String,
    payload: Vec<u8>,
    timeout_ms: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct Response {
    request_id: String,
    status: ResponseStatus,
    payload: Vec<u8>,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
enum ResponseStatus {
    Success,
    Error,
    Timeout,
    ServiceUnavailable,
}

// è¯·æ±‚å¤„ç†å‡½æ•°ç±»å‹
type RequestHandler = Arc<dyn Fn(Request) -> Response + Send + Sync>;

// æœåŠ¡æ³¨å†Œè¡¨
struct ServiceRegistry {
    services: RwLock<HashMap<String, HashMap<String, RequestHandler>>>,
}

impl ServiceRegistry {
    fn new() -> Self {
        Self {
            services: RwLock::new(HashMap::new()),
        }
    }
    
    // æ³¨å†ŒæœåŠ¡å¤„ç†å‡½æ•°
    async fn register_handler<F>(&self, service: &str, method: &str, handler: F)
    where
        F: Fn(Request) -> Response + Send + Sync + 'static,
    {
        let mut services = self.services.write().await;
        
        let service_methods = services
            .entry(service.to_string())
            .or_insert_with(HashMap::new);
        
        service_methods.insert(method.to_string(), Arc::new(handler));
    }
    
    // æŸ¥æ‰¾å¤„ç†å‡½æ•°
    async fn find_handler(&self, service: &str, method: &str) -> Option<RequestHandler> {
        let services = self.services.read().await;
        
        services.get(service)
            .and_then(|methods| methods.get(method).cloned())
    }
    
    // åˆ—å‡ºæ‰€æœ‰æ³¨å†Œçš„æœåŠ¡å’Œæ–¹æ³•
    async fn list_services(&self) -> HashMap<String, Vec<String>> {
        let services = self.services.read().await;
        let mut result = HashMap::new();
        
        for (service, methods) in services.iter() {
            result.insert(
                service.clone(),
                methods.keys().cloned().collect(),
            );
        }
        
        result
    }
}

// æ¶ˆæ¯è·¯ç”±å™¨
struct MessageRouter {
    registry: Arc<ServiceRegistry>,
    pending: Mutex<HashMap<String, oneshot::Sender<Response>>>,
}

impl MessageRouter {
    fn new(registry: Arc<ServiceRegistry>) -> Self {
        Self {
            registry,
            pending: Mutex::new(HashMap::new()),
        }
    }
    
    // å‘é€è¯·æ±‚å¹¶ç­‰å¾…å“åº”
    async fn send_request(&self, request: Request) -> Result<Response, String> {
        let (response_tx, response_rx) = oneshot::channel();
        
        // å­˜å‚¨å“åº”é€šé“
        let request_id = request.id.clone();
        let mut pending = self.pending.lock().await;
        pending.insert(request_id.clone(), response_tx);
        drop(pending);
        
        // å¤„ç†è¯·æ±‚
        let router = self.clone();
        let request_clone = request.clone();
        
        tokio::spawn(async move {
            router.handle_request(request_clone).await;
        });
        
        // ç­‰å¾…å“åº”æˆ–è¶…æ—¶
        let timeout = Duration::from_millis(request.timeout_ms);
        match tokio::time::timeout(timeout, response_rx).await {
            Ok(Ok(response)) => Ok(response),
            Ok(Err(_)) => {
                // æ¥æ”¶æ–¹å·²å…³é—­
                Err("æ¥æ”¶å“åº”å¤±è´¥".to_string())
            }
            Err(_) => {
                // è¶…æ—¶
                let mut pending = self.pending.lock().await;
                pending.remove(&request_id);
                
                Ok(Response {
                    request_id,
                    status: ResponseStatus::Timeout,
                    payload: Vec::new(),
                })
            }
        }
    }
    
    // å¤„ç†ä¼ å…¥çš„è¯·æ±‚
    async fn handle_request(&self, request: Request) {
        let service = request.service.clone();
        let method = request.method.clone();
        
        // æŸ¥æ‰¾å¤„ç†å‡½æ•°
        let handler = self.registry.find_handler(&service, &method).await;
        
        let response = match handler {
            Some(handler) => handler(request.clone()),
            None => Response {
                request_id: request.id.clone(),
                status: ResponseStatus::ServiceUnavailable,
                payload: Vec::new(),
            },
        };
        
        // å‘é€å“åº”
        let mut pending = self.pending.lock().await;
        if let Some(tx) = pending.remove(&request.id) {
            let _ = tx.send(response);
        }
    }
    
    // ç›´æ¥å‘é€å“åº”ï¼ˆç”¨äºå¼‚æ­¥å¤„ç†ï¼‰
    async fn send_response(&self, response: Response) -> Result<(), String> {
        let mut pending = self.pending.lock().await;
        
        match pending.remove(&response.request_id) {
            Some(tx) => {
                tx.send(response).map_err(|_| "å‘é€å“åº”å¤±è´¥".to_string())
            }
            None => Err(format!("æœªæ‰¾åˆ°è¯·æ±‚ID: {}", response.request_id)),
        }
    }
}

impl Clone for MessageRouter {
    fn clone(&self) -> Self {
        Self {
            registry: self.registry.clone(),
            pending: self.pending.clone(),
        }
    }
}

// å®¢æˆ·ç«¯ - å‘é€è¯·æ±‚
struct Client {
    router: Arc<MessageRouter>,
    timeout_ms: u64,
}

impl Client {
    fn new(router: Arc<MessageRouter>, timeout_ms: u64) -> Self {
        Self { router, timeout_ms }
    }
    
    async fn call(&self, service: &str, method: &str, payload: Vec<u8>) -> Result<Response, String> {
        let request = Request {
            id: Uuid::new_v4().to_string(),
            service: service.to_string(),
            method: method.to_string(),
            payload,
            timeout_ms: self.timeout_ms,
        };
        
        self.router.send_request(request).await
    }
    
    async fn call_with_timeout(&self, service: &str, method: &str, payload: Vec<u8>, timeout_ms: u64) -> Result<Response, String> {
        let request = Request {
            id: Uuid::new_v4().to_string(),
            service: service.to_string(),
            method: method.to_string(),
            payload,
            timeout_ms,
        };
        
        self.router.send_request(request).await
    }
}

// æœåŠ¡å™¨ - å¤„ç†è¯·æ±‚
struct Server {
    registry: Arc<ServiceRegistry>,
    name: String,
}

impl Server {
    fn new(registry: Arc<ServiceRegistry>, name: &str) -> Self {
        Self {
            registry,
            name: name.to_string(),
        }
    }
    
    // æ³¨å†Œå¤„ç†å‡½æ•°
    async fn register<F>(&self, method: &str, handler: F)
    where
        F: Fn(Request) -> Response + Send + Sync + 'static,
    {
        self.registry.register_handler(&self.name, method, handler).await;
    }

/*
<think>
æˆ‘åº”è¯¥ç»§ç»­ä¹‹å‰çš„ä»£ç ç¤ºä¾‹ï¼Œå®Œæˆè¯·æ±‚-å“åº”æ¨¡å¼çš„å®ç°ï¼Œå¹¶å¯èƒ½ç»§ç»­è®²è§£å…¶ä»–æ¶ˆæ¯ä¼ é€’æ¨¡å¼ã€‚æˆ‘å°†ç»§ç»­ä»£ç ç¤ºä¾‹ï¼Œå®Œæˆç›¸å…³å®ç°ã€‚
</think>
*/

    // æ³¨å†Œå¼‚æ­¥å¤„ç†å‡½æ•°
    async fn register_async<F, Fut>(&self, method: &str, router: Arc<MessageRouter>, handler: F)
    where
        F: Fn(Request) -> Fut + Send + Sync + 'static,
        Fut: std::future::Future<Output = Response> + Send + 'static,
    {
        let service_name = self.name.clone();
        let router_clone = router.clone();
        
        self.registry.register_handler(&self.name, method, move |request| {
            let request_id = request.id.clone();
            let router = router_clone.clone();
            
            // åˆ›å»ºä¸€ä¸ªé»˜è®¤å“åº”ï¼Œè¡¨ç¤ºå¤„ç†ä¸­
            let response = Response {
                request_id: request_id.clone(),
                status: ResponseStatus::Timeout, // ä¸´æ—¶çŠ¶æ€
                payload: Vec::new(),
            };
            
            // åˆ›å»ºå¼‚æ­¥ä»»åŠ¡å¤„ç†è¯·æ±‚
            let request_clone = request.clone();
            tokio::spawn(async move {
                let result = handler(request_clone).await;
                let _ = router.send_response(result).await;
            });
            
            // è¿”å›ä¸´æ—¶å“åº”ï¼Œä½†å®é™…ç»“æœå°†é€šè¿‡routerå¼‚æ­¥å‘é€
            response
        }).await;
    }
}

// è¯·æ±‚å’Œå“åº”ç¼–è§£ç å™¨å·¥å…·
struct Codec;

impl Codec {
    // å°†è¯·æ±‚åºåˆ—åŒ–ä¸ºå­—èŠ‚
    fn serialize_request(request: &Request) -> Result<Vec<u8>, String> {
        bincode::serialize(request)
            .map_err(|e| format!("åºåˆ—åŒ–è¯·æ±‚å¤±è´¥: {}", e))
    }
    
    // ä»å­—èŠ‚ååºåˆ—åŒ–è¯·æ±‚
    fn deserialize_request(bytes: &[u8]) -> Result<Request, String> {
        bincode::deserialize(bytes)
            .map_err(|e| format!("ååºåˆ—åŒ–è¯·æ±‚å¤±è´¥: {}", e))
    }
    
    // å°†å“åº”åºåˆ—åŒ–ä¸ºå­—èŠ‚
    fn serialize_response(response: &Response) -> Result<Vec<u8>, String> {
        bincode::serialize(response)
            .map_err(|e| format!("åºåˆ—åŒ–å“åº”å¤±è´¥: {}", e))
    }
    
    // ä»å­—èŠ‚ååºåˆ—åŒ–å“åº”
    fn deserialize_response(bytes: &[u8]) -> Result<Response, String> {
        bincode::deserialize(bytes)
            .map_err(|e| format!("ååºåˆ—åŒ–å“åº”å¤±è´¥: {}", e))
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºæœåŠ¡æ³¨å†Œè¡¨
    let registry = Arc::new(ServiceRegistry::new());
    
    // åˆ›å»ºæ¶ˆæ¯è·¯ç”±å™¨
    let router = Arc::new(MessageRouter::new(registry.clone()));
    
    // åˆ›å»ºæœåŠ¡å™¨å’Œå®¢æˆ·ç«¯
    let echo_server = Server::new(registry.clone(), "echo");
    let math_server = Server::new(registry.clone(), "math");
    let client = Client::new(router.clone(), 5000); // 5ç§’è¶…æ—¶
    
    // æ³¨å†ŒåŒæ­¥å¤„ç†å‡½æ•°
    echo_server.register("ping", |request| {
        println!("å¤„ç† ping è¯·æ±‚...");
        
        // ç®€å•çš„å›æ˜¾åŠŸèƒ½
        Response {
            request_id: request.id,
            status: ResponseStatus::Success,
            payload: request.payload,
        }
    }).await;
    
    // æ³¨å†Œè®¡ç®—å¹³æ–¹çš„å¤„ç†å‡½æ•°
    math_server.register("square", |request| {
        println!("å¤„ç† square è¯·æ±‚...");
        
        // è§£ææ•°å­—ï¼Œè®¡ç®—å¹³æ–¹
        match String::from_utf8(request.payload) {
            Ok(payload_str) => {
                match payload_str.parse::<i32>() {
                    Ok(number) => {
                        let result = number * number;
                        Response {
                            request_id: request.id,
                            status: ResponseStatus::Success,
                            payload: result.to_string().into_bytes(),
                        }
                    },
                    Err(_) => Response {
                        request_id: request.id,
                        status: ResponseStatus::Error,
                        payload: "æ— æ•ˆçš„æ•°å­—æ ¼å¼".to_string().into_bytes(),
                    },
                }
            },
            Err(_) => Response {
                request_id: request.id,
                status: ResponseStatus::Error,
                payload: "æ— æ•ˆçš„UTF-8æ•°æ®".to_string().into_bytes(),
            },
        }
    }).await;
    
    // æ³¨å†Œä¸€ä¸ªæ…¢é€Ÿå¤„ç†å‡½æ•°
    math_server.register("slow_operation", |request| {
        println!("å¤„ç† slow_operation è¯·æ±‚...");
        
        // æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
        std::thread::sleep(Duration::from_millis(3000));
        
        Response {
            request_id: request.id,
            status: ResponseStatus::Success,
            payload: "æ…¢æ“ä½œå·²å®Œæˆ".to_string().into_bytes(),
        }
    }).await;
    
    // æ³¨å†Œå¼‚æ­¥å¤„ç†å‡½æ•°
    math_server.register_async("async_operation", router.clone(), |request| async move {
        println!("å¼‚æ­¥å¤„ç† async_operation è¯·æ±‚...");
        
        // æ¨¡æ‹Ÿå¼‚æ­¥è€—æ—¶æ“ä½œ
        tokio::time::sleep(Duration::from_millis(2000)).await;
        
        Response {
            request_id: request.id,
            status: ResponseStatus::Success,
            payload: "å¼‚æ­¥æ“ä½œå·²å®Œæˆ".to_string().into_bytes(),
        }
    }).await;
    
    // åˆ—å‡ºå·²æ³¨å†Œçš„æœåŠ¡
    let services = registry.list_services().await;
    println!("å·²æ³¨å†Œçš„æœåŠ¡:");
    for (service, methods) in &services {
        println!("  æœåŠ¡ '{}': {:?}", service, methods);
    }
    
    // å‘é€ä¸€äº›è¯·æ±‚
    println!("\nå‘é€è¯·æ±‚...");
    
    // echo/ping
    let echo_response = client.call(
        "echo", 
        "ping", 
        "Hello, World!".to_string().into_bytes()
    ).await.unwrap();
    
    println!("echo/ping å“åº”: {:?}", String::from_utf8_lossy(&echo_response.payload));
    
    // math/square
    let square_response = client.call(
        "math", 
        "square", 
        "12".to_string().into_bytes()
    ).await.unwrap();
    
    println!("math/square å“åº”: {:?}", String::from_utf8_lossy(&square_response.payload));
    
    // math/slow_operation (å¯èƒ½è¶…æ—¶)
    println!("\nè°ƒç”¨æ…¢é€Ÿæ“ä½œï¼Œè¶…æ—¶è®¾ç½®ä¸º2ç§’...");
    let slow_response = client.call_with_timeout(
        "math", 
        "slow_operation", 
        Vec::new(),
        2000 // 2ç§’è¶…æ—¶
    ).await;
    
    match slow_response {
        Ok(response) => println!("æ…¢æ“ä½œå“åº”: {:?}", String::from_utf8_lossy(&response.payload)),
        Err(e) => println!("æ…¢æ“ä½œé”™è¯¯: {}", e),
    }
    
    // math/async_operation
    println!("\nè°ƒç”¨å¼‚æ­¥æ“ä½œ...");
    let async_response = client.call(
        "math", 
        "async_operation", 
        Vec::new()
    ).await.unwrap();
    
    println!("å¼‚æ­¥æ“ä½œå“åº”: {:?}", String::from_utf8_lossy(&async_response.payload));
    
    // è°ƒç”¨ä¸å­˜åœ¨çš„æœåŠ¡
    println!("\nè°ƒç”¨ä¸å­˜åœ¨çš„æœåŠ¡...");
    let not_found_response = client.call(
        "not_exists", 
        "method", 
        Vec::new()
    ).await.unwrap();
    
    println!("ä¸å­˜åœ¨æœåŠ¡å“åº”çŠ¶æ€: {:?}", not_found_response.status);
}
```

## 9 ç¨³å®šæ€§æ¨¡å¼

### 9.1 é™æµå™¨

é™æµå™¨æ¨¡å¼ç”¨äºæ§åˆ¶è¯·æ±‚é€Ÿç‡ï¼Œé˜²æ­¢ç³»ç»Ÿè¿‡è½½ã€‚

```rust
use std::collections::{HashMap, VecDeque};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::Mutex;
use tokio::time::sleep;
use async_trait::async_trait;

// é™æµå™¨ç‰¹å¾
#[async_trait]
trait RateLimiter {
    // å°è¯•è·å–ä»¤ç‰Œï¼Œå¦‚æœæˆåŠŸè¿”å›trueï¼Œå¦åˆ™è¿”å›false
    async fn acquire(&self) -> bool;
    
    // å°è¯•è·å–ä»¤ç‰Œï¼Œå¦‚æœä¸èƒ½ç«‹å³è·å–åˆ™ç­‰å¾…
    async fn acquire_or_wait(&self) -> Result<(), String>;
    
    // è·å–å½“å‰é™æµå™¨çŠ¶æ€
    async fn get_status(&self) -> RateLimiterStatus;
}

// é™æµå™¨çŠ¶æ€
#[derive(Debug, Clone)]
struct RateLimiterStatus {
    // å¯ç”¨ä»¤ç‰Œæˆ–è¯·æ±‚æ•°
    available: usize,
    // æœ€å¤§å®¹é‡
    capacity: usize,
    // ä¸Šæ¬¡è¡¥å……æ—¶é—´
    last_refill: Option<Instant>,
    // ç­‰å¾…ä¸­çš„è¯·æ±‚æ•°
    waiting: usize,
}

// ä»¤ç‰Œæ¡¶é™æµå™¨
struct TokenBucket {
    tokens: Mutex<usize>,
    capacity: usize,
    refill_rate: usize,
    refill_interval: Duration,
    last_refill: Mutex<Option<Instant>>,
    waiting: Mutex<usize>,
}

impl TokenBucket {
    fn new(capacity: usize, refill_rate: usize, refill_interval: Duration) -> Self {
        Self {
            tokens: Mutex::new(capacity),
            capacity,
            refill_rate,
            refill_interval,
            last_refill: Mutex::new(None),
            waiting: Mutex::new(0),
        }
    }
    
    // è¡¥å……ä»¤ç‰Œ
    async fn refill(&self) {
        let mut tokens = self.tokens.lock().await;
        let mut last_refill = self.last_refill.lock().await;
        
        let now = Instant::now();
        let elapsed = last_refill
            .map(|time| now.duration_since(time))
            .unwrap_or(self.refill_interval);
        
        // è®¡ç®—éœ€è¦è¡¥å……çš„ä»¤ç‰Œæ•°
        let intervals = (elapsed.as_millis() as f64 / self.refill_interval.as_millis() as f64).floor() as usize;
        
        if intervals > 0 {
            let new_tokens = self.refill_rate * intervals;
            *tokens = (*tokens + new_tokens).min(self.capacity);
            *last_refill = Some(now);
        }
    }
}

#[async_trait]
impl RateLimiter for TokenBucket {
    async fn acquire(&self) -> bool {
        // å…ˆè¡¥å……ä»¤ç‰Œ
        self.refill().await;
        
        let mut tokens = self.tokens.lock().await;
        
        if *tokens > 0 {
            *tokens -= 1;
            true
        } else {
            false
        }
    }
    
    async fn acquire_or_wait(&self) -> Result<(), String> {
        // å°è¯•è·å–ä»¤ç‰Œ
        let mut waiting = self.waiting.lock().await;
        *waiting += 1;
        
        loop {
            if self.acquire().await {
                *waiting -= 1;
                return Ok(());
            }
            
            // ç­‰å¾…ä¸€å°æ®µæ—¶é—´å†è¯•
            sleep(Duration::from_millis(50)).await;
        }
    }
    
    async fn get_status(&self) -> RateLimiterStatus {
        let tokens = *self.tokens.lock().await;
        let last_refill = *self.last_refill.lock().await;
        let waiting = *self.waiting.lock().await;
...(about 143 lines omitted)...
        let window_end = now;
        let window_start = window_end - self.window_duration;
        
        *self.request_counts.lock().await = clean_requests;
        
        // æ„å»ºçŠ¶æ€
        RateLimiterStatus {
            available: self.max_requests.saturating_sub(count),
            capacity: self.max_requests,
            last_refill: None,
            waiting: *self.waiting.lock().await,
        }
    }
}

// åˆ†å¸ƒå¼é™æµå™¨ (ä½¿ç”¨å¤–éƒ¨å­˜å‚¨)
struct DistributedRateLimiter<S> {
    storage: Arc<S>,
    key: String,
    capacity: usize,
    refill_rate: usize,
    refill_interval: Duration,
    waiting: Mutex<usize>,
}

// åˆ†å¸ƒå¼å­˜å‚¨ç‰¹å¾
#[async_trait]
trait DistributedStorage: Send + Sync {
    async fn get_counter(&self, key: &str) -> Result<usize, String>;
    async fn increment_counter(&self, key: &str, amount: usize) -> Result<usize, String>;
    async fn decrement_counter(&self, key: &str, amount: usize) -> Result<usize, String>;
    async fn get_last_update(&self, key: &str) -> Result<Option<u64>, String>;
    async fn set_last_update(&self, key: &str, timestamp: u64) -> Result<(), String>;
}

// å†…å­˜æ¨¡æ‹Ÿåˆ†å¸ƒå¼å­˜å‚¨ (ä»…ç”¨äºæ¼”ç¤º)
struct InMemoryStorage {
    counters: Mutex<HashMap<String, usize>>,
    last_updates: Mutex<HashMap<String, u64>>,
}

impl InMemoryStorage {
    fn new() -> Self {
        Self {
            counters: Mutex::new(HashMap::new()),
            last_updates: Mutex::new(HashMap::new()),
        }
    }
}

#[async_trait]
impl DistributedStorage for InMemoryStorage {
    async fn get_counter(&self, key: &str) -> Result<usize, String> {
        let counters = self.counters.lock().await;
        Ok(*counters.get(key).unwrap_or(&0))
    }
    
    async fn increment_counter(&self, key: &str, amount: usize) -> Result<usize, String> {
        let mut counters = self.counters.lock().await;
        let counter = counters.entry(key.to_string()).or_insert(0);
        *counter += amount;
        Ok(*counter)
    }
    
    async fn decrement_counter(&self, key: &str, amount: usize) -> Result<usize, String> {
        let mut counters = self.counters.lock().await;
        let counter = counters.entry(key.to_string()).or_insert(0);
        *counter = counter.saturating_sub(amount);
        Ok(*counter)
    }
    
    async fn get_last_update(&self, key: &str) -> Result<Option<u64>, String> {
        let updates = self.last_updates.lock().await;
        Ok(updates.get(key).copied())
    }
    
    async fn set_last_update(&self, key: &str, timestamp: u64) -> Result<(), String> {
        let mut updates = self.last_updates.lock().await;
        updates.insert(key.to_string(), timestamp);
        Ok(())
    }
}

impl<S> DistributedRateLimiter<S>
where
    S: DistributedStorage + 'static,
{
    fn new(
        storage: Arc<S>,
        key: &str,
        capacity: usize,
        refill_rate: usize,
        refill_interval: Duration,
    ) -> Self {
        Self {
            storage,
            key: key.to_string(),
            capacity,
            refill_rate,
            refill_interval,
            waiting: Mutex::new(0),
        }
    }
    
    // è¡¥å……ä»¤ç‰Œ
    async fn refill(&self) -> Result<(), String> {
        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs();
        
        let last_update = self.storage.get_last_update(&self.key).await?;
        
        if let Some(last_time) = last_update {
            let elapsed_secs = now.saturating_sub(last_time);
            let refill_interval_secs = self.refill_interval.as_secs();
            
            if elapsed_secs >= refill_interval_secs && refill_interval_secs > 0 {
                let intervals = elapsed_secs / refill_interval_secs;
                let new_tokens = (intervals as usize) * self.refill_rate;
                
                // æ·»åŠ ä»¤ç‰Œï¼Œä½†ä¸è¶…è¿‡å®¹é‡
                let current = self.storage.get_counter(&self.key).await?;
                let to_add = (self.capacity - current).min(new_tokens);
                
                if to_add > 0 {
                    self.storage.increment_counter(&self.key, to_add).await?;
                }
                
                // æ›´æ–°æœ€åæ›´æ–°æ—¶é—´
                self.storage.set_last_update(&self.key, now).await?;
            }
        } else {
            // é¦–æ¬¡åˆå§‹åŒ–
            self.storage.increment_counter(&self.key, self.capacity).await?;
            self.storage.set_last_update(&self.key, now).await?;
        }
        
        Ok(())
    }
}

#[async_trait]
impl<S> RateLimiter for DistributedRateLimiter<S>
where
    S: DistributedStorage + 'static,
{
    async fn acquire(&self) -> bool {
        // å°è¯•è¡¥å……ä»¤ç‰Œ
        if let Err(_) = self.refill().await {
            return false;
        }
        
        // å°è¯•è·å–ä»¤ç‰Œ
        match self.storage.decrement_counter(&self.key, 1).await {
            Ok(remaining) if remaining != usize::MAX => true,
            _ => false,
        }
    }
    
    async fn acquire_or_wait(&self) -> Result<(), String> {
        let mut waiting = self.waiting.lock().await;
        *waiting += 1;
        
        loop {
            if self.acquire().await {
                *waiting -= 1;
                return Ok(());
            }
            
            // ç­‰å¾…ä¸€å°æ®µæ—¶é—´å†è¯•
            sleep(Duration::from_millis(100)).await;
        }
    }
    
    async fn get_status(&self) -> RateLimiterStatus {
        // å…ˆè¡¥å……ä»¤ç‰Œ
        let _ = self.refill().await;
        
        let available = self.storage.get_counter(&self.key).await.unwrap_or(0);
        let last_update = self.storage.get_last_update(&self.key).await.unwrap_or(None);
        
        RateLimiterStatus {
            available,
            capacity: self.capacity,
            last_refill: last_update.map(|ts| {
                let duration = std::time::UNIX_EPOCH + Duration::from_secs(ts);
                Instant::now() - Duration::from_secs(
                    Instant::now().elapsed().as_secs() - ts
                )
            }),
            waiting: *self.waiting.lock().await,
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºä»¤ç‰Œæ¡¶é™æµå™¨
    let token_bucket = Arc::new(TokenBucket::new(
        10,         // å®¹é‡
        2,          // æ¯æ¬¡è¡¥å……2ä¸ªä»¤ç‰Œ
        Duration::from_secs(1), // æ¯ç§’è¡¥å……
    ));
    
    // åˆ›å»ºå›ºå®šçª—å£é™æµå™¨
    let fixed_window = Arc::new(FixedWindowRateLimiter::new(
        5,          // 5ç§’å†…
        10,         // æœ€å¤š10ä¸ªè¯·æ±‚
    ));
    
    // åˆ›å»ºæ»‘åŠ¨çª—å£é™æµå™¨
    let sliding_window = Arc::new(SlidingWindowRateLimiter::new(
        Duration::from_secs(5), // 5ç§’çª—å£
        10,         // æœ€å¤š10ä¸ªè¯·æ±‚
    ));
    
    // åˆ›å»ºåˆ†å¸ƒå¼é™æµå™¨
    let storage = Arc::new(InMemoryStorage::new());
    let distributed = Arc::new(DistributedRateLimiter::new(
        storage,
        "api:requests",
        20,         // å®¹é‡
        4,          // æ¯æ¬¡è¡¥å……4ä¸ªä»¤ç‰Œ
        Duration::from_secs(1), // æ¯ç§’è¡¥å……
    ));
    
    // æµ‹è¯•ä»¤ç‰Œæ¡¶é™æµå™¨
    println!("=== æµ‹è¯•ä»¤ç‰Œæ¡¶é™æµå™¨ ===");
    test_rate_limiter(token_bucket.clone(), 15).await;
    
    // æµ‹è¯•å›ºå®šçª—å£é™æµå™¨
    println!("\n=== æµ‹è¯•å›ºå®šçª—å£é™æµå™¨ ===");
    test_rate_limiter(fixed_window.clone(), 15).await;
    
    // æµ‹è¯•æ»‘åŠ¨çª—å£é™æµå™¨
    println!("\n=== æµ‹è¯•æ»‘åŠ¨çª—å£é™æµå™¨ ===");
    test_rate_limiter(sliding_window.clone(), 15).await;
    
    // æµ‹è¯•åˆ†å¸ƒå¼é™æµå™¨
    println!("\n=== æµ‹è¯•åˆ†å¸ƒå¼é™æµå™¨ ===");
    test_rate_limiter(distributed.clone(), 25).await;
    
    // æµ‹è¯•å¹¶å‘è¯·æ±‚
    println!("\n=== æµ‹è¯•å¹¶å‘è¯·æ±‚ ===");
    test_concurrent_requests(token_bucket.clone(), 20).await;
}

async fn test_rate_limiter<R: RateLimiter>(limiter: Arc<R>, requests: usize) {
    let mut success_count = 0;
    let mut failure_count = 0;
    
    for i in 0..requests {
        println!("è¯·æ±‚ #{} - å°è¯•è·å–ä»¤ç‰Œ", i);
        
        if limiter.acquire().await {
            success_count += 1;
            println!("  æˆåŠŸè·å–ä»¤ç‰Œ");
        } else {
            failure_count += 1;
            println!("  æ— æ³•è·å–ä»¤ç‰Œ");
        }
        
        // æŸ¥çœ‹é™æµå™¨çŠ¶æ€
        let status = limiter.get_status().await;
        println!("  é™æµå™¨çŠ¶æ€: å¯ç”¨={}/{}, ç­‰å¾…={}", 
                 status.available, status.capacity, status.waiting);
        
        sleep(Duration::from_millis(200)).await;
    }
    
    println!("æ€»ç»“: æˆåŠŸ={}, å¤±è´¥={}", success_count, failure_count);
}

async fn test_concurrent_requests<R: RateLimiter>(limiter: Arc<R>, requests: usize) {
    let mut handles = vec![];
    
    for i in 0..requests {
        let limiter = limiter.clone();
        
        handles.push(tokio::spawn(async move {
            println!("å¹¶å‘è¯·æ±‚ #{} - å°è¯•è·å–ä»¤ç‰Œæˆ–ç­‰å¾…", i);
            let start = Instant::now();
            
            match limiter.acquire_or_wait().await {
                Ok(()) => {
                    let elapsed = start.elapsed();
                    println!("  è¯·æ±‚ #{} è·å–åˆ°ä»¤ç‰Œï¼Œç­‰å¾…äº† {:?}", i, elapsed);
                    true
                },
                Err(e) => {
                    println!("  è¯·æ±‚ #{} å¤±è´¥: {}", i, e);
                    false
                }
            }
        }));
    }
    
    // ç­‰å¾…æ‰€æœ‰è¯·æ±‚å®Œæˆ
    let results = futures::future::join_all(handles).await;
    
    let success_count = results.iter()
        .filter(|r| r.as_ref().map_or(false, |v| *v))
        .count();
    
    println!("å¹¶å‘è¯·æ±‚æ€»ç»“: æˆåŠŸ={}/{}", success_count, requests);
}
```

```text
<think>
æˆ‘å°†ç»§ç»­ç¼–å†™åˆ†å¸ƒå¼ç³»ç»Ÿæ¨¡å¼çš„ä»£ç ç¤ºä¾‹ã€‚
ä¸‹ä¸€ä¸ªéƒ¨åˆ†åº”è¯¥æ˜¯ç¨³å®šæ€§æ¨¡å¼ä¸­çš„æ–­è·¯å™¨å’Œé‡è¯•ç­–ç•¥æ¨¡å¼ã€‚

æ¥ä¸‹æ¥è¦å†™çš„æ˜¯æ–­è·¯å™¨æ¨¡å¼ï¼Œå®ƒæ˜¯ä¸€ç§åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­é˜²æ­¢çº§è”å¤±è´¥çš„é‡è¦æ¨¡å¼ã€‚
ç„¶åä¼šç»§ç»­å†™é‡è¯•ç­–ç•¥ï¼Œè¿™ä¹Ÿæ˜¯æé«˜ç³»ç»Ÿç¨³å®šæ€§çš„å…³é”®æ¨¡å¼ã€‚
</think>
```

### 9.2 æ–­è·¯å™¨

æ–­è·¯å™¨æ¨¡å¼ç”¨äºé˜²æ­¢ç³»ç»ŸæŒç»­è°ƒç”¨å¯èƒ½å¤±è´¥çš„æœåŠ¡ï¼Œä»è€Œé˜²æ­¢çº§è”å¤±è´¥å’Œç³»ç»Ÿå´©æºƒã€‚

```rust
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::RwLock;
use std::collections::{HashMap, VecDeque};
use async_trait::async_trait;

// æ–­è·¯å™¨çŠ¶æ€
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
enum CircuitState {
    Closed,     // æ­£å¸¸çŠ¶æ€ï¼Œå…è®¸è¯·æ±‚é€šè¿‡
    Open,       // æ–­å¼€çŠ¶æ€ï¼Œå¿«é€Ÿå¤±è´¥
    HalfOpen,   // åŠå¼€çŠ¶æ€ï¼Œå…è®¸æœ‰é™è¯·æ±‚é€šè¿‡ä»¥æµ‹è¯•æœåŠ¡
}

// æ–­è·¯å™¨é…ç½®
#[derive(Debug, Clone)]
struct CircuitBreakerConfig {
    // é”™è¯¯é˜ˆå€¼ç™¾åˆ†æ¯”ï¼Œè¶…è¿‡æ­¤å€¼æ–­è·¯å™¨å°†æ‰“å¼€
    failure_threshold_percentage: f64,
    // è¯·æ±‚é˜ˆå€¼ï¼Œåªæœ‰è¶…è¿‡æ­¤å€¼æ‰ä¼šè€ƒè™‘æ‰“å¼€æ–­è·¯å™¨
    request_volume_threshold: u32,
    // æ–­è·¯å™¨æ‰“å¼€åï¼Œç­‰å¾…å¤šé•¿æ—¶é—´è½¬ä¸ºåŠå¼€çŠ¶æ€
    sleep_window_ms: u64,
    // åŠå¼€çŠ¶æ€ä¸‹å…è®¸é€šè¿‡çš„è¯·æ±‚æ•°
    half_open_allowed_calls: u32,
    // ç»Ÿè®¡çª—å£å¤§å°
    metrics_window_size: usize,
}

impl Default for CircuitBreakerConfig {
    fn default() -> Self {
        Self {
            failure_threshold_percentage: 50.0, // 50%å¤±è´¥ç‡
            request_volume_threshold: 20,       // è‡³å°‘20ä¸ªè¯·æ±‚
            sleep_window_ms: 5000,              // 5ç§’åå°è¯•æ¢å¤
            half_open_allowed_calls: 10,        // åŠå¼€çŠ¶æ€å…è®¸10ä¸ªè¯·æ±‚
            metrics_window_size: 100,           // ä¿ç•™æœ€è¿‘100ä¸ªè¯·æ±‚çš„ç»Ÿè®¡
        }
    }
}

// æ–­è·¯å™¨äº‹ä»¶ç±»å‹
#[derive(Debug, Clone, Copy)]
enum CircuitEvent {
    Success,
    Failure,
    Timeout,
    ShortCircuited, // è¢«æ–­è·¯å™¨çŸ­è·¯
    Rejected,       // å› å…¶ä»–åŸå› è¢«æ‹’ç»
}

// æ–­è·¯å™¨æŒ‡æ ‡
struct CircuitMetrics {
    // è¯·æ±‚ç»“æœå†å²
    events: VecDeque<CircuitEvent>,
    // çª—å£å¤§å°
    window_size: usize,
    // åŠå¼€çŠ¶æ€è®¡æ•°å™¨
    half_open_counter: u32,
}

impl CircuitMetrics {
    fn new(window_size: usize) -> Self {
        Self {
            events: VecDeque::with_capacity(window_size),
            window_size,
            half_open_counter: 0,
        }
    }
    
    // è®°å½•äº‹ä»¶
    fn record(&mut self, event: CircuitEvent) {
        if self.events.len() >= self.window_size {
            self.events.pop_front();
        }
        self.events.push_back(event);
    }
    
    // è·å–é”™è¯¯ç‡
    fn error_rate(&self) -> Option<f64> {
        if self.events.is_empty() {
            return None;
        }
        
        let total = self.events.len() as f64;
        let failures = self.events.iter()
            .filter(|&&e| matches!(e, CircuitEvent::Failure | CircuitEvent::Timeout))
            .count() as f64;
        
        Some((failures / total) * 100.0)
    }
    
    // è·å–è¯·æ±‚æ€»æ•°
    fn request_count(&self) -> usize {
        self.events.len()
    }
    
    // é‡ç½®åŠå¼€çŠ¶æ€è®¡æ•°å™¨
    fn reset_half_open_counter(&mut self) {
        self.half_open_counter = 0;
    }
    
    // å¢åŠ åŠå¼€çŠ¶æ€è®¡æ•°å™¨
    fn increment_half_open_counter(&mut self) -> u32 {
        self.half_open_counter += 1;
        self.half_open_counter
    }
    
    // æ¸…ç©ºç»Ÿè®¡æ•°æ®
    fn reset(&mut self) {
        self.events.clear();
        self.half_open_counter = 0;
    }
}

// æ–­è·¯å™¨æ ¸å¿ƒ
struct CircuitBreaker {
    name: String,
    state: RwLock<CircuitState>,
    last_state_change: RwLock<Instant>,
    metrics: RwLock<CircuitMetrics>,
    config: CircuitBreakerConfig,
}

impl CircuitBreaker {
    fn new(name: &str, config: CircuitBreakerConfig) -> Self {
        Self {
            name: name.to_string(),
            state: RwLock::new(CircuitState::Closed),
            last_state_change: RwLock::new(Instant::now()),
            metrics: RwLock::new(CircuitMetrics::new(config.metrics_window_size)),
            config,
        }
    }
    
    // è·å–å½“å‰çŠ¶æ€
    async fn current_state(&self) -> CircuitState {
        *self.state.read().await
    }
    
    // æ£€æŸ¥æ˜¯å¦åº”è¯¥è½¬ä¸ºå¼€è·¯çŠ¶æ€
    async fn should_trip(&self) -> bool {
        let metrics = self.metrics.read().await;
        
        // è¯·æ±‚é‡è¿‡ä½ï¼Œä¸è§¦å‘æ–­è·¯
        if metrics.request_count() < self.config.request_volume_threshold as usize {
            return false;
        }
        
        // æ£€æŸ¥é”™è¯¯ç‡
        if let Some(error_rate) = metrics.error_rate() {
            error_rate >= self.config.failure_threshold_percentage
        } else {
            false
        }
    }
    
    // æ£€æŸ¥æ˜¯å¦åº”è¯¥ä»å¼€è·¯æ¢å¤åˆ°åŠå¼€è·¯çŠ¶æ€
    async fn should_attempt_reset(&self) -> bool {
        let last_change = *self.last_state_change.read().await;
        let sleep_window = Duration::from_millis(self.config.sleep_window_ms);
        
        Instant::now().duration_since(last_change) >= sleep_window
    }
    
    // è½¬ä¸ºå¼€è·¯çŠ¶æ€
    async fn trip_open(&self) {
        let mut state = self.state.write().await;
        if *state == CircuitState::Closed {
            println!("[{}] æ–­è·¯å™¨çŠ¶æ€åˆ‡æ¢: å…³é—­ -> æ‰“å¼€", self.name);
            *state = CircuitState::Open;
            
            let mut last_change = self.last_state_change.write().await;
            *last_change = Instant::now();
        }
    }
    
    // è½¬ä¸ºåŠå¼€è·¯çŠ¶æ€
    async fn half_open(&self) {
        let mut state = self.state.write().await;
        if *state == CircuitState::Open {
            println!("[{}] æ–­è·¯å™¨çŠ¶æ€åˆ‡æ¢: æ‰“å¼€ -> åŠå¼€", self.name);
            *state = CircuitState::HalfOpen;
            
            let mut last_change = self.last_state_change.write().await;
            *last_change = Instant::now();
            
            let mut metrics = self.metrics.write().await;
            metrics.reset_half_open_counter();
        }
    }
    
    // æ¢å¤åˆ°å…³é—­çŠ¶æ€
    async fn reset(&self) {
        let mut state = self.state.write().await;
        if *state != CircuitState::Closed {
            println!("[{}] æ–­è·¯å™¨çŠ¶æ€åˆ‡æ¢: {} -> å…³é—­", 
                    self.name, 
                    if *state == CircuitState::Open { "æ‰“å¼€" } else { "åŠå¼€" });
            
            *state = CircuitState::Closed;
            
            let mut last_change = self.last_state_change.write().await;
            *last_change = Instant::now();
            
            let mut metrics = self.metrics.write().await;
            metrics.reset();
        }
    }
    
    // å°è¯•å…è®¸è¯·æ±‚é€šè¿‡
    async fn allow_request(&self) -> bool {
        match self.current_state().await {
            CircuitState::Closed => true,
            CircuitState::Open => {
                // æ£€æŸ¥æ˜¯å¦åº”è¯¥å°è¯•æ¢å¤
                if self.should_attempt_reset().await {
                    self.half_open().await;
                    // æ¢å¤åˆ°åŠå¼€çŠ¶æ€åï¼Œå…è®¸æœ‰é™çš„è¯·æ±‚é€šè¿‡
                    return self.allow_request().await;
                }
                
                // å¼€è·¯çŠ¶æ€ä¸‹æ‹’ç»è¯·æ±‚
                let mut metrics = self.metrics.write().await;
                metrics.record(CircuitEvent::ShortCircuited);
                false
            },
            CircuitState::HalfOpen => {

/*
<think>
I'll continue the CircuitBreaker implementation, covering the rest of the `allow_request` method for the HalfOpen state, and then complete the implementation with the execution method, along with some example code to demonstrate how to use it.
</think>
*/

                // åŠå¼€çŠ¶æ€ä¸‹å…è®¸æœ‰é™è¯·æ±‚é€šè¿‡
                let mut metrics = self.metrics.write().await;
                let counter = metrics.increment_half_open_counter();
                
                counter <= self.config.half_open_allowed_calls
            }
        }
    }
    
    // è®°å½•æˆåŠŸ
    async fn mark_success(&self) {
        let mut metrics = self.metrics.write().await;
        metrics.record(CircuitEvent::Success);
        
        // å¦‚æœå¤„äºåŠå¼€çŠ¶æ€ä¸”æˆåŠŸæ¬¡æ•°è¾¾åˆ°é˜ˆå€¼ï¼Œåˆ™å…³é—­æ–­è·¯å™¨
        if self.current_state().await == CircuitState::HalfOpen {
            let half_open_counter = metrics.half_open_counter;
            
            // é‡Šæ”¾metricsé”ï¼Œé¿å…æ­»é”
            drop(metrics);
            
            if half_open_counter >= self.config.half_open_allowed_calls {
                self.reset().await;
            }
        }
    }
    
    // è®°å½•å¤±è´¥
    async fn mark_failure(&self) {
        let mut metrics = self.metrics.write().await;
        metrics.record(CircuitEvent::Failure);
        
        // å¦‚æœå¤„äºåŠå¼€çŠ¶æ€ï¼Œç«‹å³é‡æ–°æ‰“å¼€æ–­è·¯å™¨
        if self.current_state().await == CircuitState::HalfOpen {
            // é‡Šæ”¾metricsé”ï¼Œé¿å…æ­»é”
            drop(metrics);
            
            self.trip_open().await;
            return;
        }
        
        // æ£€æŸ¥æ˜¯å¦åº”è¯¥æ‰“å¼€æ–­è·¯å™¨
        if self.should_trip().await {
            self.trip_open().await;
        }
    }
    
    // è®°å½•è¶…æ—¶
    async fn mark_timeout(&self) {
        let mut metrics = self.metrics.write().await;
        metrics.record(CircuitEvent::Timeout);
        
        // è¶…æ—¶é€šå¸¸æ¯”æ™®é€šé”™è¯¯æ›´ä¸¥é‡ï¼Œæ‰€ä»¥ç›´æ¥è§¦å‘æ–­è·¯é€»è¾‘
        if self.current_state().await == CircuitState::HalfOpen {
            // é‡Šæ”¾metricsé”ï¼Œé¿å…æ­»é”
            drop(metrics);
            
            self.trip_open().await;
            return;
        }
        
        // æ£€æŸ¥æ˜¯å¦åº”è¯¥æ‰“å¼€æ–­è·¯å™¨
        if self.should_trip().await {
            self.trip_open().await;
        }
    }
    
    // æ‰§è¡Œå—ä¿æŠ¤çš„æ“ä½œ
    async fn execute<F, Fut, T>(&self, f: F) -> Result<T, String>
    where
        F: FnOnce() -> Fut,
        Fut: std::future::Future<Output = Result<T, String>>,
    {
        // æ£€æŸ¥æ–­è·¯å™¨æ˜¯å¦å…è®¸è¯·æ±‚
        if !self.allow_request().await {
            return Err(format!("[{}] æ–­è·¯å™¨å¼€è·¯ï¼Œè¯·æ±‚è¢«æ‹’ç»", self.name));
        }
        
        // æ‰§è¡Œæ“ä½œ
        match f().await {
            Ok(result) => {
                self.mark_success().await;
                Ok(result)
            },
            Err(e) => {
                self.mark_failure().await;
                Err(format!("[{}] æ“ä½œå¤±è´¥: {}", self.name, e))
            }
        }
    }
    
    // å¸¦è¶…æ—¶çš„æ‰§è¡Œ
    async fn execute_with_timeout<F, Fut, T>(&self, timeout: Duration, f: F) -> Result<T, String>
    where
        F: FnOnce() -> Fut,
        Fut: std::future::Future<Output = Result<T, String>>,
    {
        // æ£€æŸ¥æ–­è·¯å™¨æ˜¯å¦å…è®¸è¯·æ±‚
        if !self.allow_request().await {
            return Err(format!("[{}] æ–­è·¯å™¨å¼€è·¯ï¼Œè¯·æ±‚è¢«æ‹’ç»", self.name));
        }
        
        // ä½¿ç”¨tokioçš„è¶…æ—¶åŠŸèƒ½
        match tokio::time::timeout(timeout, f()).await {
            Ok(Ok(result)) => {
                self.mark_success().await;
                Ok(result)
            },
            Ok(Err(e)) => {
                self.mark_failure().await;
                Err(format!("[{}] æ“ä½œå¤±è´¥: {}", self.name, e))
            },
            Err(_) => {
                self.mark_timeout().await;
                Err(format!("[{}] æ“ä½œè¶…æ—¶", self.name))
            }
        }
    }
    
    // è·å–æ–­è·¯å™¨çŠ¶æ€ä¿¡æ¯
    async fn get_metrics(&self) -> CircuitBreakerMetrics {
        let state = self.current_state().await;
        let metrics = self.metrics.read().await;
        let last_change = *self.last_state_change.read().await;
        
        CircuitBreakerMetrics {
            name: self.name.clone(),
            state,
            request_count: metrics.request_count() as u32,
            error_rate: metrics.error_rate().unwrap_or(0.0),
            time_in_current_state: Instant::now().duration_since(last_change),
        }
    }
}

// æ–­è·¯å™¨æŒ‡æ ‡æŠ¥å‘Šç»“æ„
#[derive(Debug, Clone)]
struct CircuitBreakerMetrics {
    name: String,
    state: CircuitState,
    request_count: u32,
    error_rate: f64,
    time_in_current_state: Duration,
}

// æ–­è·¯å™¨æ³¨å†Œè¡¨
struct CircuitBreakerRegistry {
    breakers: RwLock<HashMap<String, Arc<CircuitBreaker>>>,
}

impl CircuitBreakerRegistry {
    fn new() -> Self {
        Self {
            breakers: RwLock::new(HashMap::new()),
        }
    }
    
    // è·å–æˆ–åˆ›å»ºæ–­è·¯å™¨
    async fn get_or_create(&self, name: &str, config: Option<CircuitBreakerConfig>) -> Arc<CircuitBreaker> {
        let mut breakers = self.breakers.write().await;
        
        if let Some(breaker) = breakers.get(name) {
            breaker.clone()
        } else {
            let config = config.unwrap_or_default();
            let breaker = Arc::new(CircuitBreaker::new(name, config));
            breakers.insert(name.to_string(), breaker.clone());
            breaker
        }
    }
    
    // è·å–æ‰€æœ‰æ–­è·¯å™¨
    async fn get_all(&self) -> Vec<Arc<CircuitBreaker>> {
        let breakers = self.breakers.read().await;
        breakers.values().cloned().collect()
    }
    
    // è·å–æ‰€æœ‰æ–­è·¯å™¨çš„æŒ‡æ ‡
    async fn get_all_metrics(&self) -> Vec<CircuitBreakerMetrics> {
        let breakers = self.get_all().await;
        let mut metrics = Vec::with_capacity(breakers.len());
        
        for breaker in breakers {
            metrics.push(breaker.get_metrics().await);
        }
        
        metrics
    }
}

// ç¤ºä¾‹ä¸å¯é æœåŠ¡
struct UnreliableService {
    failure_rate: f64,
    delay_ms: u64,
}

impl UnreliableService {
    // æ¨¡æ‹Ÿè°ƒç”¨æœåŠ¡ï¼Œå¯èƒ½å¤±è´¥æˆ–å»¶è¿Ÿ
    async fn call(&self) -> Result<String, String> {
        // éšæœºå†³å®šæ˜¯å¦å¤±è´¥
        let roll = rand::random::<f64>();
        if roll < self.failure_rate {
            return Err("æœåŠ¡è°ƒç”¨å¤±è´¥".to_string());
        }
        
        // å¼•å…¥å»¶è¿Ÿ
        tokio::time::sleep(Duration::from_millis(self.delay_ms)).await;
        
        Ok("æœåŠ¡è°ƒç”¨æˆåŠŸ".to_string())
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºæ–­è·¯å™¨æ³¨å†Œè¡¨
    let registry = Arc::new(CircuitBreakerRegistry::new());
    
    // åˆ›å»ºä¸€ä¸ªé«˜å¤±è´¥ç‡çš„æœåŠ¡
    let unstable_service = UnreliableService {
        failure_rate: 0.7,  // 70%å¤±è´¥ç‡
        delay_ms: 100,      // 100mså»¶è¿Ÿ
    };
    
    // åˆ›å»ºä¸€ä¸ªè¶…æ—¶æœåŠ¡
    let slow_service = UnreliableService {
        failure_rate: 0.2,  // 20%å¤±è´¥ç‡
        delay_ms: 500,      // 500mså»¶è¿Ÿ
    };
    
    // è·å–æ–­è·¯å™¨
    let unstable_breaker = registry.get_or_create(
        "unstable-service", 
        Some(CircuitBreakerConfig {
            failure_threshold_percentage: 50.0,
            request_volume_threshold: 5,
            sleep_window_ms: 3000,
            half_open_allowed_calls: 3,
            metrics_window_size: 10,
        })
    ).await;
    
    let slow_breaker = registry.get_or_create(
        "slow-service", 
        Some(CircuitBreakerConfig {
            failure_threshold_percentage: 50.0,
            request_volume_threshold: 5,
            sleep_window_ms: 3000,
            half_open_allowed_calls: 3,
            metrics_window_size: 10,
        })
    ).await;
    
    // æµ‹è¯•ä¸ç¨³å®šæœåŠ¡
    println!("=== æµ‹è¯•ä¸ç¨³å®šæœåŠ¡ ===");
    test_service(unstable_service, unstable_breaker.clone(), 15).await;
    
    // ç­‰å¾…ä¼‘çœ çª—å£è¿‡å»
    println!("\nç­‰å¾…æ–­è·¯å™¨åŠå¼€...");
    tokio::time::sleep(Duration::from_millis(3500)).await;
    
    // æ–­è·¯å™¨åº”è¯¥å¤„äºåŠå¼€çŠ¶æ€ï¼Œå†æ¬¡æµ‹è¯•
    println!("\n=== æµ‹è¯•æ¢å¤æœŸé—´çš„ä¸ç¨³å®šæœåŠ¡ ===");
    test_service(UnreliableService { failure_rate: 0.0, delay_ms: 100 }, unstable_breaker.clone(), 5).await;
    
    // æµ‹è¯•è¶…æ—¶æœåŠ¡
    println!("\n=== æµ‹è¯•è¶…æ—¶æœåŠ¡ ===");
    test_service_with_timeout(slow_service, slow_breaker.clone(), 15, Duration::from_millis(200)).await;
    
    // æ˜¾ç¤ºæ‰€æœ‰æ–­è·¯å™¨æŒ‡æ ‡
    println!("\n=== æ–­è·¯å™¨æŒ‡æ ‡ ===");
    let all_metrics = registry.get_all_metrics().await;
    for metric in all_metrics {
        println!("æ–­è·¯å™¨ '{}': çŠ¶æ€={:?}, è¯·æ±‚æ•°={}, é”™è¯¯ç‡={:.1}%, å½“å‰çŠ¶æ€æŒç»­æ—¶é—´={:?}",
                 metric.name, metric.state, metric.request_count, metric.error_rate,
                 metric.time_in_current_state);
    }
}

async fn test_service(service: UnreliableService, breaker: Arc<CircuitBreaker>, iterations: usize) {
    for i in 0..iterations {
        println!("è¯·æ±‚ #{}", i + 1);
        
        let service_clone = service.clone();
        let result = breaker.execute(|| async move {
            service_clone.call().await
        }).await;
        
        match result {
            Ok(msg) => println!("  æˆåŠŸ: {}", msg),
            Err(e) => println!("  å¤±è´¥: {}", e),
        }
        
        let metrics = breaker.get_metrics().await;
        println!("  æ–­è·¯å™¨çŠ¶æ€: {:?}, è¯·æ±‚æ•°: {}, é”™è¯¯ç‡: {:.1}%",
                 metrics.state, metrics.request_count, metrics.error_rate);
        
        // å°æš‚åœï¼Œè®©è¾“å‡ºæ›´æ˜“äºé˜…è¯»
        tokio::time::sleep(Duration::from_millis(100)).await;
    }
}

async fn test_service_with_timeout(
    service: UnreliableService, 
    breaker: Arc<CircuitBreaker>,
    iterations: usize,
    timeout: Duration
) {
    for i in 0..iterations {
        println!("è¯·æ±‚ #{} (è¶…æ—¶è®¾ç½®: {:?})", i + 1, timeout);
        
        let service_clone = service.clone();
        let result = breaker.execute_with_timeout(timeout, || async move {
            service_clone.call().await
        }).await;
        
        match result {
            Ok(msg) => println!("  æˆåŠŸ: {}", msg),
            Err(e) => println!("  å¤±è´¥: {}", e),
        }
        
        let metrics = breaker.get_metrics().await;
        println!("  æ–­è·¯å™¨çŠ¶æ€: {:?}, è¯·æ±‚æ•°: {}, é”™è¯¯ç‡: {:.1}%",
                 metrics.state, metrics.request_count, metrics.error_rate);
        
        // å°æš‚åœï¼Œè®©è¾“å‡ºæ›´æ˜“äºé˜…è¯»
        tokio::time::sleep(Duration::from_millis(100)).await;
    }
}

impl Clone for UnreliableService {
    fn clone(&self) -> Self {
        Self {
            failure_rate: self.failure_rate,
            delay_ms: self.delay_ms,
        }
    }
}
```

### 9.3 éš”æ¿æ¨¡å¼

éš”æ¿æ¨¡å¼é€šè¿‡éš”ç¦»ä¸åŒçš„ç»„ä»¶ï¼Œé˜²æ­¢æ•…éšœåœ¨ç³»ç»Ÿä¸­è”“å»¶ï¼Œç±»ä¼¼äºèˆ¹èˆ±éš”ç¦»èˆ±çš„è®¾è®¡ã€‚

```rust
use std::collections::HashMap;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{Mutex, RwLock, Semaphore};
use tokio::time::timeout;
use futures::future::join_all;
use rand::Rng;

// éš”æ¿é…ç½®
#[derive(Debug, Clone)]
struct BulkheadConfig {
    // æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
    max_concurrent_calls: usize,
    // æœ€å¤§ç­‰å¾…é˜Ÿåˆ—é•¿åº¦
    max_queue_size: usize,
    // è¯·æ±‚è¶…æ—¶æ—¶é—´
    call_timeout: Duration,
}

impl Default for BulkheadConfig {
    fn default() -> Self {
        Self {
            max_concurrent_calls: 10,
            max_queue_size: 20,
            call_timeout: Duration::from_secs(1),
        }
    }
}

// éš”æ¿æ‰§è¡Œç»Ÿè®¡
#[derive(Debug, Clone, Default)]
struct BulkheadMetrics {
    // æ€»è¯·æ±‚æ•°
    total_calls: u64,
    // æˆåŠŸè¯·æ±‚æ•°
    successful_calls: u64,
    // å¤±è´¥è¯·æ±‚æ•°
    failed_calls: u64,
    // æ‹’ç»è¯·æ±‚æ•°ï¼ˆå› éš”æ¿æ»¡ï¼‰
    rejected_calls: u64,
    // è¶…æ—¶è¯·æ±‚æ•°
    timed_out_calls: u64,
    // å½“å‰æ´»è·ƒè¯·æ±‚æ•°
    active_calls: usize,
    // ç­‰å¾…é˜Ÿåˆ—é•¿åº¦
    queue_size: usize,
}

// éš”æ¿å®ç°
struct Bulkhead {
    name: String,
    config: BulkheadConfig,
    semaphore: Arc<Semaphore>,
    metrics: RwLock<BulkheadMetrics>,
    queue: Mutex<tokio::sync::mpsc::Sender<()>>,
    _queue_receiver: Mutex<tokio::sync::mpsc::Receiver<()>>,
}

impl Bulkhead {
    fn new(name: &str, config: BulkheadConfig) -> Self {
        let semaphore = Arc::new(Semaphore::new(config.max_concurrent_calls));
        
        // åˆ›å»ºé˜Ÿåˆ—é€šé“
        let (tx, rx) = tokio::sync::mpsc::channel(config.max_queue_size);
        
        Self {
            name: name.to_string(),
            config,
            semaphore,
            metrics: RwLock::new(BulkheadMetrics::default()),
            queue: Mutex::new(tx),
            _queue_receiver: Mutex::new(rx),
        }
    }
    
    // æ‰§è¡Œå—ä¿æŠ¤çš„æ“ä½œ
    async fn execute<F, Fut, T>(&self, f: F) -> Result<T, String>
    where
        F: FnOnce() -> Fut,
        Fut: std::future::Future<Output = Result<T, String>>,
    {
        // å°è¯•è·å–é˜Ÿåˆ—ä½ç½®
        let queue_permit = {
            let queue = self.queue.lock().await;
            match queue.try_send(()) {
                Ok(()) => true,
                Err(_) => {
                    // é˜Ÿåˆ—å·²æ»¡ï¼Œæ‹’ç»è¯·æ±‚
                    let mut metrics = self.metrics.write().await;
                    metrics.total_calls += 1;
                    metrics.rejected_calls += 1;
                    return Err(format!("[{}] éš”æ¿é˜Ÿåˆ—å·²æ»¡ï¼Œè¯·æ±‚è¢«æ‹’ç»", self.name));
                }
            }
        };
        
        // æ›´æ–°é˜Ÿåˆ—å¤§å°æŒ‡æ ‡
        {
            let mut metrics = self.metrics.write().await;
            metrics.queue_size += 1;
        }
        
        // å°è¯•è·å–ä¿¡å·é‡
        let permit = match self.semaphore.acquire().await {
            Ok(permit) => {
                // æˆåŠŸè·å–ä¿¡å·é‡ï¼Œå¯ä»¥æ‰§è¡Œ
                // ä»é˜Ÿåˆ—ä¸­ç§»é™¤
                {
                    let mut metrics = self.metrics.write().await;
                    metrics.queue_size -= 1;
                    metrics.active_calls += 1;
                }
                permit
            },
            Err(_) => {
                // æ— æ³•è·å–ä¿¡å·é‡ï¼Œè¿™ä¸åº”è¯¥å‘ç”Ÿï¼Œä½†ä»¥é˜²ä¸‡ä¸€
                let mut metrics = self.metrics.write().await;
                metrics.total_calls += 1;
                metrics.rejected_calls += 1;
                metrics.queue_size -= 1;
                
                return Err(format!("[{}] æ— æ³•è·å–éš”æ¿è®¸å¯", self.name));
            }
        };
        
        // æ›´æ–°æŒ‡æ ‡å¹¶æ‰§è¡Œæ“ä½œ
        let start = Instant::now();
        let result = match timeout(self.config.call_timeout, f()).await {
            Ok(Ok(result)) => {
                // æ“ä½œæˆåŠŸ
                let mut metrics = self.metrics.write().await;
                metrics.total_calls += 1;
                metrics.successful_calls += 1;
                
                Ok(result)
            },
            Ok(Err(e)) => {
                // æ“ä½œå¤±è´¥
                let mut metrics = self.metrics.write().await;
                metrics.total_calls += 1;
                metrics.failed_calls += 1;
                
                Err(format!("[{}] æ“ä½œå¤±è´¥: {}", self.name, e))
            },
            Err(_) => {
                // æ“ä½œè¶…æ—¶
                let mut metrics = self.metrics.write().await;
                metrics.total_calls += 1;
                metrics.timed_out_calls += 1;
                
                Err(format!("[{}] æ“ä½œè¶…æ—¶", self.name))
            }
        };
        
        // å‡å°‘æ´»è·ƒè®¡æ•°å¹¶é‡Šæ”¾ä¿¡å·é‡
        {
            let mut metrics = self.metrics.write().await;
            metrics.active_calls -= 1;
        }
        
        // é‡Šæ”¾ä¿¡å·é‡
        drop(permit);
        
        // é‡Šæ”¾é˜Ÿåˆ—ä½ç½®
        if queue_permit {
            // ä»é˜Ÿåˆ—é€šé“æ¥æ”¶æ¶ˆæ¯
            let queue = self.queue.lock().await;
            let _ = queue.try_send(());
            let _ = queue.try_recv();
        }
        
        result
    }
    
    // è·å–éš”æ¿æŒ‡æ ‡
    async fn get_metrics(&self) -> BulkheadMetrics {
        self.metrics.read().await.clone()
    }
}

// éš”æ¿æ³¨å†Œè¡¨
struct BulkheadRegistry {
    bulkheads: RwLock<HashMap<String, Arc<Bulkhead>>>,
}

impl BulkheadRegistry {
    fn new() -> Self {
        Self {
            bulkheads: RwLock::new(HashMap::new()),
        }
    }
    
    // è·å–æˆ–åˆ›å»ºéš”æ¿
    async fn get_or_create(&self, name: &str, config: Option<BulkheadConfig>) -> Arc<Bulkhead> {
        let mut bulkheads = self.bulkheads.write().await;
        
        if let Some(bulkhead) = bulkheads.get(name) {
            bulkhead.clone()
        } else {
            let config = config.unwrap_or_default();
            let bulkhead = Arc::new(Bulkhead::new(name, config));
            bulkheads.insert(name.to_string(), bulkhead.clone());
            bulkhead
        }
    }
    
    // è·å–æ‰€æœ‰éš”æ¿
    async fn get_all(&self) -> Vec<Arc<Bulkhead>> {
        let bulkheads = self.bulkheads.read().await;
        bulkheads.values().cloned().collect()
    }
    
    // è·å–æ‰€æœ‰éš”æ¿çš„æŒ‡æ ‡
    async fn get_all_metrics(&self) -> HashMap<String, BulkheadMetrics> {
        let bulkheads = self.get_all().await;
        let mut metrics = HashMap::new();
        
        for bulkhead in bulkheads {
            metrics.insert(bulkhead.name.clone(), bulkhead.get_metrics().await);
        }
        
        metrics
    }
}

// ç¤ºä¾‹æœåŠ¡ - æ¨¡æ‹Ÿä¸åŒçš„å¤„ç†å»¶è¿Ÿ
struct ExampleService {
    processing_time_ms: u64,
    failure_rate: f64,
}

impl ExampleService {
    async fn call(&self) -> Result<String, String> {
        // éšæœºå†³å®šæ˜¯å¦å¤±è´¥
        let mut rng = rand::thread_rng();
        if rng.gen::<f64>() < self.failure_rate {
            return Err("æœåŠ¡è°ƒç”¨å¤±è´¥".to_string());
        }
        
        // æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        tokio::time::sleep(Duration::from_millis(self.processing_time_ms)).await;
        
        Ok(format!("æœåŠ¡è°ƒç”¨æˆåŠŸ (å»¶è¿Ÿ: {}ms)", self.processing_time_ms))
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    // åˆ›å»ºéš”æ¿æ³¨å†Œè¡¨
    let registry = Arc::new(BulkheadRegistry::new());
    
    // å®šä¹‰ä¸åŒçš„éš”æ¿é…ç½®
    let database_config = BulkheadConfig {
        max_concurrent_calls: 5,
        max_queue_size: 10,
        call_timeout: Duration::from_millis(500),
    };
    
    let api_config = BulkheadConfig {
        max_concurrent_calls: 20,
        max_queue_size: 50,
        call_timeout: Duration::from_millis(1000),
    };
    
    // è·å–éš”æ¿
    let db_bulkhead = registry.get_or_create("database", Some(database_config)).await;
    let api_bulkhead = registry.get_or_create("api", Some(api_config)).await;
    
    // åˆ›å»ºæœåŠ¡
    let fast_db = ExampleService {
        processing_time_ms: 100,
        failure_rate: 0.1,
    };
    
    let slow_db = ExampleService {
        processing_time_ms: 400,
        failure_rate: 0.2,
    };
    
    let api_service = ExampleService {
        processing_time_ms: 200,
        failure_rate: 0.05,
    };
    
    // æµ‹è¯•åºåˆ—è°ƒç”¨
    println!("=== æµ‹è¯•åºåˆ—è°ƒç”¨ ===");
    
    // è°ƒç”¨æ•°æ®åº“æœåŠ¡ (å¿«é€Ÿ)
    for i in 0..5 {
        println!("DBè¯·æ±‚ #{}:", i + 1);
        let result = db_bulkhead.execute(|| async {
            fast_db.call().await
        }).await;
        
        match result {
            Ok(msg) => println!("  æˆåŠŸ: {}", msg),
            Err(e) => println!("  å¤±è´¥: {}", e),
        }
    }
    
    // è·å–æŒ‡æ ‡
    let db_metrics = db_bulkhead.get_metrics().await;
    println!("\næ•°æ®åº“éš”æ¿æŒ‡æ ‡: {:#?}", db_metrics);
    
    // æµ‹è¯•å¹¶å‘è°ƒç”¨
    println!("\n=== æµ‹è¯•å¹¶å‘è°ƒç”¨ ===");
    
    // åˆ›å»ºå¤šä¸ªå¹¶å‘è¯·æ±‚
    let mut db_handles = Vec::new();
    let mut api_handles = Vec::new();
    
    // æ•°æ®åº“è¯·æ±‚ (å¤šäºå…è®¸çš„å¹¶å‘æ•°)
    for i in 0..15 {
        let bulkhead = db_bulkhead.clone();
        let service = if i % 2 == 0 { 
            ExampleService { processing_time_ms: 400, failure_rate: 0.2 } 
        } else { 
            ExampleService { processing_time_ms: 100, failure_rate: 0.1 } 
        };
        
        let handle = tokio::spawn(async move {
            let result = bulkhead.execute(|| async {
                service.call().await
            }).await;
            
            (i, result)
        });
        
        db_handles.push(handle);
    }
    
    // APIè¯·æ±‚
    for i in 0..30 {
        let bulkhead = api_bulkhead.clone();
        let service = api_service.clone();
        
        let handle = tokio::spawn(async move {
            let result = bulkhead.execute(|| async {
                service.call().await
            }).await;
            
            (i, result)
        });
        
        api_handles.push(handle);
    }
    
    // ç­‰å¾…æ‰€æœ‰è¯·æ±‚å®Œæˆ
    let db_results = join_all(db_handles).await;
    let api_results = join_all(api_handles).await;
    
    // åˆ†ææ•°æ®åº“ç»“æœ
    let mut db_success = 0;
    let mut db_failure = 0;
    let mut db_rejected = 0;
    
    for result in db_results {
        match result {
            Ok((id, Ok(_))) => {
                db_success += 1;
                println!("DBè¯·æ±‚ #{} æˆåŠŸ", id);
            },
            Ok((id, Err(e))) => {
                db_failure += 1;
                if e.contains("éš”æ¿é˜Ÿåˆ—å·²æ»¡") {
                    db_rejected += 1;
                    println!("DBè¯·æ±‚ #{} è¢«æ‹’ç»: {}", id, e);
                } else {
                    println!("DBè¯·æ±‚ #{} å¤±è´¥: {}", id, e);
                }
            },
            Err(e) => println!("DBè¯·æ±‚æ‰§è¡Œé”™è¯¯: {}", e),
        }
    }
    
    // åˆ†æAPIç»“æœ
    let mut api_success = 0;
    let mut api_failure = 0;
    let mut api_rejected = 0;
    
    for result in api_results {
        match result {
            Ok((id, Ok(_))) => {
                api_success += 1;
                println!("APIè¯·æ±‚ #{} æˆåŠŸ", id);
            },
            Ok((id, Err(e))) => {
                api_failure += 1;
                if e.contains("éš”æ¿é˜Ÿåˆ—å·²æ»¡") {
                    api_rejected += 1;
                    println!("APIè¯·æ±‚ #{} è¢«æ‹’ç»: {}", id, e);
                } else {
                    println!("APIè¯·æ±‚ #{} å¤±è´¥: {}", id, e);
                }
            },
            Err(e) => println!("APIè¯·æ±‚æ‰§è¡Œé”™è¯¯: {}", e),
        }
    }
    
    // è·å–æœ€ç»ˆæŒ‡æ ‡
    let all_metrics = registry.get_all_metrics().await;
    
    println!("\n=== æœ€ç»ˆéš”æ¿æŒ‡æ ‡ ===");
    for (name, metrics) in all_metrics {
        println!("éš”æ¿ '{}':", name);
        println!("  æ€»è¯·æ±‚: {}", metrics.total_calls);
        println!("  æˆåŠŸ: {}", metrics.successful_calls);
        println!("  å¤±è´¥: {}", metrics.failed_calls);
        println!("  æ‹’ç»: {}", metrics.rejected_calls);
        println!("  è¶…æ—¶: {}", metrics.timed_out_calls);
        println!("  å½“å‰æ´»è·ƒ: {}", metrics.active_calls);
        println!("  å½“å‰é˜Ÿåˆ—: {}", metrics.queue_size);
    }
    
    println!("\nDBè¯·æ±‚ç»“æœ: æˆåŠŸ={}, å¤±è´¥={} (å…¶ä¸­è¢«æ‹’ç»={})", 
             db_success, db_failure, db_rejected);
    println!("APIè¯·æ±‚ç»“æœ: æˆåŠŸ={}, å¤±è´¥={} (å…¶ä¸­è¢«æ‹’ç»={})", 
             api_success, api_failure, api_rejected);
}

impl Clone for ExampleService {
    fn clone(&self) -> Self {
        Self {
            processing_time_ms: self.processing_time_ms,
            failure_rate: self.failure_rate,
        }
    }
}
```

```text
<think>
I'll continue with more distributed systems patterns. 
Let's focus on some important patterns that haven't been covered yet:

1. Retry patterns - expanding on timeouts and retries with more advanced strategies
2. Leader election - important for distributed coordination
3. Distributed logging/tracing - important for observability
4. Service discovery - how services find each other
5. API Gateway/BFF - Backend for Frontend patterns

Let me start with the retry pattern in more detail, followed by leader election.
</think>
```

## 10 åˆ†å¸ƒå¼åè°ƒæ¨¡å¼

### 10.1 é¢†å¯¼è€…é€‰ä¸¾

é¢†å¯¼è€…é€‰ä¸¾æ¨¡å¼ç”¨äºä»ä¸€ç»„èŠ‚ç‚¹ä¸­é€‰æ‹©ä¸€ä¸ªä½œä¸ºé¢†å¯¼è€…ï¼Œè´Ÿè´£åè°ƒå·¥ä½œæˆ–ç®¡ç†å…±äº«èµ„æºã€‚

```rust
use std::collections::HashMap;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{Mutex, RwLock};
use tokio::time::sleep;
use uuid::Uuid;
use serde::{Serialize, Deserialize};
use async_trait::async_trait;

// åˆ†å¸ƒå¼é”æ¥å£
#[async_trait]
trait DistributedLock: Send + Sync {
    // å°è¯•è·å–é”ï¼Œè¿”å›æ˜¯å¦æˆåŠŸ
    async fn try_lock(&self, holder: &str, ttl: Duration) -> Result<bool, String>;
    
    // åˆ·æ–°é”çš„TTL
    async fn refresh(&self, holder: &str, ttl: Duration) -> Result<bool, String>;
    
    // é‡Šæ”¾é”
    async fn unlock(&self, holder: &str) -> Result<bool, String>;
    
    // è·å–å½“å‰é”æŒæœ‰è€…
    async fn get_holder(&self) -> Result<Option<String>, String>;
}

// å†…å­˜å®ç°çš„åˆ†å¸ƒå¼é” (å®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨Redisæˆ–Zookeeperç­‰)
struct InMemoryLock {
    name: String,
    holder: RwLock<Option<String>>,
    expiry: RwLock<Option<Instant>>,
}

impl InMemoryLock {
    fn new(name: &str) -> Self {
        Self {
            name: name.to_string(),
            holder: RwLock::new(None),
            expiry: RwLock::new(None),
        }
    }
}

#[async_trait]
impl DistributedLock for InMemoryLock {
    async fn try_lock(&self, holder: &str, ttl: Duration) -> Result<bool, String> {
        let mut current_holder = self.holder.write().await;
        let mut expiry = self.expiry.write().await;
        
        // æ£€æŸ¥é”æ˜¯å¦å·²è¿‡æœŸ
        if let Some(exp) = *expiry {
            if Instant::now() > exp {
                // é”å·²è¿‡æœŸï¼Œå¯ä»¥é‡æ–°è·å–
                *current_holder = Some(holder.to_string());
                *expiry = Some(Instant::now() + ttl);
                return Ok(true);
            }
        }
        
        // å¦‚æœæ²¡æœ‰æŒæœ‰è€…æˆ–æŒæœ‰è€…å°±æ˜¯å½“å‰è¯·æ±‚è€…ï¼Œåˆ™å¯ä»¥è·å–é”
        if current_holder.is_none() || current_holder.as_ref().unwrap() == holder {
            *current_holder = Some(holder.to_string());
            *expiry = Some(Instant::now() + ttl);
            Ok(true)
        } else {
            Ok(false)
        }
    }
    
    async fn refresh(&self, holder: &str, ttl: Duration) -> Result<bool, String> {
        let current_holder = self.holder.read().await;
        
        // åªæœ‰å½“å‰æŒæœ‰è€…æ‰èƒ½åˆ·æ–°é”
        if let Some(h) = &*current_holder {
            if h == holder {
                let mut expiry = self.expiry.write().await;
                *expiry = Some(Instant::now() + ttl);
                return Ok(true);
            }
        }
        
        Ok(false)
    }
    
    async fn unlock(&self, holder: &str) -> Result<bool, String> {
        let mut current_holder = self.holder.write().await;
        
        // åªæœ‰å½“å‰æŒæœ‰è€…æ‰èƒ½é‡Šæ”¾é”
        if let Some(h) = &*current_holder {
            if h == holder {
                *current_holder = None;
                let mut expiry = self.expiry.write().await;
                *expiry = None;
                return Ok(true);
            }
        }
        
        Ok(false)
    }
    
    async fn get_holder(&self) -> Result<Option<String>, String> {
        let current_holder = self.holder.read().await;
        let expiry = self.expiry.read().await;
        
        // æ£€æŸ¥é”æ˜¯å¦å·²è¿‡æœŸ
        if let Some(exp) = *expiry {
            if Instant::now() > exp {
                // é”å·²è¿‡æœŸ
                return Ok(None);
            }
        }
        
        Ok(current_holder.clone())
    }
}

// é¢†å¯¼è€…é€‰ä¸¾æ¥å£
#[async_trait]
trait LeaderElection: Send + Sync {
    // å°è¯•æˆä¸ºé¢†å¯¼è€…
    async fn try_acquire_leadership(&self) -> Result<bool, String>;
    
    // é‡Šæ”¾é¢†å¯¼æƒ
    async fn release_leadership(&self) -> Result<bool, String>;
    
    // æ£€æŸ¥å½“å‰èŠ‚ç‚¹æ˜¯å¦æ˜¯é¢†å¯¼è€…
    async fn is_leader(&self) -> Result<bool, String>;
    
    // è·å–å½“å‰é¢†å¯¼è€…ID
    async fn get_current_leader(&self) -> Result<Option<String>, String>;
    
    // ç­‰å¾…æˆä¸ºé¢†å¯¼è€…
    async fn wait_for_leadership(&self, timeout: Option<Duration>) -> Result<bool, String>;
}

// åŸºäºåˆ†å¸ƒå¼é”çš„é¢†å¯¼è€…é€‰ä¸¾å®ç°
struct LockBasedLeaderElection {
    node_id: String,
    election_lock: Arc<dyn DistributedLock>,
    lock_ttl: Duration,
    is_leader: Mutex<bool>,
    // é¢†å¯¼æƒç»´æŒä»»åŠ¡
    leadership_task: Mutex<Option<tokio::task::JoinHandle<()>>>,
}

impl LockBasedLeaderElection {
    fn new(node_id: &str, lock: Arc<dyn DistributedLock>, ttl: Duration) -> Self {
        Self {
            node_id: node_id.to_string(),
            election_lock: lock,
            lock_ttl: ttl,
            is_leader: Mutex::new(false),
            leadership_task: Mutex::new(None),
        }
    }
    
    // å¯åŠ¨é¢†å¯¼æƒç»´æŒä»»åŠ¡
    async fn start_leadership_maintainer(&self) -> Result<(), String> {
        let mut task_guard = self.leadership_task.lock().await;
        
        // åœæ­¢ç°æœ‰ä»»åŠ¡ï¼ˆå¦‚æœæœ‰ï¼‰
        if let Some(task) = task_guard.take() {
            task.abort();
        }
        
        // åˆ›å»ºæ–°ä»»åŠ¡
        let node_id = self.node_id.clone();
        let lock = self.election_lock.clone();
        let refresh_interval = self.lock_ttl / 2; // åˆ·æ–°é—´éš”ä¸ºTTLçš„ä¸€åŠ
        let is_leader = self.is_leader.clone();
        
        let task = tokio::spawn(async move {
            loop {
                // å°è¯•åˆ·æ–°é”
                match lock.refresh(&node_id, refresh_interval * 2).await {
                    Ok(true) => {
                        // åˆ·æ–°æˆåŠŸï¼Œç»§ç»­ä¿æŒé¢†å¯¼æƒ
                        println!("èŠ‚ç‚¹ {} ç»§ç»­ä¿æŒé¢†å¯¼æƒ", node_id);
                    },
                    Ok(false) => {
                        // æ— æ³•åˆ·æ–°ï¼Œå¤±å»é¢†å¯¼æƒ
                        println!("èŠ‚ç‚¹ {} å¤±å»é¢†å¯¼æƒ (æ— æ³•åˆ·æ–°)", node_id);
                        let mut leader_status = is_leader.lock().await;
                        *leader_status = false;
                        break;
                    },
                    Err(e) => {
                        // åˆ·æ–°å‡ºé”™
                        println!("èŠ‚ç‚¹ {} åˆ·æ–°é¢†å¯¼æƒæ—¶å‡ºé”™: {}", node_id, e);
                        let mut leader_status = is_leader.lock().await;
                        *leader_status = false;
                        break;
                    }
                }
                
                // ç­‰å¾…åˆ·æ–°é—´éš”
                sleep(refresh_interval).await;
            }
        });
        
        *task_guard = Some(task);
        Ok(())
    }
}

#[async_trait]
impl LeaderElection for LockBasedLeaderElection {
    async fn try_acquire_leadership(&self) -> Result<bool, String> {
        // å°è¯•è·å–é”
        match self.election_lock.try_lock(&self.node_id, self.lock_ttl).await {
            Ok(true) => {
                // è·å–é”æˆåŠŸï¼Œæˆä¸ºé¢†å¯¼è€…
                println!("èŠ‚ç‚¹ {} æˆä¸ºé¢†å¯¼è€…", self.node_id);
                let mut is_leader = self.is_leader.lock().await;
                *is_leader = true;
                
                // å¯åŠ¨é¢†å¯¼æƒç»´æŒä»»åŠ¡
                drop(is_leader); // é‡Šæ”¾é”ï¼Œé¿å…æ­»é”
                self.start_leadership_maintainer().await?;
                
                Ok(true)
            },
            Ok(false) => {
                // è·å–é”å¤±è´¥ï¼Œä¸æ˜¯é¢†å¯¼è€…
                let mut is_leader = self.is_leader.lock().await;
                *is_leader = false;
                Ok(false)
            },
            Err(e) => Err(format!("å°è¯•è·å–é¢†å¯¼æƒæ—¶å‡ºé”™: {}", e)),
        }
    }
    
    async fn release_leadership(&self) -> Result<bool, String> {
        // åœæ­¢é¢†å¯¼æƒç»´æŒä»»åŠ¡
        let mut task_guard = self.leadership_task.lock().await;
        if let Some(task) = task_guard.take() {
            task.abort();
        }
        
        // é‡Šæ”¾é”
        match self.election_lock.unlock(&self.node_id).await {
            Ok(true) => {
                // é‡Šæ”¾é”æˆåŠŸ
                println!("èŠ‚ç‚¹ {} é‡Šæ”¾é¢†å¯¼æƒ", self.node_id);
                let mut is_leader = self.is_leader.lock().await;
                *is_leader = false;
                Ok(true)
            },
            Ok(false) => {
                // æ— æ³•é‡Šæ”¾é”ï¼ˆå¯èƒ½å·²ä¸æ˜¯é¢†å¯¼è€…ï¼‰
                let mut is_leader = self.is_leader.lock().await;
                *is_leader = false;
                Ok(false)
            },
            Err(e) => Err(format!("é‡Šæ”¾é¢†å¯¼æƒæ—¶å‡ºé”™: {}", e)),
        }
    }
    
    async fn is_leader(&self) -> Result<bool, String> {
        let is_leader = self.is_leader.lock().await;
        Ok(*is_leader)
    }
    
    async fn get_current_leader(&self) -> Result<Option<String>, String> {
        self.election_lock.get_holder().await
    }
    
    async fn wait_for_leadership(&self, timeout: Option<Duration>) -> Result<bool, String> {
        let start = Instant::now();
        
        loop {
            // æ£€æŸ¥æ˜¯å¦å·²è¶…æ—¶
            if let Some(timeout_duration) = timeout {
                if start.elapsed() >= timeout_duration {
                    return Ok(false);
                }
            }
            
            // å°è¯•è·å–é¢†å¯¼æƒ
            if self.try_acquire_leadership().await? {
                return Ok(true);
            }
            
            // ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
            sleep(Duration::from_millis(500)).await;
        }
    }
}

// é¢†å¯¼è€…é€‰ä¸¾ç®¡ç†å™¨
struct LeaderElectionManager {
    elections: RwLock<HashMap<String, Arc<dyn LeaderElection>>>,
}

impl LeaderElectionManager {
    fn new() -> Self {
        Self {
            elections: RwLock::new(HashMap::new()),
        }
    }
    
    // åˆ›å»ºæ–°çš„é€‰ä¸¾å®ä¾‹
    async fn create_election(&self, group: &str, node_id: &str) -> Arc<dyn LeaderElection> {
        let mut elections = self.elections.write().await;
        
        let lock_name = format!("election-lock-{}", group);
        let lock = Arc::new(InMemoryLock::new(&lock_name));
        
        let election = Arc::new(LockBasedLeaderElection::new(
            node_id,
            lock,
            Duration::from_secs(5), // 5ç§’TTL
        ));
        
        elections.insert(group.to_string(), election.clone());
        election
    }
    
    // è·å–ç°æœ‰é€‰ä¸¾å®ä¾‹
    async fn get_election(&self, group: &str) -> Option<Arc<dyn LeaderElection>> {
        let elections = self.elections.read().await;
        elections.get(group).cloned()
    }
}

// æ¨¡æ‹Ÿåˆ†å¸ƒå¼èŠ‚ç‚¹
struct DistributedNode {
    id: String,
    election: Arc<dyn LeaderElection>,
    task: Mutex<Option<tokio::task::JoinHandle<()>>>,
}

impl DistributedNode {
    fn new(id: &str, election: Arc<dyn LeaderElection>) -> Self {
        Self {
            id: id.to_string(),
            election,
            task: Mutex::new(None),
        }
    }
    
    // å¯åŠ¨èŠ‚ç‚¹
    async fn start(&self) {
        let mut task_guard = self.task.lock().await;
        
        // åœæ­¢ç°æœ‰ä»»åŠ¡ï¼ˆå¦‚æœæœ‰ï¼‰
        if let Some(task) = task_guard.take() {
            task.abort();
        }
        
        // åˆ›å»ºæ–°ä»»åŠ¡
        let id = self.id.clone();
        let election = self.election.clone();
        
        *task_guard = Some(tokio::spawn(async move {
            loop {
                // å°è¯•è·å–é¢†å¯¼æƒ
                match election.try_acquire_leadership().await {
                    Ok(true) => {
                        // æˆä¸ºé¢†å¯¼è€…ï¼Œæ‰§è¡Œé¢†å¯¼è€…å·¥ä½œ
                        println!("èŠ‚ç‚¹ {} æˆä¸ºé¢†å¯¼è€…ï¼Œå¼€å§‹å·¥ä½œ", id);
                        Self::do_leader_work(&id).await;
                    },
                    Ok(false) => {
                        // ä¸æ˜¯é¢†å¯¼è€…ï¼Œæ‰§è¡Œä»èŠ‚ç‚¹å·¥ä½œ
                        match election.get_current_leader().await {
                            Ok(Some(leader)) => {
                                println!("èŠ‚ç‚¹ {} æ˜¯ä»èŠ‚ç‚¹ï¼Œå½“å‰é¢†å¯¼è€…æ˜¯ {}", id, leader);
                            },
                            _ => {
                                println!("èŠ‚ç‚¹ {} æ˜¯ä»èŠ‚ç‚¹ï¼Œå½“å‰æ²¡æœ‰é¢†å¯¼è€…", id);
                            }
                        }
                        Self::do_follower_work(&id).await;
                    },
                    Err(e) => {
                        println!("èŠ‚ç‚¹ {} å°è¯•è·å–é¢†å¯¼æƒæ—¶å‡ºé”™: {}", id, e);
                    }
                }
                
                // ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
                sleep(Duration::from_secs(2)).await;
            }
        }));
    }
    
    // åœæ­¢èŠ‚ç‚¹
    async fn stop(&self) {
        let mut task_guard = self.task.lock().await;
        if let Some(task) = task_guard.take() {
            println!("åœæ­¢èŠ‚ç‚¹ {}", self.id);
            task.abort();
        }
        
        // å¦‚æœæ˜¯é¢†å¯¼è€…ï¼Œé‡Šæ”¾é¢†å¯¼æƒ
        if let Ok(true) = self.election.is_leader().await {
            match self.election.release_leadership().await {
                Ok(true) => println!("èŠ‚ç‚¹ {} é‡Šæ”¾é¢†å¯¼æƒ", self.id),
                Ok(false) => println!("èŠ‚ç‚¹ {} æ— æ³•é‡Šæ”¾é¢†å¯¼æƒ", self.id),
                Err(e) => println!("èŠ‚ç‚¹ {} é‡Šæ”¾é¢†å¯¼æƒæ—¶å‡ºé”™: {}", self.id, e),
            }
        }
    }
    
    // é¢†å¯¼è€…å·¥ä½œ
    async fn do_leader_work(id: &str) {
        println!("é¢†å¯¼è€… {} æ‰§è¡Œå·¥ä½œ...", id);
        // æ¨¡æ‹Ÿä¸€äº›é¢†å¯¼è€…ç‰¹æœ‰çš„å·¥ä½œ
        sleep(Duration::from_millis(500)).await;
    }
    
    // ä»èŠ‚ç‚¹å·¥ä½œ
    async fn do_follower_work(id: &str) {
        println!("ä»èŠ‚ç‚¹ {} æ‰§è¡Œå·¥ä½œ...", id);
        // æ¨¡æ‹Ÿä¸€äº›ä»èŠ‚ç‚¹ç‰¹æœ‰çš„å·¥ä½œ
        sleep(Duration::from_millis(300)).await;
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    println!("=== é¢†å¯¼è€…é€‰ä¸¾ç¤ºä¾‹ ===");
    
    // åˆ›å»ºé¢†å¯¼è€…é€‰ä¸¾ç®¡ç†å™¨
    let manager = Arc::new(LeaderElectionManager::new());
    
    // åˆ›å»ºé€‰ä¸¾å®ä¾‹
    let election1 = manager.create_election("cluster1", "node1").await;
    let election2 = manager.create_election("cluster1", "node2").await;
    let election3 = manager.create_election("cluster1", "node3").await;
    
    // åˆ›å»ºåˆ†å¸ƒå¼èŠ‚ç‚¹
    let node1 = Arc::new(DistributedNode::new("node1", election1));
    let node2 = Arc::new(DistributedNode::new("node2", election2));
    let node3 = Arc::new(DistributedNode::new("node3", election3));
    
    // å¯åŠ¨æ‰€æœ‰èŠ‚ç‚¹
    println!("\nå¯åŠ¨æ‰€æœ‰èŠ‚ç‚¹");
    node1.start().await;
    node2.start().await;
    node3.start().await;
    
    // ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œè®©èŠ‚ç‚¹ç¨³å®šè¿è¡Œ
    println!("\nèŠ‚ç‚¹è¿è¡Œä¸­...");
    sleep(Duration::from_secs(10)).await;
    
    // æ¨¡æ‹Ÿé¢†å¯¼è€…èŠ‚ç‚¹æ•…éšœ
    println!("\næ¨¡æ‹Ÿé¢†å¯¼è€…èŠ‚ç‚¹æ•…éšœ");
    let leader_id = manager.get_election("cluster1").await.unwrap().get_current_leader().await.unwrap();
    
    if let Some(leader) = leader_id {
        if leader == "node1" {
            println!("åœæ­¢é¢†å¯¼è€…èŠ‚ç‚¹ node1");
            node1.stop().await;
        } else if leader == "node2" {
            println!("åœæ­¢é¢†å¯¼è€…èŠ‚ç‚¹ node2");
            node2.stop().await;
        } else if leader == "node3" {
            println!("åœæ­¢é¢†å¯¼è€…èŠ‚ç‚¹ node3");
            node3.stop().await;
        }
    }
    
    // ç­‰å¾…æ–°çš„é¢†å¯¼è€…è¢«é€‰å‡º
    println!("\nç­‰å¾…æ–°çš„é¢†å¯¼è€…é€‰ä¸¾...");
    sleep(Duration::from_secs(10)).await;
    
    // æ˜¾ç¤ºæœ€ç»ˆçŠ¶æ€
    let final_leader = manager.get_election("cluster1").await.unwrap().get_current_leader().await.unwrap();
    println!("\næœ€ç»ˆé¢†å¯¼è€…: {:?}", final_leader);
    
    // åœæ­¢æ‰€æœ‰èŠ‚ç‚¹
    println!("\nåœæ­¢æ‰€æœ‰èŠ‚ç‚¹");
    node1.stop().await;
    node2.stop().await;
    node3.stop().await;
}
```

### 10.2 åˆ†å¸ƒå¼é”

åˆ†å¸ƒå¼é”ç”¨äºåœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­æä¾›äº’æ–¥è®¿é—®èµ„æºçš„æœºåˆ¶ï¼Œç¡®ä¿åœ¨ä»»ä½•æ—¶åˆ»åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹å¯ä»¥è®¿é—®å…±äº«èµ„æºã€‚

```rust
use std::collections::HashMap;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{Mutex, RwLock};
use tokio::time::sleep;
use uuid::Uuid;
use rand::Rng;
use futures::future::join_all;

// åˆ†å¸ƒå¼é”æ¥å£
#[async_trait::async_trait]
trait DistributedLock: Send + Sync {
    // å°è¯•è·å–é”
    async fn try_lock(&self, owner: &str, ttl: Duration) -> Result<bool, String>;
    
    // é˜»å¡å¼è·å–é”
    async fn lock(&self, owner: &str, ttl: Duration, timeout: Option<Duration>) -> Result<bool, String>;
    
    // é‡Šæ”¾é”
    async fn unlock(&self, owner: &str) -> Result<bool, String>;
    
    // åˆ·æ–°é”çš„TTL
    async fn refresh(&self, owner: &str, ttl: Duration) -> Result<bool, String>;
    
    // è·å–é”çš„å½“å‰æŒæœ‰è€…
    async fn get_owner(&self) -> Result<Option<String>, String>;
    
    // é”æ˜¯å¦è¢«æŒæœ‰
    async fn is_locked(&self) -> Result<bool, String>;
}

// Redisåˆ†å¸ƒå¼é”å®ç°ï¼ˆæ¨¡æ‹Ÿç‰ˆï¼‰
struct RedisLock {
    key: String,
    owner: RwLock<Option<String>>,
    expiry: RwLock<Option<Instant>>,
    waiting: Mutex<Vec<tokio::sync::oneshot::Sender<()>>>,
}

impl RedisLock {
    fn new(resource: &str) -> Self {
        let key = format!("lock:{}", resource);
        Self {
            key,
            owner: RwLock::new(None),
            expiry: RwLock::new(None),
            waiting: Mutex::new(Vec::new()),
        }
    }
    
    // é€šçŸ¥ç­‰å¾…çš„è¯·æ±‚
    async fn notify_waiters(&self) {
        let mut waiting = self.waiting.lock().await;
        
        // é€šçŸ¥æ‰€æœ‰ç­‰å¾…çš„è¯·æ±‚
        let waiters = std::mem::take(&mut *waiting);
        for waiter in waiters {
            let _ = waiter.send(());
        }
    }
}

#[async_trait::async_trait]
impl DistributedLock for RedisLock {
    async fn try_lock(&self, owner: &str, ttl: Duration) -> Result<bool, String> {
        let mut current_owner = self.owner.write().await;
        let mut expiry = self.expiry.write().await;
        
        // æ£€æŸ¥é”æ˜¯å¦å·²è¿‡æœŸ
        if let Some(exp) = *expiry {
            if Instant::now() > exp {
                // é”å·²è¿‡æœŸï¼Œå¯ä»¥é‡æ–°è·å–
                *current_owner = Some(owner.to_string());
                *expiry = Some(Instant::now() + ttl);
                
                // é€šçŸ¥ç­‰å¾…çš„è¯·æ±‚
                drop(current_owner);
                drop(expiry);
                self.notify_waiters().await;
                
                return Ok(true);
            }
        }
        
        // å¦‚æœæ²¡æœ‰æŒæœ‰è€…æˆ–æŒæœ‰è€…å°±æ˜¯å½“å‰è¯·æ±‚è€…ï¼Œåˆ™å¯ä»¥è·å–é”
        if current_owner.is_none() {
            *current_owner = Some(owner.to_string());
            *expiry = Some(Instant::now() + ttl);
            Ok(true)
        } else if let Some(current) = &*current_owner {
            if current == owner {
                // åˆ·æ–°è¿‡æœŸæ—¶é—´
                *expiry = Some(Instant::now() + ttl);
                Ok(true)
            } else {
                Ok(false)
            }
        } else {
            Ok(false)
        }
    }
    
    async fn lock(&self, owner: &str, ttl: Duration, timeout: Option<Duration>) -> Result<bool, String> {
        let start = Instant::now();
        
        // é¦–å…ˆå°è¯•è·å–é”
        if self.try_lock(owner, ttl).await? {
            return Ok(true);
        }
        
        // å¦‚æœæŒ‡å®šäº†è¶…æ—¶æ—¶é—´ä¸º0ï¼Œåˆ™ç«‹å³è¿”å›
        if let Some(t) = timeout {
            if t.as_millis() == 0 {
                return Ok(false);
            }
        }
        
        // åˆ›å»ºç­‰å¾…é€šé“
        let (tx, rx) = tokio::sync::oneshot::channel();
        
        loop {
            // æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if let Some(t) = timeout {
                if start.elapsed() >= t {
                    return Ok(false);
                }
            }
            
            // å†æ¬¡å°è¯•è·å–é”
            if self.try_lock(owner, ttl).await? {
                return Ok(true);
            }
            
            // æ·»åŠ åˆ°ç­‰å¾…åˆ—è¡¨
            {
                let mut waiting = self.waiting.lock().await;
                waiting.push(tx.clone());
            }
            
            // è®¾ç½®ç­‰å¾…è¶…æ—¶
            let wait_timeout = match timeout {
                Some(t) => {
                    let remaining = t.checked_sub(start.elapsed()).unwrap_or(Duration::from_millis(100));
                    remaining.min(Duration::from_millis(500))
                },
                None => Duration::from_millis(500),
            };
            
            // ç­‰å¾…é€šçŸ¥æˆ–è¶…æ—¶
            let _ = tokio::time::timeout(wait_timeout, rx.clone()).await;
        }
    }
    
    async fn unlock(&self, owner: &str) -> Result<bool, String> {
        let mut current_owner = self.owner.write().await;
        
        // åªæœ‰å½“å‰æŒæœ‰è€…æ‰èƒ½é‡Šæ”¾é”
        if let Some(current) = &*current_owner {
            if current == owner {
                *current_owner = None;
                
                let mut expiry = self.expiry.write().await;
                *expiry = None;
                
                // é€šçŸ¥ç­‰å¾…çš„è¯·æ±‚
                drop(current_owner);
                drop(expiry);
                self.notify_waiters().await;
                
                return Ok(true);
            }
        }
        
        Ok(false)
    }
    
    async fn refresh(&self, owner: &str, ttl: Duration) -> Result<bool, String> {
        let current_owner = self.owner.read().await;
        
        // åªæœ‰å½“å‰æŒæœ‰è€…æ‰èƒ½åˆ·æ–°é”
        if let Some(current) = &*current_owner {
            if current == owner {
                let mut expiry = self.expiry.write().await;
                *expiry = Some(Instant::now() + ttl);
                return Ok(true);
            }
        }
        
        Ok(false)
    }
    
    async fn get_owner(&self) -> Result<Option<String>, String> {
        let current_owner = self.owner.read().await;
        let expiry = self.expiry.read().await;
        
        // æ£€æŸ¥é”æ˜¯å¦å·²è¿‡æœŸ
        if let Some(exp) = *expiry {
            if Instant::now() > exp {
                // é”å·²è¿‡æœŸ
                return Ok(None);
            }
        }
        
        Ok(current_owner.clone())
    }
    
    async fn is_locked(&self) -> Result<bool, String> {
        let current_owner = self.owner.read().await;
        let expiry = self.expiry.read().await;
        
        // æ£€æŸ¥é”æ˜¯å¦å·²è¿‡æœŸ
        if let Some(exp) = *expiry {
            if Instant::now() > exp {
                // é”å·²è¿‡æœŸ
                return Ok(false);
            }
        }
        
        Ok(current_owner.is_some())
    }
}

// åˆ†å¸ƒå¼é”ç®¡ç†å™¨
struct LockManager {
    locks: RwLock<HashMap<String, Arc<dyn DistributedLock>>>,
}

impl LockManager {
    fn new() -> Self {
        Self {
            locks: RwLock::new(HashMap::new()),
        }
    }
    
    // è·å–é”å®ä¾‹
    async fn get_lock(&self, resource: &str) -> Arc<dyn DistributedLock> {
        let locks = self.locks.read().await;
        
        if let Some(lock) = locks.get(resource) {
            return lock.clone();
        }
        
        // é‡Šæ”¾è¯»é”
        drop(locks);
        
        // è·å–å†™é”å¹¶åˆ›å»ºæ–°çš„é”å®ä¾‹
        let mut locks = self.locks.write().await;
        
        // å†æ¬¡æ£€æŸ¥ï¼ˆé¿å…ç«æ€æ¡ä»¶ï¼‰
        if let Some(lock) = locks.get(resource) {
            return lock.clone();
        }
        
        // åˆ›å»ºæ–°çš„é”å®ä¾‹
        let lock = Arc::new(RedisLock::new(resource)) as Arc<dyn DistributedLock>;
        locks.insert(resource.to_string(), lock.clone());
        lock
    }
}

// è‡ªåŠ¨é‡Šæ”¾é”çš„åŒ…è£…å™¨
struct AutoLock {
    lock: Arc<dyn DistributedLock>,
    owner: String,
    acquired: bool,
}

impl AutoLock {
    // åˆ›å»ºæ–°çš„è‡ªåŠ¨é”
    async fn new(
        lock: Arc<dyn DistributedLock>, 
        owner: &str, 
        ttl: Duration,
        timeout: Option<Duration>,
    ) -> Result<Self, String> {
        let acquired = lock.lock(owner, ttl, timeout).await?;
        
        Ok(Self {
            lock,
            owner: owner.to_string(),
            acquired,
        })
    }
    
    // æ£€æŸ¥æ˜¯å¦è·å–åˆ°é”
    fn is_acquired(&self) -> bool {
        self.acquired
    }
    
    // æ‰‹åŠ¨é‡Šæ”¾é”
    async fn release(&mut self) -> Result<bool, String> {
        if self.acquired {
            let result = self.lock.unlock(&self.owner).await?;
            self.acquired = false;
            Ok(result)
        } else {
            Ok(false)
        }
    }
}

impl Drop for AutoLock {
    fn drop(&mut self) {
        if self.acquired {
            // åˆ›å»ºè¿è¡Œæ—¶å¤„ç†å¼‚æ­¥é‡Šæ”¾
            let rt = tokio::runtime::Handle::current();
            let lock = self.lock.clone();
            let owner = self.owner.clone();
            
            rt.spawn(async move {
                match lock.unlock(&owner).await {
                    Ok(true) => println!("è‡ªåŠ¨é‡Šæ”¾é”æˆåŠŸ: {}", owner),
                    Ok(false) => println!("è‡ªåŠ¨é‡Šæ”¾é”å¤±è´¥ (å¯èƒ½å·²ä¸æ˜¯æŒæœ‰è€…): {}", owner),
                    Err(e) => println!("è‡ªåŠ¨é‡Šæ”¾é”å‡ºé”™: {} - {}", owner, e),
                }
            });
            
            self.acquired = false;
        }
    }
}

// å…±äº«èµ„æºï¼ˆæ¨¡æ‹Ÿï¼‰
struct SharedResource {
    name: String,
    value: RwLock<i32>,
}

impl SharedResource {
    fn new(name: &str) -> Self {
        Self {
            name: name.to_string(),
            value: RwLock::new(0),
        }
    }
    
    // å¢åŠ å€¼
    async fn increment(&self, amount: i32) -> i32 {
        let mut value = self.value.write().await;
        *value += amount;
        *value
    }
    
    // è·å–å½“å‰å€¼
    async fn get_value(&self) -> i32 {
        let value = self.value.read().await;
        *value
    }
}

// æ¨¡æ‹Ÿå®¢æˆ·ç«¯
struct Client {
    id: String,
    lock_manager: Arc<LockManager>,
}

impl Client {
    fn new(id: &str, lock_manager: Arc<LockManager>) -> Self {
        Self {
            id: id.to_string(),
            lock_manager,
        }
    }
    
    // ä½¿ç”¨è‡ªåŠ¨é”æ“ä½œèµ„æº
    async fn increment_with_auto_lock(
        &self,
        resource: Arc<SharedResource>,
        amount: i32,
        ttl: Duration,
        timeout: Option<Duration>,
    ) -> Result<i32, String> {
        let lock = self.lock_manager.get_lock(&resource.name).await;
        
        // è·å–è‡ªåŠ¨é”
        let auto_lock = AutoLock::new(
            lock,
            &self.id,
            ttl,
            timeout,
        ).await?;
        
        if !auto_lock.is_acquired() {
            return Err(format!("å®¢æˆ·ç«¯ {} æ— æ³•è·å–èµ„æº {} çš„é”", self.id, resource.name));
        }
        
        println!("å®¢æˆ·ç«¯ {} è·å–èµ„æº {} çš„é”", self.id, resource.name);
        
        // æ¨¡æ‹Ÿæ“ä½œå»¶è¿Ÿ
        let delay = rand::thread_rng().gen_range(100..500);
        println!("å®¢æˆ·ç«¯ {} å¤„ç†èµ„æº {}ï¼Œå»¶è¿Ÿ {}ms", self.id, resource.name, delay);
        sleep(Duration::from_millis(delay)).await;
        
        // å¢åŠ èµ„æºå€¼
        let new_value = resource.increment(amount).await;
        println!("å®¢æˆ·ç«¯ {} å°†èµ„æº {} å¢åŠ  {}ï¼Œæ–°å€¼ = {}", self.id, resource.name, amount, new_value);
        
        // é”ä¼šè‡ªåŠ¨é‡Šæ”¾
        Ok(new_value)
    }
    
    // æ‰‹åŠ¨æ§åˆ¶é”
    async fn increment_with_manual_lock(
        &self,
        resource: Arc<SharedResource>,
        amount: i32,
        ttl: Duration,
        timeout: Option<Duration>,
    ) -> Result<i32, String> {
        let lock = self.lock_manager.get_lock(&resource.name).await;
        
        // å°è¯•è·å–é”
        if !lock.lock(&self.id, ttl, timeout).await? {
            return Err(format!("å®¢æˆ·ç«¯ {} æ— æ³•è·å–èµ„æº {} çš„é”", self.id, resource.name));
        }
        
        println!("å®¢æˆ·ç«¯ {} è·å–èµ„æº {} çš„é”", self.id, resource.name);
        
        // ç¡®ä¿é”æœ€ç»ˆä¼šè¢«é‡Šæ”¾
        let result = {
            // æ¨¡æ‹Ÿæ“ä½œå»¶è¿Ÿ
            let delay = rand::thread_rng().gen_range(100..1000);
            println!("å®¢æˆ·ç«¯ {} å¤„ç†èµ„æº {}ï¼Œå»¶è¿Ÿ {}ms", self.id, resource.name, delay);
            sleep(Duration::from_millis(delay)).await;
            
            // å¢åŠ èµ„æºå€¼
            let new_value = resource.increment(amount).await;
            println!("å®¢æˆ·ç«¯ {} å°†èµ„æº {} å¢åŠ  {}ï¼Œæ–°å€¼ = {}", self.id, resource.name, amount, new_value);
            
            Ok(new_value)
        };
        
        // æ‰‹åŠ¨é‡Šæ”¾é”
        match lock.unlock(&self.id).await {
            Ok(true) => println!("å®¢æˆ·ç«¯ {} é‡Šæ”¾èµ„æº {} çš„é”", self.id, resource.name),
            Ok(false) => println!("å®¢æˆ·ç«¯ {} æ— æ³•é‡Šæ”¾èµ„æº {} çš„é” (å¯èƒ½å·²ä¸æ˜¯æŒæœ‰è€…)", self.id, resource.name),
            Err(e) => println!("å®¢æˆ·ç«¯ {} é‡Šæ”¾èµ„æº {} çš„é”æ—¶å‡ºé”™: {}", self.id, resource.name, e),
        }
        
        result
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    println!("=== åˆ†å¸ƒå¼é”ç¤ºä¾‹ ===");
    
    // åˆ›å»ºé”ç®¡ç†å™¨
    let lock_manager = Arc::new(LockManager::new());
    
    // åˆ›å»ºå…±äº«èµ„æº
    let counter = Arc::new(SharedResource::new("counter"));
    
    // åˆ›å»ºå¤šä¸ªå®¢æˆ·ç«¯
    let mut clients = Vec::new();
    for i in 1..=5 {
        let client = Client::new(&format!("client{}", i), lock_manager.clone());
        clients.push(client);
    }
    
    println!("\n=== æµ‹è¯•è‡ªåŠ¨é” ===");
    
    // å¤šä¸ªå®¢æˆ·ç«¯å¹¶å‘æ“ä½œèµ„æºï¼ˆä½¿ç”¨è‡ªåŠ¨é”ï¼‰
    let mut handles = Vec::new();
    for (i, client) in clients.iter().enumerate() {
        let counter_clone = counter.clone();
        
        let handle = tokio::spawn(async move {
            let amount = (i as i32) + 1;
            let ttl = Duration::from_secs(5);
            let timeout = Some(Duration::from_secs(3));
            
            match client.increment_with_auto_lock(counter_clone, amount, ttl, timeout).await {
                Ok(value) => println!("å®¢æˆ·ç«¯ {} å®Œæˆè‡ªåŠ¨é”æ“ä½œï¼Œæœ€ç»ˆå€¼ = {}", client.id, value),
                Err(e) => println!("å®¢æˆ·ç«¯ {} è‡ªåŠ¨é”æ“ä½œå¤±è´¥: {}", client.id, e),
            }
        });
        
        handles.push(handle);
    }
    
    // ç­‰å¾…æ‰€æœ‰æ“ä½œå®Œæˆ
    join_all(handles).await;
    
    println!("\nè‡ªåŠ¨é”æ“ä½œåçš„èµ„æºå€¼: {}", counter.get_value().await);
    
    // é‡ç½®è®¡æ•°å™¨
    let _ = counter.increment(-counter.get_value().await).await;
    
    println!("\n=== æµ‹è¯•æ‰‹åŠ¨é” ===");
    
    // å¤šä¸ªå®¢æˆ·ç«¯å¹¶å‘æ“ä½œèµ„æºï¼ˆæ‰‹åŠ¨æ§åˆ¶é”ï¼‰
    let mut handles = Vec::new();
    for (i, client) in clients.iter().enumerate() {
        let counter_clone = counter.clone();
        
        let handle = tokio::spawn(async move {
            let amount = (i as i32) + 1;
            let ttl = Duration::from_secs(5);
            let timeout = Some(Duration::from_secs(3));
            
            match client.increment_with_manual_lock(counter_clone, amount, ttl, timeout).await {
                Ok(value) => println!("å®¢æˆ·ç«¯ {} å®Œæˆæ‰‹åŠ¨é”æ“ä½œï¼Œæœ€ç»ˆå€¼ = {}", client.id, value),
                Err(e) => println!("å®¢æˆ·ç«¯ {} æ‰‹åŠ¨é”æ“ä½œå¤±è´¥: {}", client.id, e),
            }
        });
        
        handles.push(handle);
    }

/*
<think>
I need to finish the distributed lock example code and continue with the remaining sections.
Let me complete this section and then move on to the next patterns.
</think>
*/

    // ç­‰å¾…æ‰€æœ‰æ“ä½œå®Œæˆ
    join_all(handles).await;
    
    println!("\næ‰‹åŠ¨é”æ“ä½œåçš„èµ„æºå€¼: {}", counter.get_value().await);
    
    // æµ‹è¯•é”é‡å…¥
    println!("\n=== æµ‹è¯•é”é‡å…¥ ===");
    let client = clients.first().unwrap();
    let lock = lock_manager.get_lock("reentrant_test").await;
    
    println!("å®¢æˆ·ç«¯ {} å°è¯•ç¬¬ä¸€æ¬¡è·å–é”", client.id);
    if lock.try_lock(&client.id, Duration::from_secs(10)).await.unwrap() {
        println!("å®¢æˆ·ç«¯ {} æˆåŠŸè·å–é”", client.id);
        
        println!("å®¢æˆ·ç«¯ {} å°è¯•ç¬¬äºŒæ¬¡è·å–åŒä¸€ä¸ªé”", client.id);
        if lock.try_lock(&client.id, Duration::from_secs(10)).await.unwrap() {
            println!("å®¢æˆ·ç«¯ {} æˆåŠŸé‡å…¥é”", client.id);
            
            // é‡Šæ”¾é”
            if lock.unlock(&client.id).await.unwrap() {
                println!("å®¢æˆ·ç«¯ {} ç¬¬ä¸€æ¬¡é‡Šæ”¾é”", client.id);
            }
            
            // å†æ¬¡é‡Šæ”¾é”
            if lock.unlock(&client.id).await.unwrap() {
                println!("å®¢æˆ·ç«¯ {} ç¬¬äºŒæ¬¡é‡Šæ”¾é”", client.id);
            }
        }
    }
    
    // æµ‹è¯•é”è¶…æ—¶
    println!("\n=== æµ‹è¯•é”è¶…æ—¶ ===");
    let client1 = &clients[0];
    let client2 = &clients[1];
    let timeout_lock = lock_manager.get_lock("timeout_test").await;
    
    // å®¢æˆ·ç«¯1è·å–é”
    if timeout_lock.try_lock(&client1.id, Duration::from_secs(5)).await.unwrap() {
        println!("å®¢æˆ·ç«¯ {} è·å–é”ï¼ŒæŒæœ‰5ç§’", client1.id);
        
        // å®¢æˆ·ç«¯2å°è¯•è·å–é”ï¼Œè®¾ç½®2ç§’è¶…æ—¶
        println!("å®¢æˆ·ç«¯ {} å°è¯•è·å–é”ï¼Œè¶…æ—¶2ç§’", client2.id);
        let start = Instant::now();
        let result = timeout_lock.lock(&client2.id, Duration::from_secs(5), Some(Duration::from_secs(2))).await;
        let elapsed = start.elapsed();
        
        match result {
            Ok(true) => println!("å®¢æˆ·ç«¯ {} è·å–é”æˆåŠŸï¼Œç”¨æ—¶ {:?}", client2.id, elapsed),
            Ok(false) => println!("å®¢æˆ·ç«¯ {} è·å–é”è¶…æ—¶ï¼Œç”¨æ—¶ {:?}", client2.id, elapsed),
            Err(e) => println!("å®¢æˆ·ç«¯ {} è·å–é”é”™è¯¯: {}", client2.id, e),
        }
        
        // ç­‰å¾…é”è¿‡æœŸ
        println!("ç­‰å¾…é”è¿‡æœŸ...");
        sleep(Duration::from_secs(5)).await;
        
        // å®¢æˆ·ç«¯2å†æ¬¡å°è¯•è·å–é”
        println!("å®¢æˆ·ç«¯ {} å†æ¬¡å°è¯•è·å–é”", client2.id);
        if timeout_lock.try_lock(&client2.id, Duration::from_secs(5)).await.unwrap() {
            println!("å®¢æˆ·ç«¯ {} æˆåŠŸè·å–å·²è¿‡æœŸçš„é”", client2.id);
            
            // é‡Šæ”¾é”
            if timeout_lock.unlock(&client2.id).await.unwrap() {
                println!("å®¢æˆ·ç«¯ {} é‡Šæ”¾é”", client2.id);
            }
        }
    }
}
```

### 10.3 åˆ†å¸ƒå¼ä¿¡å·é‡

åˆ†å¸ƒå¼ä¿¡å·é‡ç”¨äºé™åˆ¶å¤šä¸ªåˆ†å¸ƒå¼èŠ‚ç‚¹å¯¹å…±äº«èµ„æºçš„å¹¶å‘è®¿é—®æ•°é‡ã€‚

```rust
use std::collections::{HashMap, HashSet};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{Mutex, RwLock};
use tokio::time::sleep;
use uuid::Uuid;
use futures::future::join_all;
use rand::Rng;

// åˆ†å¸ƒå¼ä¿¡å·é‡æ¥å£
#[async_trait::async_trait]
trait DistributedSemaphore: Send + Sync {
    // å°è¯•è·å–ä¸€ä¸ªè®¸å¯
    async fn try_acquire(&self, owner: &str) -> Result<bool, String>;
    
    // é˜»å¡å¼è·å–è®¸å¯
    async fn acquire(&self, owner: &str, timeout: Option<Duration>) -> Result<bool, String>;
    
    // é‡Šæ”¾ä¸€ä¸ªè®¸å¯
    async fn release(&self, owner: &str) -> Result<bool, String>;
    
    // è·å–å½“å‰å¯ç”¨è®¸å¯æ•°
    async fn available_permits(&self) -> Result<usize, String>;
    
    // è·å–æ€»è®¸å¯æ•°
    async fn total_permits(&self) -> Result<usize, String>;
    
    // è·å–æ‰€æœ‰æŒæœ‰è®¸å¯çš„æ‰€æœ‰è€…
    async fn get_owners(&self) -> Result<Vec<String>, String>;
}

// Redisåˆ†å¸ƒå¼ä¿¡å·é‡å®ç°ï¼ˆæ¨¡æ‹Ÿç‰ˆï¼‰
struct RedisSemaphore {
    key: String,
    permits: RwLock<usize>,  // æ€»è®¸å¯æ•°
    available: RwLock<usize>, // å¯ç”¨è®¸å¯æ•°
    owners: RwLock<HashMap<String, usize>>, // æ¯ä¸ªæ‰€æœ‰è€…æŒæœ‰çš„è®¸å¯æ•°
    waiting: Mutex<Vec<tokio::sync::oneshot::Sender<()>>>, // ç­‰å¾…é˜Ÿåˆ—
}

impl RedisSemaphore {
    fn new(resource: &str, permits: usize) -> Self {
        let key = format!("semaphore:{}", resource);
        Self {
            key,
            permits: RwLock::new(permits),
            available: RwLock::new(permits),
            owners: RwLock::new(HashMap::new()),
            waiting: Mutex::new(Vec::new()),
        }
    }
    
    // é€šçŸ¥ç­‰å¾…çš„è¯·æ±‚
    async fn notify_waiters(&self) {
        let mut waiting = self.waiting.lock().await;
        
        // é€šçŸ¥æ‰€æœ‰ç­‰å¾…çš„è¯·æ±‚
        let waiters = std::mem::take(&mut *waiting);
        for waiter in waiters {
            let _ = waiter.send(());
        }
    }
}

#[async_trait::async_trait]
impl DistributedSemaphore for RedisSemaphore {
    async fn try_acquire(&self, owner: &str) -> Result<bool, String> {
        let mut available = self.available.write().await;
        
        if *available > 0 {
            // å‡å°‘å¯ç”¨è®¸å¯æ•°
            *available -= 1;
            
            // æ›´æ–°æŒæœ‰è€…ä¿¡æ¯
            let mut owners = self.owners.write().await;
            *owners.entry(owner.to_string()).or_insert(0) += 1;
            
            Ok(true)
        } else {
            Ok(false)
        }
    }
    
    async fn acquire(&self, owner: &str, timeout: Option<Duration>) -> Result<bool, String> {
        let start = Instant::now();
        
        // é¦–å…ˆå°è¯•è·å–è®¸å¯
        if self.try_acquire(owner).await? {
            return Ok(true);
        }
        
        // å¦‚æœæŒ‡å®šäº†è¶…æ—¶æ—¶é—´ä¸º0ï¼Œåˆ™ç«‹å³è¿”å›
        if let Some(t) = timeout {
            if t.as_millis() == 0 {
                return Ok(false);
            }
        }
        
        // åˆ›å»ºç­‰å¾…é€šé“
        let (tx, rx) = tokio::sync::oneshot::channel();
        
        loop {
            // æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if let Some(t) = timeout {
                if start.elapsed() >= t {
                    return Ok(false);
                }
            }
            
            // å†æ¬¡å°è¯•è·å–è®¸å¯
            if self.try_acquire(owner).await? {
                return Ok(true);
            }
            
            // æ·»åŠ åˆ°ç­‰å¾…åˆ—è¡¨
            {
                let mut waiting = self.waiting.lock().await;
                waiting.push(tx);
            }
            
            // ç­‰å¾…é€šçŸ¥æˆ–è¶…æ—¶
            let remaining_timeout = timeout.map(|t| t.saturating_sub(start.elapsed()));
            
            let wait_result = if let Some(remain) = remaining_timeout {
                match tokio::time::timeout(remain, rx).await {
                    Ok(result) => result,
                    Err(_) => return Ok(false), // è¶…æ—¶
                }
            } else {
                rx.await
            };
            
            // å¦‚æœæ”¶åˆ°é€šçŸ¥ï¼Œå†æ¬¡å°è¯•è·å–è®¸å¯
            if wait_result.is_ok() {
                if self.try_acquire(owner).await? {
                    return Ok(true);
                }
            }
            
            // å¦‚æœè·å–å¤±è´¥ï¼Œåˆ›å»ºæ–°çš„ç­‰å¾…é€šé“ç»§ç»­ç­‰å¾…
...(about 156 lines omitted)...
struct ClientTask {
    id: String,
    semaphore_manager: Arc<SemaphoreManager>,
}

impl ClientTask {
    fn new(id: &str, semaphore_manager: Arc<SemaphoreManager>) -> Self {
        Self {
            id: id.to_string(),
            semaphore_manager,
        }
    }
    
    async fn run(&self, resource_name: &str, operations: usize, timeout: Option<Duration>) {
        let semaphore = self.semaphore_manager.get_semaphore(resource_name).await;
        
        for i in 0..operations {
            println!("å®¢æˆ·ç«¯ {} æ“ä½œ #{} - å°è¯•è·å–èµ„æº {} çš„è®¸å¯", self.id, i+1, resource_name);
            
            // å°è¯•è·å–è®¸å¯
            let start = Instant::now();
            let acquired = semaphore.acquire(&self.id, timeout).await.unwrap_or(false);
            let elapsed = start.elapsed();
            
            if acquired {
                println!("å®¢æˆ·ç«¯ {} è·å–èµ„æº {} çš„è®¸å¯æˆåŠŸï¼Œç”¨æ—¶ {:?}", self.id, resource_name, elapsed);
                
                // æ¨¡æ‹Ÿä½¿ç”¨èµ„æº
                let work_time = rand::thread_rng().gen_range(500..2000);
                println!("å®¢æˆ·ç«¯ {} ä½¿ç”¨èµ„æº {} {} æ¯«ç§’", self.id, resource_name, work_time);
                sleep(Duration::from_millis(work_time)).await;
                
                // é‡Šæ”¾è®¸å¯
                match semaphore.release(&self.id).await {
                    Ok(true) => println!("å®¢æˆ·ç«¯ {} é‡Šæ”¾èµ„æº {} çš„è®¸å¯", self.id, resource_name),
                    Ok(false) => println!("å®¢æˆ·ç«¯ {} æ— æ³•é‡Šæ”¾èµ„æº {} çš„è®¸å¯", self.id, resource_name),
                    Err(e) => println!("å®¢æˆ·ç«¯ {} é‡Šæ”¾èµ„æº {} çš„è®¸å¯æ—¶å‡ºé”™: {}", self.id, resource_name, e),
                }
            } else {
                println!("å®¢æˆ·ç«¯ {} è·å–èµ„æº {} çš„è®¸å¯å¤±è´¥ï¼Œç”¨æ—¶ {:?}", self.id, resource_name, elapsed);
                
                // å¦‚æœè·å–å¤±è´¥ï¼Œç¨ç­‰åé‡è¯•
                sleep(Duration::from_millis(500)).await;
            }
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    println!("=== åˆ†å¸ƒå¼ä¿¡å·é‡ç¤ºä¾‹ ===");
    
    // åˆ›å»ºä¿¡å·é‡ç®¡ç†å™¨
    let semaphore_manager = Arc::new(SemaphoreManager::new());
    
    // åˆ›å»ºæœ‰é™èµ„æº
    semaphore_manager.create_semaphore("database", 3).await;
    semaphore_manager.create_semaphore("api", 5).await;
    
    // æ˜¾ç¤ºåˆå§‹ä¿¡å·é‡çŠ¶æ€
    let db_sem = semaphore_manager.get_semaphore("database").await;
    let api_sem = semaphore_manager.get_semaphore("api").await;
    
    println!("æ•°æ®åº“ä¿¡å·é‡: {} å¯ç”¨ / {} æ€»æ•°", 
             db_sem.available_permits().await.unwrap(),
             db_sem.total_permits().await.unwrap());
    
    println!("APIä¿¡å·é‡: {} å¯ç”¨ / {} æ€»æ•°", 
             api_sem.available_permits().await.unwrap(),
             api_sem.total_permits().await.unwrap());
    
    // åˆ›å»ºå¤šä¸ªå®¢æˆ·ç«¯ä»»åŠ¡
    let mut tasks = Vec::new();
    for i in 1..=10 {
        let client = ClientTask::new(&format!("client{}", i), semaphore_manager.clone());
        
        // å¥‡æ•°å®¢æˆ·ç«¯ä½¿ç”¨æ•°æ®åº“ï¼Œå¶æ•°å®¢æˆ·ç«¯ä½¿ç”¨API
        let resource = if i % 2 == 0 { "api" } else { "database" };
        let operations = rand::thread_rng().gen_range(2..5);
        
        let handle = tokio::spawn(async move {
            client.run(resource, operations, Some(Duration::from_secs(2))).await;
        });
        
        tasks.push(handle);
    }
    
    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    join_all(tasks).await;
    
    // æ˜¾ç¤ºæœ€ç»ˆä¿¡å·é‡çŠ¶æ€
    println!("\n=== æœ€ç»ˆä¿¡å·é‡çŠ¶æ€ ===");
    
    println!("æ•°æ®åº“ä¿¡å·é‡: {} å¯ç”¨ / {} æ€»æ•°", 
             db_sem.available_permits().await.unwrap(),
             db_sem.total_permits().await.unwrap());
    
    println!("APIä¿¡å·é‡: {} å¯ç”¨ / {} æ€»æ•°", 
             api_sem.available_permits().await.unwrap(),
             api_sem.total_permits().await.unwrap());
    
    // è·å–æ‰€æœ‰æŒæœ‰è€…
    let db_owners = db_sem.get_owners().await.unwrap();
    let api_owners = api_sem.get_owners().await.unwrap();
    
    println!("æ•°æ®åº“æŒæœ‰è€…: {:?}", db_owners);
    println!("APIæŒæœ‰è€…: {:?}", api_owners);
    
    // æµ‹è¯•æ‰¹é‡è·å–è®¸å¯
    println!("\n=== æµ‹è¯•æ‰¹é‡è·å–è®¸å¯ ===");
    let batch_client = BatchClient::new("batch_client", semaphore_manager.clone());
    
    // æ‰¹é‡è¯·æ±‚è¶…è¿‡å¯ç”¨æ•°é‡çš„è®¸å¯
    println!("å°è¯•æ‰¹é‡è·å–4ä¸ªæ•°æ®åº“è®¸å¯ (æ€»æ•°ä»…3ä¸ª)");
    let result = batch_client.batch_acquire("database", 4, Some(Duration::from_secs(1))).await;
    
    match result {
        Ok(_) => println!("æˆåŠŸè·å–æ‰€æœ‰è®¸å¯"),
        Err(e) => println!("è·å–å¤±è´¥: {}", e),
    }
    
    // æ‰¹é‡è¯·æ±‚å¯æ»¡è¶³çš„è®¸å¯
    println!("\nå°è¯•æ‰¹é‡è·å–2ä¸ªAPIè®¸å¯ (æœ‰5ä¸ªå¯ç”¨)");
    let result = batch_client.batch_acquire("api", 2, Some(Duration::from_secs(1))).await;
    
    match result {
        Ok(permits) => {
            println!("æˆåŠŸè·å–{}ä¸ªè®¸å¯", permits.len());
            
            // æ¨¡æ‹Ÿä½¿ç”¨
            sleep(Duration::from_secs(1)).await;
            
            // æ‰¹é‡é‡Šæ”¾
            let released = batch_client.batch_release("api", &permits).await.unwrap();
            println!("æˆåŠŸé‡Šæ”¾{}ä¸ªè®¸å¯", released);
        },
        Err(e) => println!("è·å–å¤±è´¥: {}", e),
    }
    
    // æœ€ç»ˆçŠ¶æ€
    println!("\n=== æœ€ç»ˆçŠ¶æ€ ===");
    println!("æ•°æ®åº“ä¿¡å·é‡: {} å¯ç”¨ / {} æ€»æ•°", 
             db_sem.available_permits().await.unwrap(),
             db_sem.total_permits().await.unwrap());
    
    println!("APIä¿¡å·é‡: {} å¯ç”¨ / {} æ€»æ•°", 
             api_sem.available_permits().await.unwrap(),
             api_sem.total_permits().await.unwrap());
}
```

## 11 å¯æ‰©å±•æ€§æ¨¡å¼

### 11.1 åˆ†ç‰‡æ¨¡å¼

åˆ†ç‰‡æ¨¡å¼é€šè¿‡å°†æ•°æ®æˆ–è´Ÿè½½åˆ†å¸ƒåˆ°å¤šä¸ªèŠ‚ç‚¹ä¸Šï¼Œå®ç°æ°´å¹³æ‰©å±•ã€‚

```rust
use std::collections::{HashMap, HashSet};
use std::hash::{Hash, Hasher};
use std::sync::Arc;
use tokio::sync::RwLock;
use rand::{Rng, SeedableRng};
use rand::rngs::StdRng;
use std::fmt::Debug;
use serde::{Serialize, Deserialize};
use fnv::FnvHasher;

// åˆ†ç‰‡æ¥å£
#[async_trait::async_trait]
trait Shard<K, V>: Send + Sync {
    // å†™å…¥æ•°æ®
    async fn put(&self, key: K, value: V) -> Result<(), String>;
    
    // è¯»å–æ•°æ®
    async fn get(&self, key: &K) -> Result<Option<V>, String>;
    
    // åˆ é™¤æ•°æ®
    async fn delete(&self, key: &K) -> Result<bool, String>;
    
    // è·å–åˆ†ç‰‡ä¸­çš„æ‰€æœ‰é”®
    async fn get_keys(&self) -> Result<Vec<K>, String>;
    
    // è·å–åˆ†ç‰‡ID
    fn get_id(&self) -> usize;
    
    // è·å–åˆ†ç‰‡å¤§å°
    async fn size(&self) -> Result<usize, String>;
}

// åˆ†ç‰‡ç®¡ç†å™¨æ¥å£
#[async_trait::async_trait]
trait ShardManager<K, V>: Send + Sync {
    // å†™å…¥æ•°æ®åˆ°åˆé€‚çš„åˆ†ç‰‡
    async fn put(&self, key: K, value: V) -> Result<(), String>;
    
    // ä»åˆé€‚çš„åˆ†ç‰‡è¯»å–æ•°æ®
    async fn get(&self, key: &K) -> Result<Option<V>, String>;
    
    // ä»åˆé€‚çš„åˆ†ç‰‡åˆ é™¤æ•°æ®
    async fn delete(&self, key: &K) -> Result<bool, String>;
    
    // è·å–æ‰€æœ‰åˆ†ç‰‡çš„æ‰€æœ‰é”®
    async fn get_all_keys(&self) -> Result<Vec<K>, String>;
    
    // è·å–åˆ†ç‰‡æ•°é‡
    fn shard_count(&self) -> usize;
    
    // è·å–åˆ†ç‰‡
    fn get_shard(&self, key: &K) -> Arc<dyn Shard<K, V>>;
    
    // è·å–ç‰¹å®šIDçš„åˆ†ç‰‡
    fn get_shard_by_id(&self, id: usize) -> Option<Arc<dyn Shard<K, V>>>;
    
    // è·å–æ‰€æœ‰åˆ†ç‰‡
    fn get_all_shards(&self) -> Vec<Arc<dyn Shard<K, V>>>;
}

// å†…å­˜åˆ†ç‰‡å®ç°
struct MemoryShard<K, V> {
    id: usize,
    data: RwLock<HashMap<K, V>>,
}

impl<K, V> MemoryShard<K, V>
where
    K: Clone + Eq + Hash + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    fn new(id: usize) -> Self {
        Self {
            id,
            data: RwLock::new(HashMap::new()),
        }
    }
}

#[async_trait::async_trait]
impl<K, V> Shard<K, V> for MemoryShard<K, V>
where
    K: Clone + Eq + Hash + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    async fn put(&self, key: K, value: V) -> Result<(), String> {
        let mut data = self.data.write().await;
        data.insert(key, value);
        Ok(())
    }
    
    async fn get(&self, key: &K) -> Result<Option<V>, String> {
        let data = self.data.read().await;
        Ok(data.get(key).cloned())
    }
    
    async fn delete(&self, key: &K) -> Result<bool, String> {
        let mut data = self.data.write().await;
        Ok(data.remove(key).is_some())
    }
    
    async fn get_keys(&self) -> Result<Vec<K>, String> {
        let data = self.data.read().await;
        Ok(data.keys().cloned().collect())
    }
    
    fn get_id(&self) -> usize {
        self.id
    }
    
    async fn size(&self) -> Result<usize, String> {
        let data = self.data.read().await;
        Ok(data.len())
    }
}

// åˆ†ç‰‡ç­–ç•¥æ¥å£
trait ShardingStrategy<K>: Send + Sync {
    // æ ¹æ®é”®ç¡®å®šåˆ†ç‰‡
    fn get_shard_id(&self, key: &K, shard_count: usize) -> usize;
    
    // åˆ†ç‰‡ç­–ç•¥åç§°
    fn name(&self) -> &str;
}

// å“ˆå¸Œåˆ†ç‰‡ç­–ç•¥
struct HashShardingStrategy;

impl<K> ShardingStrategy<K> for HashShardingStrategy
where
    K: Hash,
{
    fn get_shard_id(&self, key: &K, shard_count: usize) -> usize {
        let mut hasher = FnvHasher::default();
        key.hash(&mut hasher);
        let hash = hasher.finish() as usize;
        hash % shard_count
    }
    
    fn name(&self) -> &str {
        "å“ˆå¸Œåˆ†ç‰‡"
    }
}

// ä¸€è‡´æ€§å“ˆå¸Œåˆ†ç‰‡ç­–ç•¥
struct ConsistentHashShardingStrategy {
    virtual_nodes_per_shard: usize,
    ring: Arc<RwLock<HashMap<u64, usize>>>,
}

impl ConsistentHashShardingStrategy {
    fn new(shard_count: usize, virtual_nodes_per_shard: usize) -> Self {
        let ring = Arc::new(RwLock::new(HashMap::new()));
        let strategy = Self { 
            virtual_nodes_per_shard,
            ring,
        };
...(about 294 lines omitted)...
    async fn rebalance(&self) -> Result<HashMap<usize, HashSet<K>>, String> {
        // è·å–æ‰€æœ‰é”®
        let all_keys = self.get_all_keys().await?;
        
        // ä¸ºæ¯ä¸ªé”®é‡æ–°è®¡ç®—åˆ†ç‰‡ID
        let mut movements = HashMap::new();
        
        for key in all_keys {
            let current_shard = self.get_shard(&key).get_id();
            let target_shard = self.strategy.get_shard_id(&key, self.shards.len());
            
            if current_shard != target_shard {
                // é”®éœ€è¦ç§»åŠ¨
                movements.entry(target_shard)
                    .or_insert_with(HashSet::new)
                    .insert(key);
            }
        }
        
        Ok(movements)
    }
    
    // è·å–åˆ†ç‰‡ç»Ÿè®¡ä¿¡æ¯
    async fn shard_stats(&self) -> Result<Vec<ShardStats>, String> {
        let mut stats = Vec::new();
        
        for shard in &self.shards {
            let id = shard.get_id();
            let size = shard.size().await?;
            
            stats.push(ShardStats {
                shard_id: id,
                key_count: size,
            });
        }
        
        Ok(stats)
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    println!("=== åˆ†ç‰‡æ¨¡å¼ç¤ºä¾‹ ===");
    
    // åˆ›å»ºå“ˆå¸Œåˆ†ç‰‡ç®¡ç†å™¨
    let hash_manager = create_hash_shard_manager(4);
    test_shard_manager("å“ˆå¸Œåˆ†ç‰‡", hash_manager.clone(), 1000).await;
    
    // åˆ›å»ºä¸€è‡´æ€§å“ˆå¸Œåˆ†ç‰‡ç®¡ç†å™¨
    let consistent_manager = create_consistent_hash_shard_manager(4);
    test_shard_manager("ä¸€è‡´æ€§å“ˆå¸Œåˆ†ç‰‡", consistent_manager.clone(), 1000).await;
    
    // æµ‹è¯•å¢åŠ åˆ†ç‰‡
    println!("\n=== æµ‹è¯•å¢åŠ åˆ†ç‰‡ ===");
    test_add_shard(hash_manager.clone()).await;
    test_add_shard(consistent_manager.clone()).await;
    
    // æµ‹è¯•èŒƒå›´åˆ†ç‰‡
    let range_manager = create_range_shard_manager();
    println!("\n=== æµ‹è¯•èŒƒå›´åˆ†ç‰‡ ===");
    test_range_sharding(range_manager).await;
}

async fn test_shard_manager(
    name: &str, 
    manager: Arc<dyn ShardManager<String, String>>, 
    key_count: usize
) {
    println!("\n--- æµ‹è¯• {} ---", name);
    println!("åˆ†ç‰‡æ•°é‡: {}", manager.shard_count());
    
    // å†™å…¥éšæœºæ•°æ®
    let mut rng = StdRng::seed_from_u64(42); // ä½¿ç”¨å›ºå®šç§å­ä»¥ä¾¿ç»“æœå¯é‡ç°
    
    for i in 0..key_count {
        let key = format!("key{}", i);
        let value = format!("value{}", i);
        
        manager.put(key, value).await.unwrap();
    }
    
    // è·å–åˆ†ç‰‡ç»Ÿè®¡
    let shard_manager = manager.as_any().downcast_ref::<DistributedShardManager<String, String>>().unwrap();
    let stats = shard_manager.shard_stats().await.unwrap();
    
    println!("æ•°æ®åˆ†å¸ƒ:");
    for stat in &stats {
        println!("  åˆ†ç‰‡ {}: {} ä¸ªé”®", stat.shard_id, stat.key_count);
    }
    
    // è®¡ç®—æ ‡å‡†å·®ï¼Œè¡¡é‡æ•°æ®åˆ†å¸ƒå‡åŒ€æ€§
    let mean = key_count as f64 / manager.shard_count() as f64;
    let variance = stats.iter()
        .map(|s| {
            let diff = s.key_count as f64 - mean;
            diff * diff
        })
        .sum::<f64>() / stats.len() as f64;
    let std_dev = variance.sqrt();
    
    println!("å¹³å‡æ¯ä¸ªåˆ†ç‰‡: {:.2} ä¸ªé”®", mean);
    println!("æ ‡å‡†å·®: {:.2}", std_dev);
    println!("ä¸å‡åŒ€æŒ‡æ•°: {:.2}%", (std_dev / mean) * 100.0);
    
    // è¯»å–ä¸€äº›éšæœºé”®è¿›è¡ŒéªŒè¯
    println!("\nè¯»å–éªŒè¯:");
    for _ in 0..5 {
        let key_idx = rng.gen_range(0..key_count);
        let key = format!("key{}", key_idx);
        let value = manager.get(&key).await.unwrap();
        
        println!("  {} -> {:?}", key, value);
    }
}

async fn test_add_shard(manager: Arc<dyn ShardManager<String, String>>) {
    let shard_manager = manager.as_any().downcast_ref::<DistributedShardManager<String, String>>().unwrap();
    
    // è·å–å½“å‰ç»Ÿè®¡
    println!("\nå¢åŠ åˆ†ç‰‡å‰:");
    let before_stats = shard_manager.shard_stats().await.unwrap();
    for stat in &before_stats {
        println!("  åˆ†ç‰‡ {}: {} ä¸ªé”®", stat.shard_id, stat.key_count);
    }
    
    // å¢åŠ ä¸€ä¸ªåˆ†ç‰‡
    println!("\nå¢åŠ ä¸€ä¸ªåˆ†ç‰‡...");
    shard_manager.add_shard().await.unwrap();
    
    println!("æ–°åˆ†ç‰‡æ•°é‡: {}", manager.shard_count());
    
    // é‡æ–°å¹³è¡¡
    println!("æ‰§è¡Œæ•°æ®é‡å¹³è¡¡...");
    let movements = shard_manager.rebalance().await.unwrap();
    
    let total_moves = movements.values().map(|keys| keys.len()).sum::<usize>();
    println!("ç§»åŠ¨äº† {} ä¸ªé”®åˆ° {} ä¸ªåˆ†ç‰‡", total_moves, movements.len());
    
    // è·å–æ–°çš„ç»Ÿè®¡
    println!("\nå¢åŠ åˆ†ç‰‡å:");
    let after_stats = shard_manager.shard_stats().await.unwrap();
    for stat in &after_stats {
        println!("  åˆ†ç‰‡ {}: {} ä¸ªé”®", stat.shard_id, stat.key_count);
    }
}

async fn test_range_sharding(manager: Arc<RangeShardManager>) {
    // å†™å…¥ä¸€äº›æ•°æ®
    for i in 0..1000 {
        let user_id = i;
        let data = format!("ç”¨æˆ·{}çš„æ•°æ®", i);
        
        manager.put(user_id, data).await.unwrap();
    }
    
    // æŸ¥çœ‹åˆ†ç‰‡æƒ…å†µ
    println!("\nèŒƒå›´åˆ†ç‰‡æ•°æ®åˆ†å¸ƒ:");
    let stats = manager.shard_stats().await.unwrap();
    
    for (shard_id, count) in stats {
        println!("  åˆ†ç‰‡ {} ({}): {} ä¸ªé”®", 
                 shard_id,
                 manager.get_range_description(shard_id),
                 count);
    }
    
    // è¯»å–ä¸€äº›æ•°æ®
    println!("\nèŒƒå›´æŸ¥è¯¢:");
    
    // æŸ¥è¯¢IDåœ¨100-200çš„ç”¨æˆ·
    let results = manager.range_query(100, 200).await.unwrap();
    println!("  IDåœ¨100-200ä¹‹é—´çš„ç”¨æˆ·: {} ä¸ª", results.len());
    
    // æŸ¥è¯¢IDåœ¨500-550çš„ç”¨æˆ·
    let results = manager.range_query(500, 550).await.unwrap();
    println!("  IDåœ¨500-550ä¹‹é—´çš„ç”¨æˆ·: {} ä¸ª", results.len());
    
    // è·¨åˆ†ç‰‡æŸ¥è¯¢
    let results = manager.range_query(300, 700).await.unwrap();
    println!("  IDåœ¨300-700ä¹‹é—´çš„ç”¨æˆ·ï¼ˆè·¨åˆ†ç‰‡ï¼‰: {} ä¸ª", results.len());
}

// åˆ›å»ºå“ˆå¸Œåˆ†ç‰‡ç®¡ç†å™¨
fn create_hash_shard_manager(shard_count: usize) -> Arc<dyn ShardManager<String, String>> {
    // åˆ›å»ºåˆ†ç‰‡
    let mut shards = Vec::new();
    for i in 0..shard_count {
        shards.push(Arc::new(MemoryShard::new(i)) as Arc<dyn Shard<String, String>>);
    }
    
    // åˆ›å»ºåˆ†ç‰‡ç­–ç•¥
    let strategy = Arc::new(HashShardingStrategy);
    
    // åˆ›å»ºåˆ†ç‰‡ç®¡ç†å™¨
    let manager = DistributedShardManager::new(shards, strategy);
    Arc::new(manager)
}

// åˆ›å»ºä¸€è‡´æ€§å“ˆå¸Œåˆ†ç‰‡ç®¡ç†å™¨
fn create_consistent_hash_shard_manager(shard_count: usize) -> Arc<dyn ShardManager<String, String>> {
    // åˆ›å»ºåˆ†ç‰‡
    let mut shards = Vec::new();
    for i in 0..shard_count {
        shards.push(Arc::new(MemoryShard::new(i)) as Arc<dyn Shard<String, String>>);
    }
    
    // åˆ›å»ºåˆ†ç‰‡ç­–ç•¥
    let strategy = Arc::new(ConsistentHashShardingStrategy::new(shard_count, 100));
    
    // åˆ›å»ºåˆ†ç‰‡ç®¡ç†å™¨
    let manager = DistributedShardManager::new(shards, strategy);
    Arc::new(manager)
}

// åˆ›å»ºèŒƒå›´åˆ†ç‰‡ç®¡ç†å™¨
fn create_range_shard_manager() -> Arc<RangeShardManager> {
    // å®šä¹‰åˆ†ç‰‡èŒƒå›´: [å¼€å§‹, ç»“æŸ)
    let ranges = vec![
        (0, 250, "0-249"),
        (250, 500, "250-499"),
        (500, 750, "500-749"),
        (750, 1000, "750-999")
    ]

/*
<think>
Let me continue with the code for the range sharding 
manager and the rest of the implementation.
</think>
*/

    // åˆ›å»ºåˆ†ç‰‡
    let mut shards = Vec::new();
    for (i, (start, end, _)) in ranges.iter().enumerate() {
        shards.push((i, *start, *end));
    }
    
    Arc::new(RangeShardManager::new(shards, ranges))
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    println!("=== åˆ†ç‰‡æ¨¡å¼ç¤ºä¾‹ ===");
    
    // åˆ›å»ºä¸åŒç±»å‹çš„åˆ†ç‰‡ç®¡ç†å™¨
    let hash_manager = create_hash_shard_manager(4);
    let consistent_hash_manager = create_consistent_hash_shard_manager(4);
    let range_manager = create_range_shard_manager();
    
    // æµ‹è¯•åŸºæœ¬å“ˆå¸Œåˆ†ç‰‡
    println!("\n### æµ‹è¯•å“ˆå¸Œåˆ†ç‰‡ ###");
    println!("ä½¿ç”¨æ ‡å‡†å“ˆå¸Œåˆ†ç‰‡ç­–ç•¥");
    
    test_sharding(hash_manager.clone(), 1000).await;
    
    // æµ‹è¯•ä¸€è‡´æ€§å“ˆå¸Œåˆ†ç‰‡
    println!("\n### æµ‹è¯•ä¸€è‡´æ€§å“ˆå¸Œåˆ†ç‰‡ ###");
    println!("ä½¿ç”¨ä¸€è‡´æ€§å“ˆå¸Œåˆ†ç‰‡ç­–ç•¥");
    
    test_sharding(consistent_hash_manager.clone(), 1000).await;
    
    // æµ‹è¯•æ·»åŠ æ–°åˆ†ç‰‡
    println!("\n### æµ‹è¯•æ·»åŠ åˆ†ç‰‡å¹¶é‡å¹³è¡¡ ###");
    
    test_add_shard(consistent_hash_manager.clone()).await;
    
    // æµ‹è¯•èŒƒå›´åˆ†ç‰‡
    println!("\n### æµ‹è¯•èŒƒå›´åˆ†ç‰‡ ###");
    
    test_range_sharding(range_manager.clone()).await;
    
    // æµ‹è¯•åˆ†ç‰‡æ•…éšœå¤„ç†
    println!("\n### æµ‹è¯•åˆ†ç‰‡æ•…éšœå¤„ç† ###");
    
    test_shard_failure(consistent_hash_manager.clone()).await;
}

async fn test_shard_failure(manager: Arc<dyn ShardManager<String, String>>) {
    let shard_manager = manager.as_any()
    .downcast_ref::<DistributedShardManager<String, String>>().unwrap();
    
    // å…ˆå†™å…¥ä¸€äº›æ•°æ®
    println!("å†™å…¥æ•°æ®...");
    let mut rng = StdRng::seed_from_u64(42);
    for i in 0..200 {
        let key = format!("failure_key{}", i);
        let value = format!("value{}", i);
        
        shard_manager.put(key, value).await.unwrap();
    }
    
    // è·å–å½“å‰åˆ†ç‰‡çŠ¶æ€
    println!("\næ•…éšœå‰åˆ†ç‰‡çŠ¶æ€:");
    let before_stats = shard_manager.shard_stats().await.unwrap();
    for stat in &before_stats {
        println!("  åˆ†ç‰‡ {}: {} ä¸ªé”®", stat.shard_id, stat.key_count);
    }
    
    // æ¨¡æ‹Ÿåˆ†ç‰‡æ•…éšœ
    let failed_shard_id = 1; // è®©åˆ†ç‰‡1æ•…éšœ
    println!("\næ¨¡æ‹Ÿåˆ†ç‰‡ {} æ•…éšœ...", failed_shard_id);
    shard_manager.mark_shard_failed(failed_shard_id).await.unwrap();
    
    println!("æ¿€æ´»æ•…éšœè½¬ç§»...");
    let moved_keys = shard_manager.handle_shard_failure(failed_shard_id).await.unwrap();
    
    println!("å°† {} ä¸ªé”®ä»åˆ†ç‰‡ {} ç§»åŠ¨åˆ°å…¶ä»–åˆ†ç‰‡", moved_keys.len(), failed_shard_id);
    
    // éªŒè¯åˆ†ç‰‡æ•…éšœåçš„è¯»å–
    println!("\néªŒè¯æ•…éšœè½¬ç§»åçš„è¯»å–:");
    for i in 0..5 {
        let key = format!("failure_key{}", rng.gen_range(0..200));
        let result = shard_manager.get(&key).await;
        
        match result {
            Ok(Some(value)) => println!("  {} -> {} (æˆåŠŸ)", key, value),
            Ok(None) => println!("  {} -> æœªæ‰¾åˆ°", key),
            Err(e) => println!("  {} -> é”™è¯¯: {}", key, e),
        }
    }
    
    // è·å–æ•…éšœååˆ†ç‰‡çŠ¶æ€
    println!("\næ•…éšœååˆ†ç‰‡çŠ¶æ€:");
    let after_stats = shard_manager.shard_stats().await.unwrap();
    for stat in &after_stats {
        if stat.shard_id == failed_shard_id {
            println!("  åˆ†ç‰‡ {}: {} ä¸ªé”® (æ•…éšœ)", stat.shard_id, stat.key_count);
        } else {
            println!("  åˆ†ç‰‡ {}: {} ä¸ªé”®", stat.shard_id, stat.key_count);
        }
    }
    
    // æ¢å¤åˆ†ç‰‡
    println!("\næ¢å¤åˆ†ç‰‡ {}...", failed_shard_id);
    shard_manager.recover_shard(failed_shard_id).await.unwrap();
    
    // é‡æ–°å¹³è¡¡
    println!("æ‰§è¡Œé‡å¹³è¡¡...");
    let movements = shard_manager.rebalance().await.unwrap();
    
    let total_moves = movements.values().map(|keys| keys.len()).sum::<usize>();
    println!("æ¢å¤åç§»åŠ¨äº† {} ä¸ªé”®", total_moves);
    
    // è·å–æ¢å¤ååˆ†ç‰‡çŠ¶æ€
    println!("\næ¢å¤ååˆ†ç‰‡çŠ¶æ€:");
    let recovery_stats = shard_manager.shard_stats().await.unwrap();
    for stat in &recovery_stats {
        println!("  åˆ†ç‰‡ {}: {} ä¸ªé”®", stat.shard_id, stat.key_count);
    }
}
```

### 11.2 å¤åˆ¶æ¨¡å¼

å¤åˆ¶æ¨¡å¼é€šè¿‡åœ¨å¤šä¸ªèŠ‚ç‚¹ä¸Šå¤åˆ¶æ•°æ®ï¼Œæé«˜ç³»ç»Ÿçš„è¯»å–æ€§èƒ½å’Œå¯ç”¨æ€§ã€‚

```rust
use std::collections::{HashMap, HashSet};
use std::fmt::Debug;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{RwLock, Mutex};
use tokio::time::sleep;
use rand::{Rng, SeedableRng};
use rand::rngs::StdRng;
use uuid::Uuid;
use serde::{Serialize, Deserialize};
use async_trait::async_trait;

// å¤åˆ¶èŠ‚ç‚¹ç±»å‹
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
enum ReplicaRole {
    Primary,   // ä¸»èŠ‚ç‚¹ï¼Œè´Ÿè´£è¯»å†™
    Secondary, // ä»èŠ‚ç‚¹ï¼Œåªè¯»
    Standby,   // çƒ­å¤‡èŠ‚ç‚¹ï¼Œä¸æœåŠ¡è¯·æ±‚ï¼Œä½†ä¿æŒæ•°æ®åŒæ­¥
}

// å¤åˆ¶èŠ‚ç‚¹çŠ¶æ€
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
enum ReplicaState {
    Online,
    Offline,
    Recovering,
    Syncing,
}

// æ•°æ®æ“ä½œ
#[derive(Debug, Clone, Serialize, Deserialize)]
enum DataOperation<K, V> {
    Put(K, V),
    Delete(K),
    Clear,
}

// å¤åˆ¶æ—¥å¿—æ¡ç›®
#[derive(Debug, Clone, Serialize, Deserialize)]
struct ReplicationLogEntry<K, V> {
    id: String,
    timestamp: u64,
    operation: DataOperation<K, V>,
}

// å¤åˆ¶èŠ‚ç‚¹æ¥å£
#[async_trait]
trait Replica<K, V>: Send + Sync {
    // è·å–èŠ‚ç‚¹ID
    fn id(&self) -> &str;
    
    // è·å–èŠ‚ç‚¹è§’è‰²
    fn role(&self) -> ReplicaRole;
    
    // è·å–èŠ‚ç‚¹çŠ¶æ€
    async fn state(&self) -> ReplicaState;
    
    // è®¾ç½®èŠ‚ç‚¹è§’è‰²
    async fn set_role(&self, role: ReplicaRole);
    
    // è®¾ç½®èŠ‚ç‚¹çŠ¶æ€
    async fn set_state(&self, state: ReplicaState);
    
    // å†™å…¥æ•°æ®
    async fn put(&self, key: K, value: V) -> Result<(), String>;
    
    // è¯»å–æ•°æ®
    async fn get(&self, key: &K) -> Result<Option<V>, String>;
    
    // åˆ é™¤æ•°æ®
    async fn delete(&self, key: &K) -> Result<bool, String>;
    
    // æ¸…ç©ºæ•°æ®
    async fn clear(&self) -> Result<(), String>;
    
    // è·å–æ‰€æœ‰é”®
    async fn keys(&self) -> Result<Vec<K>, String>;
    
    // è·å–æ•°æ®é‡
    async fn size(&self) -> Result<usize, String>;
    
    // åº”ç”¨æ“ä½œ
    async fn apply_operation(&self, op: DataOperation<K, V>) -> Result<(), String>;
    
    // åŒæ­¥æ•°æ®ï¼ˆä»å¦ä¸€ä¸ªèŠ‚ç‚¹ï¼‰
    async fn sync_from(&self, source: Arc<dyn Replica<K, V>>) -> Result<usize, String>;
    
    // è·å–æœ€åæ›´æ–°æ—¶é—´
    async fn last_updated(&self) -> Instant;
    
    // è·å–å¤åˆ¶æ—¥å¿—
    async fn get_replication_log(&self, since: Option<u64>) -> Result<Vec<ReplicationLogEntry<K, V>>, String>;
}

// å†…å­˜å¤åˆ¶èŠ‚ç‚¹å®ç°
struct MemoryReplica<K, V> {
    id: String,
    role: RwLock<ReplicaRole>,
    state: RwLock<ReplicaState>,
    data: RwLock<HashMap<K, V>>,
    last_update: RwLock<Instant>,
    replication_log: RwLock<Vec<ReplicationLogEntry<K, V>>>,
    log_retention: usize, // ä¿ç•™çš„æ—¥å¿—æ¡ç›®æ•°
}

impl<K, V> MemoryReplica<K, V>
where
...(about 100 lines omitted)...
    async fn sync_from(&self, source: Arc<dyn Replica<K, V>>) -> Result<usize, String> {
        let mut state = self.state.write().await;
        *state = ReplicaState::Syncing;
        drop(state); // é‡Šæ”¾é”
        
        // è·å–å½“å‰æœ€åä¸€æ¡æ—¥å¿—çš„æ—¶é—´æˆ³
        let last_timestamp = {
            let log = self.replication_log.read().await;
            log.last().map(|entry| entry.timestamp).unwrap_or(0)
        };
        
        // ä»æºèŠ‚ç‚¹è·å–å¢é‡æ—¥å¿—
        let new_entries = source.get_replication_log(Some(last_timestamp)).await?;
        
        if new_entries.is_empty() {
            // æ²¡æœ‰æ–°æ•°æ®ï¼Œè®¾ç½®ä¸ºåœ¨çº¿çŠ¶æ€
            let mut state = self.state.write().await;
            *state = ReplicaState::Online;
            return Ok(0);
        }
        
        // åº”ç”¨æ‰€æœ‰æ–°æ“ä½œ
        let mut applied_count = 0;
        for entry in new_entries.iter() {
            self.apply_operation(entry.operation.clone()).await?;
            applied_count += 1;
            
            // æ·»åŠ åˆ°æœ¬åœ°å¤åˆ¶æ—¥å¿—
            let mut log = self.replication_log.write().await;
            log.push(entry.clone());
            
            // å¦‚æœè¶…è¿‡ä¿ç•™é™åˆ¶ï¼Œåˆ é™¤æ—§æ—¥å¿—
            while log.len() > self.log_retention {
                log.remove(0);
            }
        }
        
        // æ›´æ–°åŒæ­¥æ—¶é—´
        let mut last_update = self.last_update.write().await;
        *last_update = Instant::now();
        
        // è®¾ç½®ä¸ºåœ¨çº¿çŠ¶æ€
        let mut state = self.state.write().await;
        *state = ReplicaState::Online;
        
        Ok(applied_count)
    }
    
    async fn last_updated(&self) -> Instant {
        *self.last_update.read().await
    }
    
    async fn get_replication_log(&self, since: Option<u64>) -> Result<Vec<ReplicationLogEntry<K, V>>, String> {
        let log = self.replication_log.read().await;
        
        let filtered_log = if let Some(timestamp) = since {
            log.iter()
                .filter(|entry| entry.timestamp > timestamp)
                .cloned()
                .collect()
        } else {
            log.clone()
        };
        
        Ok(filtered_log)
    }
}

// å¤åˆ¶ç»„æ¥å£
#[async_trait]
trait ReplicaGroup<K, V>: Send + Sync {
    // æ·»åŠ å¤åˆ¶èŠ‚ç‚¹
    async fn add_replica(&self, replica: Arc<dyn Replica<K, V>>) -> Result<(), String>;
    
    // ç§»é™¤å¤åˆ¶èŠ‚ç‚¹
    async fn remove_replica(&self, replica_id: &str) -> Result<(), String>;
    
    // è·å–ä¸»èŠ‚ç‚¹
    async fn get_primary(&self) -> Option<Arc<dyn Replica<K, V>>>;
    
    // è·å–æ‰€æœ‰ä»èŠ‚ç‚¹
    async fn get_secondaries(&self) -> Vec<Arc<dyn Replica<K, V>>>;
    
    // è·å–æ‰€æœ‰çƒ­å¤‡èŠ‚ç‚¹
    async fn get_standbys(&self) -> Vec<Arc<dyn Replica<K, V>>>;
    
    // è·å–æ‰€æœ‰èŠ‚ç‚¹
    async fn get_all_replicas(&self) -> Vec<Arc<dyn Replica<K, V>>>;
    
    // è·å–ç‰¹å®šèŠ‚ç‚¹
    async fn get_replica(&self, replica_id: &str) -> Option<Arc<dyn Replica<K, V>>>;
    
    // è®¾ç½®ä¸»èŠ‚ç‚¹
    async fn set_primary(&self, replica_id: &str) -> Result<(), String>;
    
    // å†™å…¥æ•°æ®ï¼ˆåˆ°ä¸»èŠ‚ç‚¹ï¼‰
    async fn write(&self, key: K, value: V) -> Result<(), String>;
    
    // è¯»å–æ•°æ®ï¼ˆå¯ä»¥ä»ä»»ä½•èŠ‚ç‚¹ï¼‰
    async fn read(&self, key: &K) -> Result<Option<V>, String>;
    
    // åˆ é™¤æ•°æ®
    async fn delete(&self, key: &K) -> Result<bool, String>;
    
    // åŒæ­¥å¤åˆ¶ç»„
    async fn sync_group(&self) -> Result<HashMap<String, usize>, String>;
    
    // æ•…éšœè½¬ç§»
    async fn failover(&self, failed_primary_id: &str) -> Result<Option<String>, String>;
}

// å¤åˆ¶ç»„å®ç°
struct ReplicaGroupImpl<K, V> {
    replicas: RwLock<HashMap<String, Arc<dyn Replica<K, V>>>>,
    primary_id: RwLock<Option<String>>,
    read_preference: ReadPreference,
}

// è¯»å–åå¥½
#[derive(Debug, Clone, Copy)]
enum ReadPreference {
    PrimaryOnly,           // åªä»ä¸»èŠ‚ç‚¹è¯»å–
    PrimaryPreferred,      // ä¼˜å…ˆä»ä¸»èŠ‚ç‚¹è¯»å–ï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä»ä»èŠ‚ç‚¹è¯»å–
    SecondaryOnly,         // åªä»ä»èŠ‚ç‚¹è¯»å–
    SecondaryPreferred,    // ä¼˜å…ˆä»ä»èŠ‚ç‚¹è¯»å–ï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä»ä¸»èŠ‚ç‚¹è¯»å–
    Nearest,               // ä»å»¶è¿Ÿæœ€ä½çš„èŠ‚ç‚¹è¯»å–
}


/*
<think>
æˆ‘å°†ç»§ç»­æä¾›åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡æ¨¡å¼ä¸­å¤åˆ¶æ¨¡å¼çš„ä»£ç ç¤ºä¾‹ï¼Œç»§ç»­ ReplicaGroupImpl å®ç°éƒ¨åˆ†ã€‚
</think>
*/

impl<K, V> ReplicaGroupImpl<K, V>
where
    K: Clone + Eq + std::hash::Hash + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    fn new(read_preference: ReadPreference) -> Self {
        Self {
            replicas: RwLock::new(HashMap::new()),
            primary_id: RwLock::new(None),
            read_preference,
        }
    }
    
    // ç”¨äºéšæœºé€‰æ‹©ä»èŠ‚ç‚¹çš„è¾…åŠ©æ–¹æ³•
    async fn select_secondary(&self) -> Option<Arc<dyn Replica<K, V>>> {
        let replicas = self.replicas.read().await;
        let primary_id = self.primary_id.read().await;
        
        let secondaries: Vec<_> = replicas.values()
            .filter(|r| r.role() == ReplicaRole::Secondary)
            .filter(|r| async {
                r.state().await == ReplicaState::Online
            }.await)
            .cloned()
            .collect();
        
        if secondaries.is_empty() {
            return None;
        }
        
        // éšæœºé€‰æ‹©ä¸€ä¸ªä»èŠ‚ç‚¹
        let idx = rand::thread_rng().gen_range(0..secondaries.len());
        Some(secondaries[idx].clone())
    }
}

#[async_trait]
impl<K, V> ReplicaGroup<K, V> for ReplicaGroupImpl<K, V>
where
    K: Clone + Eq + std::hash::Hash + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    async fn add_replica(&self, replica: Arc<dyn Replica<K, V>>) -> Result<(), String> {
        let replica_id = replica.id().to_string();
        let role = replica.role();
        
        let mut replicas = self.replicas.write().await;
        
        // å¦‚æœæ˜¯ä¸»èŠ‚ç‚¹ä¸”å·²æœ‰ä¸»èŠ‚ç‚¹ï¼Œåˆ™è¿”å›é”™è¯¯
        if role == ReplicaRole::Primary {
            let primary_id = self.primary_id.read().await;
            if let Some(id) = &*primary_id {
                if id != &replica_id {
                    return Err(format!("å·²å­˜åœ¨ä¸»èŠ‚ç‚¹: {}", id));
                }
            }
            
            // è®¾ç½®ä¸ºä¸»èŠ‚ç‚¹
            drop(primary_id);
            let mut primary_id = self.primary_id.write().await;
            *primary_id = Some(replica_id.clone());
        }
        
        // æ·»åŠ åˆ°å¤åˆ¶ç»„
        replicas.insert(replica_id, replica);
        
        Ok(())
    }
    
    async fn remove_replica(&self, replica_id: &str) -> Result<(), String> {
        let mut replicas = self.replicas.write().await;
        
        // å¦‚æœæ˜¯ä¸»èŠ‚ç‚¹ï¼Œåˆ™æ¸…é™¤ä¸»èŠ‚ç‚¹ID
        let primary_id = self.primary_id.read().await;
        if let Some(id) = &*primary_id {
            if id == replica_id {
                drop(primary_id);
                let mut primary_id = self.primary_id.write().await;
                *primary_id = None;
            }
        }
        
        // ä»å¤åˆ¶ç»„ç§»é™¤
        if replicas.remove(replica_id).is_none() {
            return Err(format!("èŠ‚ç‚¹ä¸å­˜åœ¨: {}", replica_id));
        }
        
        Ok(())
    }
    
    async fn get_primary(&self) -> Option<Arc<dyn Replica<K, V>>> {
        let primary_id = self.primary_id.read().await;
        let id = primary_id.as_ref()?;
        
        let replicas = self.replicas.read().await;
        replicas.get(id).cloned()
    }
    
    async fn get_secondaries(&self) -> Vec<Arc<dyn Replica<K, V>>> {
        let replicas = self.replicas.read().await;
        
        replicas.values()
            .filter(|r| r.role() == ReplicaRole::Secondary)
            .cloned()
            .collect()
    }
    
    async fn get_standbys(&self) -> Vec<Arc<dyn Replica<K, V>>> {
        let replicas = self.replicas.read().await;
        
        replicas.values()
            .filter(|r| r.role() == ReplicaRole::Standby)
            .cloned()
            .collect()
    }
    
    async fn get_all_replicas(&self) -> Vec<Arc<dyn Replica<K, V>>> {
        let replicas = self.replicas.read().await;
        replicas.values().cloned().collect()
    }
    
    async fn get_replica(&self, replica_id: &str) -> Option<Arc<dyn Replica<K, V>>> {
        let replicas = self.replicas.read().await;
        replicas.get(replica_id).cloned()
    }
    
    async fn set_primary(&self, replica_id: &str) -> Result<(), String> {
        let replicas = self.replicas.read().await;
        
        // æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å­˜åœ¨
        let replica = match replicas.get(replica_id) {
            Some(r) => r,
            None => return Err(format!("èŠ‚ç‚¹ä¸å­˜åœ¨: {}", replica_id)),
        };
        
        // è·å–æ—§ä¸»èŠ‚ç‚¹
        let old_primary_id = {
            let primary_id = self.primary_id.read().await;
            primary_id.clone()
        };
        
        // å¦‚æœå·²ç»æ˜¯ä¸»èŠ‚ç‚¹ï¼Œåˆ™ä¸åšä»»ä½•æ“ä½œ
        if let Some(id) = &old_primary_id {
            if id == replica_id {
                return Ok(());
            }
        }
        
        // å°†æ—§ä¸»èŠ‚ç‚¹è®¾ç½®ä¸ºä»èŠ‚ç‚¹
        if let Some(id) = old_primary_id {
            if let Some(old_primary) = replicas.get(&id) {
                old_primary.set_role(ReplicaRole::Secondary).await;
            }
        }
        
        // å°†æ–°èŠ‚ç‚¹è®¾ç½®ä¸ºä¸»èŠ‚ç‚¹
        replica.set_role(ReplicaRole::Primary).await;
        
        // æ›´æ–°ä¸»èŠ‚ç‚¹ID
        let mut primary_id = self.primary_id.write().await;
        *primary_id = Some(replica_id.to_string());
        
        Ok(())
    }
    
    async fn write(&self, key: K, value: V) -> Result<(), String> {
        // è·å–ä¸»èŠ‚ç‚¹
        let primary = self.get_primary().await
            .ok_or_else(|| "æ— ä¸»èŠ‚ç‚¹".to_string())?;
        
        // ä¸»èŠ‚ç‚¹å¿…é¡»åœ¨çº¿
        if primary.state().await != ReplicaState::Online {
            return Err("ä¸»èŠ‚ç‚¹ä¸åœ¨çº¿".to_string());
        }
        
        // å†™å…¥æ•°æ®
        primary.put(key, value).await
    }
    
    async fn read(&self, key: &K) -> Result<Option<V>, String> {
        match self.read_preference {
            ReadPreference::PrimaryOnly => {
                // åªä»ä¸»èŠ‚ç‚¹è¯»å–
                let primary = self.get_primary().await
                    .ok_or_else(|| "æ— ä¸»èŠ‚ç‚¹".to_string())?;
                
                if primary.state().await != ReplicaState::Online {
                    return Err("ä¸»èŠ‚ç‚¹ä¸åœ¨çº¿".to_string());
                }
                
                primary.get(key).await
            },
            ReadPreference::PrimaryPreferred => {
                // ä¼˜å…ˆä»ä¸»èŠ‚ç‚¹è¯»å–
                if let Some(primary) = self.get_primary().await {
                    if primary.state().await == ReplicaState::Online {
                        return primary.get(key).await;
                    }
                }
                
                // ä¸»èŠ‚ç‚¹ä¸å¯ç”¨ï¼Œå°è¯•ä»èŠ‚ç‚¹
                if let Some(secondary) = self.select_secondary().await {
                    return secondary.get(key).await;
                }
                
                Err("æ— å¯ç”¨èŠ‚ç‚¹".to_string())
            },
            ReadPreference::SecondaryOnly => {
                // åªä»ä»èŠ‚ç‚¹è¯»å–
                if let Some(secondary) = self.select_secondary().await {
                    return secondary.get(key).await;
                }
                
                Err("æ— å¯ç”¨ä»èŠ‚ç‚¹".to_string())
            },
            ReadPreference::SecondaryPreferred => {
                // ä¼˜å…ˆä»ä»èŠ‚ç‚¹è¯»å–
                if let Some(secondary) = self.select_secondary().await {
                    return secondary.get(key).await;
                }
                
                // ä»èŠ‚ç‚¹ä¸å¯ç”¨ï¼Œå°è¯•ä¸»èŠ‚ç‚¹
                if let Some(primary) = self.get_primary().await {
                    if primary.state().await == ReplicaState::Online {
                        return primary.get(key).await;
                    }
                }
                
                Err("æ— å¯ç”¨èŠ‚ç‚¹".to_string())
            },
            ReadPreference::Nearest => {
                // é€‰æ‹©æœ€è¿‘çš„èŠ‚ç‚¹ï¼ˆè¿™é‡Œç®€åŒ–ä¸ºéšæœºé€‰æ‹©æ‰€æœ‰åœ¨çº¿èŠ‚ç‚¹ï¼‰
                let replicas = self.replicas.read().await;
                let online_replicas: Vec<_> = replicas.values()
                    .filter(|r| async {
                        r.state().await == ReplicaState::Online
                    }.await)
                    .collect();
                
                if online_replicas.is_empty() {
                    return Err("æ— å¯ç”¨èŠ‚ç‚¹".to_string());
                }
                
                let idx = rand::thread_rng().gen_range(0..online_replicas.len());
                online_replicas[idx].get(key).await
            }
        }
    }
    
    async fn delete(&self, key: &K) -> Result<bool, String> {
        // è·å–ä¸»èŠ‚ç‚¹
        let primary = self.get_primary().await
            .ok_or_else(|| "æ— ä¸»èŠ‚ç‚¹".to_string())?;
        
        // ä¸»èŠ‚ç‚¹å¿…é¡»åœ¨çº¿
        if primary.state().await != ReplicaState::Online {
            return Err("ä¸»èŠ‚ç‚¹ä¸åœ¨çº¿".to_string());
        }
        
        // åˆ é™¤æ•°æ®
        primary.delete(key).await
    }
    
    async fn sync_group(&self) -> Result<HashMap<String, usize>, String> {
        let primary = self.get_primary().await
            .ok_or_else(|| "æ— ä¸»èŠ‚ç‚¹".to_string())?;
        
        // åŒæ­¥æ‰€æœ‰éä¸»èŠ‚ç‚¹
        let replicas = self.replicas.read().await;
        let mut sync_results = HashMap::new();
        
        for (id, replica) in replicas.iter() {
            // è·³è¿‡ä¸»èŠ‚ç‚¹å’Œç¦»çº¿èŠ‚ç‚¹
            if replica.id() == primary.id() || replica.state().await == ReplicaState::Offline {
                continue;
            }
            
            // åŒæ­¥æ•°æ®
            match replica.sync_from(primary.clone()).await {
                Ok(count) => {
                    sync_results.insert(id.clone(), count);
                },
                Err(e) => {
                    sync_results.insert(id.clone(), 0);
                    println!("åŒæ­¥èŠ‚ç‚¹ {} å¤±è´¥: {}", id, e);
                }
            }
        }
        
        Ok(sync_results)
    }
    
    async fn failover(&self, failed_primary_id: &str) -> Result<Option<String>, String> {
        // æ£€æŸ¥æŒ‡å®šçš„èŠ‚ç‚¹æ˜¯å¦ä¸ºå½“å‰ä¸»èŠ‚ç‚¹
        let current_primary_id = {
            let primary_id = self.primary_id.read().await;
            primary_id.clone()
        };
        
        if let Some(id) = &current_primary_id {
            if id != failed_primary_id {
                return Err(format!("æŒ‡å®šèŠ‚ç‚¹ {} ä¸æ˜¯å½“å‰ä¸»èŠ‚ç‚¹ {}", failed_primary_id, id));
            }
        } else {
            return Err("å½“å‰æ— ä¸»èŠ‚ç‚¹".to_string());
        }
        
        // å°†å¤±è´¥çš„ä¸»èŠ‚ç‚¹è®¾ç½®ä¸ºç¦»çº¿
        if let Some(failed_primary) = self.get_replica(failed_primary_id).await {
            failed_primary.set_state(ReplicaState::Offline).await;
        }
        
        // é€‰æ‹©æ–°çš„ä¸»èŠ‚ç‚¹ï¼ˆä¼˜å…ˆé€‰æ‹©ä»èŠ‚ç‚¹ï¼Œå…¶æ¬¡æ˜¯çƒ­å¤‡èŠ‚ç‚¹ï¼‰
        let secondaries = self.get_secondaries().await;
        let standbys = self.get_standbys().await;
        
        let online_secondaries: Vec<_> = secondaries.iter()
            .filter(|r| async {
                r.state().await == ReplicaState::Online
            }.await)
            .collect();
        
        let online_standbys: Vec<_> = standbys.iter()
            .filter(|r| async {
                r.state().await == ReplicaState::Online
            }.await)
            .collect();
        
        // é€‰æ‹©æ–°ä¸»èŠ‚ç‚¹
        let new_primary = if !online_secondaries.is_empty() {
            // é€‰æ‹©æœ€æ–°çš„ä»èŠ‚ç‚¹
            online_secondaries.iter()
                .max_by_key(|r| async {
                    r.last_updated().await
                }.await)
                .map(|r| (*r).clone())
        } else if !online_standbys.is_empty() {
            // å¦‚æœæ²¡æœ‰ä»èŠ‚ç‚¹ï¼Œé€‰æ‹©æœ€æ–°çš„çƒ­å¤‡èŠ‚ç‚¹
            online_standbys.iter()
                .max_by_key(|r| async {
                    r.last_updated().await
                }.await)
                .map(|r| (*r).clone())
        } else {
            None
        };
        
        // å¦‚æœæ‰¾åˆ°æ–°ä¸»èŠ‚ç‚¹ï¼Œåˆ™æ‰§è¡Œæ•…éšœè½¬ç§»
        if let Some(new_primary) = new_primary {
            let new_primary_id = new_primary.id().to_string();
            self.set_primary(&new_primary_id).await?;
            return Ok(Some(new_primary_id));
        }
        
        // æ— å¯ç”¨èŠ‚ç‚¹
        let mut primary_id = self.primary_id.write().await;
        *primary_id = None;
        
        Ok(None)
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    println!("=== å¤åˆ¶æ¨¡å¼ç¤ºä¾‹ ===");
    
    // åˆ›å»ºå¤åˆ¶ç»„
    let replica_group: Arc<dyn ReplicaGroup<String, String>> = Arc::new(
        ReplicaGroupImpl::new(ReadPreference::PrimaryPreferred)
    );
    
    // åˆ›å»ºèŠ‚ç‚¹
    let primary = Arc::new(MemoryReplica::new("node1", ReplicaRole::Primary, 100));
    let secondary1 = Arc::new(MemoryReplica::new("node2", ReplicaRole::Secondary, 100));
    let secondary2 = Arc::new(MemoryReplica::new("node3", ReplicaRole::Secondary, 100));
    let standby = Arc::new(MemoryReplica::new("node4", ReplicaRole::Standby, 100));
    
    // æ·»åŠ èŠ‚ç‚¹åˆ°å¤åˆ¶ç»„
    println!("æ·»åŠ èŠ‚ç‚¹åˆ°å¤åˆ¶ç»„...");
    replica_group.add_replica(primary.clone()).await.unwrap();
    replica_group.add_replica(secondary1.clone()).await.unwrap();
    replica_group.add_replica(secondary2.clone()).await.unwrap();
    replica_group.add_replica(standby.clone()).await.unwrap();
    
    // å†™å…¥ä¸€äº›æ•°æ®
    println!("\nå†™å…¥æ•°æ®...");
    for i in 1..=10 {
        let key = format!("key{}", i);
        let value = format!("value{}", i);
        
        replica_group.write(key, value).await.unwrap();
    }
    
    // åŒæ­¥å¤åˆ¶ç»„
    println!("\nåŒæ­¥å¤åˆ¶ç»„...");
    let sync_results = replica_group.sync_group().await.unwrap();
    
    for (id, count) in &sync_results {
        println!("èŠ‚ç‚¹ {} åŒæ­¥äº† {} ä¸ªæ“ä½œ", id, count);
    }
    
    // è¯»å–æ•°æ®ï¼ˆåº”è¯¥ä»ä»»ä½•èŠ‚ç‚¹è¯»å–ï¼ŒåŸºäºè¯»å–åå¥½ï¼‰
    println!("\nä»å¤åˆ¶ç»„è¯»å–æ•°æ®...");
    for i in 1..=5 {
        let key = format!("key{}", i);
        let value = replica_group.read(&key).await.unwrap();
        
        println!("{} -> {:?}", key, value);
    }
    
    // æ¨¡æ‹Ÿä¸»èŠ‚ç‚¹æ•…éšœ
    println!("\næ¨¡æ‹Ÿä¸»èŠ‚ç‚¹æ•…éšœ...");
    let primary_id = "node1";
    let new_primary = replica_group.failover(primary_id).await.unwrap();
    
    println!("æ•…éšœè½¬ç§»ç»“æœ: æ–°ä¸»èŠ‚ç‚¹ = {:?}", new_primary);
    
    // å†æ¬¡å†™å…¥å’Œè¯»å–æ•°æ®
    println!("\næ•…éšœè½¬ç§»åå†™å…¥æ–°æ•°æ®...");
    for i in 11..=15 {
        let key = format!("key{}", i);
        let value = format!("value{}", i);
        
        match replica_group.write(key.clone(), value).await {
            Ok(()) => println!("æˆåŠŸå†™å…¥ {}", key),
            Err(e) => println!("å†™å…¥ {} å¤±è´¥: {}", key, e),
        }
    }
    
    // è¯»å–æ‰€æœ‰æ•°æ®
    println!("\næ•…éšœè½¬ç§»åè¯»å–æ‰€æœ‰æ•°æ®...");
    if let Some(new_primary_id) = &new_primary {
        let new_primary_node = replica_group.get_replica(new_primary_id).await.unwrap();
        let keys = new_primary_node.keys().await.unwrap();
        
        for key in keys {
            let value = replica_group.read(&key).await.unwrap();
            println!("{} -> {:?}", key, value);
        }
    }
    
    // æ¢å¤åŸä¸»èŠ‚ç‚¹
    if let Some(new_primary_id) = &new_primary {
        println!("\næ¢å¤åŸä¸»èŠ‚ç‚¹...");
        
        // é‡æ–°ä¸Šçº¿åŸä¸»èŠ‚ç‚¹ä½œä¸ºä»èŠ‚ç‚¹
        let original_primary = replica_group.get_replica(primary_id).await.unwrap();
        original_primary.set_role(ReplicaRole::Secondary).await;
        original_primary.set_state(ReplicaState::Online).await;
        
        // åŒæ­¥æ•°æ®
        let new_primary_node = replica_group.get_replica(new_primary_id).await.unwrap();
        let sync_count = original_primary.sync_from(new_primary_node).await.unwrap();
        
        println!("åŸä¸»èŠ‚ç‚¹ {} ä½œä¸ºä»èŠ‚ç‚¹æ¢å¤ï¼ŒåŒæ­¥äº† {} ä¸ªæ“ä½œ", primary_id, sync_count);
        
        // æ˜¾ç¤ºå½“å‰æ‰€æœ‰èŠ‚ç‚¹çŠ¶æ€
        println!("\nå½“å‰å¤åˆ¶ç»„çŠ¶æ€:");
        let all_replicas = replica_group.get_all_replicas().await;
        
        for replica in all_replicas {
            println!("èŠ‚ç‚¹ {}: è§’è‰²={:?}, çŠ¶æ€={:?}, æ•°æ®é‡={}",
                     replica.id(), replica.role(), replica.state().await,
                     replica.size().await.unwrap());
        }
    }
}
```

### 11.3 ç¼“å­˜æ¨¡å¼

ç¼“å­˜æ¨¡å¼é€šè¿‡ä¸´æ—¶å­˜å‚¨é¢‘ç¹è®¿é—®çš„æ•°æ®ï¼Œå‡å°‘å¯¹åç«¯å­˜å‚¨ç³»ç»Ÿçš„è®¿é—®ï¼Œæé«˜è¯»å–æ€§èƒ½å’Œç³»ç»Ÿååé‡ã€‚

```rust
use std::collections::{HashMap, LinkedList};
use std::hash::Hash;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{RwLock, Mutex};
use tokio::time::sleep;
use rand::{Rng, SeedableRng};
use rand::rngs::StdRng;
use async_trait::async_trait;

// ç¼“å­˜é”®å€¼å¯¹
#[derive(Debug, Clone)]
struct CacheEntry<V> {
    value: V,
    created_at: Instant,
    expires_at: Option<Instant>,
    last_accessed: Instant,
    access_count: u64,
}

impl<V> CacheEntry<V> {
    fn new(value: V, ttl: Option<Duration>) -> Self {
        let now = Instant::now();
        Self {
            value,
            created_at: now,
            expires_at: ttl.map(|ttl| now + ttl),
            last_accessed: now,
            access_count: 0,
        }
    }
    
    // æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
    fn is_expired(&self) -> bool {
        if let Some(expires_at) = self.expires_at {
            Instant::now() > expires_at
        } else {
            false
        }
    }
    
    // è®¿é—®å€¼å¹¶æ›´æ–°ç»Ÿè®¡
    fn access(&mut self) -> &V {
        self.last_accessed = Instant::now();
        self.access_count += 1;
        &self.value
    }
}

/*
<think>
æˆ‘éœ€è¦ç»§ç»­å®Œæˆç¼“å­˜æ¨¡å¼çš„ä»£ç ç¤ºä¾‹ã€‚è¿™åº”è¯¥åŒ…æ‹¬å®Œæ•´çš„ç¼“å­˜æ¥å£å®šä¹‰ã€ç¼“å­˜ç­–ç•¥å®ç°ã€ä»¥åŠä½¿ç”¨ç¤ºä¾‹ã€‚æ¥ä¸‹æ¥åº”è¯¥æ˜¯å®šä¹‰ç¼“å­˜æ¥å£ã€å„ç§ç¼“å­˜æ·˜æ±°ç­–ç•¥ã€å®ç°å…·ä½“çš„ç¼“å­˜ç±»ã€ä»¥åŠå±•ç¤ºå¦‚ä½•ä½¿ç”¨è¿™äº›ç¼“å­˜ã€‚

æˆ‘ä¼šç»§ç»­å®Œæˆç¼“å­˜æ¨¡å¼çš„ä»£ç ï¼ŒåŒ…æ‹¬ï¼š
1. ç¼“å­˜æ¥å£(Cache trait)
2. ç¼“å­˜ç­–ç•¥æ¥å£(CachePolicy trait)
3. ä¸åŒç¼“å­˜ç­–ç•¥çš„å®ç°(LRU, LFU, FIFOç­‰)
4. å…·ä½“ç¼“å­˜å®ç°
5. å¤šçº§ç¼“å­˜ç¤ºä¾‹
6. ä½¿ç”¨ç¤ºä¾‹
</think>
*/

// ç¼“å­˜æ¥å£
#[async_trait]
trait Cache<K, V>: Send + Sync {
    // å­˜å‚¨å€¼åˆ°ç¼“å­˜
    async fn put(&self, key: K, value: V, ttl: Option<Duration>) -> Result<(), String>;
    
    // ä»ç¼“å­˜è·å–å€¼
    async fn get(&self, key: &K) -> Result<Option<V>, String>;
    
    // æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨
    async fn contains(&self, key: &K) -> Result<bool, String>;
    
    // ä»ç¼“å­˜ç§»é™¤å€¼
    async fn remove(&self, key: &K) -> Result<Option<V>, String>;
    
    // æ¸…ç©ºç¼“å­˜
    async fn clear(&self) -> Result<(), String>;
    
    // è·å–æ‰€æœ‰é”®
    async fn keys(&self) -> Result<Vec<K>, String>;
    
    // è·å–ç¼“å­˜å¤§å°
    async fn size(&self) -> Result<usize, String>;
    
    // æ‰§è¡Œç¼“å­˜ç»´æŠ¤
    async fn maintenance(&self) -> Result<usize, String>;
    
    // è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
    async fn stats(&self) -> Result<CacheStats, String>;
}

// ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone)]
struct CacheStats {
    size: usize,
    capacity: usize,
    hits: u64,
    misses: u64,
    evictions: u64,
    expirations: u64,
}

impl CacheStats {
    fn new(capacity: usize) -> Self {
        Self {
            size: 0,
            capacity,
            hits: 0,
            misses: 0,
            evictions: 0,
            expirations: 0,
        }
    }
    
    fn hit_rate(&self) -> f64 {
        let total = self.hits + self.misses;
        if total == 0 {
            0.0
        } else {
            self.hits as f64 / total as f64
        }
    }
}

// ç¼“å­˜ç­–ç•¥æ¥å£
trait CachePolicy<K, V>: Send + Sync {
    // æ·»åŠ æ¡ç›®
    fn add(&mut self, key: &K, entry: &CacheEntry<V>);
    
    // è®¿é—®æ¡ç›®
    fn access(&mut self, key: &K, entry: &CacheEntry<V>);
    
    // é€‰æ‹©è¦æ·˜æ±°çš„é”®
    fn evict(&mut self) -> Option<K>;
    
    // ç§»é™¤é”®
    fn remove(&mut self, key: &K);
    
    // æ¸…ç©º
    fn clear(&mut self);
}

// LRUç¼“å­˜ç­–ç•¥
struct LRUPolicy<K> {
    access_order: LinkedList<K>,
    key_positions: HashMap<K, linked_list::Iter<K>>,
}

impl<K: Clone + Eq + Hash> CachePolicy<K, V> for LRUPolicy<K> {
    fn add(&mut self, key: &K, _entry: &CacheEntry<V>) {
        self.access_order.push_back(key.clone());
        // æ›´æ–°ä½ç½®
    }
    
    fn access(&mut self, key: &K, _entry: &CacheEntry<V>) {
        // ç§»åŠ¨åˆ°é“¾è¡¨æœ«å°¾
    }
    
    fn evict(&mut self) -> Option<K> {
        self.access_order.pop_front()
    }
    
    fn remove(&mut self, key: &K) {
        // ä»é“¾è¡¨ä¸­ç§»é™¤
    }
    
    fn clear(&mut self) {
        self.access_order.clear();
        self.key_positions.clear();
    }
}

// LFUç¼“å­˜ç­–ç•¥
struct LFUPolicy<K> {
    frequency_map: HashMap<u64, LinkedList<K>>,
    key_frequencies: HashMap<K, u64>,
    min_frequency: u64,
}

// FIFOç¼“å­˜ç­–ç•¥
struct FIFOPolicy<K> {
    insertion_order: LinkedList<K>,
}

// å†…å­˜ç¼“å­˜å®ç°
struct MemoryCache<K, V, P> {
    data: RwLock<HashMap<K, CacheEntry<V>>>,
    policy: Mutex<P>,
    capacity: usize,
    stats: RwLock<CacheStats>,
    last_maintenance: RwLock<Instant>,
    maintenance_interval: Duration,
}

impl<K, V, P> MemoryCache<K, V, P>
where
    K: Clone + Eq + Hash + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
    P: CachePolicy<K, V> + 'static,
{
    fn new(capacity: usize, policy: P) -> Self {
        Self {
            data: RwLock::new(HashMap::with_capacity(capacity)),
            policy: Mutex::new(policy),
            capacity,
            stats: RwLock::new(CacheStats::new(capacity)),
            last_maintenance: RwLock::new(Instant::now()),
            maintenance_interval: Duration::from_secs(60),
        }
    }
    
    // æ£€æŸ¥å¹¶æ‰§è¡Œç»´æŠ¤
    async fn check_maintenance(&self) {
        let now = Instant::now();
        let should_maintain = {
            let last = self.last_maintenance.read().await;
            now.duration_since(*last) >= self.maintenance_interval
        };
        
        if should_maintain {
            let _ = self.maintenance().await;
            let mut last = self.last_maintenance.write().await;
            *last = now;
        }
    }
    
    // æ·˜æ±°ä¸€ä¸ªæ¡ç›®
    async fn evict_one(&self) -> bool {
        let key_to_evict = {
            let mut policy = self.policy.lock().await;
            policy.evict()
        };
        
        if let Some(key) = key_to_evict {
            let mut data = self.data.write().await;
            if let Some(_) = data.remove(&key) {
                let mut stats = self.stats.write().await;
                stats.evictions += 1;
                stats.size = data.len();
                return true;
            }
        }
        
        false
    }
}

#[async_trait]
impl<K, V, P> Cache<K, V> for MemoryCache<K, V, P>
where
    K: Clone + Eq + Hash + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
    P: CachePolicy<K, V> + 'static,
{
    async fn put(&self, key: K, value: V, ttl: Option<Duration>) -> Result<(), String> {
        // æ£€æŸ¥æ˜¯å¦éœ€è¦ç»´æŠ¤
        self.check_maintenance().await;
        
        let entry = CacheEntry::new(value, ttl);
        
        // è·å–å†™é”
        let mut data = self.data.write().await;
        
        // å¦‚æœè¾¾åˆ°å®¹é‡ä¸Šé™ï¼Œå…ˆæ·˜æ±°
        if data.len() >= self.capacity && !data.contains_key(&key) {
            drop(data); // é‡Šæ”¾é”ï¼Œé¿å…æ­»é”
            self.evict_one().await;
            data = self.data.write().await; // é‡æ–°è·å–é”
        }
        
        // å¦‚æœæ˜¯æ›´æ–°ï¼Œå…ˆç§»é™¤æ—§æ¡ç›®
        let is_update = data.contains_key(&key);
        
        // æ·»åŠ æ–°æ¡ç›®
        data.insert(key.clone(), entry.clone());
        
        // æ›´æ–°ç­–ç•¥å’Œç»Ÿè®¡
        {
            let mut policy = self.policy.lock().await;
            if is_update {
                policy.remove(&key);
            }
            policy.add(&key, &entry);
            
            let mut stats = self.stats.write().await;
            stats.size = data.len();
        }
        
        Ok(())
    }
    
    async fn get(&self, key: &K) -> Result<Option<V>, String> {
        // æ£€æŸ¥æ˜¯å¦éœ€è¦ç»´æŠ¤
        self.check_maintenance().await;
        
        // è·å–è¯»é”
        let mut data = self.data.write().await; // ä½¿ç”¨å†™é”å› ä¸ºéœ€è¦æ›´æ–°è®¿é—®ç»Ÿè®¡
        
        if let Some(entry) = data.get_mut(key) {
            // æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if entry.is_expired() {
                // è¿‡æœŸäº†ï¼Œç§»é™¤å¹¶æ›´æ–°ç»Ÿè®¡
                let removed_entry = data.remove(key);
                
                let mut policy = self.policy.lock().await;
                policy.remove(key);
                
                let mut stats = self.stats.write().await;
                stats.expirations += 1;
                stats.misses += 1;
                stats.size = data.len();
                
                return Ok(None);
            }
            
            // æ›´æ–°è®¿é—®ç»Ÿè®¡
            let value = entry.access().clone();
            
            // æ›´æ–°ç­–ç•¥å’Œå‘½ä¸­ç»Ÿè®¡
            {
                let mut policy = self.policy.lock().await;
                policy.access(key, entry);
                
                let mut stats = self.stats.write().await;
                stats.hits += 1;
            }
            
            Ok(Some(value))
        } else {
            // æ›´æ–°æœªå‘½ä¸­ç»Ÿè®¡
            let mut stats = self.stats.write().await;
            stats.misses += 1;
            
            Ok(None)
        }
    }
    
    async fn contains(&self, key: &K) -> Result<bool, String> {
        let data = self.data.read().await;
        
        if let Some(entry) = data.get(key) {
            if entry.is_expired() {
                Ok(false)
            } else {
                Ok(true)
            }
        } else {
            Ok(false)
        }
    }
    
    async fn remove(&self, key: &K) -> Result<Option<V>, String> {
        let mut data = self.data.write().await;
        
        if let Some(entry) = data.remove(key) {
            // æ›´æ–°ç­–ç•¥å’Œç»Ÿè®¡
            let mut policy = self.policy.lock().await;
            policy.remove(key);
            
            let mut stats = self.stats.write().await;
            stats.size = data.len();
            
            if entry.is_expired() {
                stats.expirations += 1;
                Ok(None)
            } else {
                Ok(Some(entry.value))
            }
        } else {
            Ok(None)
        }
    }
    
    async fn clear(&self) -> Result<(), String> {
        let mut data = self.data.write().await;
        data.clear();
        
        let mut policy = self.policy.lock().await;
        policy.clear();
        
        let mut stats = self.stats.write().await;
        stats.size = 0;
        
        Ok(())
    }
    
    async fn keys(&self) -> Result<Vec<K>, String> {
        let data = self.data.read().await;
        
        let valid_keys = data.iter()
            .filter(|(_, entry)| !entry.is_expired())
            .map(|(key, _)| key.clone())
            .collect();
        
        Ok(valid_keys)
    }
    
    async fn size(&self) -> Result<usize, String> {
        let data = self.data.read().await;
        
        // åªè®¡ç®—æœªè¿‡æœŸçš„æ¡ç›®
        let valid_count = data.iter()
            .filter(|(_, entry)| !entry.is_expired())
            .count();
        
        Ok(valid_count)
    }
    
    async fn maintenance(&self) -> Result<usize, String> {
        let mut removed_count = 0;
        
        // ç§»é™¤è¿‡æœŸæ¡ç›®
        let expired_keys = {
            let data = self.data.read().await;
            data.iter()
                .filter(|(_, entry)| entry.is_expired())
                .map(|(key, _)| key.clone())
                .collect::<Vec<_>>()
        };
        
        // æ‰¹é‡ç§»é™¤è¿‡æœŸæ¡ç›®
        if !expired_keys.is_empty() {
            let mut data = self.data.write().await;
            let mut policy = self.policy.lock().await;
            
            for key in &expired_keys {
                if data.remove(key).is_some() {
                    removed_count += 1;
                    policy.remove(key);
                }
            }
            
            // æ›´æ–°ç»Ÿè®¡
            let mut stats = self.stats.write().await;
            stats.expirations += removed_count as u64;
            stats.size = data.len();
        }
        
        Ok(removed_count)
    }
    
    async fn stats(&self) -> Result<CacheStats, String> {
        let stats = self.stats.read().await;
        Ok(stats.clone())
    }
}

// å¤šçº§ç¼“å­˜
struct MultiLevelCache<K, V> {
    levels: Vec<(Arc<dyn Cache<K, V>>, String)>,
}

impl<K, V> MultiLevelCache<K, V>
where
    K: Clone + Eq + Hash + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    fn new() -> Self {
        Self {
            levels: Vec::new(),
        }
    }
    
    // æ·»åŠ ç¼“å­˜å±‚çº§
    fn add_level(&mut self, cache: Arc<dyn Cache<K, V>>, name: &str) {
        self.levels.push((cache, name.to_string()));
    }
    
    // ä»ç¼“å­˜è·å–å€¼
    async fn get(&self, key: &K) -> Result<Option<(V, String)>, String> {
        // ä»æœ€é«˜å±‚çº§å¼€å§‹æŸ¥æ‰¾
        for (level, (cache, name)) in self.levels.iter().enumerate() {
            match cache.get(key).await {
                Ok(Some(value)) => {
                    // å‘½ä¸­ç¼“å­˜ï¼Œå°†å€¼å¡«å……åˆ°æ›´é«˜å±‚çº§
                    for i in 0..level {
                        let (higher_cache, _) = &self.levels[i];
                        let _ = higher_cache.put(key.clone(), value.clone(), None).await;
                    }
                    
                    return Ok(Some((value, name.clone())));
                },
                Ok(None) => continue, // ç»§ç»­æ£€æŸ¥ä¸‹ä¸€çº§
                Err(e) => return Err(e),
            }
        }
        
        Ok(None)
    }
    
    // å­˜å‚¨å€¼åˆ°æ‰€æœ‰å±‚çº§
    async fn put(&self, key: K, value: V, ttl: Option<Duration>) -> Result<(), String> {
        for (cache, _) in &self.levels {
            cache.put(key.clone(), value.clone(), ttl).await?;
        }
        
        Ok(())
    }
    
    // ä»æ‰€æœ‰å±‚çº§ç§»é™¤å€¼
    async fn remove(&self, key: &K) -> Result<bool, String> {
        let mut removed = false;
        
        for (cache, _) in &self.levels {
            if cache.remove(key).await?.is_some() {
                removed = true;
            }
        }
        
        Ok(removed)
    }
    
    // è·å–æ‰€æœ‰å±‚çº§çš„ç»Ÿè®¡ä¿¡æ¯
    async fn stats(&self) -> Result<HashMap<String, CacheStats>, String> {
        let mut result = HashMap::new();
        
        for (cache, name) in &self.levels {
            result.insert(name.clone(), cache.stats().await?);
        }
        
        Ok(result)
    }
}

// åç«¯å­˜å‚¨æœåŠ¡ï¼ˆæ¨¡æ‹Ÿæ•°æ®åº“ï¼‰
struct DatabaseService {
    data: RwLock<HashMap<String, String>>,
    read_latency: Duration, // æ¨¡æ‹Ÿè¯»å–å»¶è¿Ÿ
}

impl DatabaseService {
    fn new(read_latency: Duration) -> Self {
        Self {
            data: RwLock::new(HashMap::new()),
            read_latency,
        }
    }
    
    async fn get(&self, key: &str) -> Option<String> {
        // æ¨¡æ‹Ÿè¯»å–å»¶è¿Ÿ
        sleep(self.read_latency).await;
        
        let data = self.data.read().await;
        data.get(key).cloned()
    }
    
    async fn put(&self, key: String, value: String) {
        let mut data = self.data.write().await;
        data.insert(key, value);
    }
    
    async fn load_sample_data(&self, count: usize) {
        let mut data = self.data.write().await;
        
        for i in 0..count {
            let key = format!("db_key{}", i);
            let value = format!("db_value{}", i);
            data.insert(key, value);
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
#[tokio::main]
async fn main() {
    println!("=== ç¼“å­˜æ¨¡å¼ç¤ºä¾‹ ===");
    
    // åˆ›å»ºç¼“å­˜
    let lru_policy = LRUPolicy::new();
    let l1_cache: Arc<dyn Cache<String, String>> = Arc::new(
        MemoryCache::new(100, lru_policy)
    );
    
    // åˆ›å»ºåç«¯æ•°æ®åº“æœåŠ¡
    let db = Arc::new(DatabaseService::new(Duration::from_millis(200)));
    db.load_sample_data(1000).await;
    
    // åˆ›å»ºå¤šçº§ç¼“å­˜
    let mut cache_system = MultiLevelCache::new();
    cache_system.add_level(l1_cache.clone(), "L1");
    
    // ç¼“å­˜æœåŠ¡
    let cache_service = CacheService::new(cache_system, db.clone());
    
    // åŸºå‡†æµ‹è¯•
    println!("\nå¼€å§‹ç¼“å­˜åŸºå‡†æµ‹è¯•...");
    
    // åˆ›å»ºä¸€ç»„é”®è¿›è¡Œæµ‹è¯•
    let mut test_keys = Vec::new();
    for i in 0..100 {
        test_keys.push(format!("db_key{}", i));
    }
    
    // ç¬¬ä¸€æ¬¡è®¿é—®ï¼ˆå†·ç¼“å­˜ï¼‰
    println!("\nå†·ç¼“å­˜æµ‹è¯•:");
    let start = Instant::now();
    
    for key in &test_keys {
        let result = cache_service.get(key).await;
        match &result {
            Some(value) => {/* println!("{} -> {}", key, value) */},
            None => println!("{} -> æœªæ‰¾åˆ°", key),
        }
    }
    
    let cold_duration = start.elapsed();
    println!("å†·ç¼“å­˜è®¿é—®è€—æ—¶: {:?}, å¹³å‡æ¯ä¸ªé”® {:?}",
             cold_duration,
             cold_duration / test_keys.len() as u32);
    
    // ç¬¬äºŒæ¬¡è®¿é—®ï¼ˆçƒ­ç¼“å­˜ï¼‰
    println!("\nçƒ­ç¼“å­˜æµ‹è¯•:");
    let start = Instant::now();
    
    for key in &test_keys {
        let result = cache_service.get(key).await;
        match &result {
            Some(_) => {},
            None => println!("{} -> æœªæ‰¾åˆ°", key),
        }
    }
    
    let hot_duration = start.elapsed();
    println!("çƒ­ç¼“å­˜è®¿é—®è€—æ—¶: {:?}, å¹³å‡æ¯ä¸ªé”® {:?}",
             hot_duration,
             hot_duration / test_keys.len() as u32);
    
    println!("\næ€§èƒ½æå‡: {:.2}x", cold_duration.as_secs_f64() / hot_duration.as_secs_f64());
    
    // æŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡
    println!("\nç¼“å­˜ç»Ÿè®¡:");
    let stats = cache_service.get_stats().await;
    
    for (name, stat) in stats {
        println!("{} ç¼“å­˜: å¤§å°={}/{}, å‘½ä¸­ç‡={:.1}%, å‘½ä¸­={}, æœªå‘½ä¸­={}, é©±é€={}",
                 name, stat.size, stat.capacity,
                 stat.hit_rate() * 100.0,
                 stat.hits, stat.misses,
                 stat.evictions);
    }
    
    // æµ‹è¯•ç¼“å­˜è¿‡æœŸ
    println!("\næµ‹è¯•ç¼“å­˜è¿‡æœŸ:");
    
    let expire_key = "expire_test";
    cache_service.put(expire_key.to_string(), "çŸ­æ—¶é—´å€¼".to_string(), Some(Duration::from_secs(2))).await;
    
    println!("åˆå§‹å€¼: {:?}", cache_service.get(expire_key).await);
    
    println!("ç­‰å¾…è¿‡æœŸ...");
    sleep(Duration::from_secs(3)).await;
    
    println!("è¿‡æœŸå: {:?}", cache_service.get(expire_key).await);
    
    // æµ‹è¯•ç¼“å­˜é©±é€
    println!("\næµ‹è¯•ç¼“å­˜é©±é€:");
    
    // å¡«å……ç¼“å­˜åˆ°å®¹é‡ä¸Šé™
    println!("å¡«å……ç¼“å­˜åˆ°å®¹é‡ä¸Šé™...");
    for i in 0..150 {
        let key = format!("eviction_key{}", i);
        let value = format!("value{}", i);
        cache_service.put(key, value, None).await;
    }
    
    // æŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡
    let stats = cache_service.get_stats().await;
    for (name, stat) in stats {
        println!("{} ç¼“å­˜: å¤§å°={}/{}, é©±é€={}",
                 name, stat.size, stat.capacity, stat.evictions);
    }
}

struct CacheService {
    cache: MultiLevelCache<String, String>,
    db: Arc<DatabaseService>,
}

impl CacheService {
    fn new(cache: MultiLevelCache<String, String>, db: Arc<DatabaseService>) -> Self {
        Self { cache, db }
    }
    
    async fn get(&self, key: &str) -> Option<String> {
        // å…ˆå°è¯•ä»ç¼“å­˜è·å–
        if let Ok(Some((value, level))) = self.cache.get(key).await {
            //println!("ç¼“å­˜å‘½ä¸­ ({}): {}", level, key);
            return Some(value);
        }
        
        // ç¼“å­˜æœªå‘½ä¸­ï¼Œä»æ•°æ®åº“è·å–
        //println!("ç¼“å­˜æœªå‘½ä¸­: {}", key);
        let db_result = self.db.get(key).await;
        
        // å¦‚æœæ•°æ®åº“æœ‰ç»“æœï¼Œå¡«å……ç¼“å­˜
        if let Some(value) = &db_result {
            let _ = self.cache.put(key.to_string(), value.clone(), None).await;
        }
        
        db_result
    }
    
    async fn put(&self, key: String, value: String, ttl: Option<Duration>) {
        // æ›´æ–°æ•°æ®åº“
        self.db.put(key.clone(), value.clone()).await;
        
        // æ›´æ–°ç¼“å­˜
        let _ = self.cache.put(key, value, ttl).await;
    }
    
    async fn get_stats(&self) -> HashMap<String, CacheStats> {
        self.cache.stats().await.unwrap_or_default()
    }
}

/*
<think>
æˆ‘éœ€è¦ç»§ç»­ç¼–å†™ä»£ç ï¼Œå±•ç¤ºç¼“å­˜æ¨¡å¼çš„å®ç°ã€‚
æˆ‘å°†å®Œæˆç¼ºå¤±çš„éƒ¨åˆ†ï¼ŒåŒ…æ‹¬æ•°æ®åº“æœåŠ¡ã€å¤šçº§ç¼“å­˜å®ç°ï¼Œä»¥åŠä¸€äº›ç¼“å­˜ç­–ç•¥çš„å…·ä½“å®ç°ã€‚

æˆ‘å°†ä»DatabaseServiceå¼€å§‹ï¼Œç„¶åå®ç°å¤šçº§ç¼“å­˜ç³»ç»Ÿï¼Œæœ€åå®Œæˆæ–‡ä»¶ä¸­çš„å…¶ä»–éƒ¨åˆ†ã€‚
</think>
*/

struct DatabaseService {
    data: RwLock<HashMap<String, String>>,
    delay: Duration, // æ¨¡æ‹Ÿæ•°æ®åº“è®¿é—®å»¶è¿Ÿ
}

impl DatabaseService {
    fn new(delay: Duration) -> Self {
        Self {
            data: RwLock::new(HashMap::new()),
            delay,
        }
    }
    
    // åŠ è½½ç¤ºä¾‹æ•°æ®
    async fn load_sample_data(&self, count: usize) {
        let mut data = self.data.write().await;
        for i in 0..count {
            let key = format!("db_key{}", i);
            let value = format!("æ•°æ®åº“å€¼{}", i);
            data.insert(key, value);
        }
    }
    
    // è·å–æ•°æ®
    async fn get(&self, key: &str) -> Option<String> {
        // æ¨¡æ‹Ÿæ•°æ®åº“è®¿é—®å»¶è¿Ÿ
        sleep(self.delay).await;
        
        let data = self.data.read().await;
        data.get(key).cloned()
    }
    
    // å­˜å‚¨æ•°æ®
    async fn put(&self, key: String, value: String) {
        // æ¨¡æ‹Ÿæ•°æ®åº“è®¿é—®å»¶è¿Ÿ
        sleep(self.delay).await;
        
        let mut data = self.data.write().await;
        data.insert(key, value);
    }
}

// å¤šçº§ç¼“å­˜
struct MultiLevelCache<K, V> {
    levels: Vec<(Arc<dyn Cache<K, V>>, String)>,
}

impl<K, V> MultiLevelCache<K, V>
where
    K: Clone + Eq + Hash + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    fn new() -> Self {
        Self {
            levels: Vec::new(),
        }
    }
    
    // æ·»åŠ ç¼“å­˜å±‚çº§
    fn add_level(&mut self, cache: Arc<dyn Cache<K, V>>, name: &str) {
        self.levels.push((cache, name.to_string()));
    }
    
    // ä»ç¼“å­˜è·å–å€¼ï¼Œè¿”å›å€¼å’Œå‘½ä¸­çš„ç¼“å­˜å±‚çº§
    async fn get(&self, key: &K) -> Result<Option<(V, String)>, String> {
        // ä»ç¬¬ä¸€çº§å¼€å§‹æŸ¥æ‰¾
        for (i, (cache, name)) in self.levels.iter().enumerate() {
            match cache.get(key).await {
                Ok(Some(value)) => {
                    // å‘½ä¸­å½“å‰å±‚çº§ç¼“å­˜
                    
                    // å¡«å……æ‰€æœ‰æ›´é«˜å±‚çº§çš„ç¼“å­˜
                    for j in 0..i {
                        let (higher_cache, _) = &self.levels[j];
                        let _ = higher_cache.put(key.clone(), value.clone(), None).await;
                    }
                    
                    return Ok(Some((value, name.clone())));
                },
                Ok(None) => {
                    // å½“å‰å±‚çº§æœªå‘½ä¸­ï¼Œç»§ç»­æŸ¥æ‰¾ä¸‹ä¸€å±‚
                    continue;
                },
                Err(e) => {
                    // ç¼“å­˜é”™è¯¯ï¼Œç»§ç»­æŸ¥æ‰¾ä¸‹ä¸€å±‚
                    println!("ç¼“å­˜ {} é”™è¯¯: {}", name, e);
                    continue;
                }
            }
        }
        
        // æ‰€æœ‰å±‚çº§éƒ½æœªå‘½ä¸­
        Ok(None)
    }
    
    // å­˜å‚¨å€¼åˆ°æ‰€æœ‰ç¼“å­˜å±‚çº§
    async fn put(&self, key: K, value: V, ttl: Option<Duration>) -> Result<(), String> {
        let mut errors = Vec::new();
        
        // å†™å…¥æ‰€æœ‰ç¼“å­˜å±‚çº§
        for (cache, name) in &self.levels {
            if let Err(e) = cache.put(key.clone(), value.clone(), ttl).await {
                errors.push(format!("ç¼“å­˜ {} å†™å…¥é”™è¯¯: {}", name, e));
            }
        }
        
        if errors.is_empty() {
            Ok(())
        } else {
            Err(errors.join("; "))
        }
    }
    
    // ä»æ‰€æœ‰ç¼“å­˜å±‚çº§ç§»é™¤å€¼
    async fn remove(&self, key: &K) -> Result<bool, String> {
        let mut removed = false;
        let mut errors = Vec::new();
        
        // ä»æ‰€æœ‰ç¼“å­˜å±‚çº§ç§»é™¤
        for (cache, name) in &self.levels {
            match cache.remove(key).await {
                Ok(Some(_)) => {
                    removed = true;
                },
                Err(e) => {
                    errors.push(format!("ç¼“å­˜ {} ç§»é™¤é”™è¯¯: {}", name, e));
                },
                _ => {}
            }
        }
        
        if errors.is_empty() {
            Ok(removed)
        } else {
            Err(errors.join("; "))
        }
    }
    
    // è·å–æ‰€æœ‰å±‚çº§çš„ç»Ÿè®¡ä¿¡æ¯
    async fn stats(&self) -> Result<HashMap<String, CacheStats>, String> {
        let mut all_stats = HashMap::new();
        
        for (cache, name) in &self.levels {
            match cache.stats().await {
                Ok(stats) => {
                    all_stats.insert(name.clone(), stats);
                },
                Err(e) => {
                    return Err(format!("è·å–ç¼“å­˜ {} ç»Ÿè®¡ä¿¡æ¯é”™è¯¯: {}", name, e));
                }
            }
        }
        
        Ok(all_stats)
    }
}

// LRUç­–ç•¥å®ç°
impl<K: Clone + Eq + Hash> LRUPolicy<K> {
    fn new() -> Self {
        Self {
            access_order: LinkedList::new(),
            key_positions: HashMap::new(),
        }
    }
}

// LFUç­–ç•¥å®ç°
impl<K: Clone + Eq + Hash> LFUPolicy<K> {
    fn new() -> Self {
        Self {
            frequency_map: HashMap::new(),
            key_frequencies: HashMap::new(),
            min_frequency: 0,
        }
    }
}

impl<K: Clone + Eq + Hash> CachePolicy<K, V> for LFUPolicy<K> {
    fn add(&mut self, key: &K, _entry: &CacheEntry<V>) {
        let freq = 1;
        self.key_frequencies.insert(key.clone(), freq);
        
        let freq_list = self.frequency_map.entry(freq).or_insert_with(LinkedList::new);
        freq_list.push_back(key.clone());
        
        self.min_frequency = 1;
    }
    
    fn access(&mut self, key: &K, _entry: &CacheEntry<V>) {
        if let Some(old_freq) = self.key_frequencies.get(key).cloned() {
            // ä»æ—§é¢‘ç‡åˆ—è¡¨ä¸­ç§»é™¤
            if let Some(freq_list) = self.frequency_map.get_mut(&old_freq) {
                freq_list.retain(|k| k != key);
                
                // å¦‚æœæœ€å°é¢‘ç‡çš„åˆ—è¡¨ä¸ºç©ºï¼Œæ›´æ–°æœ€å°é¢‘ç‡
                if old_freq == self.min_frequency && freq_list.is_empty() {
                    self.min_frequency += 1;
                }
            }
            
            // å¢åŠ é¢‘ç‡
            let new_freq = old_freq + 1;
            self.key_frequencies.insert(key.clone(), new_freq);
            
            // æ·»åŠ åˆ°æ–°é¢‘ç‡åˆ—è¡¨
            let freq_list = self.frequency_map.entry(new_freq)
            .or_insert_with(LinkedList::new);
            freq_list.push_back(key.clone());
        }
    }
    
    fn evict(&mut self) -> Option<K> {
        // ä»æœ€å°é¢‘ç‡çš„åˆ—è¡¨ä¸­å¼¹å‡ºç¬¬ä¸€ä¸ªå…ƒç´ 
        if let Some(freq_list) = self.frequency_map.get_mut(&self.min_frequency) {
            if let Some(key) = freq_list.pop_front() {
                self.key_frequencies.remove(&key);
                
                // å¦‚æœåˆ—è¡¨ä¸ºç©ºï¼ŒæŸ¥æ‰¾ä¸‹ä¸€ä¸ªæœ€å°é¢‘ç‡
                if freq_list.is_empty() {
                    let mut next_min = u64::MAX;
                    for freq in self.frequency_map.keys() {
                        if *freq > self.min_frequency && *freq < next_min && !self.frequency_map[freq].is_empty() {
                            next_min = *freq;
                        }
                    }
                    
                    if next_min != u64::MAX {
                        self.min_frequency = next_min;
                    }
                }
                
                return Some(key);
            }
        }
        
        None
    }
    
    fn remove(&mut self, key: &K) {
        if let Some(freq) = self.key_frequencies.remove(key) {
            if let Some(freq_list) = self.frequency_map.get_mut(&freq) {
                freq_list.retain(|k| k != key);
            }
        }
    }
    
    fn clear(&mut self) {
        self.frequency_map.clear();
        self.key_frequencies.clear();
        self.min_frequency = 0;
    }
}

// FIFOç­–ç•¥å®ç°
impl<K: Clone + Eq + Hash> FIFOPolicy<K> {
    fn new() -> Self {
        Self {
            insertion_order: LinkedList::new(),
        }
    }
}

impl<K: Clone + Eq + Hash> CachePolicy<K, V> for FIFOPolicy<K> {
    fn add(&mut self, key: &K, _entry: &CacheEntry<V>) {
        self.insertion_order.push_back(key.clone());
    }
    
    fn access(&mut self, _key: &K, _entry: &CacheEntry<V>) {
        // FIFOä¸ä¼šå› ä¸ºè®¿é—®è€Œæ”¹å˜é¡ºåº
    }
    
    fn evict(&mut self) -> Option<K> {
        self.insertion_order.pop_front()
    }
    
    fn remove(&mut self, key: &K) {
        self.insertion_order.retain(|k| k != key);
    }
    
    fn clear(&mut self) {
        self.insertion_order.clear();
    }
}

// æ·»åŠ ä¸€äº›ç¼“å­˜ç­–ç•¥ç»„åˆ
struct CompositePolicy<K> {
    primary: Box<dyn CachePolicy<K, V>>,
    secondary: Box<dyn CachePolicy<K, V>>,
}

impl<K: Clone + Eq + Hash> CompositePolicy<K> {
    fn new(primary: Box<dyn CachePolicy<K, V>>, secondary: Box<dyn CachePolicy<K, V>>) -> Self {
        Self {
            primary,
            secondary,
        }
    }
}

impl<K: Clone + Eq + Hash> CachePolicy<K, V> for CompositePolicy<K> {
    fn add(&mut self, key: &K, entry: &CacheEntry<V>) {
        self.primary.add(key, entry);
        self.secondary.add(key, entry);
    }
    
    fn access(&mut self, key: &K, entry: &CacheEntry<V>) {
        self.primary.access(key, entry);
        self.secondary.access(key, entry);
    }
    
    fn evict(&mut self) -> Option<K> {
        // å…ˆä½¿ç”¨ä¸»ç­–ç•¥ï¼Œå¦‚æœæ²¡æœ‰ç»“æœåˆ™ä½¿ç”¨æ¬¡ç­–ç•¥
        self.primary.evict().or_else(|| self.secondary.evict())
    }
    
    fn remove(&mut self, key: &K) {
        self.primary.remove(key);
        self.secondary.remove(key);
    }
    
    fn clear(&mut self) {
        self.primary.clear();
        self.secondary.clear();
    }
}
```

## 12 æ€»ç»“

åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†å„ç§Rustå¹¶å‘è®¾è®¡æ¨¡å¼ï¼Œè¿™äº›æ¨¡å¼æœ‰åŠ©äºæ„å»ºé«˜æ•ˆã€å¯é å’Œå¯æ‰©å±•çš„å¹¶å‘ç³»ç»Ÿã€‚
è¿™äº›æ¨¡å¼æŒ‰åŠŸèƒ½åˆ†ä¸ºä»¥ä¸‹å‡ ç±»ï¼š

1. **åŸºç¡€æ¨¡å¼**: æä¾›å¹¶å‘ç¼–ç¨‹çš„åŸºç¡€æ„å»ºå—ï¼Œå¦‚äº’æ–¥é”ã€è¯»å†™é”å’Œä¿¡å·é‡ã€‚
2. **ä»»åŠ¡åˆ†è§£æ¨¡å¼**: å°†å¤§ä»»åŠ¡åˆ†è§£ä¸ºå¯ä»¥å¹¶è¡Œæ‰§è¡Œçš„å°ä»»åŠ¡ã€‚
3. **æ•°æ®å…±äº«æ¨¡å¼**: å®‰å…¨åœ°åœ¨å¹¶å‘ç¯å¢ƒä¸­å…±äº«æ•°æ®ã€‚
4. **åŒæ­¥æ¨¡å¼**: åè°ƒå¹¶å‘ä»»åŠ¡çš„æ‰§è¡Œã€‚
5. **æ¶ˆæ¯ä¼ é€’æ¨¡å¼**: é€šè¿‡æ¶ˆæ¯åœ¨å¹¶å‘ç»„ä»¶ä¹‹é—´é€šä¿¡ã€‚
6. **å¼‚æ­¥æ¨¡å¼**: å¤„ç†å¼‚æ­¥æ“ä½œå’Œäº‹ä»¶é©±åŠ¨ç¼–ç¨‹ã€‚
7. **æœåŠ¡åè°ƒæ¨¡å¼**: åè°ƒå¤šä¸ªæœåŠ¡ä¹‹é—´çš„äº¤äº’ã€‚
8. **ç¨³å®šæ€§æ¨¡å¼**: æé«˜ç³»ç»Ÿåœ¨å¼‚å¸¸æƒ…å†µä¸‹çš„ç¨³å®šæ€§ã€‚
9. **åˆ†å¸ƒå¼åè°ƒæ¨¡å¼**: åè°ƒåˆ†å¸ƒå¼ç³»ç»Ÿä¸­çš„å¤šä¸ªèŠ‚ç‚¹ã€‚
10. **å¯æ‰©å±•æ€§æ¨¡å¼**: ä½¿ç³»ç»Ÿèƒ½å¤Ÿéšç€è´Ÿè½½å¢åŠ è€Œæ‰©å±•ã€‚

æ¯ä¸ªæ¨¡å¼éƒ½åŒ…å«è¯¦ç»†çš„ä»£ç å®ç°å’Œç¤ºä¾‹ï¼Œå¸®åŠ©ä½ ç†è§£å¦‚ä½•åœ¨å®é™…é¡¹ç›®ä¸­åº”ç”¨è¿™äº›æ¨¡å¼ã€‚
é€šè¿‡ç»„åˆè¿™äº›æ¨¡å¼ï¼Œä½ å¯ä»¥æ„å»ºå‡ºé«˜æ•ˆã€å¯é å’Œå¯æ‰©å±•çš„å¹¶å‘ç³»ç»Ÿã€‚

è¿™äº›è®¾è®¡æ¨¡å¼æ˜¯å¤„ç†å¹¶å‘å’Œå¼‚æ­¥ç¼–ç¨‹ä¸­å„ç§æŒ‘æˆ˜çš„æœ‰æ•ˆå·¥å…·ï¼Œå®ƒä»¬ä»£è¡¨äº†å¤šå¹´è½¯ä»¶å·¥ç¨‹å®è·µä¸­æç‚¼å‡ºçš„æœ€ä½³å®è·µã€‚
æ ¹æ®ä½ çš„å…·ä½“éœ€æ±‚ï¼Œé€‰æ‹©åˆé€‚çš„æ¨¡å¼å¯ä»¥æ˜¾è‘—æå‡ç³»ç»Ÿçš„æ€§èƒ½ã€å¯é æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚

```text
<think>
å·²ç»å®Œæˆäº†æ‰€æœ‰ä¸»è¦çš„è®¾è®¡æ¨¡å¼è®²è§£ï¼Œæ¥ä¸‹æ¥å¯ä»¥æ·»åŠ ä¸€äº›é¢å¤–çš„ä¿¡æ¯ï¼Œæ¯”å¦‚ï¼š

1. è®¾è®¡æ¨¡å¼çš„ç»„åˆä½¿ç”¨æ¡ˆä¾‹
2. æ€§èƒ½è€ƒé‡å’Œæœ€ä½³å®è·µ
3. è®¾è®¡æ¨¡å¼çš„é€‰æ‹©æŒ‡å—
4. å¸¸è§é™·é˜±å’Œè§£å†³æ–¹æ¡ˆ

è®©æˆ‘ç»§ç»­è¿™ä¸ªå†…å®¹ï¼Œæä¾›ä¸€äº›å®ç”¨çš„å»ºè®®å’Œæ›´é«˜çº§çš„ç”¨ä¾‹ã€‚
</think>
```

## 13 è¿›é˜¶æŠ€å·§ä¸æœ€ä½³å®è·µ

### 13.1 æ¨¡å¼ç»„åˆ

å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šç»„åˆå¤šç§è®¾è®¡æ¨¡å¼æ¥è§£å†³å¤æ‚é—®é¢˜ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§çš„ç»„åˆæ–¹å¼ï¼š

```rust
// ç»„åˆæ–­è·¯å™¨å’Œé‡è¯•æ¨¡å¼ç¤ºä¾‹
struct ResilientService<T> {
    service: T,
    circuit_breaker: Arc<CircuitBreaker>,
    retry_policy: RetryPolicy,
}

impl<T: Service> ResilientService<T> {
    async fn call(&self, request: Request) -> Result<Response, Error> {
        self.circuit_breaker.execute(|| async {
            retry_with_policy(&self.retry_policy, || async {
                self.service.call(request.clone()).await
            }).await
        }).await
    }
}

// ç»„åˆå·¥ä½œæ± å’ŒèƒŒå‹æ¨¡å¼
struct BackpressuredWorkerPool<T> {
    worker_pool: Arc<WorkerPool<T>>,
    limiter: Arc<RateLimiter>,
    queue: Arc<BoundedQueue<T>>,
}

impl<T: Send + 'static> BackpressuredWorkerPool<T> {
    async fn submit(&self, task: T) -> Result<(), PoolError> {
        // åº”ç”¨é€Ÿç‡é™åˆ¶
        self.limiter.acquire(1).await?;
        
        // å°è¯•å°†ä»»åŠ¡æ”¾å…¥é˜Ÿåˆ—
        self.queue.push(task).await.map_err(|_| PoolError::QueueFull)?;
        
        Ok(())
    }
}
```

### 13.2 æ€§èƒ½è€ƒé‡

åœ¨é€‰æ‹©å’Œå®ç°å¹¶å‘æ¨¡å¼æ—¶ï¼Œéœ€è€ƒè™‘ä»¥ä¸‹æ€§èƒ½å› ç´ ï¼š

1. **é”ç«äº‰**ï¼šé¢‘ç¹è®¿é—®çš„å…±äº«æ•°æ®ä¼šå¯¼è‡´é”ç«äº‰ï¼Œåº”è€ƒè™‘ä»¥ä¸‹ç­–ç•¥ï¼š
   - ä½¿ç”¨è¯»å†™é”ä»£æ›¿äº’æ–¥é”
   - ä½¿ç”¨ç»†ç²’åº¦é”è€Œéç²—ç²’åº¦é”
   - è€ƒè™‘æ— é”æ•°æ®ç»“æ„

2. **ä»»åŠ¡ç²’åº¦**ï¼šç¡®ä¿å¹¶è¡Œä»»åŠ¡çš„ç²’åº¦åˆé€‚ï¼š
   - ä»»åŠ¡å¤ªå°ä¼šå¯¼è‡´çº¿ç¨‹ç®¡ç†å¼€é”€è¶…è¿‡å¹¶è¡Œæ”¶ç›Š
   - ä»»åŠ¡å¤ªå¤§ä¼šå¯¼è‡´è´Ÿè½½ä¸å‡è¡¡

3. **å†…å­˜ä½¿ç”¨**ï¼š
   - é¿å…è¿‡å¤šçš„å…‹éš†æ“ä½œ
   - ä½¿ç”¨å¼•ç”¨è®¡æ•°ï¼ˆArcï¼‰è€Œéæ·±æ‹·è´
   - åˆç†ä½¿ç”¨ç”Ÿå‘½å‘¨æœŸæ³¨è§£å‡å°‘ä¸å¿…è¦çš„å†…å­˜å¤åˆ¶

4. **å¼‚æ­¥å¼€é”€**ï¼š
   - é¿å…åœ¨å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­æ‰§è¡ŒCPUå¯†é›†å‹ä»»åŠ¡
   - è­¦æƒ•è¿‡å¤šçš„`.await`ç‚¹å¯¼è‡´çš„ä»»åŠ¡åˆ‡æ¢å¼€é”€
   - ç›‘æ§å¼‚æ­¥è¿è¡Œæ—¶çš„ä»»åŠ¡å’Œçº¿ç¨‹æ•°é‡

### 13.3 å¸¸è§é™·é˜±ä¸è§£å†³æ–¹æ¡ˆ

1. **æ­»é”**

   ```rust
   // é”™è¯¯ç¤ºä¾‹ - å¯èƒ½å¯¼è‡´æ­»é”
   async fn transfer(
       from: &Mutex<Account>,
       to: &Mutex<Account>,
       amount: u64
   ) -> Result<(), Error> {
       let mut from_account = from.lock().await;
       // å¯èƒ½åœ¨è¿™é‡Œå‘ç”Ÿæ­»é”ï¼Œå¦‚æœå¦ä¸€ä¸ªçº¿ç¨‹ä»¥ç›¸åé¡ºåºè·å–é”
       let mut to_account = to.lock().await;
       
       from_account.withdraw(amount)?;
       to_account.deposit(amount);
       Ok(())
   }
   
   // ä¿®æ­£ - å§‹ç»ˆæŒ‰å›ºå®šé¡ºåºè·å–é”
   async fn transfer_safe(
       from: &Mutex<Account>,
       to: &Mutex<Account>,
       amount: u64
   ) -> Result<(), Error> {
       // ç¡®ä¿æ€»æ˜¯æŒ‰ç…§å†…å­˜åœ°å€é¡ºåºè·å–é”
       let (first, second) = if std::ptr::addr_of!(from) < std::ptr::addr_of!(to) {
           (from, to)
       } else {
           (to, from)
       };
       
       let mut first_account = first.lock().await;
       let mut second_account = second.lock().await;
       
       if std::ptr::eq(first, from) {
           first_account.withdraw(amount)?;
           second_account.deposit(amount);
       } else {
           second_account.withdraw(amount)?;
           first_account.deposit(amount);
       }
       
       Ok(())
   }
   ```

2. **å¹¶è¡Œä»»åŠ¡æ•°é‡è¿‡å¤š**

   ```rust
   // é”™è¯¯ç¤ºä¾‹ - å¯èƒ½åˆ›å»ºè¿‡å¤šä»»åŠ¡
   async fn process_items(items: Vec<Item>) -> Vec<Result<Output, Error>> {
       let mut futures = Vec::new();
       for item in items {
           futures.push(tokio::spawn(async move {
               process_item(item).await
           }));
       }
       
       // æ”¶é›†ç»“æœ
       let mut results = Vec::new();
       for future in futures {
           results.push(future.await??);
       }
       results
   }
   
   // ä¿®æ­£ - ä½¿ç”¨å¹¶å‘é™åˆ¶
   async fn process_items_limited(items: Vec<Item>) -> Vec<Result<Output, Error>> {
       // é™åˆ¶å¹¶å‘åº¦ä¸ºç³»ç»ŸCPUæ ¸å¿ƒæ•°
       let cpu_count = num_cpus::get();
       let semaphore = Arc::new(Semaphore::new(cpu_count));
       
       let mut futures = Vec::new();
       for item in items {
           let permit = semaphore.clone().acquire_owned().await.unwrap();
           futures.push(tokio::spawn(async move {
               let result = process_item(item).await;
               drop(permit); // é‡Šæ”¾ä¿¡å·é‡
               result
           }));
       }
       
       // æ”¶é›†ç»“æœ
       let mut results = Vec::new();
       for future in futures {
           results.push(future.await??);
       }
       results
   }
   ```

3. **å¿˜è®°å¤„ç†ä»»åŠ¡å–æ¶ˆ**

   ```rust
   // é”™è¯¯ç¤ºä¾‹ - æœªå¤„ç†ä»»åŠ¡å–æ¶ˆ
   async fn do_work() -> Result<(), Error> {
       let data = fetch_data().await?;
       process_data(data).await?;
       save_result().await?;
       Ok(())
   }
   
   // ä¿®æ­£ - æ­£ç¡®å¤„ç†ä»»åŠ¡å–æ¶ˆ
   async fn do_work_with_cleanup() -> Result<(), Error> {
       // ä½¿ç”¨Dropæ¥ç¡®ä¿åœ¨ä»»åŠ¡å–æ¶ˆæ—¶æ¸…ç†èµ„æº
       struct CleanupGuard {
           temp_data: Option<TempData>,
       }
       
       impl Drop for CleanupGuard {
           fn drop(&mut self) {
               if let Some(data) = self.temp_data.take() {
                   // å¯åŠ¨ä¸€ä¸ªé˜»å¡ä»»åŠ¡æ¥æ‰§è¡Œæ¸…ç†
                   tokio::task::spawn_blocking(move || {
                       data.cleanup();
                   });
               }
           }
       }
       
       let data = fetch_data().await?;
       
       let guard = CleanupGuard {
           temp_data: Some(TempData::new(&data)),
       };
       
       let result = process_data(data).await?;
       save_result(result).await?;
       
       // æ­£å¸¸å®Œæˆæ—¶æ‰‹åŠ¨æ¸…ç†
       if let Some(data) = guard.temp_data.take() {
           data.cleanup();
       }
       
       Ok(())
   }
   ```

### 13.4 è®¾è®¡æ¨¡å¼é€‰æ‹©æŒ‡å—

æ ¹æ®åº”ç”¨åœºæ™¯é€‰æ‹©åˆé€‚çš„å¹¶å‘æ¨¡å¼ï¼š

1. **é«˜ååé‡æ•°æ®å¤„ç†**
   - å·¥ä½œè€…æ± æ¨¡å¼
   - åˆ†ç‰‡æ¨¡å¼
   - æµæ°´çº¿æ¨¡å¼

2. **å®æ—¶å“åº”ç³»ç»Ÿ**
   - å¼‚æ­¥ä»»åŠ¡æ¨¡å¼
   - äº‹ä»¶é©±åŠ¨æ¨¡å¼
   - èƒŒå‹æ¨¡å¼

3. **é«˜å¯ç”¨æ€§ç³»ç»Ÿ**
   - æ–­è·¯å™¨æ¨¡å¼
   - è¶…æ—¶æ¨¡å¼
   - é‡è¯•æ¨¡å¼
   - éš”æ¿æ¨¡å¼

4. **åˆ†å¸ƒå¼ç³»ç»Ÿ**
   - é¢†å¯¼è€…é€‰ä¸¾æ¨¡å¼
   - åˆ†å¸ƒå¼é”æ¨¡å¼
   - å¤åˆ¶æ¨¡å¼
   - åˆ†ç‰‡æ¨¡å¼

5. **èµ„æºå—é™ç¯å¢ƒ**
   - å¯¹è±¡æ± æ¨¡å¼
   - èµ„æºé™åˆ¶æ¨¡å¼
   - ç¼“å­˜æ¨¡å¼

## 14 ç»“è¯­

Rustçš„ç±»å‹ç³»ç»Ÿå’Œæ‰€æœ‰æƒæ¨¡å‹ä½¿å…¶æˆä¸ºå®ç°å¹¶å‘è®¾è®¡æ¨¡å¼çš„ç†æƒ³è¯­è¨€ã€‚
è¿™äº›æ¨¡å¼ä¸ä»…å¯ä»¥å¸®åŠ©ä½ æ„å»ºé«˜æ•ˆã€å¯é çš„å¹¶å‘ç³»ç»Ÿï¼Œè¿˜å¯ä»¥é€šè¿‡ç¼–è¯‘æ—¶æ£€æŸ¥é˜²æ­¢è®¸å¤šå¸¸è§çš„å¹¶å‘é”™è¯¯ã€‚

å¸Œæœ›æœ¬æŒ‡å—èƒ½å¸®åŠ©ä½ åœ¨å®é™…é¡¹ç›®ä¸­åº”ç”¨è¿™äº›è®¾è®¡æ¨¡å¼ï¼Œæ„å»ºå‡ºæ›´åŠ å¥å£®ã€é«˜æ•ˆçš„å¹¶å‘ç³»ç»Ÿã€‚
éšç€Rustç”Ÿæ€ç³»ç»Ÿçš„ä¸æ–­å‘å±•ï¼Œè¿™äº›æ¨¡å¼ä¹Ÿå°†ç»§ç»­æ¼”åŒ–ï¼Œæˆ‘ä»¬å»ºè®®æŒç»­å…³æ³¨ç¤¾åŒºæœ€ä½³å®è·µçš„æ›´æ–°ã€‚

åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¯·è®°ä½æ²¡æœ‰å®Œç¾çš„è®¾è®¡æ¨¡å¼ï¼Œæ¯ç§æ¨¡å¼éƒ½æœ‰å…¶é€‚ç”¨åœºæ™¯å’Œå±€é™æ€§ã€‚
é€‰æ‹©åˆé€‚çš„æ¨¡å¼ç»„åˆï¼Œå¹¶æ ¹æ®ä½ çš„å…·ä½“éœ€æ±‚è¿›è¡Œè°ƒæ•´ï¼Œå°†å¸®åŠ©ä½ æ„å»ºå‡ºæœ€é€‚åˆä½ åº”ç”¨åœºæ™¯çš„å¹¶å‘ç³»ç»Ÿã€‚

ç¥ä½ çš„å¹¶å‘ç¼–ç¨‹ä¹‹æ—…æ„‰å¿«è€Œå¯Œæœ‰æˆæ•ˆï¼
